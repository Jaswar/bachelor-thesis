Looking for a split for p=0.4
Found split for p=0.4 [3700 videos]
Moving sampled images to a separate folder
Finished sampling
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00231]	Time 5.99 (5.99)	Loss 1.88 (1.88)
		cls_loss 0.56 (0.56)	reg_loss 0.66 (0.66)
Epoch: [000][00020/00231]	Time 0.78 (3.38)	Loss 1.42 (1.65)
		cls_loss 0.47 (0.52)	reg_loss 0.47 (0.57)
Epoch: [000][00030/00231]	Time 0.34 (2.37)	Loss 1.86 (1.72)
		cls_loss 0.57 (0.53)	reg_loss 0.64 (0.59)
Epoch: [000][00040/00231]	Time 0.41 (1.88)	Loss 1.77 (1.73)
		cls_loss 0.54 (0.54)	reg_loss 0.61 (0.60)
Epoch: [000][00050/00231]	Time 0.56 (1.62)	Loss 1.64 (1.71)
		cls_loss 0.71 (0.57)	reg_loss 0.46 (0.57)
Epoch: [000][00060/00231]	Time 0.37 (1.41)	Loss 0.81 (1.56)
		cls_loss 0.37 (0.54)	reg_loss 0.22 (0.51)
Epoch: [000][00070/00231]	Time 0.51 (1.28)	Loss 0.61 (1.43)
		cls_loss 0.35 (0.51)	reg_loss 0.13 (0.46)
Epoch: [000][00080/00231]	Time 0.28 (1.15)	Loss 1.19 (1.40)
		cls_loss 0.54 (0.52)	reg_loss 0.32 (0.44)
Epoch: [000][00090/00231]	Time 0.33 (1.06)	Loss 0.81 (1.33)
		cls_loss 0.43 (0.51)	reg_loss 0.19 (0.41)
Epoch: [000][00100/00231]	Time 0.32 (0.99)	Loss 1.25 (1.32)
		cls_loss 0.60 (0.51)	reg_loss 0.33 (0.40)
Epoch: [000][00110/00231]	Time 0.22 (0.92)	Loss 0.86 (1.28)
		cls_loss 0.45 (0.51)	reg_loss 0.21 (0.39)
Epoch: [000][00120/00231]	Time 0.26 (0.86)	Loss 0.79 (1.24)
		cls_loss 0.39 (0.50)	reg_loss 0.20 (0.37)
Epoch: [000][00130/00231]	Time 0.25 (0.82)	Loss 0.62 (1.19)
		cls_loss 0.31 (0.48)	reg_loss 0.16 (0.35)
Epoch: [000][00140/00231]	Time 0.28 (0.78)	Loss 0.70 (1.16)
		cls_loss 0.34 (0.47)	reg_loss 0.18 (0.34)
Epoch: [000][00150/00231]	Time 0.22 (0.74)	Loss 0.73 (1.13)
		cls_loss 0.36 (0.47)	reg_loss 0.18 (0.33)
Epoch: [000][00160/00231]	Time 0.19 (0.71)	Loss 0.89 (1.11)
		cls_loss 0.42 (0.46)	reg_loss 0.23 (0.33)
Epoch: [000][00170/00231]	Time 0.21 (0.68)	Loss 0.68 (1.09)
		cls_loss 0.32 (0.45)	reg_loss 0.18 (0.32)
Epoch: [000][00180/00231]	Time 0.21 (0.65)	Loss 1.08 (1.09)
		cls_loss 0.51 (0.46)	reg_loss 0.29 (0.32)
Epoch: [000][00190/00231]	Time 0.25 (0.63)	Loss 0.73 (1.07)
		cls_loss 0.32 (0.45)	reg_loss 0.20 (0.31)
Epoch: [000][00200/00231]	Time 0.21 (0.61)	Loss 1.23 (1.08)
		cls_loss 0.56 (0.46)	reg_loss 0.34 (0.31)
Epoch: [000][00210/00231]	Time 0.25 (0.59)	Loss 1.13 (1.08)
		cls_loss 0.51 (0.46)	reg_loss 0.31 (0.31)
Epoch: [000][00220/00231]	Time 0.20 (0.57)	Loss 0.58 (1.06)
		cls_loss 0.32 (0.45)	reg_loss 0.13 (0.30)
Epoch: [000][00230/00231]	Time 0.22 (0.56)	Loss 1.56 (1.08)
		cls_loss 0.66 (0.46)	reg_loss 0.45 (0.31)
[Train]: Epoch 0 finished with lr=0.00020017


[Train]: Epoch 1 started
Epoch: [001][00010/00231]	Time 0.24 (0.24)	Loss 0.90 (0.90)
		cls_loss 0.41 (0.41)	reg_loss 0.25 (0.25)
Epoch: [001][00020/00231]	Time 0.19 (0.22)	Loss 0.90 (0.90)
		cls_loss 0.41 (0.41)	reg_loss 0.25 (0.25)
Epoch: [001][00030/00231]	Time 0.20 (0.21)	Loss 1.20 (1.00)
		cls_loss 0.56 (0.46)	reg_loss 0.32 (0.27)
Epoch: [001][00040/00231]	Time 0.21 (0.21)	Loss 0.90 (0.97)
		cls_loss 0.46 (0.46)	reg_loss 0.22 (0.26)
Epoch: [001][00050/00231]	Time 0.22 (0.21)	Loss 1.07 (0.99)
		cls_loss 0.50 (0.47)	reg_loss 0.28 (0.26)
Epoch: [001][00060/00231]	Time 0.22 (0.22)	Loss 0.94 (0.98)
		cls_loss 0.41 (0.46)	reg_loss 0.27 (0.26)
Epoch: [001][00070/00231]	Time 0.22 (0.22)	Loss 0.99 (0.99)
		cls_loss 0.48 (0.46)	reg_loss 0.25 (0.26)
Epoch: [001][00080/00231]	Time 0.21 (0.22)	Loss 1.22 (1.01)
		cls_loss 0.60 (0.48)	reg_loss 0.31 (0.27)
Epoch: [001][00090/00231]	Time 0.22 (0.22)	Loss 1.34 (1.05)
		cls_loss 0.63 (0.50)	reg_loss 0.35 (0.28)
Epoch: [001][00100/00231]	Time 0.22 (0.22)	Loss 1.02 (1.05)
		cls_loss 0.50 (0.50)	reg_loss 0.26 (0.28)
Epoch: [001][00110/00231]	Time 0.22 (0.22)	Loss 1.73 (1.11)
		cls_loss 0.76 (0.52)	reg_loss 0.49 (0.29)
Epoch: [001][00120/00231]	Time 0.22 (0.22)	Loss 0.97 (1.10)
		cls_loss 0.45 (0.51)	reg_loss 0.26 (0.29)
Epoch: [001][00130/00231]	Time 0.22 (0.22)	Loss 0.64 (1.06)
		cls_loss 0.36 (0.50)	reg_loss 0.14 (0.28)
Epoch: [001][00140/00231]	Time 0.22 (0.22)	Loss 0.79 (1.04)
		cls_loss 0.39 (0.49)	reg_loss 0.20 (0.27)
Epoch: [001][00150/00231]	Time 0.22 (0.22)	Loss 0.89 (1.03)
		cls_loss 0.42 (0.49)	reg_loss 0.23 (0.27)
Epoch: [001][00160/00231]	Time 0.22 (0.22)	Loss 1.21 (1.04)
		cls_loss 0.54 (0.49)	reg_loss 0.34 (0.28)
Epoch: [001][00170/00231]	Time 0.22 (0.22)	Loss 1.06 (1.05)
		cls_loss 0.50 (0.49)	reg_loss 0.28 (0.28)
Epoch: [001][00180/00231]	Time 0.22 (0.22)	Loss 1.11 (1.05)
		cls_loss 0.53 (0.49)	reg_loss 0.29 (0.28)
Epoch: [001][00190/00231]	Time 0.22 (0.22)	Loss 1.58 (1.08)
		cls_loss 0.73 (0.51)	reg_loss 0.42 (0.29)
Epoch: [001][00200/00231]	Time 0.20 (0.22)	Loss 1.02 (1.07)
		cls_loss 0.45 (0.50)	reg_loss 0.29 (0.29)
Epoch: [001][00210/00231]	Time 0.22 (0.22)	Loss 1.17 (1.08)
		cls_loss 0.54 (0.51)	reg_loss 0.31 (0.29)
Epoch: [001][00220/00231]	Time 0.19 (0.21)	Loss 0.50 (1.05)
		cls_loss 0.25 (0.49)	reg_loss 0.12 (0.28)
Epoch: [001][00230/00231]	Time 0.32 (0.22)	Loss 1.00 (1.05)
		cls_loss 0.46 (0.49)	reg_loss 0.27 (0.28)
[Train]: Epoch 1 finished with lr=0.00040035


[Train]: Epoch 2 started
Epoch: [002][00010/00231]	Time 0.22 (0.22)	Loss 1.19 (1.19)
		cls_loss 0.55 (0.55)	reg_loss 0.32 (0.32)
Epoch: [002][00020/00231]	Time 0.27 (0.25)	Loss 0.71 (0.95)
		cls_loss 0.33 (0.44)	reg_loss 0.19 (0.26)
Epoch: [002][00030/00231]	Time 0.20 (0.23)	Loss 0.90 (0.93)
		cls_loss 0.44 (0.44)	reg_loss 0.23 (0.25)
Epoch: [002][00040/00231]	Time 0.19 (0.22)	Loss 0.83 (0.91)
		cls_loss 0.41 (0.43)	reg_loss 0.21 (0.24)
Epoch: [002][00050/00231]	Time 0.20 (0.22)	Loss 0.97 (0.92)
		cls_loss 0.45 (0.43)	reg_loss 0.26 (0.24)
Epoch: [002][00060/00231]	Time 0.19 (0.21)	Loss 1.57 (1.03)
		cls_loss 0.70 (0.48)	reg_loss 0.43 (0.27)
Epoch: [002][00070/00231]	Time 1.00 (0.32)	Loss 0.75 (0.99)
		cls_loss 0.35 (0.46)	reg_loss 0.20 (0.26)
Epoch: [002][00080/00231]	Time 0.19 (0.31)	Loss 0.74 (0.96)
		cls_loss 0.31 (0.44)	reg_loss 0.21 (0.26)
Epoch: [002][00090/00231]	Time 0.20 (0.29)	Loss 1.07 (0.97)
		cls_loss 0.47 (0.44)	reg_loss 0.30 (0.26)
Epoch: [002][00100/00231]	Time 0.20 (0.29)	Loss 0.92 (0.97)
		cls_loss 0.44 (0.44)	reg_loss 0.24 (0.26)
Epoch: [002][00110/00231]	Time 0.20 (0.28)	Loss 0.75 (0.95)
		cls_loss 0.36 (0.44)	reg_loss 0.19 (0.25)
Epoch: [002][00120/00231]	Time 0.21 (0.27)	Loss 0.72 (0.93)
		cls_loss 0.31 (0.43)	reg_loss 0.21 (0.25)
Epoch: [002][00130/00231]	Time 0.21 (0.27)	Loss 0.90 (0.92)
		cls_loss 0.43 (0.43)	reg_loss 0.23 (0.25)
Epoch: [002][00140/00231]	Time 0.20 (0.26)	Loss 0.74 (0.91)
		cls_loss 0.36 (0.42)	reg_loss 0.19 (0.24)
Epoch: [002][00150/00231]	Time 0.21 (0.26)	Loss 1.03 (0.92)
		cls_loss 0.41 (0.42)	reg_loss 0.31 (0.25)
Epoch: [002][00160/00231]	Time 0.22 (0.26)	Loss 0.81 (0.91)
		cls_loss 0.37 (0.42)	reg_loss 0.22 (0.25)
Epoch: [002][00170/00231]	Time 0.21 (0.25)	Loss 1.13 (0.92)
		cls_loss 0.48 (0.42)	reg_loss 0.33 (0.25)
Epoch: [002][00180/00231]	Time 0.21 (0.25)	Loss 1.04 (0.93)
		cls_loss 0.54 (0.43)	reg_loss 0.25 (0.25)
Epoch: [002][00190/00231]	Time 0.21 (0.25)	Loss 0.67 (0.92)
		cls_loss 0.33 (0.42)	reg_loss 0.17 (0.25)
Epoch: [002][00200/00231]	Time 0.21 (0.25)	Loss 0.68 (0.91)
		cls_loss 0.35 (0.42)	reg_loss 0.17 (0.24)
Epoch: [002][00210/00231]	Time 0.22 (0.25)	Loss 1.53 (0.94)
		cls_loss 0.71 (0.43)	reg_loss 0.41 (0.25)
Epoch: [002][00220/00231]	Time 0.21 (0.24)	Loss 0.59 (0.92)
		cls_loss 0.31 (0.43)	reg_loss 0.14 (0.25)
Epoch: [002][00230/00231]	Time 0.18 (0.24)	Loss 0.63 (0.91)
		cls_loss 0.28 (0.42)	reg_loss 0.17 (0.24)
[Train]: Epoch 2 finished with lr=0.00060052


[Train]: Epoch 3 started
Epoch: [003][00010/00231]	Time 0.25 (0.25)	Loss 0.80 (0.80)
		cls_loss 0.40 (0.40)	reg_loss 0.20 (0.20)
Epoch: [003][00020/00231]	Time 0.21 (0.23)	Loss 0.91 (0.85)
		cls_loss 0.41 (0.41)	reg_loss 0.25 (0.22)
Epoch: [003][00030/00231]	Time 0.21 (0.22)	Loss 0.70 (0.80)
		cls_loss 0.37 (0.39)	reg_loss 0.16 (0.20)
Epoch: [003][00040/00231]	Time 0.25 (0.23)	Loss 0.84 (0.81)
		cls_loss 0.41 (0.40)	reg_loss 0.21 (0.21)
Epoch: [003][00050/00231]	Time 1.67 (0.52)	Loss 0.78 (0.81)
		cls_loss 0.34 (0.39)	reg_loss 0.22 (0.21)
Epoch: [003][00060/00231]	Time 0.39 (0.50)	Loss 0.56 (0.76)
		cls_loss 0.29 (0.37)	reg_loss 0.14 (0.20)
Epoch: [003][00070/00231]	Time 0.20 (0.45)	Loss 0.85 (0.78)
		cls_loss 0.40 (0.37)	reg_loss 0.22 (0.20)
Epoch: [003][00080/00231]	Time 0.36 (0.44)	Loss 0.43 (0.73)
		cls_loss 0.24 (0.36)	reg_loss 0.10 (0.19)
Epoch: [003][00090/00231]	Time 0.19 (0.41)	Loss 0.90 (0.75)
		cls_loss 0.42 (0.36)	reg_loss 0.24 (0.19)
Epoch: [003][00100/00231]	Time 0.18 (0.39)	Loss 1.26 (0.80)
		cls_loss 0.63 (0.39)	reg_loss 0.32 (0.21)
Epoch: [003][00110/00231]	Time 0.21 (0.37)	Loss 0.82 (0.80)
		cls_loss 0.37 (0.39)	reg_loss 0.23 (0.21)
Epoch: [003][00120/00231]	Time 0.20 (0.36)	Loss 0.61 (0.79)
		cls_loss 0.30 (0.38)	reg_loss 0.16 (0.20)
Epoch: [003][00130/00231]	Time 0.19 (0.35)	Loss 0.43 (0.76)
		cls_loss 0.19 (0.37)	reg_loss 0.12 (0.20)
Epoch: [003][00140/00231]	Time 0.25 (0.34)	Loss 0.61 (0.75)
		cls_loss 0.28 (0.36)	reg_loss 0.16 (0.19)
Epoch: [003][00150/00231]	Time 0.20 (0.33)	Loss 0.79 (0.75)
		cls_loss 0.41 (0.36)	reg_loss 0.19 (0.19)
Epoch: [003][00160/00231]	Time 0.21 (0.32)	Loss 0.49 (0.74)
		cls_loss 0.26 (0.36)	reg_loss 0.12 (0.19)
Epoch: [003][00170/00231]	Time 0.22 (0.32)	Loss 0.52 (0.72)
		cls_loss 0.27 (0.35)	reg_loss 0.12 (0.19)
Epoch: [003][00180/00231]	Time 0.22 (0.31)	Loss 0.80 (0.73)
		cls_loss 0.39 (0.35)	reg_loss 0.20 (0.19)
Epoch: [003][00190/00231]	Time 0.21 (0.31)	Loss 1.30 (0.76)
		cls_loss 0.59 (0.37)	reg_loss 0.35 (0.20)
Epoch: [003][00200/00231]	Time 0.22 (0.30)	Loss 1.41 (0.79)
		cls_loss 0.73 (0.38)	reg_loss 0.34 (0.20)
Epoch: [003][00210/00231]	Time 0.21 (0.30)	Loss 1.32 (0.81)
		cls_loss 0.58 (0.39)	reg_loss 0.37 (0.21)
Epoch: [003][00220/00231]	Time 0.21 (0.29)	Loss 1.04 (0.82)
		cls_loss 0.50 (0.40)	reg_loss 0.27 (0.21)
Epoch: [003][00230/00231]	Time 0.18 (0.29)	Loss 0.60 (0.82)
		cls_loss 0.31 (0.39)	reg_loss 0.14 (0.21)
[Train]: Epoch 3 finished with lr=0.00080069


[Train]: Epoch 4 started
Epoch: [004][00010/00231]	Time 0.25 (0.25)	Loss 0.78 (0.78)
		cls_loss 0.37 (0.37)	reg_loss 0.21 (0.21)
Epoch: [004][00020/00231]	Time 0.20 (0.22)	Loss 0.74 (0.76)
		cls_loss 0.39 (0.38)	reg_loss 0.18 (0.19)
Epoch: [004][00030/00231]	Time 0.21 (0.22)	Loss 0.89 (0.80)
		cls_loss 0.42 (0.39)	reg_loss 0.23 (0.21)
Epoch: [004][00040/00231]	Time 0.21 (0.22)	Loss 0.69 (0.77)
		cls_loss 0.35 (0.38)	reg_loss 0.17 (0.20)
Epoch: [004][00050/00231]	Time 0.22 (0.22)	Loss 0.87 (0.79)
		cls_loss 0.41 (0.39)	reg_loss 0.23 (0.20)
Epoch: [004][00060/00231]	Time 0.22 (0.22)	Loss 0.62 (0.76)
		cls_loss 0.32 (0.38)	reg_loss 0.15 (0.19)
Epoch: [004][00070/00231]	Time 0.22 (0.22)	Loss 1.11 (0.81)
		cls_loss 0.50 (0.39)	reg_loss 0.31 (0.21)
Epoch: [004][00080/00231]	Time 0.22 (0.22)	Loss 1.06 (0.84)
		cls_loss 0.47 (0.40)	reg_loss 0.29 (0.22)
Epoch: [004][00090/00231]	Time 0.22 (0.22)	Loss 0.60 (0.82)
		cls_loss 0.27 (0.39)	reg_loss 0.16 (0.21)
Epoch: [004][00100/00231]	Time 0.22 (0.22)	Loss 0.61 (0.80)
		cls_loss 0.30 (0.38)	reg_loss 0.16 (0.21)
Epoch: [004][00110/00231]	Time 0.22 (0.22)	Loss 0.82 (0.80)
		cls_loss 0.38 (0.38)	reg_loss 0.22 (0.21)
Epoch: [004][00120/00231]	Time 0.22 (0.22)	Loss 0.67 (0.79)
		cls_loss 0.29 (0.37)	reg_loss 0.19 (0.21)
Epoch: [004][00130/00231]	Time 0.22 (0.22)	Loss 1.48 (0.84)
		cls_loss 0.68 (0.40)	reg_loss 0.40 (0.22)
Epoch: [004][00140/00231]	Time 0.22 (0.22)	Loss 0.83 (0.84)
		cls_loss 0.38 (0.40)	reg_loss 0.23 (0.22)
Epoch: [004][00150/00231]	Time 0.22 (0.22)	Loss 0.84 (0.84)
		cls_loss 0.37 (0.39)	reg_loss 0.24 (0.22)
Epoch: [004][00160/00231]	Time 0.22 (0.22)	Loss 0.76 (0.83)
		cls_loss 0.38 (0.39)	reg_loss 0.19 (0.22)
Epoch: [004][00170/00231]	Time 0.22 (0.22)	Loss 0.76 (0.83)
		cls_loss 0.39 (0.39)	reg_loss 0.19 (0.22)
Epoch: [004][00180/00231]	Time 0.22 (0.22)	Loss 0.66 (0.82)
		cls_loss 0.33 (0.39)	reg_loss 0.17 (0.22)
Epoch: [004][00190/00231]	Time 0.22 (0.22)	Loss 1.09 (0.84)
		cls_loss 0.50 (0.39)	reg_loss 0.30 (0.22)
Epoch: [004][00200/00231]	Time 0.22 (0.22)	Loss 0.61 (0.82)
		cls_loss 0.31 (0.39)	reg_loss 0.15 (0.22)
Epoch: [004][00210/00231]	Time 0.22 (0.22)	Loss 0.66 (0.82)
		cls_loss 0.32 (0.39)	reg_loss 0.17 (0.21)
Epoch: [004][00220/00231]	Time 0.22 (0.22)	Loss 0.89 (0.82)
		cls_loss 0.41 (0.39)	reg_loss 0.24 (0.22)
Epoch: [004][00230/00231]	Time 0.18 (0.22)	Loss 1.01 (0.83)
		cls_loss 0.42 (0.39)	reg_loss 0.29 (0.22)
[Train]: Epoch 4 finished with lr=0.00100000


[Train]: Epoch 5 started
Epoch: [005][00010/00231]	Time 0.81 (0.81)	Loss 1.14 (1.14)
		cls_loss 0.54 (0.54)	reg_loss 0.30 (0.30)
Epoch: [005][00020/00231]	Time 0.22 (0.51)	Loss 1.25 (1.19)
		cls_loss 0.58 (0.56)	reg_loss 0.33 (0.32)
Epoch: [005][00030/00231]	Time 0.22 (0.42)	Loss 0.91 (1.10)
		cls_loss 0.43 (0.52)	reg_loss 0.24 (0.29)
Epoch: [005][00040/00231]	Time 0.22 (0.37)	Loss 1.15 (1.11)
		cls_loss 0.52 (0.52)	reg_loss 0.31 (0.30)
Epoch: [005][00050/00231]	Time 0.22 (0.34)	Loss 0.76 (1.04)
		cls_loss 0.35 (0.49)	reg_loss 0.20 (0.28)
Epoch: [005][00060/00231]	Time 0.22 (0.32)	Loss 1.00 (1.03)
		cls_loss 0.49 (0.49)	reg_loss 0.25 (0.27)
Epoch: [005][00070/00231]	Time 0.22 (0.30)	Loss 0.64 (0.98)
		cls_loss 0.28 (0.46)	reg_loss 0.18 (0.26)
Epoch: [005][00080/00231]	Time 0.21 (0.29)	Loss 0.78 (0.95)
		cls_loss 0.37 (0.45)	reg_loss 0.21 (0.25)
Epoch: [005][00090/00231]	Time 0.23 (0.28)	Loss 1.30 (0.99)
		cls_loss 0.61 (0.46)	reg_loss 0.34 (0.26)
Epoch: [005][00100/00231]	Time 0.22 (0.28)	Loss 0.80 (0.97)
		cls_loss 0.39 (0.46)	reg_loss 0.21 (0.26)
Epoch: [005][00110/00231]	Time 0.21 (0.27)	Loss 0.97 (0.97)
		cls_loss 0.44 (0.46)	reg_loss 0.26 (0.26)
Epoch: [005][00120/00231]	Time 0.22 (0.27)	Loss 1.30 (1.00)
		cls_loss 0.60 (0.47)	reg_loss 0.35 (0.27)
Epoch: [005][00130/00231]	Time 0.22 (0.26)	Loss 1.18 (1.01)
		cls_loss 0.54 (0.47)	reg_loss 0.32 (0.27)
Epoch: [005][00140/00231]	Time 0.22 (0.26)	Loss 1.31 (1.03)
		cls_loss 0.68 (0.49)	reg_loss 0.32 (0.27)
Epoch: [005][00150/00231]	Time 0.22 (0.26)	Loss 0.89 (1.02)
		cls_loss 0.41 (0.48)	reg_loss 0.24 (0.27)
Epoch: [005][00160/00231]	Time 0.22 (0.26)	Loss 0.80 (1.01)
		cls_loss 0.36 (0.48)	reg_loss 0.22 (0.27)
Epoch: [005][00170/00231]	Time 0.22 (0.25)	Loss 0.98 (1.01)
		cls_loss 0.42 (0.47)	reg_loss 0.28 (0.27)
Epoch: [005][00180/00231]	Time 0.22 (0.25)	Loss 1.17 (1.02)
		cls_loss 0.52 (0.47)	reg_loss 0.33 (0.27)
Epoch: [005][00190/00231]	Time 0.22 (0.25)	Loss 1.08 (1.02)
		cls_loss 0.50 (0.48)	reg_loss 0.29 (0.27)
Epoch: [005][00200/00231]	Time 0.22 (0.25)	Loss 0.88 (1.01)
		cls_loss 0.40 (0.47)	reg_loss 0.24 (0.27)
Epoch: [005][00210/00231]	Time 0.22 (0.25)	Loss 0.70 (1.00)
		cls_loss 0.33 (0.47)	reg_loss 0.19 (0.27)
Epoch: [005][00220/00231]	Time 0.22 (0.25)	Loss 1.39 (1.02)
		cls_loss 0.64 (0.47)	reg_loss 0.38 (0.27)
Epoch: [005][00230/00231]	Time 0.18 (0.24)	Loss 1.08 (1.02)
		cls_loss 0.54 (0.48)	reg_loss 0.27 (0.27)
[Train]: Epoch 5 finished with lr=0.00097553


[Train]: Epoch 6 started
Epoch: [006][00010/00231]	Time 0.26 (0.26)	Loss 1.13 (1.13)
		cls_loss 0.51 (0.51)	reg_loss 0.31 (0.31)
Epoch: [006][00020/00231]	Time 0.21 (0.23)	Loss 0.87 (1.00)
		cls_loss 0.39 (0.45)	reg_loss 0.24 (0.28)
Epoch: [006][00030/00231]	Time 0.22 (0.23)	Loss 0.82 (0.94)
		cls_loss 0.39 (0.43)	reg_loss 0.21 (0.25)
Epoch: [006][00040/00231]	Time 0.22 (0.23)	Loss 0.68 (0.88)
		cls_loss 0.29 (0.40)	reg_loss 0.20 (0.24)
Epoch: [006][00050/00231]	Time 0.22 (0.22)	Loss 1.33 (0.97)
		cls_loss 0.56 (0.43)	reg_loss 0.38 (0.27)
Epoch: [006][00060/00231]	Time 0.22 (0.22)	Loss 1.41 (1.04)
		cls_loss 0.70 (0.47)	reg_loss 0.35 (0.28)
Epoch: [006][00070/00231]	Time 0.22 (0.22)	Loss 0.93 (1.03)
		cls_loss 0.41 (0.47)	reg_loss 0.26 (0.28)
Epoch: [006][00080/00231]	Time 0.22 (0.22)	Loss 1.04 (1.03)
		cls_loss 0.52 (0.47)	reg_loss 0.26 (0.28)
Epoch: [006][00090/00231]	Time 0.22 (0.22)	Loss 0.57 (0.98)
		cls_loss 0.28 (0.45)	reg_loss 0.14 (0.26)
Epoch: [006][00100/00231]	Time 0.22 (0.22)	Loss 0.77 (0.96)
		cls_loss 0.34 (0.44)	reg_loss 0.22 (0.26)
Epoch: [006][00110/00231]	Time 0.22 (0.22)	Loss 1.01 (0.96)
		cls_loss 0.43 (0.44)	reg_loss 0.29 (0.26)
Epoch: [006][00120/00231]	Time 0.22 (0.22)	Loss 0.85 (0.95)
		cls_loss 0.40 (0.44)	reg_loss 0.22 (0.26)
Epoch: [006][00130/00231]	Time 0.22 (0.22)	Loss 0.75 (0.94)
		cls_loss 0.35 (0.43)	reg_loss 0.20 (0.25)
Epoch: [006][00140/00231]	Time 0.22 (0.22)	Loss 0.60 (0.91)
		cls_loss 0.30 (0.42)	reg_loss 0.15 (0.25)
Epoch: [006][00150/00231]	Time 0.22 (0.22)	Loss 0.74 (0.90)
		cls_loss 0.34 (0.41)	reg_loss 0.20 (0.24)
Epoch: [006][00160/00231]	Time 0.21 (0.22)	Loss 1.08 (0.91)
		cls_loss 0.51 (0.42)	reg_loss 0.29 (0.25)
Epoch: [006][00170/00231]	Time 1.56 (0.30)	Loss 0.85 (0.91)
		cls_loss 0.41 (0.42)	reg_loss 0.22 (0.24)
Epoch: [006][00180/00231]	Time 1.02 (0.34)	Loss 1.52 (0.94)
		cls_loss 0.63 (0.43)	reg_loss 0.45 (0.26)
Epoch: [006][00190/00231]	Time 0.21 (0.33)	Loss 0.80 (0.94)
		cls_loss 0.35 (0.43)	reg_loss 0.23 (0.25)
Epoch: [006][00200/00231]	Time 0.36 (0.33)	Loss 0.85 (0.93)
		cls_loss 0.42 (0.43)	reg_loss 0.21 (0.25)
Epoch: [006][00210/00231]	Time 0.55 (0.34)	Loss 0.54 (0.91)
		cls_loss 0.27 (0.42)	reg_loss 0.13 (0.25)
Epoch: [006][00220/00231]	Time 0.27 (0.34)	Loss 0.81 (0.91)
		cls_loss 0.39 (0.42)	reg_loss 0.21 (0.25)
Epoch: [006][00230/00231]	Time 0.17 (0.33)	Loss 0.72 (0.90)
		cls_loss 0.33 (0.41)	reg_loss 0.20 (0.24)
[Train]: Epoch 6 finished with lr=0.00090451


[Train]: Epoch 7 started
Epoch: [007][00010/00231]	Time 0.25 (0.25)	Loss 0.81 (0.81)
		cls_loss 0.35 (0.35)	reg_loss 0.23 (0.23)
Epoch: [007][00020/00231]	Time 0.21 (0.23)	Loss 0.65 (0.73)
		cls_loss 0.35 (0.35)	reg_loss 0.15 (0.19)
Epoch: [007][00030/00231]	Time 0.21 (0.22)	Loss 0.79 (0.75)
		cls_loss 0.43 (0.37)	reg_loss 0.18 (0.19)
Epoch: [007][00040/00231]	Time 0.21 (0.22)	Loss 1.09 (0.84)
		cls_loss 0.48 (0.40)	reg_loss 0.31 (0.22)
Epoch: [007][00050/00231]	Time 0.21 (0.22)	Loss 1.15 (0.90)
		cls_loss 0.54 (0.43)	reg_loss 0.30 (0.23)
Epoch: [007][00060/00231]	Time 0.22 (0.22)	Loss 0.98 (0.91)
		cls_loss 0.47 (0.44)	reg_loss 0.25 (0.24)
Epoch: [007][00070/00231]	Time 0.22 (0.22)	Loss 0.80 (0.90)
		cls_loss 0.35 (0.42)	reg_loss 0.23 (0.24)
Epoch: [007][00080/00231]	Time 0.22 (0.22)	Loss 0.77 (0.88)
		cls_loss 0.36 (0.42)	reg_loss 0.20 (0.23)
Epoch: [007][00090/00231]	Time 0.22 (0.22)	Loss 1.11 (0.91)
		cls_loss 0.57 (0.43)	reg_loss 0.27 (0.24)
Epoch: [007][00100/00231]	Time 0.22 (0.22)	Loss 0.67 (0.88)
		cls_loss 0.31 (0.42)	reg_loss 0.18 (0.23)
Epoch: [007][00110/00231]	Time 0.22 (0.22)	Loss 0.97 (0.89)
		cls_loss 0.49 (0.43)	reg_loss 0.24 (0.23)
Epoch: [007][00120/00231]	Time 0.20 (0.22)	Loss 0.90 (0.89)
		cls_loss 0.41 (0.43)	reg_loss 0.25 (0.23)
Epoch: [007][00130/00231]	Time 1.10 (0.28)	Loss 0.92 (0.89)
		cls_loss 0.48 (0.43)	reg_loss 0.22 (0.23)
Epoch: [007][00140/00231]	Time 0.19 (0.28)	Loss 0.71 (0.88)
		cls_loss 0.35 (0.42)	reg_loss 0.18 (0.23)
Epoch: [007][00150/00231]	Time 0.20 (0.27)	Loss 0.87 (0.88)
		cls_loss 0.42 (0.42)	reg_loss 0.23 (0.23)
Epoch: [007][00160/00231]	Time 0.21 (0.27)	Loss 0.81 (0.87)
		cls_loss 0.35 (0.42)	reg_loss 0.23 (0.23)
Epoch: [007][00170/00231]	Time 0.22 (0.27)	Loss 0.77 (0.87)
		cls_loss 0.37 (0.42)	reg_loss 0.20 (0.23)
Epoch: [007][00180/00231]	Time 0.22 (0.26)	Loss 0.83 (0.87)
		cls_loss 0.42 (0.42)	reg_loss 0.21 (0.23)
Epoch: [007][00190/00231]	Time 0.21 (0.26)	Loss 2.05 (0.93)
		cls_loss 1.12 (0.45)	reg_loss 0.47 (0.24)
Epoch: [007][00200/00231]	Time 0.21 (0.26)	Loss 0.57 (0.91)
		cls_loss 0.31 (0.45)	reg_loss 0.13 (0.23)
Epoch: [007][00210/00231]	Time 0.21 (0.26)	Loss 0.93 (0.91)
		cls_loss 0.43 (0.44)	reg_loss 0.25 (0.23)
Epoch: [007][00220/00231]	Time 0.20 (0.25)	Loss 0.90 (0.91)
		cls_loss 0.38 (0.44)	reg_loss 0.26 (0.23)
Epoch: [007][00230/00231]	Time 0.18 (0.25)	Loss 1.16 (0.92)
		cls_loss 0.51 (0.45)	reg_loss 0.32 (0.24)
[Train]: Epoch 7 finished with lr=0.00079389


[Train]: Epoch 8 started
Epoch: [008][00010/00231]	Time 0.33 (0.33)	Loss 1.11 (1.11)
		cls_loss 0.47 (0.47)	reg_loss 0.32 (0.32)
Epoch: [008][00020/00231]	Time 0.20 (0.26)	Loss 0.78 (0.94)
		cls_loss 0.38 (0.43)	reg_loss 0.20 (0.26)
Epoch: [008][00030/00231]	Time 0.22 (0.25)	Loss 1.08 (0.99)
		cls_loss 0.52 (0.46)	reg_loss 0.28 (0.27)
Epoch: [008][00040/00231]	Time 0.22 (0.24)	Loss 1.14 (1.02)
		cls_loss 0.54 (0.48)	reg_loss 0.30 (0.27)
Epoch: [008][00050/00231]	Time 0.22 (0.24)	Loss 0.68 (0.96)
		cls_loss 0.30 (0.44)	reg_loss 0.19 (0.26)
Epoch: [008][00060/00231]	Time 0.22 (0.23)	Loss 0.72 (0.92)
		cls_loss 0.36 (0.43)	reg_loss 0.18 (0.24)
Epoch: [008][00070/00231]	Time 0.22 (0.23)	Loss 1.08 (0.94)
		cls_loss 0.50 (0.44)	reg_loss 0.29 (0.25)
Epoch: [008][00080/00231]	Time 0.22 (0.23)	Loss 1.36 (0.99)
		cls_loss 0.61 (0.46)	reg_loss 0.38 (0.27)
Epoch: [008][00090/00231]	Time 0.22 (0.23)	Loss 0.55 (0.94)
		cls_loss 0.28 (0.44)	reg_loss 0.13 (0.25)
Epoch: [008][00100/00231]	Time 0.22 (0.23)	Loss 0.58 (0.91)
		cls_loss 0.30 (0.43)	reg_loss 0.14 (0.24)
Epoch: [008][00110/00231]	Time 0.22 (0.23)	Loss 0.94 (0.91)
		cls_loss 0.43 (0.43)	reg_loss 0.25 (0.24)
Epoch: [008][00120/00231]	Time 0.22 (0.23)	Loss 0.81 (0.90)
		cls_loss 0.41 (0.43)	reg_loss 0.20 (0.24)
Epoch: [008][00130/00231]	Time 0.19 (0.22)	Loss 0.71 (0.89)
		cls_loss 0.36 (0.42)	reg_loss 0.18 (0.23)
Epoch: [008][00140/00231]	Time 0.36 (0.23)	Loss 0.90 (0.89)
		cls_loss 0.44 (0.42)	reg_loss 0.23 (0.23)
Epoch: [008][00150/00231]	Time 0.18 (0.23)	Loss 0.76 (0.88)
		cls_loss 0.35 (0.42)	reg_loss 0.20 (0.23)
Epoch: [008][00160/00231]	Time 1.28 (0.30)	Loss 0.64 (0.86)
		cls_loss 0.33 (0.41)	reg_loss 0.16 (0.23)
Epoch: [008][00170/00231]	Time 2.49 (0.42)	Loss 0.73 (0.86)
		cls_loss 0.34 (0.41)	reg_loss 0.20 (0.22)
Epoch: [008][00180/00231]	Time 0.37 (0.42)	Loss 0.78 (0.85)
		cls_loss 0.39 (0.41)	reg_loss 0.19 (0.22)
Epoch: [008][00190/00231]	Time 0.19 (0.41)	Loss 0.50 (0.83)
		cls_loss 0.22 (0.40)	reg_loss 0.14 (0.22)
Epoch: [008][00200/00231]	Time 0.31 (0.40)	Loss 0.98 (0.84)
		cls_loss 0.47 (0.40)	reg_loss 0.26 (0.22)
Epoch: [008][00210/00231]	Time 0.20 (0.39)	Loss 0.63 (0.83)
		cls_loss 0.36 (0.40)	reg_loss 0.14 (0.22)
Epoch: [008][00220/00231]	Time 0.18 (0.39)	Loss 0.84 (0.83)
		cls_loss 0.39 (0.40)	reg_loss 0.22 (0.22)
Epoch: [008][00230/00231]	Time 0.18 (0.38)	Loss 0.42 (0.81)
		cls_loss 0.21 (0.39)	reg_loss 0.10 (0.21)
[Train]: Epoch 8 finished with lr=0.00065451


[Train]: Epoch 9 started
Epoch: [009][00010/00231]	Time 0.22 (0.22)	Loss 0.69 (0.69)
		cls_loss 0.34 (0.34)	reg_loss 0.17 (0.17)
Epoch: [009][00020/00231]	Time 0.19 (0.21)	Loss 0.71 (0.70)
		cls_loss 0.33 (0.33)	reg_loss 0.19 (0.18)
Epoch: [009][00030/00231]	Time 0.20 (0.20)	Loss 1.07 (0.82)
		cls_loss 0.55 (0.41)	reg_loss 0.26 (0.21)
Epoch: [009][00040/00231]	Time 0.20 (0.20)	Loss 0.85 (0.83)
		cls_loss 0.41 (0.41)	reg_loss 0.22 (0.21)
Epoch: [009][00050/00231]	Time 0.21 (0.20)	Loss 0.82 (0.83)
		cls_loss 0.39 (0.40)	reg_loss 0.22 (0.21)
Epoch: [009][00060/00231]	Time 0.20 (0.20)	Loss 0.73 (0.81)
		cls_loss 0.33 (0.39)	reg_loss 0.20 (0.21)
Epoch: [009][00070/00231]	Time 0.21 (0.20)	Loss 0.81 (0.81)
		cls_loss 0.40 (0.39)	reg_loss 0.20 (0.21)
Epoch: [009][00080/00231]	Time 0.20 (0.20)	Loss 0.46 (0.77)
		cls_loss 0.23 (0.37)	reg_loss 0.12 (0.20)
Epoch: [009][00090/00231]	Time 0.21 (0.21)	Loss 1.10 (0.80)
		cls_loss 0.48 (0.38)	reg_loss 0.31 (0.21)
Epoch: [009][00100/00231]	Time 1.39 (0.32)	Loss 0.77 (0.80)
		cls_loss 0.34 (0.38)	reg_loss 0.22 (0.21)
Epoch: [009][00110/00231]	Time 0.61 (0.35)	Loss 0.79 (0.80)
		cls_loss 0.40 (0.38)	reg_loss 0.20 (0.21)
Epoch: [009][00120/00231]	Time 0.18 (0.34)	Loss 0.90 (0.81)
		cls_loss 0.41 (0.38)	reg_loss 0.25 (0.21)
Epoch: [009][00130/00231]	Time 1.58 (0.43)	Loss 0.49 (0.78)
		cls_loss 0.27 (0.37)	reg_loss 0.11 (0.20)
Epoch: [009][00140/00231]	Time 0.22 (0.42)	Loss 0.94 (0.80)
		cls_loss 0.46 (0.38)	reg_loss 0.24 (0.21)
Epoch: [009][00150/00231]	Time 0.24 (0.40)	Loss 0.44 (0.77)
		cls_loss 0.22 (0.37)	reg_loss 0.11 (0.20)
Epoch: [009][00160/00231]	Time 0.20 (0.39)	Loss 0.67 (0.77)
		cls_loss 0.34 (0.37)	reg_loss 0.17 (0.20)
Epoch: [009][00170/00231]	Time 0.21 (0.38)	Loss 0.72 (0.76)
		cls_loss 0.34 (0.37)	reg_loss 0.19 (0.20)
Epoch: [009][00180/00231]	Time 0.22 (0.37)	Loss 0.73 (0.76)
		cls_loss 0.35 (0.36)	reg_loss 0.19 (0.20)
Epoch: [009][00190/00231]	Time 0.22 (0.36)	Loss 1.15 (0.78)
		cls_loss 0.51 (0.37)	reg_loss 0.32 (0.20)
Epoch: [009][00200/00231]	Time 0.22 (0.36)	Loss 1.58 (0.82)
		cls_loss 0.71 (0.39)	reg_loss 0.43 (0.22)
Epoch: [009][00210/00231]	Time 0.22 (0.35)	Loss 0.72 (0.82)
		cls_loss 0.34 (0.39)	reg_loss 0.19 (0.21)
Epoch: [009][00220/00231]	Time 0.22 (0.34)	Loss 0.72 (0.81)
		cls_loss 0.33 (0.38)	reg_loss 0.19 (0.21)
Epoch: [009][00230/00231]	Time 0.18 (0.34)	Loss 0.90 (0.82)
		cls_loss 0.42 (0.39)	reg_loss 0.24 (0.21)
[Train]: Epoch 9 finished with lr=0.00050001


[Train]: Epoch 10 started
Epoch: [010][00010/00231]	Time 0.24 (0.24)	Loss 0.34 (0.34)
		cls_loss 0.18 (0.18)	reg_loss 0.08 (0.08)
Epoch: [010][00020/00231]	Time 0.77 (0.51)	Loss 0.74 (0.54)
		cls_loss 0.30 (0.24)	reg_loss 0.22 (0.15)
Epoch: [010][00030/00231]	Time 0.21 (0.41)	Loss 0.62 (0.56)
		cls_loss 0.34 (0.27)	reg_loss 0.14 (0.15)
Epoch: [010][00040/00231]	Time 0.20 (0.36)	Loss 1.03 (0.68)
		cls_loss 0.50 (0.33)	reg_loss 0.26 (0.18)
Epoch: [010][00050/00231]	Time 0.20 (0.33)	Loss 0.59 (0.66)
		cls_loss 0.30 (0.32)	reg_loss 0.14 (0.17)
Epoch: [010][00060/00231]	Time 0.31 (0.32)	Loss 0.87 (0.70)
		cls_loss 0.40 (0.34)	reg_loss 0.24 (0.18)
Epoch: [010][00070/00231]	Time 0.21 (0.31)	Loss 0.53 (0.67)
		cls_loss 0.25 (0.32)	reg_loss 0.14 (0.17)
Epoch: [010][00080/00231]	Time 0.19 (0.29)	Loss 0.67 (0.67)
		cls_loss 0.31 (0.32)	reg_loss 0.18 (0.18)
Epoch: [010][00090/00231]	Time 0.18 (0.28)	Loss 0.78 (0.68)
		cls_loss 0.37 (0.33)	reg_loss 0.21 (0.18)
Epoch: [010][00100/00231]	Time 0.23 (0.27)	Loss 0.95 (0.71)
		cls_loss 0.42 (0.34)	reg_loss 0.27 (0.19)
Epoch: [010][00110/00231]	Time 0.20 (0.27)	Loss 0.93 (0.73)
		cls_loss 0.42 (0.34)	reg_loss 0.25 (0.19)
Epoch: [010][00120/00231]	Time 0.18 (0.26)	Loss 0.69 (0.73)
		cls_loss 0.31 (0.34)	reg_loss 0.19 (0.19)
Epoch: [010][00130/00231]	Time 0.61 (0.29)	Loss 0.52 (0.71)
		cls_loss 0.26 (0.33)	reg_loss 0.13 (0.19)
Epoch: [010][00140/00231]	Time 0.21 (0.28)	Loss 1.06 (0.74)
		cls_loss 0.52 (0.35)	reg_loss 0.27 (0.19)
Epoch: [010][00150/00231]	Time 0.20 (0.28)	Loss 0.83 (0.74)
		cls_loss 0.38 (0.35)	reg_loss 0.22 (0.20)
Epoch: [010][00160/00231]	Time 0.19 (0.27)	Loss 0.81 (0.75)
		cls_loss 0.31 (0.35)	reg_loss 0.25 (0.20)
Epoch: [010][00170/00231]	Time 0.21 (0.27)	Loss 0.97 (0.76)
		cls_loss 0.44 (0.35)	reg_loss 0.27 (0.20)
Epoch: [010][00180/00231]	Time 0.19 (0.26)	Loss 0.62 (0.75)
		cls_loss 0.31 (0.35)	reg_loss 0.15 (0.20)
Epoch: [010][00190/00231]	Time 0.20 (0.26)	Loss 1.16 (0.77)
		cls_loss 0.59 (0.36)	reg_loss 0.28 (0.20)
Epoch: [010][00200/00231]	Time 0.22 (0.26)	Loss 0.91 (0.78)
		cls_loss 0.44 (0.37)	reg_loss 0.24 (0.21)
Epoch: [010][00210/00231]	Time 0.22 (0.26)	Loss 0.73 (0.78)
		cls_loss 0.37 (0.37)	reg_loss 0.18 (0.21)
Epoch: [010][00220/00231]	Time 0.22 (0.25)	Loss 0.62 (0.77)
		cls_loss 0.31 (0.36)	reg_loss 0.15 (0.20)
Epoch: [010][00230/00231]	Time 0.18 (0.25)	Loss 0.89 (0.78)
		cls_loss 0.43 (0.37)	reg_loss 0.23 (0.20)
[Train]: Epoch 10 finished with lr=0.00034550


[Train]: Epoch 11 started
Epoch: [011][00010/00231]	Time 0.26 (0.26)	Loss 0.61 (0.61)
		cls_loss 0.31 (0.31)	reg_loss 0.15 (0.15)
Epoch: [011][00020/00231]	Time 0.22 (0.24)	Loss 0.80 (0.71)
		cls_loss 0.37 (0.34)	reg_loss 0.21 (0.18)
Epoch: [011][00030/00231]	Time 0.21 (0.23)	Loss 0.47 (0.63)
		cls_loss 0.26 (0.31)	reg_loss 0.10 (0.16)
Epoch: [011][00040/00231]	Time 0.21 (0.22)	Loss 1.07 (0.74)
		cls_loss 0.47 (0.35)	reg_loss 0.30 (0.19)
Epoch: [011][00050/00231]	Time 0.21 (0.22)	Loss 0.93 (0.78)
		cls_loss 0.42 (0.37)	reg_loss 0.25 (0.20)
Epoch: [011][00060/00231]	Time 0.21 (0.22)	Loss 0.73 (0.77)
		cls_loss 0.41 (0.37)	reg_loss 0.16 (0.20)
Epoch: [011][00070/00231]	Time 0.22 (0.22)	Loss 0.79 (0.77)
		cls_loss 0.36 (0.37)	reg_loss 0.22 (0.20)
Epoch: [011][00080/00231]	Time 0.22 (0.22)	Loss 0.70 (0.76)
		cls_loss 0.31 (0.36)	reg_loss 0.19 (0.20)
Epoch: [011][00090/00231]	Time 0.22 (0.22)	Loss 0.56 (0.74)
		cls_loss 0.29 (0.36)	reg_loss 0.14 (0.19)
Epoch: [011][00100/00231]	Time 0.22 (0.22)	Loss 0.65 (0.73)
		cls_loss 0.31 (0.35)	reg_loss 0.17 (0.19)
Epoch: [011][00110/00231]	Time 0.22 (0.22)	Loss 0.67 (0.72)
		cls_loss 0.35 (0.35)	reg_loss 0.16 (0.19)
Epoch: [011][00120/00231]	Time 0.22 (0.22)	Loss 0.58 (0.71)
		cls_loss 0.27 (0.34)	reg_loss 0.16 (0.18)
Epoch: [011][00130/00231]	Time 0.22 (0.22)	Loss 0.69 (0.71)
		cls_loss 0.36 (0.34)	reg_loss 0.16 (0.18)
Epoch: [011][00140/00231]	Time 0.22 (0.22)	Loss 0.76 (0.71)
		cls_loss 0.36 (0.35)	reg_loss 0.20 (0.18)
Epoch: [011][00150/00231]	Time 0.22 (0.22)	Loss 0.71 (0.71)
		cls_loss 0.33 (0.34)	reg_loss 0.19 (0.18)
Epoch: [011][00160/00231]	Time 0.22 (0.22)	Loss 0.70 (0.71)
		cls_loss 0.35 (0.35)	reg_loss 0.17 (0.18)
Epoch: [011][00170/00231]	Time 0.22 (0.22)	Loss 1.11 (0.74)
		cls_loss 0.50 (0.35)	reg_loss 0.31 (0.19)
Epoch: [011][00180/00231]	Time 0.22 (0.22)	Loss 0.87 (0.74)
		cls_loss 0.38 (0.36)	reg_loss 0.25 (0.19)
Epoch: [011][00190/00231]	Time 0.22 (0.22)	Loss 0.74 (0.74)
		cls_loss 0.36 (0.36)	reg_loss 0.19 (0.19)
Epoch: [011][00200/00231]	Time 0.22 (0.22)	Loss 0.99 (0.76)
		cls_loss 0.45 (0.36)	reg_loss 0.27 (0.20)
Epoch: [011][00210/00231]	Time 0.22 (0.22)	Loss 1.07 (0.77)
		cls_loss 0.50 (0.37)	reg_loss 0.28 (0.20)
Epoch: [011][00220/00231]	Time 0.22 (0.22)	Loss 1.01 (0.78)
		cls_loss 0.45 (0.37)	reg_loss 0.28 (0.21)
Epoch: [011][00230/00231]	Time 0.18 (0.22)	Loss 0.92 (0.79)
		cls_loss 0.49 (0.38)	reg_loss 0.21 (0.21)
[Train]: Epoch 11 finished with lr=0.00020612


[Train]: Epoch 12 started
Epoch: [012][00010/00231]	Time 0.24 (0.24)	Loss 0.50 (0.50)
		cls_loss 0.26 (0.26)	reg_loss 0.12 (0.12)
Epoch: [012][00020/00231]	Time 0.19 (0.21)	Loss 0.44 (0.47)
		cls_loss 0.25 (0.25)	reg_loss 0.10 (0.11)
Epoch: [012][00030/00231]	Time 0.22 (0.21)	Loss 0.56 (0.50)
		cls_loss 0.26 (0.26)	reg_loss 0.15 (0.12)
Epoch: [012][00040/00231]	Time 0.22 (0.21)	Loss 0.38 (0.47)
		cls_loss 0.20 (0.24)	reg_loss 0.09 (0.11)
Epoch: [012][00050/00231]	Time 0.22 (0.22)	Loss 1.26 (0.63)
		cls_loss 0.60 (0.32)	reg_loss 0.33 (0.16)
Epoch: [012][00060/00231]	Time 0.22 (0.22)	Loss 0.92 (0.68)
		cls_loss 0.43 (0.34)	reg_loss 0.25 (0.17)
Epoch: [012][00070/00231]	Time 0.20 (0.21)	Loss 0.49 (0.65)
		cls_loss 0.20 (0.32)	reg_loss 0.14 (0.17)
Epoch: [012][00080/00231]	Time 1.50 (0.38)	Loss 0.55 (0.64)
		cls_loss 0.24 (0.31)	reg_loss 0.15 (0.17)
Epoch: [012][00090/00231]	Time 0.25 (0.36)	Loss 0.60 (0.63)
		cls_loss 0.32 (0.31)	reg_loss 0.14 (0.16)
Epoch: [012][00100/00231]	Time 0.22 (0.35)	Loss 0.98 (0.67)
		cls_loss 0.42 (0.32)	reg_loss 0.28 (0.17)
Epoch: [012][00110/00231]	Time 0.22 (0.34)	Loss 0.48 (0.65)
		cls_loss 0.24 (0.31)	reg_loss 0.12 (0.17)
Epoch: [012][00120/00231]	Time 0.22 (0.33)	Loss 0.65 (0.65)
		cls_loss 0.32 (0.31)	reg_loss 0.17 (0.17)
Epoch: [012][00130/00231]	Time 0.20 (0.32)	Loss 0.75 (0.66)
		cls_loss 0.37 (0.32)	reg_loss 0.19 (0.17)
Epoch: [012][00140/00231]	Time 1.96 (0.43)	Loss 0.57 (0.65)
		cls_loss 0.25 (0.31)	reg_loss 0.16 (0.17)
Epoch: [012][00150/00231]	Time 0.49 (0.44)	Loss 0.76 (0.66)
		cls_loss 0.33 (0.31)	reg_loss 0.22 (0.17)
Epoch: [012][00160/00231]	Time 0.22 (0.42)	Loss 0.70 (0.66)
		cls_loss 0.34 (0.31)	reg_loss 0.18 (0.17)
Epoch: [012][00170/00231]	Time 0.22 (0.41)	Loss 0.63 (0.66)
		cls_loss 0.30 (0.31)	reg_loss 0.16 (0.17)
Epoch: [012][00180/00231]	Time 0.22 (0.40)	Loss 0.44 (0.65)
		cls_loss 0.21 (0.31)	reg_loss 0.11 (0.17)
Epoch: [012][00190/00231]	Time 0.22 (0.39)	Loss 1.22 (0.68)
		cls_loss 0.56 (0.32)	reg_loss 0.33 (0.18)
Epoch: [012][00200/00231]	Time 0.22 (0.38)	Loss 0.84 (0.69)
		cls_loss 0.42 (0.33)	reg_loss 0.21 (0.18)
Epoch: [012][00210/00231]	Time 0.22 (0.38)	Loss 0.49 (0.68)
		cls_loss 0.26 (0.32)	reg_loss 0.11 (0.18)
Epoch: [012][00220/00231]	Time 0.21 (0.37)	Loss 0.45 (0.67)
		cls_loss 0.22 (0.32)	reg_loss 0.11 (0.17)
Epoch: [012][00230/00231]	Time 0.19 (0.36)	Loss 1.06 (0.68)
		cls_loss 0.44 (0.32)	reg_loss 0.31 (0.18)
[Train]: Epoch 12 finished with lr=0.00009550


[Train]: Epoch 13 started
Epoch: [013][00010/00231]	Time 0.24 (0.24)	Loss 0.49 (0.49)
		cls_loss 0.26 (0.26)	reg_loss 0.11 (0.11)
Epoch: [013][00020/00231]	Time 0.18 (0.21)	Loss 1.16 (0.83)
		cls_loss 0.52 (0.39)	reg_loss 0.32 (0.22)
Epoch: [013][00030/00231]	Time 0.19 (0.20)	Loss 0.61 (0.76)
		cls_loss 0.32 (0.37)	reg_loss 0.15 (0.19)
Epoch: [013][00040/00231]	Time 0.20 (0.20)	Loss 0.92 (0.80)
		cls_loss 0.41 (0.38)	reg_loss 0.25 (0.21)
Epoch: [013][00050/00231]	Time 0.21 (0.21)	Loss 0.62 (0.76)
		cls_loss 0.33 (0.37)	reg_loss 0.15 (0.20)
Epoch: [013][00060/00231]	Time 0.22 (0.21)	Loss 0.82 (0.77)
		cls_loss 0.35 (0.37)	reg_loss 0.23 (0.20)
Epoch: [013][00070/00231]	Time 0.22 (0.21)	Loss 1.00 (0.80)
		cls_loss 0.48 (0.38)	reg_loss 0.26 (0.21)
Epoch: [013][00080/00231]	Time 0.22 (0.21)	Loss 0.79 (0.80)
		cls_loss 0.34 (0.38)	reg_loss 0.23 (0.21)
Epoch: [013][00090/00231]	Time 0.22 (0.21)	Loss 0.65 (0.79)
		cls_loss 0.30 (0.37)	reg_loss 0.18 (0.21)
Epoch: [013][00100/00231]	Time 0.22 (0.21)	Loss 1.08 (0.81)
		cls_loss 0.54 (0.39)	reg_loss 0.27 (0.21)
Epoch: [013][00110/00231]	Time 0.22 (0.21)	Loss 0.75 (0.81)
		cls_loss 0.37 (0.38)	reg_loss 0.19 (0.21)
Epoch: [013][00120/00231]	Time 0.22 (0.21)	Loss 0.65 (0.80)
		cls_loss 0.30 (0.38)	reg_loss 0.17 (0.21)
Epoch: [013][00130/00231]	Time 0.22 (0.21)	Loss 0.47 (0.77)
		cls_loss 0.27 (0.37)	reg_loss 0.10 (0.20)
Epoch: [013][00140/00231]	Time 0.22 (0.21)	Loss 0.60 (0.76)
		cls_loss 0.26 (0.36)	reg_loss 0.17 (0.20)
Epoch: [013][00150/00231]	Time 0.22 (0.22)	Loss 0.59 (0.75)
		cls_loss 0.30 (0.36)	reg_loss 0.14 (0.19)
Epoch: [013][00160/00231]	Time 0.22 (0.22)	Loss 0.75 (0.75)
		cls_loss 0.35 (0.36)	reg_loss 0.20 (0.20)
Epoch: [013][00170/00231]	Time 0.22 (0.22)	Loss 0.45 (0.73)
		cls_loss 0.22 (0.35)	reg_loss 0.11 (0.19)
Epoch: [013][00180/00231]	Time 0.22 (0.22)	Loss 0.57 (0.72)
		cls_loss 0.26 (0.34)	reg_loss 0.16 (0.19)
Epoch: [013][00190/00231]	Time 0.22 (0.22)	Loss 0.83 (0.73)
		cls_loss 0.40 (0.35)	reg_loss 0.21 (0.19)
Epoch: [013][00200/00231]	Time 0.22 (0.22)	Loss 0.54 (0.72)
		cls_loss 0.29 (0.34)	reg_loss 0.12 (0.19)
Epoch: [013][00210/00231]	Time 0.22 (0.22)	Loss 0.69 (0.72)
		cls_loss 0.30 (0.34)	reg_loss 0.19 (0.19)
Epoch: [013][00220/00231]	Time 0.22 (0.22)	Loss 0.55 (0.71)
		cls_loss 0.27 (0.34)	reg_loss 0.14 (0.18)
Epoch: [013][00230/00231]	Time 0.18 (0.21)	Loss 0.70 (0.71)
		cls_loss 0.33 (0.34)	reg_loss 0.19 (0.18)
[Train]: Epoch 13 finished with lr=0.00002448


[Train]: Epoch 14 started
Epoch: [014][00010/00231]	Time 0.29 (0.29)	Loss 0.75 (0.75)
		cls_loss 0.37 (0.37)	reg_loss 0.19 (0.19)
Epoch: [014][00020/00231]	Time 0.22 (0.25)	Loss 0.57 (0.66)
		cls_loss 0.28 (0.32)	reg_loss 0.15 (0.17)
Epoch: [014][00030/00231]	Time 0.22 (0.24)	Loss 0.61 (0.64)
		cls_loss 0.30 (0.31)	reg_loss 0.16 (0.16)
Epoch: [014][00040/00231]	Time 0.22 (0.24)	Loss 0.65 (0.64)
		cls_loss 0.28 (0.31)	reg_loss 0.18 (0.17)
Epoch: [014][00050/00231]	Time 0.22 (0.23)	Loss 0.45 (0.61)
		cls_loss 0.22 (0.29)	reg_loss 0.12 (0.16)
Epoch: [014][00060/00231]	Time 0.22 (0.23)	Loss 0.64 (0.61)
		cls_loss 0.30 (0.29)	reg_loss 0.17 (0.16)
Epoch: [014][00070/00231]	Time 0.22 (0.23)	Loss 0.45 (0.59)
		cls_loss 0.28 (0.29)	reg_loss 0.09 (0.15)
Epoch: [014][00080/00231]	Time 0.22 (0.23)	Loss 0.48 (0.57)
		cls_loss 0.23 (0.28)	reg_loss 0.12 (0.15)
Epoch: [014][00090/00231]	Time 0.22 (0.23)	Loss 0.95 (0.62)
		cls_loss 0.48 (0.30)	reg_loss 0.23 (0.16)
Epoch: [014][00100/00231]	Time 0.22 (0.23)	Loss 0.30 (0.58)
		cls_loss 0.19 (0.29)	reg_loss 0.06 (0.15)
Epoch: [014][00110/00231]	Time 0.22 (0.23)	Loss 0.60 (0.59)
		cls_loss 0.30 (0.29)	reg_loss 0.15 (0.15)
Epoch: [014][00120/00231]	Time 0.22 (0.23)	Loss 0.86 (0.61)
		cls_loss 0.42 (0.30)	reg_loss 0.22 (0.15)
Epoch: [014][00130/00231]	Time 0.22 (0.22)	Loss 0.95 (0.64)
		cls_loss 0.43 (0.31)	reg_loss 0.26 (0.16)
Epoch: [014][00140/00231]	Time 0.22 (0.22)	Loss 0.60 (0.63)
		cls_loss 0.29 (0.31)	reg_loss 0.16 (0.16)
Epoch: [014][00150/00231]	Time 0.22 (0.22)	Loss 0.69 (0.64)
		cls_loss 0.31 (0.31)	reg_loss 0.19 (0.16)
Epoch: [014][00160/00231]	Time 0.22 (0.22)	Loss 0.87 (0.65)
		cls_loss 0.42 (0.32)	reg_loss 0.22 (0.17)
Epoch: [014][00170/00231]	Time 0.22 (0.22)	Loss 0.85 (0.66)
		cls_loss 0.42 (0.32)	reg_loss 0.22 (0.17)
Epoch: [014][00180/00231]	Time 0.22 (0.22)	Loss 0.55 (0.66)
		cls_loss 0.27 (0.32)	reg_loss 0.14 (0.17)
Epoch: [014][00190/00231]	Time 0.22 (0.22)	Loss 0.88 (0.67)
		cls_loss 0.37 (0.32)	reg_loss 0.25 (0.17)
Epoch: [014][00200/00231]	Time 0.22 (0.22)	Loss 0.63 (0.67)
		cls_loss 0.30 (0.32)	reg_loss 0.16 (0.17)
Epoch: [014][00210/00231]	Time 0.22 (0.22)	Loss 0.61 (0.66)
		cls_loss 0.33 (0.32)	reg_loss 0.14 (0.17)
Epoch: [014][00220/00231]	Time 0.19 (0.22)	Loss 0.67 (0.66)
		cls_loss 0.34 (0.32)	reg_loss 0.17 (0.17)
Epoch: [014][00230/00231]	Time 1.27 (0.27)	Loss 1.01 (0.68)
		cls_loss 0.46 (0.33)	reg_loss 0.28 (0.17)
[Train]: Epoch 14 finished with lr=0.00000001

All done!
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
=> loading checkpoint './ckpt/anet_i3d_reproduce/epoch_015.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/04555]	Time 2.57 (2.57)
Test: [00020/04555]	Time 0.13 (1.35)
Test: [00030/04555]	Time 0.10 (0.93)
Test: [00040/04555]	Time 0.04 (0.71)
Test: [00050/04555]	Time 0.04 (0.57)
Test: [00060/04555]	Time 0.11 (0.50)
Test: [00070/04555]	Time 0.07 (0.44)
Test: [00080/04555]	Time 0.04 (0.39)
Test: [00090/04555]	Time 0.04 (0.35)
Test: [00100/04555]	Time 0.22 (0.33)
Test: [00110/04555]	Time 0.04 (0.31)
Test: [00120/04555]	Time 0.04 (0.29)
Test: [00130/04555]	Time 0.04 (0.27)
Test: [00140/04555]	Time 0.04 (0.25)
Test: [00150/04555]	Time 0.08 (0.24)
Test: [00160/04555]	Time 0.04 (0.23)
Test: [00170/04555]	Time 0.04 (0.22)
Test: [00180/04555]	Time 0.04 (0.21)
Test: [00190/04555]	Time 0.04 (0.20)
Test: [00200/04555]	Time 0.11 (0.19)
Test: [00210/04555]	Time 0.04 (0.19)
Test: [00220/04555]	Time 0.04 (0.18)
Test: [00230/04555]	Time 0.04 (0.17)
Test: [00240/04555]	Time 0.11 (0.17)
Test: [00250/04555]	Time 0.04 (0.16)
Test: [00260/04555]	Time 0.04 (0.16)
Test: [00270/04555]	Time 0.05 (0.16)
Test: [00280/04555]	Time 0.05 (0.15)
Test: [00290/04555]	Time 0.04 (0.15)
Test: [00300/04555]	Time 0.04 (0.14)
Test: [00310/04555]	Time 0.04 (0.14)
Test: [00320/04555]	Time 0.04 (0.14)
Test: [00330/04555]	Time 0.04 (0.13)
Test: [00340/04555]	Time 0.07 (0.13)
Test: [00350/04555]	Time 0.04 (0.13)
Test: [00360/04555]	Time 0.09 (0.13)
Test: [00370/04555]	Time 0.04 (0.13)
Test: [00380/04555]	Time 0.04 (0.12)
Test: [00390/04555]	Time 0.04 (0.12)
Test: [00400/04555]	Time 0.04 (0.12)
Test: [00410/04555]	Time 0.04 (0.12)
Test: [00420/04555]	Time 0.04 (0.12)
Test: [00430/04555]	Time 0.04 (0.11)
Test: [00440/04555]	Time 0.04 (0.11)
Test: [00450/04555]	Time 0.04 (0.11)
Test: [00460/04555]	Time 0.04 (0.11)
Test: [00470/04555]	Time 0.04 (0.11)
Test: [00480/04555]	Time 0.04 (0.11)
Test: [00490/04555]	Time 0.04 (0.10)
Test: [00500/04555]	Time 0.04 (0.10)
Test: [00510/04555]	Time 0.05 (0.10)
Test: [00520/04555]	Time 0.04 (0.10)
Test: [00530/04555]	Time 0.04 (0.10)
Test: [00540/04555]	Time 0.23 (0.10)
Test: [00550/04555]	Time 0.04 (0.10)
Test: [00560/04555]	Time 0.04 (0.10)
Test: [00570/04555]	Time 0.04 (0.10)
Test: [00580/04555]	Time 0.04 (0.10)
Test: [00590/04555]	Time 0.04 (0.10)
Test: [00600/04555]	Time 0.04 (0.10)
Test: [00610/04555]	Time 0.04 (0.10)
Test: [00620/04555]	Time 0.04 (0.09)
Test: [00630/04555]	Time 0.06 (0.09)
Test: [00640/04555]	Time 0.04 (0.09)
Test: [00650/04555]	Time 0.04 (0.09)
Test: [00660/04555]	Time 0.04 (0.09)
Test: [00670/04555]	Time 0.04 (0.09)
Test: [00680/04555]	Time 0.04 (0.09)
Test: [00690/04555]	Time 0.04 (0.09)
Test: [00700/04555]	Time 0.04 (0.09)
Test: [00710/04555]	Time 0.04 (0.09)
Test: [00720/04555]	Time 0.16 (0.09)
Test: [00730/04555]	Time 0.04 (0.09)
Test: [00740/04555]	Time 0.07 (0.09)
Test: [00750/04555]	Time 0.04 (0.09)
Test: [00760/04555]	Time 0.04 (0.09)
Test: [00770/04555]	Time 0.04 (0.09)
Test: [00780/04555]	Time 0.04 (0.09)
Test: [00790/04555]	Time 0.04 (0.08)
Test: [00800/04555]	Time 0.04 (0.08)
Test: [00810/04555]	Time 0.04 (0.08)
Test: [00820/04555]	Time 0.04 (0.08)
Test: [00830/04555]	Time 0.04 (0.08)
Test: [00840/04555]	Time 0.04 (0.08)
Test: [00850/04555]	Time 0.04 (0.08)
Test: [00860/04555]	Time 0.04 (0.08)
Test: [00870/04555]	Time 0.04 (0.08)
Test: [00880/04555]	Time 0.04 (0.08)
Test: [00890/04555]	Time 0.04 (0.08)
Test: [00900/04555]	Time 0.04 (0.08)
Test: [00910/04555]	Time 0.04 (0.08)
Test: [00920/04555]	Time 0.04 (0.08)
Test: [00930/04555]	Time 0.04 (0.08)
Test: [00940/04555]	Time 0.04 (0.08)
Test: [00950/04555]	Time 0.04 (0.08)
Test: [00960/04555]	Time 0.04 (0.08)
Test: [00970/04555]	Time 0.04 (0.08)
Test: [00980/04555]	Time 0.04 (0.08)
Test: [00990/04555]	Time 0.04 (0.08)
Test: [01000/04555]	Time 0.04 (0.08)
Test: [01010/04555]	Time 0.04 (0.07)
Test: [01020/04555]	Time 0.04 (0.07)
Test: [01030/04555]	Time 0.04 (0.07)
Test: [01040/04555]	Time 0.04 (0.07)
Test: [01050/04555]	Time 0.04 (0.07)
Test: [01060/04555]	Time 0.04 (0.07)
Test: [01070/04555]	Time 0.04 (0.07)
Test: [01080/04555]	Time 0.04 (0.07)
Test: [01090/04555]	Time 0.04 (0.07)
Test: [01100/04555]	Time 0.04 (0.07)
Test: [01110/04555]	Time 0.04 (0.07)
Test: [01120/04555]	Time 0.04 (0.07)
Test: [01130/04555]	Time 0.04 (0.07)
Test: [01140/04555]	Time 0.04 (0.07)
Test: [01150/04555]	Time 0.04 (0.07)
Test: [01160/04555]	Time 0.04 (0.07)
Test: [01170/04555]	Time 0.04 (0.07)
Test: [01180/04555]	Time 0.04 (0.07)
Test: [01190/04555]	Time 0.04 (0.07)
Test: [01200/04555]	Time 0.04 (0.07)
Test: [01210/04555]	Time 0.04 (0.07)
Test: [01220/04555]	Time 0.04 (0.07)
Test: [01230/04555]	Time 0.08 (0.07)
Test: [01240/04555]	Time 0.04 (0.07)
Test: [01250/04555]	Time 0.04 (0.07)
Test: [01260/04555]	Time 0.04 (0.07)
Test: [01270/04555]	Time 0.04 (0.07)
Test: [01280/04555]	Time 0.04 (0.07)
Test: [01290/04555]	Time 0.04 (0.07)
Test: [01300/04555]	Time 0.04 (0.07)
Test: [01310/04555]	Time 0.04 (0.07)
Test: [01320/04555]	Time 0.04 (0.07)
Test: [01330/04555]	Time 0.04 (0.07)
Test: [01340/04555]	Time 0.04 (0.07)
Test: [01350/04555]	Time 0.04 (0.07)
Test: [01360/04555]	Time 0.04 (0.07)
Test: [01370/04555]	Time 0.04 (0.07)
Test: [01380/04555]	Time 0.04 (0.07)
Test: [01390/04555]	Time 0.04 (0.06)
Test: [01400/04555]	Time 0.04 (0.06)
Test: [01410/04555]	Time 0.04 (0.06)
Test: [01420/04555]	Time 0.04 (0.06)
Test: [01430/04555]	Time 0.04 (0.06)
Test: [01440/04555]	Time 0.04 (0.06)
Test: [01450/04555]	Time 0.04 (0.06)
Test: [01460/04555]	Time 0.04 (0.06)
Test: [01470/04555]	Time 0.04 (0.06)
Test: [01480/04555]	Time 0.04 (0.06)
Test: [01490/04555]	Time 0.04 (0.06)
Test: [01500/04555]	Time 0.04 (0.06)
Test: [01510/04555]	Time 0.04 (0.06)
Test: [01520/04555]	Time 0.04 (0.06)
Test: [01530/04555]	Time 0.04 (0.06)
Test: [01540/04555]	Time 0.04 (0.06)
Test: [01550/04555]	Time 0.04 (0.06)
Test: [01560/04555]	Time 0.04 (0.06)
Test: [01570/04555]	Time 0.04 (0.06)
Test: [01580/04555]	Time 0.04 (0.06)
Test: [01590/04555]	Time 0.04 (0.06)
Test: [01600/04555]	Time 0.04 (0.06)
Test: [01610/04555]	Time 0.04 (0.06)
Test: [01620/04555]	Time 0.13 (0.06)
Test: [01630/04555]	Time 0.08 (0.06)
Test: [01640/04555]	Time 0.37 (0.06)
Test: [01650/04555]	Time 0.24 (0.06)
Test: [01660/04555]	Time 0.04 (0.06)
Test: [01670/04555]	Time 0.13 (0.06)
Test: [01680/04555]	Time 0.04 (0.06)
Test: [01690/04555]	Time 0.04 (0.06)
Test: [01700/04555]	Time 0.04 (0.06)
Test: [01710/04555]	Time 0.20 (0.07)
Test: [01720/04555]	Time 0.06 (0.07)
Test: [01730/04555]	Time 0.05 (0.07)
Test: [01740/04555]	Time 0.04 (0.06)
Test: [01750/04555]	Time 0.04 (0.06)
Test: [01760/04555]	Time 0.04 (0.06)
Test: [01770/04555]	Time 0.06 (0.06)
Test: [01780/04555]	Time 0.04 (0.06)
Test: [01790/04555]	Time 0.04 (0.06)
Test: [01800/04555]	Time 0.04 (0.06)
Test: [01810/04555]	Time 0.04 (0.06)
Test: [01820/04555]	Time 0.04 (0.06)
Test: [01830/04555]	Time 0.04 (0.06)
Test: [01840/04555]	Time 0.11 (0.06)
Test: [01850/04555]	Time 0.04 (0.06)
Test: [01860/04555]	Time 0.05 (0.06)
Test: [01870/04555]	Time 0.04 (0.06)
Test: [01880/04555]	Time 0.12 (0.06)
Test: [01890/04555]	Time 0.04 (0.06)
Test: [01900/04555]	Time 0.14 (0.06)
Test: [01910/04555]	Time 0.04 (0.06)
Test: [01920/04555]	Time 0.04 (0.06)
Test: [01930/04555]	Time 0.07 (0.06)
Test: [01940/04555]	Time 0.05 (0.06)
Test: [01950/04555]	Time 0.04 (0.06)
Test: [01960/04555]	Time 0.06 (0.06)
Test: [01970/04555]	Time 0.04 (0.06)
Test: [01980/04555]	Time 0.04 (0.06)
Test: [01990/04555]	Time 0.04 (0.06)
Test: [02000/04555]	Time 0.04 (0.06)
Test: [02010/04555]	Time 0.04 (0.06)
Test: [02020/04555]	Time 0.04 (0.06)
Test: [02030/04555]	Time 0.04 (0.06)
Test: [02040/04555]	Time 0.04 (0.06)
Test: [02050/04555]	Time 0.04 (0.06)
Test: [02060/04555]	Time 0.04 (0.06)
Test: [02070/04555]	Time 0.04 (0.06)
Test: [02080/04555]	Time 0.09 (0.06)
Test: [02090/04555]	Time 0.04 (0.06)
Test: [02100/04555]	Time 0.04 (0.06)
Test: [02110/04555]	Time 0.05 (0.06)
Test: [02120/04555]	Time 0.04 (0.06)
Test: [02130/04555]	Time 0.04 (0.06)
Test: [02140/04555]	Time 0.05 (0.06)
Test: [02150/04555]	Time 0.04 (0.06)
Test: [02160/04555]	Time 0.04 (0.06)
Test: [02170/04555]	Time 0.04 (0.06)
Test: [02180/04555]	Time 0.04 (0.06)
Test: [02190/04555]	Time 0.04 (0.06)
Test: [02200/04555]	Time 0.04 (0.06)
Test: [02210/04555]	Time 0.04 (0.06)
Test: [02220/04555]	Time 0.04 (0.06)
Test: [02230/04555]	Time 0.04 (0.06)
Test: [02240/04555]	Time 0.04 (0.06)
Test: [02250/04555]	Time 0.04 (0.06)
Test: [02260/04555]	Time 0.04 (0.06)
Test: [02270/04555]	Time 0.04 (0.06)
Test: [02280/04555]	Time 0.18 (0.06)
Test: [02290/04555]	Time 0.04 (0.06)
Test: [02300/04555]	Time 0.04 (0.06)
Test: [02310/04555]	Time 0.04 (0.06)
Test: [02320/04555]	Time 0.04 (0.06)
Test: [02330/04555]	Time 0.04 (0.06)
Test: [02340/04555]	Time 0.04 (0.06)
Test: [02350/04555]	Time 0.04 (0.06)
Test: [02360/04555]	Time 0.04 (0.06)
Test: [02370/04555]	Time 0.04 (0.06)
Test: [02380/04555]	Time 0.04 (0.06)
Test: [02390/04555]	Time 0.04 (0.06)
Test: [02400/04555]	Time 0.04 (0.06)
Test: [02410/04555]	Time 0.04 (0.06)
Test: [02420/04555]	Time 0.04 (0.06)
Test: [02430/04555]	Time 0.04 (0.06)
Test: [02440/04555]	Time 0.04 (0.06)
Test: [02450/04555]	Time 0.04 (0.06)
Test: [02460/04555]	Time 0.04 (0.06)
Test: [02470/04555]	Time 0.04 (0.06)
Test: [02480/04555]	Time 0.04 (0.06)
Test: [02490/04555]	Time 0.04 (0.06)
Test: [02500/04555]	Time 0.04 (0.06)
Test: [02510/04555]	Time 0.04 (0.06)
Test: [02520/04555]	Time 0.04 (0.06)
Test: [02530/04555]	Time 0.04 (0.06)
Test: [02540/04555]	Time 0.04 (0.06)
Test: [02550/04555]	Time 0.04 (0.06)
Test: [02560/04555]	Time 0.04 (0.06)
Test: [02570/04555]	Time 0.04 (0.06)
Test: [02580/04555]	Time 0.04 (0.06)
Test: [02590/04555]	Time 0.04 (0.06)
Test: [02600/04555]	Time 0.04 (0.06)
Test: [02610/04555]	Time 0.04 (0.06)
Test: [02620/04555]	Time 0.04 (0.06)
Test: [02630/04555]	Time 0.10 (0.06)
Test: [02640/04555]	Time 0.04 (0.06)
Test: [02650/04555]	Time 0.10 (0.06)
Test: [02660/04555]	Time 0.19 (0.06)
Test: [02670/04555]	Time 0.04 (0.06)
Test: [02680/04555]	Time 0.04 (0.06)
Test: [02690/04555]	Time 0.04 (0.06)
Test: [02700/04555]	Time 0.04 (0.06)
Test: [02710/04555]	Time 0.04 (0.06)
Test: [02720/04555]	Time 0.04 (0.06)
Test: [02730/04555]	Time 0.04 (0.06)
Test: [02740/04555]	Time 0.04 (0.06)
Test: [02750/04555]	Time 0.04 (0.06)
Test: [02760/04555]	Time 0.04 (0.06)
Test: [02770/04555]	Time 0.04 (0.06)
Test: [02780/04555]	Time 0.04 (0.06)
Test: [02790/04555]	Time 0.04 (0.06)
Test: [02800/04555]	Time 0.04 (0.06)
Test: [02810/04555]	Time 0.04 (0.06)
Test: [02820/04555]	Time 0.04 (0.06)
Test: [02830/04555]	Time 0.04 (0.06)
Test: [02840/04555]	Time 0.04 (0.06)
Test: [02850/04555]	Time 0.04 (0.06)
Test: [02860/04555]	Time 0.04 (0.06)
Test: [02870/04555]	Time 0.04 (0.06)
Test: [02880/04555]	Time 0.04 (0.06)
Test: [02890/04555]	Time 0.04 (0.06)
Test: [02900/04555]	Time 0.04 (0.06)
Test: [02910/04555]	Time 0.04 (0.06)
Test: [02920/04555]	Time 0.04 (0.06)
Test: [02930/04555]	Time 0.04 (0.06)
Test: [02940/04555]	Time 0.04 (0.06)
Test: [02950/04555]	Time 0.04 (0.06)
Test: [02960/04555]	Time 0.04 (0.06)
Test: [02970/04555]	Time 0.04 (0.06)
Test: [02980/04555]	Time 0.04 (0.06)
Test: [02990/04555]	Time 0.04 (0.06)
Test: [03000/04555]	Time 0.04 (0.06)
Test: [03010/04555]	Time 0.04 (0.06)
Test: [03020/04555]	Time 0.04 (0.06)
Test: [03030/04555]	Time 0.04 (0.06)
Test: [03040/04555]	Time 0.04 (0.06)
Test: [03050/04555]	Time 0.04 (0.06)
Test: [03060/04555]	Time 0.04 (0.06)
Test: [03070/04555]	Time 0.04 (0.06)
Test: [03080/04555]	Time 0.04 (0.06)
Test: [03090/04555]	Time 0.04 (0.06)
Test: [03100/04555]	Time 0.04 (0.06)
Test: [03110/04555]	Time 0.04 (0.06)
Test: [03120/04555]	Time 0.04 (0.06)
Test: [03130/04555]	Time 0.04 (0.06)
Test: [03140/04555]	Time 0.04 (0.06)
Test: [03150/04555]	Time 0.04 (0.06)
Test: [03160/04555]	Time 0.04 (0.06)
Test: [03170/04555]	Time 0.04 (0.06)
Test: [03180/04555]	Time 0.04 (0.06)
Test: [03190/04555]	Time 0.04 (0.06)
Test: [03200/04555]	Time 0.04 (0.06)
Test: [03210/04555]	Time 0.04 (0.06)
Test: [03220/04555]	Time 0.04 (0.06)
Test: [03230/04555]	Time 0.04 (0.06)
Test: [03240/04555]	Time 0.04 (0.06)
Test: [03250/04555]	Time 0.04 (0.06)
Test: [03260/04555]	Time 0.04 (0.05)
Test: [03270/04555]	Time 0.04 (0.05)
Test: [03280/04555]	Time 0.04 (0.05)
Test: [03290/04555]	Time 0.04 (0.05)
Test: [03300/04555]	Time 0.04 (0.05)
Test: [03310/04555]	Time 0.04 (0.05)
Test: [03320/04555]	Time 0.04 (0.05)
Test: [03330/04555]	Time 0.04 (0.05)
Test: [03340/04555]	Time 0.04 (0.05)
Test: [03350/04555]	Time 0.04 (0.05)
Test: [03360/04555]	Time 0.04 (0.05)
Test: [03370/04555]	Time 0.04 (0.05)
Test: [03380/04555]	Time 0.04 (0.05)
Test: [03390/04555]	Time 0.04 (0.05)
Test: [03400/04555]	Time 0.04 (0.05)
Test: [03410/04555]	Time 0.04 (0.05)
Test: [03420/04555]	Time 0.04 (0.05)
Test: [03430/04555]	Time 0.04 (0.05)
Test: [03440/04555]	Time 0.04 (0.05)
Test: [03450/04555]	Time 0.04 (0.05)
Test: [03460/04555]	Time 0.04 (0.05)
Test: [03470/04555]	Time 0.04 (0.05)
Test: [03480/04555]	Time 0.04 (0.05)
Test: [03490/04555]	Time 0.04 (0.05)
Test: [03500/04555]	Time 0.04 (0.05)
Test: [03510/04555]	Time 0.04 (0.05)
Test: [03520/04555]	Time 0.04 (0.05)
Test: [03530/04555]	Time 0.04 (0.05)
Test: [03540/04555]	Time 0.04 (0.05)
Test: [03550/04555]	Time 0.04 (0.05)
Test: [03560/04555]	Time 0.04 (0.05)
Test: [03570/04555]	Time 0.04 (0.05)
Test: [03580/04555]	Time 0.04 (0.05)
Test: [03590/04555]	Time 0.04 (0.05)
Test: [03600/04555]	Time 0.04 (0.05)
Test: [03610/04555]	Time 0.04 (0.05)
Test: [03620/04555]	Time 0.04 (0.05)
Test: [03630/04555]	Time 0.04 (0.05)
Test: [03640/04555]	Time 0.04 (0.05)
Test: [03650/04555]	Time 0.04 (0.05)
Test: [03660/04555]	Time 0.04 (0.05)
Test: [03670/04555]	Time 0.04 (0.05)
Test: [03680/04555]	Time 0.04 (0.05)
Test: [03690/04555]	Time 0.04 (0.05)
Test: [03700/04555]	Time 0.04 (0.05)
Test: [03710/04555]	Time 0.04 (0.05)
Test: [03720/04555]	Time 0.04 (0.05)
Test: [03730/04555]	Time 0.04 (0.05)
Test: [03740/04555]	Time 0.04 (0.05)
Test: [03750/04555]	Time 0.04 (0.05)
Test: [03760/04555]	Time 0.04 (0.05)
Test: [03770/04555]	Time 0.08 (0.05)
Test: [03780/04555]	Time 0.04 (0.05)
Test: [03790/04555]	Time 0.04 (0.05)
Test: [03800/04555]	Time 0.04 (0.05)
Test: [03810/04555]	Time 0.04 (0.05)
Test: [03820/04555]	Time 0.04 (0.05)
Test: [03830/04555]	Time 0.04 (0.05)
Test: [03840/04555]	Time 0.04 (0.05)
Test: [03850/04555]	Time 0.04 (0.05)
Test: [03860/04555]	Time 0.04 (0.05)
Test: [03870/04555]	Time 0.04 (0.05)
Test: [03880/04555]	Time 0.04 (0.05)
Test: [03890/04555]	Time 0.04 (0.05)
Test: [03900/04555]	Time 0.04 (0.05)
Test: [03910/04555]	Time 0.04 (0.05)
Test: [03920/04555]	Time 0.04 (0.05)
Test: [03930/04555]	Time 0.04 (0.05)
Test: [03940/04555]	Time 0.04 (0.05)
Test: [03950/04555]	Time 0.04 (0.05)
Test: [03960/04555]	Time 0.04 (0.05)
Test: [03970/04555]	Time 0.10 (0.05)
Test: [03980/04555]	Time 0.12 (0.05)
Test: [03990/04555]	Time 0.17 (0.05)
Test: [04000/04555]	Time 0.26 (0.05)
Test: [04010/04555]	Time 0.28 (0.05)
Test: [04020/04555]	Time 0.04 (0.05)
Test: [04030/04555]	Time 0.12 (0.05)
Test: [04040/04555]	Time 0.15 (0.05)
Test: [04050/04555]	Time 0.05 (0.05)
Test: [04060/04555]	Time 0.10 (0.05)
Test: [04070/04555]	Time 0.08 (0.05)
Test: [04080/04555]	Time 0.06 (0.05)
Test: [04090/04555]	Time 0.08 (0.05)
Test: [04100/04555]	Time 0.23 (0.05)
Test: [04110/04555]	Time 0.24 (0.06)
Test: [04120/04555]	Time 0.10 (0.06)
Test: [04130/04555]	Time 0.08 (0.06)
Test: [04140/04555]	Time 0.06 (0.06)
Test: [04150/04555]	Time 0.04 (0.06)
Test: [04160/04555]	Time 0.10 (0.06)
Test: [04170/04555]	Time 0.05 (0.06)
Test: [04180/04555]	Time 0.04 (0.06)
Test: [04190/04555]	Time 0.04 (0.06)
Test: [04200/04555]	Time 0.05 (0.06)
Test: [04210/04555]	Time 0.04 (0.06)
Test: [04220/04555]	Time 0.04 (0.06)
Test: [04230/04555]	Time 0.04 (0.06)
Test: [04240/04555]	Time 0.06 (0.06)
Test: [04250/04555]	Time 0.15 (0.06)
Test: [04260/04555]	Time 0.04 (0.06)
Test: [04270/04555]	Time 0.08 (0.06)
Test: [04280/04555]	Time 0.09 (0.06)
Test: [04290/04555]	Time 0.04 (0.06)
Test: [04300/04555]	Time 0.06 (0.06)
Test: [04310/04555]	Time 0.04 (0.06)
Test: [04320/04555]	Time 0.04 (0.06)
Test: [04330/04555]	Time 0.09 (0.06)
Test: [04340/04555]	Time 0.04 (0.06)
Test: [04350/04555]	Time 0.04 (0.06)
Test: [04360/04555]	Time 0.07 (0.06)
Test: [04370/04555]	Time 0.04 (0.06)
Test: [04380/04555]	Time 0.04 (0.06)
Test: [04390/04555]	Time 0.04 (0.06)
Test: [04400/04555]	Time 0.04 (0.06)
Test: [04410/04555]	Time 0.04 (0.06)
Test: [04420/04555]	Time 0.04 (0.06)
Test: [04430/04555]	Time 0.04 (0.06)
Test: [04440/04555]	Time 0.06 (0.06)
Test: [04450/04555]	Time 0.07 (0.06)
Test: [04460/04555]	Time 0.04 (0.06)
Test: [04470/04555]	Time 0.04 (0.06)
Test: [04480/04555]	Time 0.04 (0.06)
Test: [04490/04555]	Time 0.04 (0.06)
Test: [04500/04555]	Time 0.04 (0.06)
Test: [04510/04555]	Time 0.04 (0.06)
Test: [04520/04555]	Time 0.04 (0.05)
Test: [04530/04555]	Time 0.04 (0.05)
Test: [04540/04555]	Time 0.04 (0.05)
Test: [04550/04555]	Time 0.04 (0.05)
[RESULTS] Action detection results on anet1.3_i3d_filtered.

|tIoU = 0.50: mAP = 53.43 (%) Recall@1x = 60.09 (%) Recall@5x = 81.73 (%) 
|tIoU = 0.55: mAP = 50.29 (%) Recall@1x = 57.15 (%) Recall@5x = 78.43 (%) 
|tIoU = 0.60: mAP = 47.06 (%) Recall@1x = 54.30 (%) Recall@5x = 74.64 (%) 
|tIoU = 0.65: mAP = 43.49 (%) Recall@1x = 51.37 (%) Recall@5x = 70.39 (%) 
|tIoU = 0.70: mAP = 40.17 (%) Recall@1x = 48.44 (%) Recall@5x = 65.22 (%) 
|tIoU = 0.75: mAP = 35.63 (%) Recall@1x = 44.39 (%) Recall@5x = 58.45 (%) 
|tIoU = 0.80: mAP = 30.30 (%) Recall@1x = 39.26 (%) Recall@5x = 50.39 (%) 
|tIoU = 0.85: mAP = 24.03 (%) Recall@1x = 33.08 (%) Recall@5x = 40.64 (%) 
|tIoU = 0.90: mAP = 16.19 (%) Recall@1x = 24.70 (%) Recall@5x = 28.70 (%) 
|tIoU = 0.95: mAP = 5.19 (%) Recall@1x = 10.35 (%) Recall@5x = 11.57 (%) 
Average mAP: 34.58 (%)
All done! Total time: 485.30 sec
Looking for a split for p=0.4
Found split for p=0.4 [3700 videos]
Moving sampled images to a separate folder
Finished sampling
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00231]	Time 4.11 (4.11)	Loss 1.81 (1.81)
		cls_loss 0.54 (0.54)	reg_loss 0.63 (0.63)
Epoch: [000][00020/00231]	Time 0.24 (2.18)	Loss 1.42 (1.61)
		cls_loss 0.47 (0.50)	reg_loss 0.48 (0.56)
Epoch: [000][00030/00231]	Time 0.23 (1.53)	Loss 1.44 (1.56)
		cls_loss 0.45 (0.49)	reg_loss 0.49 (0.53)
Epoch: [000][00040/00231]	Time 0.20 (1.20)	Loss 1.67 (1.58)
		cls_loss 0.52 (0.50)	reg_loss 0.57 (0.54)
Epoch: [000][00050/00231]	Time 0.20 (1.00)	Loss 1.83 (1.63)
		cls_loss 0.52 (0.50)	reg_loss 0.66 (0.57)
Epoch: [000][00060/00231]	Time 0.19 (0.86)	Loss 1.19 (1.56)
		cls_loss 0.39 (0.48)	reg_loss 0.40 (0.54)
Epoch: [000][00070/00231]	Time 0.19 (0.77)	Loss 1.39 (1.54)
		cls_loss 0.61 (0.50)	reg_loss 0.39 (0.52)
Epoch: [000][00080/00231]	Time 0.23 (0.70)	Loss 0.72 (1.43)
		cls_loss 0.39 (0.49)	reg_loss 0.16 (0.47)
Epoch: [000][00090/00231]	Time 0.21 (0.65)	Loss 1.06 (1.39)
		cls_loss 0.46 (0.48)	reg_loss 0.30 (0.45)
Epoch: [000][00100/00231]	Time 0.23 (0.60)	Loss 0.79 (1.33)
		cls_loss 0.39 (0.47)	reg_loss 0.20 (0.43)
Epoch: [000][00110/00231]	Time 0.25 (0.57)	Loss 0.76 (1.28)
		cls_loss 0.38 (0.46)	reg_loss 0.19 (0.41)
Epoch: [000][00120/00231]	Time 0.23 (0.54)	Loss 0.77 (1.24)
		cls_loss 0.37 (0.46)	reg_loss 0.20 (0.39)
Epoch: [000][00130/00231]	Time 0.22 (0.52)	Loss 1.00 (1.22)
		cls_loss 0.49 (0.46)	reg_loss 0.25 (0.38)
Epoch: [000][00140/00231]	Time 0.20 (0.50)	Loss 0.82 (1.19)
		cls_loss 0.38 (0.45)	reg_loss 0.22 (0.37)
Epoch: [000][00150/00231]	Time 0.24 (0.48)	Loss 1.24 (1.19)
		cls_loss 0.54 (0.46)	reg_loss 0.35 (0.37)
Epoch: [000][00160/00231]	Time 0.19 (0.46)	Loss 0.88 (1.17)
		cls_loss 0.42 (0.46)	reg_loss 0.23 (0.36)
Epoch: [000][00170/00231]	Time 0.23 (0.45)	Loss 0.59 (1.14)
		cls_loss 0.30 (0.45)	reg_loss 0.14 (0.35)
Epoch: [000][00180/00231]	Time 0.22 (0.43)	Loss 0.69 (1.11)
		cls_loss 0.33 (0.44)	reg_loss 0.18 (0.34)
Epoch: [000][00190/00231]	Time 0.22 (0.42)	Loss 1.02 (1.11)
		cls_loss 0.49 (0.44)	reg_loss 0.26 (0.33)
Epoch: [000][00200/00231]	Time 0.20 (0.41)	Loss 0.96 (1.10)
		cls_loss 0.49 (0.45)	reg_loss 0.24 (0.33)
Epoch: [000][00210/00231]	Time 0.86 (0.43)	Loss 0.71 (1.08)
		cls_loss 0.34 (0.44)	reg_loss 0.18 (0.32)
Epoch: [000][00220/00231]	Time 0.53 (0.44)	Loss 1.59 (1.11)
		cls_loss 0.73 (0.45)	reg_loss 0.43 (0.33)
Epoch: [000][00230/00231]	Time 0.23 (0.43)	Loss 0.97 (1.10)
		cls_loss 0.43 (0.45)	reg_loss 0.27 (0.32)
[Train]: Epoch 0 finished with lr=0.00020017


[Train]: Epoch 1 started
Epoch: [001][00010/00231]	Time 0.22 (0.22)	Loss 1.03 (1.03)
		cls_loss 0.45 (0.45)	reg_loss 0.29 (0.29)
Epoch: [001][00020/00231]	Time 0.19 (0.21)	Loss 0.66 (0.85)
		cls_loss 0.31 (0.38)	reg_loss 0.18 (0.23)
Epoch: [001][00030/00231]	Time 0.19 (0.20)	Loss 1.28 (0.99)
		cls_loss 0.61 (0.46)	reg_loss 0.34 (0.27)
Epoch: [001][00040/00231]	Time 0.19 (0.20)	Loss 0.47 (0.86)
		cls_loss 0.23 (0.40)	reg_loss 0.12 (0.23)
Epoch: [001][00050/00231]	Time 0.20 (0.20)	Loss 1.15 (0.92)
		cls_loss 0.50 (0.42)	reg_loss 0.33 (0.25)
Epoch: [001][00060/00231]	Time 0.20 (0.20)	Loss 1.48 (1.01)
		cls_loss 0.64 (0.46)	reg_loss 0.42 (0.28)
Epoch: [001][00070/00231]	Time 0.21 (0.20)	Loss 0.70 (0.97)
		cls_loss 0.34 (0.44)	reg_loss 0.18 (0.26)
Epoch: [001][00080/00231]	Time 0.21 (0.20)	Loss 0.82 (0.95)
		cls_loss 0.38 (0.43)	reg_loss 0.22 (0.26)
Epoch: [001][00090/00231]	Time 0.22 (0.20)	Loss 0.72 (0.92)
		cls_loss 0.36 (0.42)	reg_loss 0.18 (0.25)
Epoch: [001][00100/00231]	Time 0.22 (0.21)	Loss 1.22 (0.95)
		cls_loss 0.56 (0.44)	reg_loss 0.33 (0.26)
Epoch: [001][00110/00231]	Time 0.22 (0.21)	Loss 1.47 (1.00)
		cls_loss 0.73 (0.46)	reg_loss 0.37 (0.27)
Epoch: [001][00120/00231]	Time 0.22 (0.21)	Loss 0.81 (0.98)
		cls_loss 0.35 (0.45)	reg_loss 0.23 (0.26)
Epoch: [001][00130/00231]	Time 0.22 (0.21)	Loss 0.41 (0.94)
		cls_loss 0.19 (0.43)	reg_loss 0.11 (0.25)
Epoch: [001][00140/00231]	Time 0.21 (0.21)	Loss 0.82 (0.93)
		cls_loss 0.37 (0.43)	reg_loss 0.22 (0.25)
Epoch: [001][00150/00231]	Time 0.21 (0.21)	Loss 0.87 (0.93)
		cls_loss 0.45 (0.43)	reg_loss 0.21 (0.25)
Epoch: [001][00160/00231]	Time 0.68 (0.24)	Loss 0.76 (0.92)
		cls_loss 0.37 (0.43)	reg_loss 0.19 (0.24)
Epoch: [001][00170/00231]	Time 0.46 (0.25)	Loss 0.79 (0.91)
		cls_loss 0.39 (0.43)	reg_loss 0.20 (0.24)
Epoch: [001][00180/00231]	Time 0.21 (0.25)	Loss 0.52 (0.89)
		cls_loss 0.22 (0.41)	reg_loss 0.15 (0.24)
Epoch: [001][00190/00231]	Time 0.21 (0.25)	Loss 0.73 (0.88)
		cls_loss 0.34 (0.41)	reg_loss 0.20 (0.23)
Epoch: [001][00200/00231]	Time 0.22 (0.25)	Loss 0.64 (0.87)
		cls_loss 0.31 (0.41)	reg_loss 0.17 (0.23)
Epoch: [001][00210/00231]	Time 0.29 (0.25)	Loss 1.23 (0.88)
		cls_loss 0.56 (0.41)	reg_loss 0.33 (0.24)
Epoch: [001][00220/00231]	Time 0.22 (0.25)	Loss 0.65 (0.87)
		cls_loss 0.30 (0.41)	reg_loss 0.18 (0.23)
Epoch: [001][00230/00231]	Time 0.18 (0.24)	Loss 0.90 (0.87)
		cls_loss 0.43 (0.41)	reg_loss 0.23 (0.23)
[Train]: Epoch 1 finished with lr=0.00040035


[Train]: Epoch 2 started
Epoch: [002][00010/00231]	Time 0.24 (0.24)	Loss 1.07 (1.07)
		cls_loss 0.50 (0.50)	reg_loss 0.29 (0.29)
Epoch: [002][00020/00231]	Time 0.19 (0.21)	Loss 1.21 (1.14)
		cls_loss 0.52 (0.51)	reg_loss 0.34 (0.32)
Epoch: [002][00030/00231]	Time 0.20 (0.21)	Loss 0.75 (1.01)
		cls_loss 0.37 (0.46)	reg_loss 0.19 (0.27)
Epoch: [002][00040/00231]	Time 0.21 (0.21)	Loss 0.56 (0.90)
		cls_loss 0.25 (0.41)	reg_loss 0.15 (0.24)
Epoch: [002][00050/00231]	Time 0.20 (0.21)	Loss 1.02 (0.92)
		cls_loss 0.48 (0.42)	reg_loss 0.27 (0.25)
Epoch: [002][00060/00231]	Time 0.21 (0.21)	Loss 1.04 (0.94)
		cls_loss 0.46 (0.43)	reg_loss 0.29 (0.26)
Epoch: [002][00070/00231]	Time 0.22 (0.21)	Loss 0.51 (0.88)
		cls_loss 0.28 (0.41)	reg_loss 0.12 (0.24)
Epoch: [002][00080/00231]	Time 0.22 (0.21)	Loss 0.88 (0.88)
		cls_loss 0.41 (0.41)	reg_loss 0.23 (0.24)
Epoch: [002][00090/00231]	Time 0.22 (0.21)	Loss 1.22 (0.92)
		cls_loss 0.54 (0.42)	reg_loss 0.34 (0.25)
Epoch: [002][00100/00231]	Time 0.21 (0.21)	Loss 0.47 (0.87)
		cls_loss 0.23 (0.40)	reg_loss 0.12 (0.23)
Epoch: [002][00110/00231]	Time 0.22 (0.21)	Loss 0.73 (0.86)
		cls_loss 0.36 (0.40)	reg_loss 0.18 (0.23)
Epoch: [002][00120/00231]	Time 0.21 (0.21)	Loss 0.63 (0.84)
		cls_loss 0.30 (0.39)	reg_loss 0.17 (0.22)
Epoch: [002][00130/00231]	Time 0.20 (0.21)	Loss 0.45 (0.81)
		cls_loss 0.23 (0.38)	reg_loss 0.11 (0.22)
Epoch: [002][00140/00231]	Time 0.21 (0.21)	Loss 0.65 (0.80)
		cls_loss 0.33 (0.38)	reg_loss 0.16 (0.21)
Epoch: [002][00150/00231]	Time 0.20 (0.21)	Loss 1.08 (0.82)
		cls_loss 0.52 (0.39)	reg_loss 0.28 (0.22)
Epoch: [002][00160/00231]	Time 0.22 (0.21)	Loss 0.93 (0.83)
		cls_loss 0.41 (0.39)	reg_loss 0.26 (0.22)
Epoch: [002][00170/00231]	Time 0.22 (0.21)	Loss 1.21 (0.85)
		cls_loss 0.55 (0.40)	reg_loss 0.33 (0.23)
Epoch: [002][00180/00231]	Time 0.22 (0.21)	Loss 0.86 (0.85)
		cls_loss 0.39 (0.40)	reg_loss 0.23 (0.23)
Epoch: [002][00190/00231]	Time 0.21 (0.21)	Loss 0.87 (0.85)
		cls_loss 0.43 (0.40)	reg_loss 0.22 (0.23)
Epoch: [002][00200/00231]	Time 0.20 (0.21)	Loss 1.18 (0.87)
		cls_loss 0.51 (0.40)	reg_loss 0.33 (0.23)
Epoch: [002][00210/00231]	Time 0.19 (0.21)	Loss 2.48 (0.94)
		cls_loss 1.27 (0.45)	reg_loss 0.60 (0.25)
Epoch: [002][00220/00231]	Time 0.20 (0.21)	Loss 0.79 (0.94)
		cls_loss 0.39 (0.44)	reg_loss 0.20 (0.25)
Epoch: [002][00230/00231]	Time 0.17 (0.21)	Loss 1.48 (0.96)
		cls_loss 0.66 (0.45)	reg_loss 0.41 (0.25)
[Train]: Epoch 2 finished with lr=0.00060052


[Train]: Epoch 3 started
Epoch: [003][00010/00231]	Time 0.24 (0.24)	Loss 0.81 (0.81)
		cls_loss 0.37 (0.37)	reg_loss 0.22 (0.22)
Epoch: [003][00020/00231]	Time 0.19 (0.21)	Loss 1.40 (1.11)
		cls_loss 0.59 (0.48)	reg_loss 0.40 (0.31)
Epoch: [003][00030/00231]	Time 0.20 (0.21)	Loss 1.11 (1.11)
		cls_loss 0.56 (0.51)	reg_loss 0.27 (0.30)
Epoch: [003][00040/00231]	Time 0.21 (0.21)	Loss 0.60 (0.98)
		cls_loss 0.28 (0.45)	reg_loss 0.16 (0.27)
Epoch: [003][00050/00231]	Time 0.22 (0.21)	Loss 0.86 (0.96)
		cls_loss 0.40 (0.44)	reg_loss 0.23 (0.26)
Epoch: [003][00060/00231]	Time 0.21 (0.21)	Loss 0.89 (0.95)
		cls_loss 0.42 (0.44)	reg_loss 0.24 (0.25)
Epoch: [003][00070/00231]	Time 0.22 (0.21)	Loss 0.81 (0.93)
		cls_loss 0.39 (0.43)	reg_loss 0.21 (0.25)
Epoch: [003][00080/00231]	Time 0.20 (0.21)	Loss 0.84 (0.92)
		cls_loss 0.41 (0.43)	reg_loss 0.21 (0.24)
Epoch: [003][00090/00231]	Time 0.22 (0.21)	Loss 0.42 (0.86)
		cls_loss 0.21 (0.40)	reg_loss 0.10 (0.23)
Epoch: [003][00100/00231]	Time 0.21 (0.21)	Loss 0.65 (0.84)
		cls_loss 0.28 (0.39)	reg_loss 0.18 (0.22)
Epoch: [003][00110/00231]	Time 0.21 (0.21)	Loss 0.47 (0.81)
		cls_loss 0.25 (0.38)	reg_loss 0.11 (0.21)
Epoch: [003][00120/00231]	Time 0.22 (0.21)	Loss 0.81 (0.81)
		cls_loss 0.36 (0.38)	reg_loss 0.22 (0.21)
Epoch: [003][00130/00231]	Time 0.21 (0.21)	Loss 0.63 (0.79)
		cls_loss 0.30 (0.37)	reg_loss 0.17 (0.21)
Epoch: [003][00140/00231]	Time 0.22 (0.21)	Loss 0.77 (0.79)
		cls_loss 0.38 (0.37)	reg_loss 0.19 (0.21)
Epoch: [003][00150/00231]	Time 0.22 (0.21)	Loss 0.98 (0.80)
		cls_loss 0.46 (0.38)	reg_loss 0.26 (0.21)
Epoch: [003][00160/00231]	Time 0.22 (0.21)	Loss 1.03 (0.82)
		cls_loss 0.47 (0.38)	reg_loss 0.28 (0.22)
Epoch: [003][00170/00231]	Time 0.22 (0.21)	Loss 0.66 (0.81)
		cls_loss 0.34 (0.38)	reg_loss 0.16 (0.21)
Epoch: [003][00180/00231]	Time 0.21 (0.21)	Loss 0.66 (0.80)
		cls_loss 0.31 (0.38)	reg_loss 0.17 (0.21)
Epoch: [003][00190/00231]	Time 0.19 (0.21)	Loss 1.33 (0.83)
		cls_loss 0.59 (0.39)	reg_loss 0.37 (0.22)
Epoch: [003][00200/00231]	Time 0.94 (0.25)	Loss 0.57 (0.82)
		cls_loss 0.28 (0.38)	reg_loss 0.15 (0.22)
Epoch: [003][00210/00231]	Time 0.19 (0.25)	Loss 0.48 (0.80)
		cls_loss 0.25 (0.38)	reg_loss 0.12 (0.21)
Epoch: [003][00220/00231]	Time 0.20 (0.24)	Loss 0.58 (0.79)
		cls_loss 0.29 (0.37)	reg_loss 0.14 (0.21)
Epoch: [003][00230/00231]	Time 0.17 (0.24)	Loss 0.67 (0.78)
		cls_loss 0.33 (0.37)	reg_loss 0.17 (0.21)
[Train]: Epoch 3 finished with lr=0.00080069


[Train]: Epoch 4 started
Epoch: [004][00010/00231]	Time 0.24 (0.24)	Loss 0.91 (0.91)
		cls_loss 0.44 (0.44)	reg_loss 0.23 (0.23)
Epoch: [004][00020/00231]	Time 0.19 (0.21)	Loss 1.01 (0.96)
		cls_loss 0.49 (0.47)	reg_loss 0.26 (0.25)
Epoch: [004][00030/00231]	Time 0.19 (0.21)	Loss 0.88 (0.93)
		cls_loss 0.43 (0.45)	reg_loss 0.23 (0.24)
Epoch: [004][00040/00231]	Time 0.20 (0.21)	Loss 1.19 (1.00)
		cls_loss 0.62 (0.50)	reg_loss 0.29 (0.25)
Epoch: [004][00050/00231]	Time 0.22 (0.21)	Loss 0.74 (0.95)
		cls_loss 0.35 (0.47)	reg_loss 0.19 (0.24)
Epoch: [004][00060/00231]	Time 0.22 (0.21)	Loss 0.46 (0.86)
		cls_loss 0.20 (0.42)	reg_loss 0.13 (0.22)
Epoch: [004][00070/00231]	Time 0.22 (0.21)	Loss 0.70 (0.84)
		cls_loss 0.29 (0.40)	reg_loss 0.21 (0.22)
Epoch: [004][00080/00231]	Time 0.22 (0.21)	Loss 1.04 (0.87)
		cls_loss 0.50 (0.41)	reg_loss 0.27 (0.23)
Epoch: [004][00090/00231]	Time 0.21 (0.21)	Loss 0.70 (0.85)
		cls_loss 0.31 (0.40)	reg_loss 0.20 (0.22)
Epoch: [004][00100/00231]	Time 0.22 (0.21)	Loss 0.86 (0.85)
		cls_loss 0.43 (0.41)	reg_loss 0.21 (0.22)
Epoch: [004][00110/00231]	Time 0.22 (0.21)	Loss 1.11 (0.87)
		cls_loss 0.50 (0.41)	reg_loss 0.31 (0.23)
Epoch: [004][00120/00231]	Time 0.22 (0.21)	Loss 1.12 (0.89)
		cls_loss 0.55 (0.43)	reg_loss 0.28 (0.23)
Epoch: [004][00130/00231]	Time 0.22 (0.21)	Loss 0.61 (0.87)
		cls_loss 0.30 (0.42)	reg_loss 0.15 (0.23)
Epoch: [004][00140/00231]	Time 0.22 (0.21)	Loss 1.32 (0.90)
		cls_loss 0.55 (0.43)	reg_loss 0.39 (0.24)
Epoch: [004][00150/00231]	Time 0.22 (0.21)	Loss 1.16 (0.92)
		cls_loss 0.57 (0.43)	reg_loss 0.30 (0.24)
Epoch: [004][00160/00231]	Time 0.22 (0.21)	Loss 1.40 (0.95)
		cls_loss 0.65 (0.45)	reg_loss 0.38 (0.25)
Epoch: [004][00170/00231]	Time 0.22 (0.21)	Loss 0.48 (0.92)
		cls_loss 0.25 (0.44)	reg_loss 0.12 (0.24)
Epoch: [004][00180/00231]	Time 0.22 (0.22)	Loss 0.71 (0.91)
		cls_loss 0.36 (0.43)	reg_loss 0.18 (0.24)
Epoch: [004][00190/00231]	Time 0.22 (0.22)	Loss 1.22 (0.93)
		cls_loss 0.52 (0.44)	reg_loss 0.35 (0.25)
Epoch: [004][00200/00231]	Time 0.22 (0.22)	Loss 0.81 (0.92)
		cls_loss 0.38 (0.43)	reg_loss 0.22 (0.24)
Epoch: [004][00210/00231]	Time 0.22 (0.22)	Loss 0.69 (0.91)
		cls_loss 0.34 (0.43)	reg_loss 0.17 (0.24)
Epoch: [004][00220/00231]	Time 0.22 (0.22)	Loss 0.88 (0.91)
		cls_loss 0.43 (0.43)	reg_loss 0.22 (0.24)
Epoch: [004][00230/00231]	Time 0.18 (0.21)	Loss 0.92 (0.91)
		cls_loss 0.44 (0.43)	reg_loss 0.24 (0.24)
[Train]: Epoch 4 finished with lr=0.00100000


[Train]: Epoch 5 started
Epoch: [005][00010/00231]	Time 0.29 (0.29)	Loss 0.69 (0.69)
		cls_loss 0.36 (0.36)	reg_loss 0.16 (0.16)
Epoch: [005][00020/00231]	Time 0.22 (0.25)	Loss 0.47 (0.58)
		cls_loss 0.25 (0.30)	reg_loss 0.11 (0.14)
Epoch: [005][00030/00231]	Time 0.22 (0.24)	Loss 1.06 (0.74)
		cls_loss 0.45 (0.35)	reg_loss 0.31 (0.19)
Epoch: [005][00040/00231]	Time 0.22 (0.24)	Loss 0.71 (0.73)
		cls_loss 0.33 (0.35)	reg_loss 0.19 (0.19)
Epoch: [005][00050/00231]	Time 0.22 (0.23)	Loss 1.57 (0.90)
		cls_loss 0.69 (0.42)	reg_loss 0.44 (0.24)
Epoch: [005][00060/00231]	Time 0.22 (0.23)	Loss 0.63 (0.85)
		cls_loss 0.31 (0.40)	reg_loss 0.16 (0.23)
Epoch: [005][00070/00231]	Time 0.81 (0.31)	Loss 0.70 (0.83)
		cls_loss 0.31 (0.39)	reg_loss 0.19 (0.22)
Epoch: [005][00080/00231]	Time 1.33 (0.44)	Loss 0.81 (0.83)
		cls_loss 0.37 (0.38)	reg_loss 0.22 (0.22)
Epoch: [005][00090/00231]	Time 0.24 (0.42)	Loss 0.86 (0.83)
		cls_loss 0.41 (0.39)	reg_loss 0.22 (0.22)
Epoch: [005][00100/00231]	Time 0.22 (0.40)	Loss 1.12 (0.86)
		cls_loss 0.56 (0.41)	reg_loss 0.28 (0.23)
Epoch: [005][00110/00231]	Time 0.22 (0.38)	Loss 0.81 (0.86)
		cls_loss 0.38 (0.40)	reg_loss 0.21 (0.23)
Epoch: [005][00120/00231]	Time 0.22 (0.37)	Loss 0.88 (0.86)
		cls_loss 0.38 (0.40)	reg_loss 0.25 (0.23)
Epoch: [005][00130/00231]	Time 0.22 (0.36)	Loss 0.82 (0.86)
		cls_loss 0.41 (0.40)	reg_loss 0.21 (0.23)
Epoch: [005][00140/00231]	Time 0.22 (0.35)	Loss 0.72 (0.85)
		cls_loss 0.35 (0.40)	reg_loss 0.19 (0.22)
Epoch: [005][00150/00231]	Time 0.22 (0.34)	Loss 0.80 (0.84)
		cls_loss 0.40 (0.40)	reg_loss 0.20 (0.22)
Epoch: [005][00160/00231]	Time 0.22 (0.33)	Loss 0.85 (0.84)
		cls_loss 0.39 (0.40)	reg_loss 0.23 (0.22)
Epoch: [005][00170/00231]	Time 0.22 (0.33)	Loss 0.78 (0.84)
		cls_loss 0.37 (0.40)	reg_loss 0.21 (0.22)
Epoch: [005][00180/00231]	Time 0.22 (0.32)	Loss 0.62 (0.83)
		cls_loss 0.29 (0.39)	reg_loss 0.17 (0.22)
Epoch: [005][00190/00231]	Time 0.22 (0.31)	Loss 1.62 (0.87)
		cls_loss 0.77 (0.41)	reg_loss 0.42 (0.23)
Epoch: [005][00200/00231]	Time 0.22 (0.31)	Loss 0.67 (0.86)
		cls_loss 0.32 (0.41)	reg_loss 0.17 (0.23)
Epoch: [005][00210/00231]	Time 0.22 (0.30)	Loss 1.33 (0.88)
		cls_loss 0.63 (0.42)	reg_loss 0.35 (0.23)
Epoch: [005][00220/00231]	Time 0.22 (0.30)	Loss 1.07 (0.89)
		cls_loss 0.45 (0.42)	reg_loss 0.31 (0.24)
Epoch: [005][00230/00231]	Time 0.18 (0.30)	Loss 0.99 (0.90)
		cls_loss 0.46 (0.42)	reg_loss 0.27 (0.24)
[Train]: Epoch 5 finished with lr=0.00097553


[Train]: Epoch 6 started
Epoch: [006][00010/00231]	Time 0.29 (0.29)	Loss 0.89 (0.89)
		cls_loss 0.39 (0.39)	reg_loss 0.25 (0.25)
Epoch: [006][00020/00231]	Time 0.22 (0.25)	Loss 1.00 (0.94)
		cls_loss 0.48 (0.43)	reg_loss 0.26 (0.25)
Epoch: [006][00030/00231]	Time 0.22 (0.24)	Loss 0.68 (0.86)
		cls_loss 0.33 (0.40)	reg_loss 0.17 (0.23)
Epoch: [006][00040/00231]	Time 0.22 (0.24)	Loss 0.97 (0.88)
		cls_loss 0.44 (0.41)	reg_loss 0.26 (0.24)
Epoch: [006][00050/00231]	Time 0.22 (0.23)	Loss 0.96 (0.90)
		cls_loss 0.42 (0.41)	reg_loss 0.27 (0.24)
Epoch: [006][00060/00231]	Time 0.22 (0.23)	Loss 0.67 (0.86)
		cls_loss 0.29 (0.39)	reg_loss 0.19 (0.23)
Epoch: [006][00070/00231]	Time 0.22 (0.23)	Loss 0.63 (0.83)
		cls_loss 0.28 (0.38)	reg_loss 0.18 (0.23)
Epoch: [006][00080/00231]	Time 0.22 (0.23)	Loss 0.54 (0.79)
		cls_loss 0.24 (0.36)	reg_loss 0.15 (0.22)
Epoch: [006][00090/00231]	Time 0.22 (0.23)	Loss 0.97 (0.81)
		cls_loss 0.46 (0.37)	reg_loss 0.26 (0.22)
Epoch: [006][00100/00231]	Time 0.22 (0.23)	Loss 0.94 (0.83)
		cls_loss 0.43 (0.38)	reg_loss 0.25 (0.22)
Epoch: [006][00110/00231]	Time 0.22 (0.22)	Loss 1.68 (0.90)
		cls_loss 0.71 (0.41)	reg_loss 0.48 (0.25)
Epoch: [006][00120/00231]	Time 0.25 (0.23)	Loss 1.31 (0.94)
		cls_loss 0.51 (0.41)	reg_loss 0.40 (0.26)
Epoch: [006][00130/00231]	Time 1.15 (0.30)	Loss 1.13 (0.95)
		cls_loss 0.50 (0.42)	reg_loss 0.32 (0.27)
Epoch: [006][00140/00231]	Time 0.22 (0.29)	Loss 0.53 (0.92)
		cls_loss 0.27 (0.41)	reg_loss 0.13 (0.26)
Epoch: [006][00150/00231]	Time 0.22 (0.29)	Loss 0.56 (0.90)
		cls_loss 0.25 (0.40)	reg_loss 0.15 (0.25)
Epoch: [006][00160/00231]	Time 0.22 (0.28)	Loss 0.79 (0.89)
		cls_loss 0.34 (0.40)	reg_loss 0.22 (0.25)
Epoch: [006][00170/00231]	Time 0.21 (0.28)	Loss 0.83 (0.89)
		cls_loss 0.37 (0.39)	reg_loss 0.23 (0.25)
Epoch: [006][00180/00231]	Time 0.23 (0.28)	Loss 0.50 (0.87)
		cls_loss 0.25 (0.39)	reg_loss 0.12 (0.24)
Epoch: [006][00190/00231]	Time 0.22 (0.27)	Loss 0.60 (0.85)
		cls_loss 0.34 (0.38)	reg_loss 0.13 (0.23)
Epoch: [006][00200/00231]	Time 0.22 (0.27)	Loss 0.71 (0.84)
		cls_loss 0.32 (0.38)	reg_loss 0.20 (0.23)
Epoch: [006][00210/00231]	Time 0.22 (0.27)	Loss 1.19 (0.86)
		cls_loss 0.57 (0.39)	reg_loss 0.31 (0.24)
Epoch: [006][00220/00231]	Time 0.22 (0.27)	Loss 0.44 (0.84)
		cls_loss 0.21 (0.38)	reg_loss 0.11 (0.23)
Epoch: [006][00230/00231]	Time 0.18 (0.26)	Loss 1.21 (0.86)
		cls_loss 0.56 (0.39)	reg_loss 0.33 (0.23)
[Train]: Epoch 6 finished with lr=0.00090451


[Train]: Epoch 7 started
Epoch: [007][00010/00231]	Time 0.26 (0.26)	Loss 1.00 (1.00)
		cls_loss 0.46 (0.46)	reg_loss 0.27 (0.27)
Epoch: [007][00020/00231]	Time 0.20 (0.23)	Loss 0.72 (0.86)
		cls_loss 0.34 (0.40)	reg_loss 0.19 (0.23)
Epoch: [007][00030/00231]	Time 0.21 (0.23)	Loss 0.44 (0.72)
		cls_loss 0.21 (0.34)	reg_loss 0.11 (0.19)
Epoch: [007][00040/00231]	Time 0.22 (0.22)	Loss 0.76 (0.73)
		cls_loss 0.39 (0.35)	reg_loss 0.18 (0.19)
Epoch: [007][00050/00231]	Time 0.22 (0.22)	Loss 0.95 (0.77)
		cls_loss 0.46 (0.37)	reg_loss 0.24 (0.20)
Epoch: [007][00060/00231]	Time 0.22 (0.22)	Loss 0.68 (0.76)
		cls_loss 0.34 (0.37)	reg_loss 0.17 (0.19)
Epoch: [007][00070/00231]	Time 0.22 (0.22)	Loss 0.80 (0.76)
		cls_loss 0.37 (0.37)	reg_loss 0.22 (0.20)
Epoch: [007][00080/00231]	Time 0.22 (0.22)	Loss 0.71 (0.76)
		cls_loss 0.37 (0.37)	reg_loss 0.17 (0.20)
Epoch: [007][00090/00231]	Time 0.21 (0.22)	Loss 1.20 (0.81)
		cls_loss 0.50 (0.38)	reg_loss 0.35 (0.21)
Epoch: [007][00100/00231]	Time 0.22 (0.22)	Loss 0.89 (0.82)
		cls_loss 0.40 (0.39)	reg_loss 0.24 (0.22)
Epoch: [007][00110/00231]	Time 0.21 (0.22)	Loss 0.75 (0.81)
		cls_loss 0.34 (0.38)	reg_loss 0.20 (0.21)
Epoch: [007][00120/00231]	Time 0.22 (0.22)	Loss 0.55 (0.79)
		cls_loss 0.26 (0.37)	reg_loss 0.15 (0.21)
Epoch: [007][00130/00231]	Time 0.22 (0.22)	Loss 0.69 (0.78)
		cls_loss 0.35 (0.37)	reg_loss 0.17 (0.21)
Epoch: [007][00140/00231]	Time 0.22 (0.22)	Loss 0.83 (0.78)
		cls_loss 0.39 (0.37)	reg_loss 0.22 (0.21)
Epoch: [007][00150/00231]	Time 0.21 (0.22)	Loss 1.07 (0.80)
		cls_loss 0.48 (0.38)	reg_loss 0.29 (0.21)
Epoch: [007][00160/00231]	Time 0.22 (0.22)	Loss 1.14 (0.82)
		cls_loss 0.53 (0.39)	reg_loss 0.31 (0.22)
Epoch: [007][00170/00231]	Time 0.22 (0.22)	Loss 0.47 (0.80)
		cls_loss 0.21 (0.38)	reg_loss 0.13 (0.21)
Epoch: [007][00180/00231]	Time 0.22 (0.22)	Loss 1.10 (0.82)
		cls_loss 0.50 (0.38)	reg_loss 0.30 (0.22)
Epoch: [007][00190/00231]	Time 0.22 (0.22)	Loss 0.63 (0.81)
		cls_loss 0.31 (0.38)	reg_loss 0.16 (0.21)
Epoch: [007][00200/00231]	Time 0.22 (0.22)	Loss 0.78 (0.81)
		cls_loss 0.37 (0.38)	reg_loss 0.20 (0.21)
Epoch: [007][00210/00231]	Time 0.22 (0.22)	Loss 1.07 (0.82)
		cls_loss 0.45 (0.38)	reg_loss 0.31 (0.22)
Epoch: [007][00220/00231]	Time 0.22 (0.22)	Loss 0.90 (0.82)
		cls_loss 0.44 (0.39)	reg_loss 0.23 (0.22)
Epoch: [007][00230/00231]	Time 0.18 (0.22)	Loss 0.55 (0.81)
		cls_loss 0.26 (0.38)	reg_loss 0.15 (0.22)
[Train]: Epoch 7 finished with lr=0.00079389


[Train]: Epoch 8 started
Epoch: [008][00010/00231]	Time 0.26 (0.26)	Loss 0.86 (0.86)
		cls_loss 0.42 (0.42)	reg_loss 0.22 (0.22)
Epoch: [008][00020/00231]	Time 0.21 (0.24)	Loss 0.97 (0.92)
		cls_loss 0.44 (0.43)	reg_loss 0.26 (0.24)
Epoch: [008][00030/00231]	Time 0.20 (0.22)	Loss 0.65 (0.83)
		cls_loss 0.33 (0.40)	reg_loss 0.16 (0.22)
Epoch: [008][00040/00231]	Time 0.20 (0.22)	Loss 0.55 (0.76)
		cls_loss 0.25 (0.36)	reg_loss 0.15 (0.20)
Epoch: [008][00050/00231]	Time 0.20 (0.21)	Loss 1.05 (0.82)
		cls_loss 0.46 (0.38)	reg_loss 0.30 (0.22)
Epoch: [008][00060/00231]	Time 0.21 (0.21)	Loss 0.39 (0.75)
		cls_loss 0.17 (0.34)	reg_loss 0.11 (0.20)
Epoch: [008][00070/00231]	Time 0.22 (0.21)	Loss 0.76 (0.75)
		cls_loss 0.40 (0.35)	reg_loss 0.18 (0.20)
Epoch: [008][00080/00231]	Time 0.22 (0.22)	Loss 0.87 (0.76)
		cls_loss 0.38 (0.35)	reg_loss 0.25 (0.21)
Epoch: [008][00090/00231]	Time 0.22 (0.22)	Loss 0.88 (0.78)
		cls_loss 0.40 (0.36)	reg_loss 0.24 (0.21)
Epoch: [008][00100/00231]	Time 0.22 (0.22)	Loss 0.39 (0.74)
		cls_loss 0.18 (0.34)	reg_loss 0.11 (0.20)
Epoch: [008][00110/00231]	Time 0.22 (0.22)	Loss 0.85 (0.75)
		cls_loss 0.42 (0.35)	reg_loss 0.22 (0.20)
Epoch: [008][00120/00231]	Time 0.22 (0.22)	Loss 0.65 (0.74)
		cls_loss 0.33 (0.35)	reg_loss 0.16 (0.20)
Epoch: [008][00130/00231]	Time 0.22 (0.22)	Loss 0.81 (0.75)
		cls_loss 0.37 (0.35)	reg_loss 0.22 (0.20)
Epoch: [008][00140/00231]	Time 0.22 (0.22)	Loss 1.25 (0.78)
		cls_loss 0.57 (0.36)	reg_loss 0.34 (0.21)
Epoch: [008][00150/00231]	Time 0.22 (0.22)	Loss 0.52 (0.76)
		cls_loss 0.29 (0.36)	reg_loss 0.11 (0.20)
Epoch: [008][00160/00231]	Time 0.22 (0.22)	Loss 0.62 (0.76)
		cls_loss 0.30 (0.36)	reg_loss 0.16 (0.20)
Epoch: [008][00170/00231]	Time 0.22 (0.22)	Loss 0.92 (0.77)
		cls_loss 0.45 (0.36)	reg_loss 0.24 (0.20)
Epoch: [008][00180/00231]	Time 0.22 (0.22)	Loss 0.65 (0.76)
		cls_loss 0.32 (0.36)	reg_loss 0.16 (0.20)
Epoch: [008][00190/00231]	Time 0.23 (0.22)	Loss 0.90 (0.77)
		cls_loss 0.44 (0.36)	reg_loss 0.23 (0.20)
Epoch: [008][00200/00231]	Time 1.29 (0.27)	Loss 0.70 (0.76)
		cls_loss 0.33 (0.36)	reg_loss 0.19 (0.20)
Epoch: [008][00210/00231]	Time 0.20 (0.27)	Loss 0.85 (0.77)
		cls_loss 0.38 (0.36)	reg_loss 0.23 (0.20)
Epoch: [008][00220/00231]	Time 0.21 (0.27)	Loss 1.50 (0.80)
		cls_loss 0.71 (0.38)	reg_loss 0.39 (0.21)
Epoch: [008][00230/00231]	Time 0.17 (0.26)	Loss 0.69 (0.80)
		cls_loss 0.31 (0.38)	reg_loss 0.19 (0.21)
[Train]: Epoch 8 finished with lr=0.00065451


[Train]: Epoch 9 started
Epoch: [009][00010/00231]	Time 0.31 (0.31)	Loss 0.82 (0.82)
		cls_loss 0.36 (0.36)	reg_loss 0.23 (0.23)
Epoch: [009][00020/00231]	Time 0.21 (0.26)	Loss 0.99 (0.90)
		cls_loss 0.45 (0.40)	reg_loss 0.27 (0.25)
Epoch: [009][00030/00231]	Time 0.21 (0.25)	Loss 1.15 (0.98)
		cls_loss 0.60 (0.47)	reg_loss 0.28 (0.26)
Epoch: [009][00040/00231]	Time 0.22 (0.24)	Loss 0.69 (0.91)
		cls_loss 0.34 (0.44)	reg_loss 0.18 (0.24)
Epoch: [009][00050/00231]	Time 0.21 (0.23)	Loss 1.09 (0.95)
		cls_loss 0.53 (0.46)	reg_loss 0.28 (0.25)
Epoch: [009][00060/00231]	Time 0.21 (0.23)	Loss 0.63 (0.89)
		cls_loss 0.33 (0.43)	reg_loss 0.15 (0.23)
Epoch: [009][00070/00231]	Time 0.21 (0.23)	Loss 0.62 (0.85)
		cls_loss 0.28 (0.41)	reg_loss 0.17 (0.22)
Epoch: [009][00080/00231]	Time 1.23 (0.35)	Loss 0.80 (0.85)
		cls_loss 0.38 (0.41)	reg_loss 0.21 (0.22)
Epoch: [009][00090/00231]	Time 0.32 (0.35)	Loss 0.60 (0.82)
		cls_loss 0.31 (0.40)	reg_loss 0.15 (0.21)
Epoch: [009][00100/00231]	Time 0.21 (0.33)	Loss 0.92 (0.83)
		cls_loss 0.38 (0.39)	reg_loss 0.27 (0.22)
Epoch: [009][00110/00231]	Time 0.21 (0.32)	Loss 0.98 (0.85)
		cls_loss 0.43 (0.40)	reg_loss 0.28 (0.22)
Epoch: [009][00120/00231]	Time 0.20 (0.31)	Loss 0.52 (0.82)
		cls_loss 0.24 (0.38)	reg_loss 0.14 (0.22)
Epoch: [009][00130/00231]	Time 0.21 (0.30)	Loss 0.76 (0.81)
		cls_loss 0.34 (0.38)	reg_loss 0.21 (0.22)
Epoch: [009][00140/00231]	Time 0.20 (0.30)	Loss 0.56 (0.80)
		cls_loss 0.26 (0.37)	reg_loss 0.15 (0.21)
Epoch: [009][00150/00231]	Time 0.21 (0.29)	Loss 0.36 (0.77)
		cls_loss 0.20 (0.36)	reg_loss 0.08 (0.20)
Epoch: [009][00160/00231]	Time 0.20 (0.29)	Loss 0.56 (0.75)
		cls_loss 0.30 (0.36)	reg_loss 0.13 (0.20)
Epoch: [009][00170/00231]	Time 0.21 (0.28)	Loss 0.92 (0.76)
		cls_loss 0.42 (0.36)	reg_loss 0.25 (0.20)
Epoch: [009][00180/00231]	Time 0.22 (0.28)	Loss 0.76 (0.76)
		cls_loss 0.34 (0.36)	reg_loss 0.21 (0.20)
Epoch: [009][00190/00231]	Time 0.21 (0.27)	Loss 0.69 (0.76)
		cls_loss 0.35 (0.36)	reg_loss 0.17 (0.20)
Epoch: [009][00200/00231]	Time 0.22 (0.27)	Loss 0.86 (0.76)
		cls_loss 0.39 (0.36)	reg_loss 0.23 (0.20)
Epoch: [009][00210/00231]	Time 0.22 (0.27)	Loss 0.69 (0.76)
		cls_loss 0.34 (0.36)	reg_loss 0.17 (0.20)
Epoch: [009][00220/00231]	Time 0.22 (0.27)	Loss 0.85 (0.76)
		cls_loss 0.38 (0.36)	reg_loss 0.24 (0.20)
Epoch: [009][00230/00231]	Time 0.18 (0.26)	Loss 0.59 (0.76)
		cls_loss 0.30 (0.36)	reg_loss 0.15 (0.20)
[Train]: Epoch 9 finished with lr=0.00050001


[Train]: Epoch 10 started
Epoch: [010][00010/00231]	Time 0.26 (0.26)	Loss 0.88 (0.88)
		cls_loss 0.42 (0.42)	reg_loss 0.23 (0.23)
Epoch: [010][00020/00231]	Time 0.20 (0.23)	Loss 0.58 (0.73)
		cls_loss 0.30 (0.36)	reg_loss 0.14 (0.19)
Epoch: [010][00030/00231]	Time 0.20 (0.22)	Loss 1.38 (0.95)
		cls_loss 0.60 (0.44)	reg_loss 0.39 (0.25)
Epoch: [010][00040/00231]	Time 0.19 (0.21)	Loss 0.94 (0.94)
		cls_loss 0.46 (0.44)	reg_loss 0.24 (0.25)
Epoch: [010][00050/00231]	Time 0.20 (0.21)	Loss 0.68 (0.89)
		cls_loss 0.33 (0.42)	reg_loss 0.17 (0.24)
Epoch: [010][00060/00231]	Time 0.20 (0.21)	Loss 0.82 (0.88)
		cls_loss 0.40 (0.42)	reg_loss 0.21 (0.23)
Epoch: [010][00070/00231]	Time 0.22 (0.21)	Loss 0.78 (0.87)
		cls_loss 0.37 (0.41)	reg_loss 0.20 (0.23)
Epoch: [010][00080/00231]	Time 0.22 (0.21)	Loss 0.55 (0.83)
		cls_loss 0.30 (0.40)	reg_loss 0.12 (0.21)
Epoch: [010][00090/00231]	Time 0.22 (0.21)	Loss 0.92 (0.84)
		cls_loss 0.44 (0.40)	reg_loss 0.24 (0.22)
Epoch: [010][00100/00231]	Time 0.22 (0.21)	Loss 0.48 (0.80)
		cls_loss 0.25 (0.39)	reg_loss 0.12 (0.21)
Epoch: [010][00110/00231]	Time 0.22 (0.21)	Loss 0.70 (0.79)
		cls_loss 0.33 (0.38)	reg_loss 0.19 (0.21)
Epoch: [010][00120/00231]	Time 0.22 (0.21)	Loss 0.85 (0.80)
		cls_loss 0.39 (0.38)	reg_loss 0.23 (0.21)
Epoch: [010][00130/00231]	Time 0.22 (0.21)	Loss 1.36 (0.84)
		cls_loss 0.56 (0.40)	reg_loss 0.40 (0.22)
Epoch: [010][00140/00231]	Time 0.22 (0.21)	Loss 0.88 (0.84)
		cls_loss 0.41 (0.40)	reg_loss 0.24 (0.22)
Epoch: [010][00150/00231]	Time 0.22 (0.21)	Loss 0.51 (0.82)
		cls_loss 0.25 (0.39)	reg_loss 0.13 (0.22)
Epoch: [010][00160/00231]	Time 0.22 (0.21)	Loss 0.35 (0.79)
		cls_loss 0.18 (0.37)	reg_loss 0.09 (0.21)
Epoch: [010][00170/00231]	Time 0.22 (0.21)	Loss 0.71 (0.79)
		cls_loss 0.29 (0.37)	reg_loss 0.21 (0.21)
Epoch: [010][00180/00231]	Time 0.22 (0.21)	Loss 0.79 (0.79)
		cls_loss 0.31 (0.37)	reg_loss 0.24 (0.21)
Epoch: [010][00190/00231]	Time 0.22 (0.21)	Loss 0.58 (0.78)
		cls_loss 0.28 (0.36)	reg_loss 0.15 (0.21)
Epoch: [010][00200/00231]	Time 0.22 (0.21)	Loss 1.02 (0.79)
		cls_loss 0.49 (0.37)	reg_loss 0.27 (0.21)
Epoch: [010][00210/00231]	Time 0.22 (0.21)	Loss 0.74 (0.79)
		cls_loss 0.35 (0.37)	reg_loss 0.19 (0.21)
Epoch: [010][00220/00231]	Time 0.22 (0.22)	Loss 0.93 (0.79)
		cls_loss 0.46 (0.37)	reg_loss 0.24 (0.21)
Epoch: [010][00230/00231]	Time 0.18 (0.21)	Loss 0.61 (0.78)
		cls_loss 0.30 (0.37)	reg_loss 0.15 (0.21)
[Train]: Epoch 10 finished with lr=0.00034550


[Train]: Epoch 11 started
Epoch: [011][00010/00231]	Time 0.24 (0.24)	Loss 1.25 (1.25)
		cls_loss 0.55 (0.55)	reg_loss 0.35 (0.35)
Epoch: [011][00020/00231]	Time 0.20 (0.22)	Loss 0.46 (0.86)
		cls_loss 0.24 (0.39)	reg_loss 0.11 (0.23)
Epoch: [011][00030/00231]	Time 0.21 (0.22)	Loss 0.53 (0.75)
		cls_loss 0.27 (0.35)	reg_loss 0.13 (0.20)
Epoch: [011][00040/00231]	Time 0.21 (0.22)	Loss 0.37 (0.65)
		cls_loss 0.20 (0.31)	reg_loss 0.08 (0.17)
Epoch: [011][00050/00231]	Time 0.20 (0.21)	Loss 0.67 (0.66)
		cls_loss 0.37 (0.32)	reg_loss 0.15 (0.17)
Epoch: [011][00060/00231]	Time 0.21 (0.21)	Loss 0.79 (0.68)
		cls_loss 0.38 (0.33)	reg_loss 0.21 (0.17)
Epoch: [011][00070/00231]	Time 0.22 (0.21)	Loss 0.52 (0.66)
		cls_loss 0.21 (0.32)	reg_loss 0.15 (0.17)
Epoch: [011][00080/00231]	Time 0.22 (0.21)	Loss 0.70 (0.66)
		cls_loss 0.36 (0.32)	reg_loss 0.17 (0.17)
Epoch: [011][00090/00231]	Time 0.22 (0.21)	Loss 0.70 (0.67)
		cls_loss 0.34 (0.32)	reg_loss 0.18 (0.17)
Epoch: [011][00100/00231]	Time 0.22 (0.21)	Loss 0.86 (0.69)
		cls_loss 0.39 (0.33)	reg_loss 0.23 (0.18)
Epoch: [011][00110/00231]	Time 0.22 (0.21)	Loss 0.43 (0.66)
		cls_loss 0.24 (0.32)	reg_loss 0.09 (0.17)
Epoch: [011][00120/00231]	Time 0.22 (0.21)	Loss 0.46 (0.65)
		cls_loss 0.24 (0.32)	reg_loss 0.11 (0.17)
Epoch: [011][00130/00231]	Time 0.22 (0.22)	Loss 0.63 (0.64)
		cls_loss 0.33 (0.32)	reg_loss 0.15 (0.16)
Epoch: [011][00140/00231]	Time 0.22 (0.22)	Loss 1.02 (0.67)
		cls_loss 0.49 (0.33)	reg_loss 0.26 (0.17)
Epoch: [011][00150/00231]	Time 0.22 (0.22)	Loss 0.64 (0.67)
		cls_loss 0.32 (0.33)	reg_loss 0.16 (0.17)
Epoch: [011][00160/00231]	Time 0.22 (0.22)	Loss 0.67 (0.67)
		cls_loss 0.33 (0.33)	reg_loss 0.17 (0.17)
Epoch: [011][00170/00231]	Time 0.21 (0.22)	Loss 0.63 (0.67)
		cls_loss 0.31 (0.33)	reg_loss 0.16 (0.17)
Epoch: [011][00180/00231]	Time 0.21 (0.22)	Loss 1.08 (0.69)
		cls_loss 0.49 (0.34)	reg_loss 0.30 (0.18)
Epoch: [011][00190/00231]	Time 0.22 (0.22)	Loss 0.38 (0.67)
		cls_loss 0.22 (0.33)	reg_loss 0.08 (0.17)
Epoch: [011][00200/00231]	Time 0.22 (0.22)	Loss 0.97 (0.69)
		cls_loss 0.50 (0.34)	reg_loss 0.24 (0.18)
Epoch: [011][00210/00231]	Time 0.22 (0.22)	Loss 0.36 (0.67)
		cls_loss 0.19 (0.33)	reg_loss 0.08 (0.17)
Epoch: [011][00220/00231]	Time 0.22 (0.22)	Loss 0.97 (0.69)
		cls_loss 0.43 (0.34)	reg_loss 0.27 (0.18)
Epoch: [011][00230/00231]	Time 0.18 (0.21)	Loss 0.68 (0.69)
		cls_loss 0.34 (0.34)	reg_loss 0.17 (0.18)
[Train]: Epoch 11 finished with lr=0.00020612


[Train]: Epoch 12 started
Epoch: [012][00010/00231]	Time 0.25 (0.25)	Loss 0.63 (0.63)
		cls_loss 0.32 (0.32)	reg_loss 0.16 (0.16)
Epoch: [012][00020/00231]	Time 0.20 (0.22)	Loss 1.32 (0.98)
		cls_loss 0.53 (0.42)	reg_loss 0.40 (0.28)
Epoch: [012][00030/00231]	Time 0.20 (0.22)	Loss 0.78 (0.91)
		cls_loss 0.39 (0.41)	reg_loss 0.20 (0.25)
Epoch: [012][00040/00231]	Time 0.22 (0.22)	Loss 0.69 (0.86)
		cls_loss 0.31 (0.38)	reg_loss 0.19 (0.24)
Epoch: [012][00050/00231]	Time 0.22 (0.22)	Loss 0.77 (0.84)
		cls_loss 0.33 (0.37)	reg_loss 0.22 (0.23)
Epoch: [012][00060/00231]	Time 0.22 (0.22)	Loss 0.35 (0.76)
		cls_loss 0.18 (0.34)	reg_loss 0.08 (0.21)
Epoch: [012][00070/00231]	Time 0.22 (0.22)	Loss 0.61 (0.74)
		cls_loss 0.28 (0.33)	reg_loss 0.17 (0.20)
Epoch: [012][00080/00231]	Time 0.22 (0.22)	Loss 0.57 (0.72)
		cls_loss 0.29 (0.33)	reg_loss 0.14 (0.19)
Epoch: [012][00090/00231]	Time 1.82 (0.39)	Loss 0.61 (0.70)
		cls_loss 0.30 (0.32)	reg_loss 0.16 (0.19)
Epoch: [012][00100/00231]	Time 1.19 (0.47)	Loss 0.36 (0.67)
		cls_loss 0.18 (0.31)	reg_loss 0.09 (0.18)
Epoch: [012][00110/00231]	Time 0.61 (0.49)	Loss 0.66 (0.67)
		cls_loss 0.31 (0.31)	reg_loss 0.17 (0.18)
Epoch: [012][00120/00231]	Time 0.22 (0.46)	Loss 0.75 (0.68)
		cls_loss 0.38 (0.32)	reg_loss 0.19 (0.18)
Epoch: [012][00130/00231]	Time 0.22 (0.45)	Loss 0.67 (0.67)
		cls_loss 0.34 (0.32)	reg_loss 0.17 (0.18)
Epoch: [012][00140/00231]	Time 0.22 (0.43)	Loss 0.92 (0.69)
		cls_loss 0.49 (0.33)	reg_loss 0.21 (0.18)
Epoch: [012][00150/00231]	Time 0.22 (0.42)	Loss 1.04 (0.72)
		cls_loss 0.46 (0.34)	reg_loss 0.29 (0.19)
Epoch: [012][00160/00231]	Time 0.22 (0.40)	Loss 1.50 (0.76)
		cls_loss 0.66 (0.36)	reg_loss 0.42 (0.20)
Epoch: [012][00170/00231]	Time 0.22 (0.39)	Loss 0.71 (0.76)
		cls_loss 0.35 (0.36)	reg_loss 0.18 (0.20)
Epoch: [012][00180/00231]	Time 0.22 (0.38)	Loss 0.68 (0.76)
		cls_loss 0.33 (0.36)	reg_loss 0.17 (0.20)
Epoch: [012][00190/00231]	Time 0.22 (0.37)	Loss 0.44 (0.74)
		cls_loss 0.21 (0.35)	reg_loss 0.12 (0.20)
Epoch: [012][00200/00231]	Time 0.22 (0.37)	Loss 0.90 (0.75)
		cls_loss 0.43 (0.35)	reg_loss 0.23 (0.20)
Epoch: [012][00210/00231]	Time 0.21 (0.36)	Loss 0.54 (0.74)
		cls_loss 0.27 (0.35)	reg_loss 0.13 (0.19)
Epoch: [012][00220/00231]	Time 0.22 (0.35)	Loss 0.40 (0.72)
		cls_loss 0.21 (0.34)	reg_loss 0.10 (0.19)
Epoch: [012][00230/00231]	Time 0.18 (0.34)	Loss 0.50 (0.71)
		cls_loss 0.25 (0.34)	reg_loss 0.13 (0.19)
[Train]: Epoch 12 finished with lr=0.00009550


[Train]: Epoch 13 started
Epoch: [013][00010/00231]	Time 0.26 (0.26)	Loss 0.62 (0.62)
		cls_loss 0.28 (0.28)	reg_loss 0.17 (0.17)
Epoch: [013][00020/00231]	Time 0.21 (0.24)	Loss 0.75 (0.68)
		cls_loss 0.35 (0.31)	reg_loss 0.20 (0.18)
Epoch: [013][00030/00231]	Time 0.22 (0.23)	Loss 0.54 (0.64)
		cls_loss 0.28 (0.30)	reg_loss 0.13 (0.17)
Epoch: [013][00040/00231]	Time 0.22 (0.23)	Loss 0.65 (0.64)
		cls_loss 0.32 (0.31)	reg_loss 0.16 (0.17)
Epoch: [013][00050/00231]	Time 0.22 (0.22)	Loss 0.41 (0.59)
		cls_loss 0.20 (0.29)	reg_loss 0.10 (0.15)
Epoch: [013][00060/00231]	Time 0.21 (0.22)	Loss 0.88 (0.64)
		cls_loss 0.42 (0.31)	reg_loss 0.23 (0.17)
Epoch: [013][00070/00231]	Time 0.22 (0.22)	Loss 0.54 (0.63)
		cls_loss 0.25 (0.30)	reg_loss 0.15 (0.16)
Epoch: [013][00080/00231]	Time 0.22 (0.22)	Loss 0.52 (0.61)
		cls_loss 0.27 (0.30)	reg_loss 0.13 (0.16)
Epoch: [013][00090/00231]	Time 0.22 (0.22)	Loss 0.49 (0.60)
		cls_loss 0.28 (0.29)	reg_loss 0.11 (0.15)
Epoch: [013][00100/00231]	Time 0.22 (0.22)	Loss 0.78 (0.62)
		cls_loss 0.37 (0.30)	reg_loss 0.21 (0.16)
Epoch: [013][00110/00231]	Time 0.21 (0.22)	Loss 0.82 (0.64)
		cls_loss 0.42 (0.31)	reg_loss 0.20 (0.16)
Epoch: [013][00120/00231]	Time 0.22 (0.22)	Loss 0.52 (0.63)
		cls_loss 0.25 (0.31)	reg_loss 0.14 (0.16)
Epoch: [013][00130/00231]	Time 0.21 (0.22)	Loss 0.54 (0.62)
		cls_loss 0.28 (0.30)	reg_loss 0.13 (0.16)
Epoch: [013][00140/00231]	Time 0.22 (0.22)	Loss 0.91 (0.64)
		cls_loss 0.36 (0.31)	reg_loss 0.28 (0.17)
Epoch: [013][00150/00231]	Time 0.21 (0.22)	Loss 0.36 (0.62)
		cls_loss 0.18 (0.30)	reg_loss 0.09 (0.16)
Epoch: [013][00160/00231]	Time 0.22 (0.22)	Loss 0.44 (0.61)
		cls_loss 0.23 (0.29)	reg_loss 0.11 (0.16)
Epoch: [013][00170/00231]	Time 0.22 (0.22)	Loss 0.51 (0.60)
		cls_loss 0.25 (0.29)	reg_loss 0.13 (0.16)
Epoch: [013][00180/00231]	Time 0.22 (0.22)	Loss 0.75 (0.61)
		cls_loss 0.38 (0.30)	reg_loss 0.18 (0.16)
Epoch: [013][00190/00231]	Time 0.22 (0.22)	Loss 0.63 (0.61)
		cls_loss 0.30 (0.30)	reg_loss 0.17 (0.16)
Epoch: [013][00200/00231]	Time 0.22 (0.22)	Loss 0.68 (0.62)
		cls_loss 0.32 (0.30)	reg_loss 0.18 (0.16)
Epoch: [013][00210/00231]	Time 0.22 (0.22)	Loss 0.72 (0.62)
		cls_loss 0.36 (0.30)	reg_loss 0.18 (0.16)
Epoch: [013][00220/00231]	Time 0.22 (0.22)	Loss 1.55 (0.66)
		cls_loss 0.64 (0.32)	reg_loss 0.46 (0.17)
Epoch: [013][00230/00231]	Time 0.18 (0.22)	Loss 0.79 (0.67)
		cls_loss 0.35 (0.32)	reg_loss 0.22 (0.18)
[Train]: Epoch 13 finished with lr=0.00002448


[Train]: Epoch 14 started
Epoch: [014][00010/00231]	Time 0.25 (0.25)	Loss 0.73 (0.73)
		cls_loss 0.33 (0.33)	reg_loss 0.20 (0.20)
Epoch: [014][00020/00231]	Time 0.20 (0.23)	Loss 0.61 (0.67)
		cls_loss 0.31 (0.32)	reg_loss 0.15 (0.17)
Epoch: [014][00030/00231]	Time 0.21 (0.22)	Loss 0.77 (0.70)
		cls_loss 0.33 (0.32)	reg_loss 0.22 (0.19)
Epoch: [014][00040/00231]	Time 0.22 (0.22)	Loss 1.12 (0.81)
		cls_loss 0.51 (0.37)	reg_loss 0.30 (0.22)
Epoch: [014][00050/00231]	Time 0.22 (0.22)	Loss 1.27 (0.90)
		cls_loss 0.62 (0.42)	reg_loss 0.32 (0.24)
Epoch: [014][00060/00231]	Time 0.21 (0.22)	Loss 0.29 (0.80)
		cls_loss 0.16 (0.38)	reg_loss 0.06 (0.21)
Epoch: [014][00070/00231]	Time 0.22 (0.22)	Loss 0.94 (0.82)
		cls_loss 0.45 (0.39)	reg_loss 0.25 (0.21)
Epoch: [014][00080/00231]	Time 0.21 (0.22)	Loss 0.68 (0.80)
		cls_loss 0.36 (0.38)	reg_loss 0.16 (0.21)
Epoch: [014][00090/00231]	Time 0.22 (0.22)	Loss 0.97 (0.82)
		cls_loss 0.50 (0.40)	reg_loss 0.24 (0.21)
Epoch: [014][00100/00231]	Time 0.22 (0.22)	Loss 0.65 (0.80)
		cls_loss 0.32 (0.39)	reg_loss 0.16 (0.21)
Epoch: [014][00110/00231]	Time 0.22 (0.22)	Loss 0.89 (0.81)
		cls_loss 0.45 (0.39)	reg_loss 0.22 (0.21)
Epoch: [014][00120/00231]	Time 0.22 (0.22)	Loss 0.39 (0.78)
		cls_loss 0.21 (0.38)	reg_loss 0.09 (0.20)
Epoch: [014][00130/00231]	Time 0.22 (0.22)	Loss 0.57 (0.76)
		cls_loss 0.30 (0.37)	reg_loss 0.13 (0.19)
Epoch: [014][00140/00231]	Time 0.22 (0.22)	Loss 0.39 (0.73)
		cls_loss 0.20 (0.36)	reg_loss 0.10 (0.19)
Epoch: [014][00150/00231]	Time 0.22 (0.22)	Loss 0.66 (0.73)
		cls_loss 0.31 (0.36)	reg_loss 0.17 (0.19)
Epoch: [014][00160/00231]	Time 0.22 (0.22)	Loss 0.74 (0.73)
		cls_loss 0.31 (0.35)	reg_loss 0.21 (0.19)
Epoch: [014][00170/00231]	Time 0.22 (0.22)	Loss 0.67 (0.73)
		cls_loss 0.30 (0.35)	reg_loss 0.18 (0.19)
Epoch: [014][00180/00231]	Time 0.22 (0.22)	Loss 0.47 (0.71)
		cls_loss 0.25 (0.35)	reg_loss 0.11 (0.18)
Epoch: [014][00190/00231]	Time 0.22 (0.22)	Loss 0.72 (0.71)
		cls_loss 0.33 (0.35)	reg_loss 0.20 (0.18)
Epoch: [014][00200/00231]	Time 0.22 (0.22)	Loss 0.71 (0.71)
		cls_loss 0.35 (0.35)	reg_loss 0.18 (0.18)
Epoch: [014][00210/00231]	Time 0.22 (0.22)	Loss 0.55 (0.70)
		cls_loss 0.28 (0.34)	reg_loss 0.14 (0.18)
Epoch: [014][00220/00231]	Time 0.22 (0.22)	Loss 0.70 (0.70)
		cls_loss 0.32 (0.34)	reg_loss 0.19 (0.18)
Epoch: [014][00230/00231]	Time 0.18 (0.22)	Loss 0.99 (0.72)
		cls_loss 0.44 (0.35)	reg_loss 0.27 (0.19)
[Train]: Epoch 14 finished with lr=0.00000001

All done!
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
=> loading checkpoint './ckpt/anet_i3d_reproduce/epoch_015.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/04555]	Time 0.53 (0.53)
Test: [00020/04555]	Time 0.04 (0.28)
Test: [00030/04555]	Time 0.12 (0.23)
Test: [00040/04555]	Time 0.05 (0.18)
Test: [00050/04555]	Time 0.07 (0.16)
Test: [00060/04555]	Time 0.06 (0.15)
Test: [00070/04555]	Time 0.06 (0.13)
Test: [00080/04555]	Time 0.04 (0.12)
Test: [00090/04555]	Time 0.04 (0.11)
Test: [00100/04555]	Time 0.06 (0.11)
Test: [00110/04555]	Time 0.04 (0.10)
Test: [00120/04555]	Time 0.04 (0.10)
Test: [00130/04555]	Time 0.04 (0.09)
Test: [00140/04555]	Time 0.04 (0.09)
Test: [00150/04555]	Time 0.07 (0.09)
Test: [00160/04555]	Time 0.07 (0.09)
Test: [00170/04555]	Time 0.08 (0.08)
Test: [00180/04555]	Time 0.04 (0.08)
Test: [00190/04555]	Time 0.04 (0.08)
Test: [00200/04555]	Time 0.05 (0.08)
Test: [00210/04555]	Time 0.08 (0.08)
Test: [00220/04555]	Time 0.04 (0.08)
Test: [00230/04555]	Time 0.08 (0.08)
Test: [00240/04555]	Time 0.04 (0.07)
Test: [00250/04555]	Time 0.04 (0.07)
Test: [00260/04555]	Time 0.04 (0.07)
Test: [00270/04555]	Time 0.06 (0.07)
Test: [00280/04555]	Time 0.04 (0.07)
Test: [00290/04555]	Time 0.06 (0.07)
Test: [00300/04555]	Time 0.05 (0.07)
Test: [00310/04555]	Time 0.04 (0.07)
Test: [00320/04555]	Time 0.04 (0.07)
Test: [00330/04555]	Time 0.04 (0.07)
Test: [00340/04555]	Time 0.04 (0.07)
Test: [00350/04555]	Time 0.04 (0.06)
Test: [00360/04555]	Time 0.04 (0.06)
Test: [00370/04555]	Time 0.04 (0.06)
Test: [00380/04555]	Time 0.04 (0.06)
Test: [00390/04555]	Time 0.04 (0.06)
Test: [00400/04555]	Time 0.04 (0.06)
Test: [00410/04555]	Time 0.04 (0.06)
Test: [00420/04555]	Time 0.08 (0.06)
Test: [00430/04555]	Time 0.04 (0.06)
Test: [00440/04555]	Time 0.04 (0.06)
Test: [00450/04555]	Time 0.14 (0.06)
Test: [00460/04555]	Time 0.24 (0.07)
Test: [00470/04555]	Time 0.29 (0.07)
Test: [00480/04555]	Time 0.34 (0.08)
Test: [00490/04555]	Time 0.18 (0.08)
Test: [00500/04555]	Time 0.04 (0.08)
Test: [00510/04555]	Time 0.06 (0.08)
Test: [00520/04555]	Time 0.05 (0.08)
Test: [00530/04555]	Time 0.31 (0.08)
Test: [00540/04555]	Time 0.14 (0.08)
Test: [00550/04555]	Time 0.12 (0.08)
Test: [00560/04555]	Time 0.05 (0.08)
Test: [00570/04555]	Time 0.04 (0.08)
Test: [00580/04555]	Time 0.04 (0.08)
Test: [00590/04555]	Time 0.04 (0.08)
Test: [00600/04555]	Time 0.04 (0.08)
Test: [00610/04555]	Time 0.04 (0.08)
Test: [00620/04555]	Time 0.04 (0.08)
Test: [00630/04555]	Time 0.10 (0.08)
Test: [00640/04555]	Time 0.04 (0.08)
Test: [00650/04555]	Time 0.04 (0.08)
Test: [00660/04555]	Time 0.04 (0.08)
Test: [00670/04555]	Time 0.11 (0.08)
Test: [00680/04555]	Time 0.24 (0.08)
Test: [00690/04555]	Time 0.24 (0.08)
Test: [00700/04555]	Time 0.24 (0.08)
Test: [00710/04555]	Time 0.07 (0.08)
Test: [00720/04555]	Time 0.04 (0.08)
Test: [00730/04555]	Time 0.04 (0.08)
Test: [00740/04555]	Time 0.04 (0.08)
Test: [00750/04555]	Time 0.04 (0.08)
Test: [00760/04555]	Time 0.04 (0.08)
Test: [00770/04555]	Time 0.06 (0.08)
Test: [00780/04555]	Time 0.10 (0.08)
Test: [00790/04555]	Time 0.04 (0.08)
Test: [00800/04555]	Time 0.04 (0.08)
Test: [00810/04555]	Time 0.12 (0.08)
Test: [00820/04555]	Time 0.05 (0.08)
Test: [00830/04555]	Time 0.04 (0.08)
Test: [00840/04555]	Time 0.04 (0.08)
Test: [00850/04555]	Time 0.04 (0.08)
Test: [00860/04555]	Time 0.04 (0.08)
Test: [00870/04555]	Time 0.04 (0.08)
Test: [00880/04555]	Time 0.04 (0.08)
Test: [00890/04555]	Time 0.07 (0.08)
Test: [00900/04555]	Time 0.04 (0.08)
Test: [00910/04555]	Time 0.04 (0.08)
Test: [00920/04555]	Time 0.04 (0.08)
Test: [00930/04555]	Time 0.04 (0.08)
Test: [00940/04555]	Time 0.04 (0.07)
Test: [00950/04555]	Time 0.04 (0.07)
Test: [00960/04555]	Time 0.04 (0.07)
Test: [00970/04555]	Time 0.04 (0.07)
Test: [00980/04555]	Time 0.04 (0.07)
Test: [00990/04555]	Time 0.04 (0.07)
Test: [01000/04555]	Time 0.04 (0.07)
Test: [01010/04555]	Time 0.04 (0.07)
Test: [01020/04555]	Time 0.04 (0.07)
Test: [01030/04555]	Time 0.04 (0.07)
Test: [01040/04555]	Time 0.04 (0.07)
Test: [01050/04555]	Time 0.04 (0.07)
Test: [01060/04555]	Time 0.04 (0.07)
Test: [01070/04555]	Time 0.04 (0.07)
Test: [01080/04555]	Time 0.04 (0.07)
Test: [01090/04555]	Time 0.22 (0.07)
Test: [01100/04555]	Time 0.24 (0.07)
Test: [01110/04555]	Time 0.24 (0.07)
Test: [01120/04555]	Time 0.24 (0.08)
Test: [01130/04555]	Time 0.20 (0.08)
Test: [01140/04555]	Time 0.04 (0.08)
Test: [01150/04555]	Time 0.04 (0.08)
Test: [01160/04555]	Time 0.04 (0.08)
Test: [01170/04555]	Time 0.04 (0.08)
Test: [01180/04555]	Time 0.04 (0.08)
Test: [01190/04555]	Time 0.04 (0.08)
Test: [01200/04555]	Time 0.04 (0.07)
Test: [01210/04555]	Time 0.04 (0.07)
Test: [01220/04555]	Time 0.04 (0.07)
Test: [01230/04555]	Time 0.04 (0.07)
Test: [01240/04555]	Time 0.04 (0.07)
Test: [01250/04555]	Time 0.04 (0.07)
Test: [01260/04555]	Time 0.04 (0.07)
Test: [01270/04555]	Time 0.04 (0.07)
Test: [01280/04555]	Time 0.04 (0.07)
Test: [01290/04555]	Time 0.04 (0.07)
Test: [01300/04555]	Time 0.04 (0.07)
Test: [01310/04555]	Time 0.04 (0.07)
Test: [01320/04555]	Time 0.04 (0.07)
Test: [01330/04555]	Time 0.04 (0.07)
Test: [01340/04555]	Time 0.04 (0.07)
Test: [01350/04555]	Time 0.04 (0.07)
Test: [01360/04555]	Time 0.04 (0.07)
Test: [01370/04555]	Time 0.04 (0.07)
Test: [01380/04555]	Time 0.04 (0.07)
Test: [01390/04555]	Time 0.04 (0.07)
Test: [01400/04555]	Time 0.04 (0.07)
Test: [01410/04555]	Time 0.04 (0.07)
Test: [01420/04555]	Time 0.04 (0.07)
Test: [01430/04555]	Time 0.04 (0.07)
Test: [01440/04555]	Time 0.04 (0.07)
Test: [01450/04555]	Time 0.08 (0.07)
Test: [01460/04555]	Time 0.04 (0.07)
Test: [01470/04555]	Time 0.04 (0.07)
Test: [01480/04555]	Time 0.04 (0.07)
Test: [01490/04555]	Time 0.04 (0.07)
Test: [01500/04555]	Time 0.04 (0.07)
Test: [01510/04555]	Time 0.04 (0.07)
Test: [01520/04555]	Time 0.04 (0.07)
Test: [01530/04555]	Time 0.04 (0.07)
Test: [01540/04555]	Time 0.04 (0.07)
Test: [01550/04555]	Time 0.04 (0.07)
Test: [01560/04555]	Time 0.04 (0.07)
Test: [01570/04555]	Time 0.04 (0.07)
Test: [01580/04555]	Time 0.04 (0.07)
Test: [01590/04555]	Time 0.04 (0.07)
Test: [01600/04555]	Time 0.04 (0.07)
Test: [01610/04555]	Time 0.04 (0.07)
Test: [01620/04555]	Time 0.04 (0.07)
Test: [01630/04555]	Time 0.04 (0.07)
Test: [01640/04555]	Time 0.04 (0.06)
Test: [01650/04555]	Time 0.04 (0.06)
Test: [01660/04555]	Time 0.04 (0.06)
Test: [01670/04555]	Time 0.04 (0.06)
Test: [01680/04555]	Time 0.04 (0.06)
Test: [01690/04555]	Time 0.06 (0.06)
Test: [01700/04555]	Time 0.04 (0.06)
Test: [01710/04555]	Time 0.04 (0.06)
Test: [01720/04555]	Time 0.04 (0.06)
Test: [01730/04555]	Time 0.04 (0.06)
Test: [01740/04555]	Time 0.04 (0.06)
Test: [01750/04555]	Time 0.04 (0.06)
Test: [01760/04555]	Time 0.04 (0.06)
Test: [01770/04555]	Time 0.04 (0.06)
Test: [01780/04555]	Time 0.04 (0.06)
Test: [01790/04555]	Time 0.04 (0.06)
Test: [01800/04555]	Time 0.04 (0.06)
Test: [01810/04555]	Time 0.04 (0.06)
Test: [01820/04555]	Time 0.04 (0.06)
Test: [01830/04555]	Time 0.06 (0.06)
Test: [01840/04555]	Time 0.07 (0.06)
Test: [01850/04555]	Time 0.04 (0.06)
Test: [01860/04555]	Time 0.04 (0.06)
Test: [01870/04555]	Time 0.04 (0.06)
Test: [01880/04555]	Time 0.04 (0.06)
Test: [01890/04555]	Time 0.04 (0.06)
Test: [01900/04555]	Time 0.04 (0.06)
Test: [01910/04555]	Time 0.04 (0.06)
Test: [01920/04555]	Time 0.04 (0.06)
Test: [01930/04555]	Time 0.04 (0.06)
Test: [01940/04555]	Time 0.04 (0.06)
Test: [01950/04555]	Time 0.04 (0.06)
Test: [01960/04555]	Time 0.04 (0.06)
Test: [01970/04555]	Time 0.04 (0.06)
Test: [01980/04555]	Time 0.04 (0.06)
Test: [01990/04555]	Time 0.04 (0.06)
Test: [02000/04555]	Time 0.04 (0.06)
Test: [02010/04555]	Time 0.04 (0.06)
Test: [02020/04555]	Time 0.04 (0.06)
Test: [02030/04555]	Time 0.04 (0.06)
Test: [02040/04555]	Time 0.04 (0.06)
Test: [02050/04555]	Time 0.04 (0.06)
Test: [02060/04555]	Time 0.04 (0.06)
Test: [02070/04555]	Time 0.04 (0.06)
Test: [02080/04555]	Time 0.04 (0.06)
Test: [02090/04555]	Time 0.04 (0.06)
Test: [02100/04555]	Time 0.06 (0.06)
Test: [02110/04555]	Time 0.04 (0.06)
Test: [02120/04555]	Time 0.04 (0.06)
Test: [02130/04555]	Time 0.04 (0.06)
Test: [02140/04555]	Time 0.04 (0.06)
Test: [02150/04555]	Time 0.04 (0.06)
Test: [02160/04555]	Time 0.04 (0.06)
Test: [02170/04555]	Time 0.04 (0.06)
Test: [02180/04555]	Time 0.04 (0.06)
Test: [02190/04555]	Time 0.05 (0.06)
Test: [02200/04555]	Time 0.04 (0.06)
Test: [02210/04555]	Time 0.04 (0.06)
Test: [02220/04555]	Time 0.04 (0.06)
Test: [02230/04555]	Time 0.04 (0.06)
Test: [02240/04555]	Time 0.04 (0.06)
Test: [02250/04555]	Time 0.04 (0.06)
Test: [02260/04555]	Time 0.04 (0.06)
Test: [02270/04555]	Time 0.07 (0.06)
Test: [02280/04555]	Time 0.11 (0.06)
Test: [02290/04555]	Time 0.04 (0.06)
Test: [02300/04555]	Time 0.04 (0.06)
Test: [02310/04555]	Time 0.04 (0.06)
Test: [02320/04555]	Time 0.04 (0.06)
Test: [02330/04555]	Time 0.04 (0.06)
Test: [02340/04555]	Time 0.04 (0.06)
Test: [02350/04555]	Time 0.04 (0.06)
Test: [02360/04555]	Time 0.04 (0.06)
Test: [02370/04555]	Time 0.05 (0.06)
Test: [02380/04555]	Time 0.11 (0.06)
Test: [02390/04555]	Time 0.05 (0.06)
Test: [02400/04555]	Time 0.11 (0.06)
Test: [02410/04555]	Time 0.04 (0.06)
Test: [02420/04555]	Time 0.12 (0.06)
Test: [02430/04555]	Time 0.06 (0.06)
Test: [02440/04555]	Time 0.04 (0.06)
Test: [02450/04555]	Time 0.04 (0.06)
Test: [02460/04555]	Time 1.74 (0.07)
Test: [02470/04555]	Time 0.21 (0.07)
Test: [02480/04555]	Time 0.33 (0.07)
Test: [02490/04555]	Time 0.39 (0.07)
Test: [02500/04555]	Time 0.08 (0.07)
Test: [02510/04555]	Time 0.04 (0.07)
Test: [02520/04555]	Time 0.12 (0.07)
Test: [02530/04555]	Time 0.24 (0.07)
Test: [02540/04555]	Time 0.26 (0.07)
Test: [02550/04555]	Time 0.14 (0.07)
Test: [02560/04555]	Time 0.07 (0.07)
Test: [02570/04555]	Time 0.07 (0.07)
Test: [02580/04555]	Time 0.48 (0.07)
Test: [02590/04555]	Time 0.24 (0.07)
Test: [02600/04555]	Time 0.04 (0.07)
Test: [02610/04555]	Time 0.14 (0.07)
Test: [02620/04555]	Time 0.04 (0.07)
Test: [02630/04555]	Time 0.04 (0.07)
Test: [02640/04555]	Time 0.04 (0.07)
Test: [02650/04555]	Time 0.04 (0.07)
Test: [02660/04555]	Time 0.29 (0.07)
Test: [02670/04555]	Time 0.04 (0.07)
Test: [02680/04555]	Time 0.13 (0.07)
Test: [02690/04555]	Time 0.13 (0.07)
Test: [02700/04555]	Time 0.15 (0.07)
Test: [02710/04555]	Time 0.04 (0.07)
Test: [02720/04555]	Time 0.04 (0.07)
Test: [02730/04555]	Time 0.04 (0.07)
Test: [02740/04555]	Time 0.14 (0.07)
Test: [02750/04555]	Time 0.05 (0.07)
Test: [02760/04555]	Time 0.04 (0.07)
Test: [02770/04555]	Time 0.04 (0.07)
Test: [02780/04555]	Time 0.05 (0.07)
Test: [02790/04555]	Time 0.04 (0.07)
Test: [02800/04555]	Time 0.04 (0.07)
Test: [02810/04555]	Time 0.04 (0.07)
Test: [02820/04555]	Time 0.04 (0.07)
Test: [02830/04555]	Time 0.05 (0.07)
Test: [02840/04555]	Time 0.06 (0.07)
Test: [02850/04555]	Time 0.04 (0.07)
Test: [02860/04555]	Time 0.04 (0.07)
Test: [02870/04555]	Time 0.04 (0.07)
Test: [02880/04555]	Time 0.04 (0.07)
Test: [02890/04555]	Time 0.04 (0.07)
Test: [02900/04555]	Time 0.12 (0.07)
Test: [02910/04555]	Time 0.04 (0.07)
Test: [02920/04555]	Time 0.04 (0.07)
Test: [02930/04555]	Time 0.04 (0.07)
Test: [02940/04555]	Time 0.06 (0.07)
Test: [02950/04555]	Time 0.04 (0.07)
Test: [02960/04555]	Time 0.04 (0.07)
Test: [02970/04555]	Time 0.04 (0.07)
Test: [02980/04555]	Time 0.04 (0.07)
Test: [02990/04555]	Time 0.04 (0.07)
Test: [03000/04555]	Time 0.07 (0.07)
Test: [03010/04555]	Time 0.04 (0.07)
Test: [03020/04555]	Time 0.04 (0.07)
Test: [03030/04555]	Time 0.04 (0.07)
Test: [03040/04555]	Time 0.04 (0.07)
Test: [03050/04555]	Time 0.04 (0.07)
Test: [03060/04555]	Time 0.04 (0.07)
Test: [03070/04555]	Time 0.04 (0.07)
Test: [03080/04555]	Time 0.04 (0.07)
Test: [03090/04555]	Time 0.04 (0.07)
Test: [03100/04555]	Time 0.04 (0.07)
Test: [03110/04555]	Time 0.04 (0.07)
Test: [03120/04555]	Time 0.07 (0.07)
Test: [03130/04555]	Time 0.07 (0.07)
Test: [03140/04555]	Time 0.04 (0.07)
Test: [03150/04555]	Time 0.04 (0.07)
Test: [03160/04555]	Time 0.04 (0.07)
Test: [03170/04555]	Time 0.07 (0.07)
Test: [03180/04555]	Time 0.04 (0.07)
Test: [03190/04555]	Time 0.05 (0.07)
Test: [03200/04555]	Time 0.04 (0.07)
Test: [03210/04555]	Time 0.04 (0.07)
Test: [03220/04555]	Time 0.04 (0.07)
Test: [03230/04555]	Time 0.04 (0.07)
Test: [03240/04555]	Time 0.04 (0.07)
Test: [03250/04555]	Time 0.04 (0.07)
Test: [03260/04555]	Time 0.04 (0.07)
Test: [03270/04555]	Time 0.04 (0.07)
Test: [03280/04555]	Time 0.04 (0.07)
Test: [03290/04555]	Time 0.09 (0.07)
Test: [03300/04555]	Time 0.04 (0.07)
Test: [03310/04555]	Time 0.04 (0.07)
Test: [03320/04555]	Time 0.04 (0.07)
Test: [03330/04555]	Time 0.04 (0.07)
Test: [03340/04555]	Time 0.04 (0.07)
Test: [03350/04555]	Time 0.04 (0.07)
Test: [03360/04555]	Time 0.12 (0.07)
Test: [03370/04555]	Time 0.04 (0.07)
Test: [03380/04555]	Time 0.04 (0.07)
Test: [03390/04555]	Time 0.04 (0.07)
Test: [03400/04555]	Time 0.04 (0.07)
Test: [03410/04555]	Time 0.04 (0.07)
Test: [03420/04555]	Time 0.04 (0.07)
Test: [03430/04555]	Time 0.04 (0.07)
Test: [03440/04555]	Time 0.04 (0.07)
Test: [03450/04555]	Time 0.04 (0.07)
Test: [03460/04555]	Time 0.04 (0.07)
Test: [03470/04555]	Time 0.04 (0.07)
Test: [03480/04555]	Time 0.17 (0.07)
Test: [03490/04555]	Time 0.21 (0.07)
Test: [03500/04555]	Time 0.31 (0.07)
Test: [03510/04555]	Time 0.07 (0.07)
Test: [03520/04555]	Time 0.17 (0.07)
Test: [03530/04555]	Time 0.05 (0.07)
Test: [03540/04555]	Time 0.04 (0.07)
Test: [03550/04555]	Time 0.09 (0.07)
Test: [03560/04555]	Time 0.05 (0.07)
Test: [03570/04555]	Time 0.05 (0.07)
Test: [03580/04555]	Time 0.06 (0.07)
Test: [03590/04555]	Time 0.04 (0.07)
Test: [03600/04555]	Time 0.06 (0.07)
Test: [03610/04555]	Time 0.08 (0.07)
Test: [03620/04555]	Time 0.04 (0.07)
Test: [03630/04555]	Time 0.04 (0.07)
Test: [03640/04555]	Time 0.04 (0.07)
Test: [03650/04555]	Time 0.05 (0.07)
Test: [03660/04555]	Time 0.07 (0.07)
Test: [03670/04555]	Time 0.06 (0.07)
Test: [03680/04555]	Time 0.04 (0.07)
Test: [03690/04555]	Time 0.04 (0.07)
Test: [03700/04555]	Time 0.04 (0.07)
Test: [03710/04555]	Time 0.04 (0.07)
Test: [03720/04555]	Time 0.04 (0.07)
Test: [03730/04555]	Time 0.04 (0.07)
Test: [03740/04555]	Time 0.04 (0.07)
Test: [03750/04555]	Time 0.04 (0.07)
Test: [03760/04555]	Time 0.04 (0.07)
Test: [03770/04555]	Time 0.10 (0.07)
Test: [03780/04555]	Time 0.04 (0.07)
Test: [03790/04555]	Time 0.09 (0.07)
Test: [03800/04555]	Time 0.06 (0.07)
Test: [03810/04555]	Time 0.04 (0.07)
Test: [03820/04555]	Time 0.05 (0.07)
Test: [03830/04555]	Time 0.04 (0.07)
Test: [03840/04555]	Time 0.08 (0.07)
Test: [03850/04555]	Time 0.05 (0.07)
Test: [03860/04555]	Time 0.06 (0.07)
Test: [03870/04555]	Time 0.04 (0.07)
Test: [03880/04555]	Time 0.04 (0.07)
Test: [03890/04555]	Time 0.04 (0.07)
Test: [03900/04555]	Time 0.04 (0.07)
Test: [03910/04555]	Time 0.04 (0.07)
Test: [03920/04555]	Time 0.04 (0.07)
Test: [03930/04555]	Time 0.04 (0.07)
Test: [03940/04555]	Time 0.08 (0.07)
Test: [03950/04555]	Time 0.04 (0.07)
Test: [03960/04555]	Time 0.05 (0.07)
Test: [03970/04555]	Time 0.04 (0.07)
Test: [03980/04555]	Time 0.05 (0.07)
Test: [03990/04555]	Time 0.07 (0.07)
Test: [04000/04555]	Time 0.07 (0.07)
Test: [04010/04555]	Time 0.04 (0.07)
Test: [04020/04555]	Time 0.04 (0.07)
Test: [04030/04555]	Time 0.04 (0.07)
Test: [04040/04555]	Time 0.04 (0.07)
Test: [04050/04555]	Time 0.04 (0.07)
Test: [04060/04555]	Time 0.04 (0.07)
Test: [04070/04555]	Time 0.04 (0.07)
Test: [04080/04555]	Time 0.04 (0.07)
Test: [04090/04555]	Time 0.04 (0.07)
Test: [04100/04555]	Time 0.04 (0.07)
Test: [04110/04555]	Time 0.04 (0.07)
Test: [04120/04555]	Time 0.07 (0.07)
Test: [04130/04555]	Time 0.04 (0.07)
Test: [04140/04555]	Time 0.04 (0.07)
Test: [04150/04555]	Time 0.08 (0.07)
Test: [04160/04555]	Time 0.04 (0.07)
Test: [04170/04555]	Time 0.04 (0.07)
Test: [04180/04555]	Time 0.04 (0.07)
Test: [04190/04555]	Time 0.04 (0.07)
Test: [04200/04555]	Time 0.04 (0.07)
Test: [04210/04555]	Time 0.04 (0.07)
Test: [04220/04555]	Time 0.04 (0.07)
Test: [04230/04555]	Time 0.04 (0.07)
Test: [04240/04555]	Time 0.04 (0.07)
Test: [04250/04555]	Time 0.04 (0.07)
Test: [04260/04555]	Time 0.04 (0.06)
Test: [04270/04555]	Time 0.04 (0.06)
Test: [04280/04555]	Time 0.04 (0.06)
Test: [04290/04555]	Time 0.04 (0.06)
Test: [04300/04555]	Time 0.04 (0.06)
Test: [04310/04555]	Time 0.04 (0.06)
Test: [04320/04555]	Time 0.04 (0.06)
Test: [04330/04555]	Time 0.04 (0.06)
Test: [04340/04555]	Time 0.04 (0.06)
Test: [04350/04555]	Time 0.04 (0.06)
Test: [04360/04555]	Time 0.04 (0.06)
Test: [04370/04555]	Time 0.04 (0.06)
Test: [04380/04555]	Time 0.04 (0.06)
Test: [04390/04555]	Time 0.04 (0.06)
Test: [04400/04555]	Time 0.04 (0.06)
Test: [04410/04555]	Time 0.04 (0.06)
Test: [04420/04555]	Time 0.04 (0.06)
Test: [04430/04555]	Time 0.04 (0.06)
Test: [04440/04555]	Time 0.04 (0.06)
Test: [04450/04555]	Time 0.04 (0.06)
Test: [04460/04555]	Time 0.04 (0.06)
Test: [04470/04555]	Time 0.04 (0.06)
Test: [04480/04555]	Time 0.04 (0.06)
Test: [04490/04555]	Time 0.04 (0.06)
Test: [04500/04555]	Time 0.04 (0.06)
Test: [04510/04555]	Time 0.04 (0.06)
Test: [04520/04555]	Time 0.04 (0.06)
Test: [04530/04555]	Time 0.04 (0.06)
Test: [04540/04555]	Time 0.04 (0.06)
Test: [04550/04555]	Time 0.04 (0.06)
[RESULTS] Action detection results on anet1.3_i3d_filtered.

|tIoU = 0.50: mAP = 53.04 (%) Recall@1x = 60.05 (%) Recall@5x = 81.67 (%) 
|tIoU = 0.55: mAP = 49.79 (%) Recall@1x = 57.17 (%) Recall@5x = 77.81 (%) 
|tIoU = 0.60: mAP = 46.69 (%) Recall@1x = 54.47 (%) Recall@5x = 74.07 (%) 
|tIoU = 0.65: mAP = 43.16 (%) Recall@1x = 51.52 (%) Recall@5x = 69.88 (%) 
|tIoU = 0.70: mAP = 39.51 (%) Recall@1x = 48.18 (%) Recall@5x = 64.70 (%) 
|tIoU = 0.75: mAP = 35.25 (%) Recall@1x = 44.40 (%) Recall@5x = 58.18 (%) 
|tIoU = 0.80: mAP = 30.23 (%) Recall@1x = 39.72 (%) Recall@5x = 50.24 (%) 
|tIoU = 0.85: mAP = 23.99 (%) Recall@1x = 33.66 (%) Recall@5x = 41.03 (%) 
|tIoU = 0.90: mAP = 15.87 (%) Recall@1x = 24.81 (%) Recall@5x = 28.50 (%) 
|tIoU = 0.95: mAP = 4.45 (%) Recall@1x = 9.41 (%) Recall@5x = 10.56 (%) 
Average mAP: 34.20 (%)
All done! Total time: 504.04 sec
Looking for a split for p=0.4
Found split for p=0.4 [3700 videos]
Moving sampled images to a separate folder
Finished sampling
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00231]	Time 5.13 (5.13)	Loss 1.69 (1.69)
		cls_loss 0.51 (0.51)	reg_loss 0.59 (0.59)
Epoch: [000][00020/00231]	Time 1.12 (3.12)	Loss 1.42 (1.55)
		cls_loss 0.46 (0.49)	reg_loss 0.48 (0.53)
Epoch: [000][00030/00231]	Time 0.43 (2.23)	Loss 1.93 (1.68)
		cls_loss 0.59 (0.52)	reg_loss 0.67 (0.58)
Epoch: [000][00040/00231]	Time 0.26 (1.73)	Loss 1.38 (1.60)
		cls_loss 0.41 (0.50)	reg_loss 0.49 (0.55)
Epoch: [000][00050/00231]	Time 0.33 (1.45)	Loss 2.75 (1.83)
		cls_loss 0.76 (0.55)	reg_loss 1.00 (0.64)
Epoch: [000][00060/00231]	Time 0.40 (1.28)	Loss 1.44 (1.77)
		cls_loss 0.35 (0.51)	reg_loss 0.54 (0.63)
Epoch: [000][00070/00231]	Time 0.39 (1.15)	Loss 1.92 (1.79)
		cls_loss 0.55 (0.52)	reg_loss 0.69 (0.63)
Epoch: [000][00080/00231]	Time 0.30 (1.04)	Loss 1.87 (1.80)
		cls_loss 0.84 (0.56)	reg_loss 0.52 (0.62)
Epoch: [000][00090/00231]	Time 0.26 (0.96)	Loss 0.84 (1.69)
		cls_loss 0.39 (0.54)	reg_loss 0.23 (0.58)
Epoch: [000][00100/00231]	Time 0.24 (0.88)	Loss 0.99 (1.62)
		cls_loss 0.45 (0.53)	reg_loss 0.27 (0.55)
Epoch: [000][00110/00231]	Time 0.22 (0.82)	Loss 1.27 (1.59)
		cls_loss 0.60 (0.54)	reg_loss 0.33 (0.53)
Epoch: [000][00120/00231]	Time 0.21 (0.77)	Loss 0.60 (1.51)
		cls_loss 0.26 (0.51)	reg_loss 0.17 (0.50)
Epoch: [000][00130/00231]	Time 0.24 (0.73)	Loss 0.89 (1.46)
		cls_loss 0.41 (0.51)	reg_loss 0.24 (0.48)
Epoch: [000][00140/00231]	Time 0.21 (0.70)	Loss 1.18 (1.44)
		cls_loss 0.53 (0.51)	reg_loss 0.32 (0.47)
Epoch: [000][00150/00231]	Time 0.19 (0.66)	Loss 0.94 (1.41)
		cls_loss 0.39 (0.50)	reg_loss 0.28 (0.45)
Epoch: [000][00160/00231]	Time 0.26 (0.64)	Loss 1.50 (1.41)
		cls_loss 0.72 (0.51)	reg_loss 0.39 (0.45)
Epoch: [000][00170/00231]	Time 0.21 (0.61)	Loss 0.99 (1.39)
		cls_loss 0.44 (0.51)	reg_loss 0.27 (0.44)
Epoch: [000][00180/00231]	Time 0.24 (0.59)	Loss 0.83 (1.36)
		cls_loss 0.41 (0.50)	reg_loss 0.21 (0.43)
Epoch: [000][00190/00231]	Time 0.20 (0.57)	Loss 0.90 (1.33)
		cls_loss 0.42 (0.50)	reg_loss 0.24 (0.42)
Epoch: [000][00200/00231]	Time 0.21 (0.55)	Loss 0.74 (1.30)
		cls_loss 0.36 (0.49)	reg_loss 0.19 (0.40)
Epoch: [000][00210/00231]	Time 0.21 (0.54)	Loss 0.69 (1.27)
		cls_loss 0.33 (0.49)	reg_loss 0.18 (0.39)
Epoch: [000][00220/00231]	Time 0.20 (0.52)	Loss 1.29 (1.27)
		cls_loss 0.60 (0.49)	reg_loss 0.35 (0.39)
Epoch: [000][00230/00231]	Time 0.20 (0.51)	Loss 0.45 (1.24)
		cls_loss 0.21 (0.48)	reg_loss 0.12 (0.38)
[Train]: Epoch 0 finished with lr=0.00020017


[Train]: Epoch 1 started
Epoch: [001][00010/00231]	Time 0.25 (0.25)	Loss 0.99 (0.99)
		cls_loss 0.41 (0.41)	reg_loss 0.29 (0.29)
Epoch: [001][00020/00231]	Time 0.20 (0.23)	Loss 1.10 (1.04)
		cls_loss 0.52 (0.47)	reg_loss 0.29 (0.29)
Epoch: [001][00030/00231]	Time 0.19 (0.21)	Loss 1.13 (1.07)
		cls_loss 0.55 (0.50)	reg_loss 0.29 (0.29)
Epoch: [001][00040/00231]	Time 0.22 (0.22)	Loss 1.13 (1.09)
		cls_loss 0.55 (0.51)	reg_loss 0.29 (0.29)
Epoch: [001][00050/00231]	Time 0.22 (0.22)	Loss 1.19 (1.11)
		cls_loss 0.56 (0.52)	reg_loss 0.31 (0.29)
Epoch: [001][00060/00231]	Time 0.22 (0.22)	Loss 0.71 (1.04)
		cls_loss 0.37 (0.49)	reg_loss 0.17 (0.27)
Epoch: [001][00070/00231]	Time 0.22 (0.22)	Loss 0.62 (0.98)
		cls_loss 0.32 (0.47)	reg_loss 0.15 (0.26)
Epoch: [001][00080/00231]	Time 0.22 (0.22)	Loss 0.70 (0.95)
		cls_loss 0.36 (0.45)	reg_loss 0.17 (0.25)
Epoch: [001][00090/00231]	Time 0.22 (0.22)	Loss 1.59 (1.02)
		cls_loss 0.79 (0.49)	reg_loss 0.40 (0.26)
Epoch: [001][00100/00231]	Time 0.22 (0.22)	Loss 0.93 (1.01)
		cls_loss 0.44 (0.49)	reg_loss 0.25 (0.26)
Epoch: [001][00110/00231]	Time 0.22 (0.22)	Loss 0.84 (1.00)
		cls_loss 0.37 (0.48)	reg_loss 0.23 (0.26)
Epoch: [001][00120/00231]	Time 0.22 (0.22)	Loss 1.17 (1.01)
		cls_loss 0.57 (0.48)	reg_loss 0.30 (0.26)
Epoch: [001][00130/00231]	Time 0.22 (0.22)	Loss 0.82 (1.00)
		cls_loss 0.41 (0.48)	reg_loss 0.20 (0.26)
Epoch: [001][00140/00231]	Time 0.22 (0.22)	Loss 0.80 (0.98)
		cls_loss 0.45 (0.48)	reg_loss 0.18 (0.25)
Epoch: [001][00150/00231]	Time 0.22 (0.22)	Loss 0.85 (0.97)
		cls_loss 0.41 (0.47)	reg_loss 0.22 (0.25)
Epoch: [001][00160/00231]	Time 0.22 (0.22)	Loss 1.20 (0.99)
		cls_loss 0.59 (0.48)	reg_loss 0.30 (0.25)
Epoch: [001][00170/00231]	Time 0.22 (0.22)	Loss 2.40 (1.07)
		cls_loss 1.21 (0.52)	reg_loss 0.59 (0.27)
Epoch: [001][00180/00231]	Time 0.22 (0.22)	Loss 0.89 (1.06)
		cls_loss 0.41 (0.52)	reg_loss 0.24 (0.27)
Epoch: [001][00190/00231]	Time 0.22 (0.22)	Loss 0.66 (1.04)
		cls_loss 0.28 (0.50)	reg_loss 0.19 (0.27)
Epoch: [001][00200/00231]	Time 0.22 (0.22)	Loss 0.56 (1.02)
		cls_loss 0.29 (0.49)	reg_loss 0.13 (0.26)
Epoch: [001][00210/00231]	Time 0.22 (0.22)	Loss 1.22 (1.03)
		cls_loss 0.55 (0.50)	reg_loss 0.33 (0.26)
Epoch: [001][00220/00231]	Time 0.22 (0.22)	Loss 0.82 (1.02)
		cls_loss 0.38 (0.49)	reg_loss 0.22 (0.26)
Epoch: [001][00230/00231]	Time 0.18 (0.22)	Loss 0.78 (1.01)
		cls_loss 0.36 (0.49)	reg_loss 0.21 (0.26)
[Train]: Epoch 1 finished with lr=0.00040035


[Train]: Epoch 2 started
Epoch: [002][00010/00231]	Time 0.26 (0.26)	Loss 0.58 (0.58)
		cls_loss 0.25 (0.25)	reg_loss 0.16 (0.16)
Epoch: [002][00020/00231]	Time 0.22 (0.24)	Loss 0.79 (0.68)
		cls_loss 0.39 (0.32)	reg_loss 0.20 (0.18)
Epoch: [002][00030/00231]	Time 0.21 (0.23)	Loss 0.59 (0.65)
		cls_loss 0.27 (0.30)	reg_loss 0.16 (0.17)
Epoch: [002][00040/00231]	Time 0.22 (0.23)	Loss 1.10 (0.76)
		cls_loss 0.48 (0.35)	reg_loss 0.31 (0.21)
Epoch: [002][00050/00231]	Time 0.22 (0.23)	Loss 0.49 (0.71)
		cls_loss 0.24 (0.32)	reg_loss 0.12 (0.19)
Epoch: [002][00060/00231]	Time 0.22 (0.22)	Loss 0.58 (0.69)
		cls_loss 0.26 (0.31)	reg_loss 0.16 (0.19)
Epoch: [002][00070/00231]	Time 0.22 (0.22)	Loss 0.55 (0.67)
		cls_loss 0.28 (0.31)	reg_loss 0.13 (0.18)
Epoch: [002][00080/00231]	Time 0.22 (0.22)	Loss 1.11 (0.72)
		cls_loss 0.55 (0.34)	reg_loss 0.28 (0.19)
Epoch: [002][00090/00231]	Time 0.22 (0.22)	Loss 0.94 (0.75)
		cls_loss 0.47 (0.35)	reg_loss 0.23 (0.20)
Epoch: [002][00100/00231]	Time 0.22 (0.22)	Loss 1.04 (0.78)
		cls_loss 0.46 (0.36)	reg_loss 0.29 (0.21)
Epoch: [002][00110/00231]	Time 0.22 (0.22)	Loss 1.28 (0.82)
		cls_loss 0.59 (0.38)	reg_loss 0.35 (0.22)
Epoch: [002][00120/00231]	Time 0.22 (0.22)	Loss 0.95 (0.83)
		cls_loss 0.46 (0.39)	reg_loss 0.24 (0.22)
Epoch: [002][00130/00231]	Time 0.22 (0.22)	Loss 1.80 (0.91)
		cls_loss 0.82 (0.42)	reg_loss 0.49 (0.24)
Epoch: [002][00140/00231]	Time 0.87 (0.27)	Loss 0.97 (0.91)
		cls_loss 0.44 (0.43)	reg_loss 0.26 (0.24)
Epoch: [002][00150/00231]	Time 0.33 (0.27)	Loss 0.67 (0.89)
		cls_loss 0.32 (0.42)	reg_loss 0.17 (0.24)
Epoch: [002][00160/00231]	Time 0.20 (0.27)	Loss 0.78 (0.89)
		cls_loss 0.37 (0.41)	reg_loss 0.21 (0.24)
Epoch: [002][00170/00231]	Time 0.20 (0.26)	Loss 0.61 (0.87)
		cls_loss 0.34 (0.41)	reg_loss 0.14 (0.23)
Epoch: [002][00180/00231]	Time 0.20 (0.26)	Loss 1.04 (0.88)
		cls_loss 0.46 (0.41)	reg_loss 0.29 (0.23)
Epoch: [002][00190/00231]	Time 0.21 (0.26)	Loss 1.00 (0.89)
		cls_loss 0.48 (0.42)	reg_loss 0.26 (0.23)
Epoch: [002][00200/00231]	Time 0.21 (0.25)	Loss 0.80 (0.88)
		cls_loss 0.38 (0.42)	reg_loss 0.21 (0.23)
Epoch: [002][00210/00231]	Time 0.21 (0.25)	Loss 0.83 (0.88)
		cls_loss 0.38 (0.41)	reg_loss 0.23 (0.23)
Epoch: [002][00220/00231]	Time 0.22 (0.25)	Loss 0.88 (0.88)
		cls_loss 0.43 (0.41)	reg_loss 0.22 (0.23)
Epoch: [002][00230/00231]	Time 0.18 (0.25)	Loss 1.80 (0.92)
		cls_loss 0.87 (0.43)	reg_loss 0.47 (0.24)
[Train]: Epoch 2 finished with lr=0.00060052


[Train]: Epoch 3 started
Epoch: [003][00010/00231]	Time 2.19 (2.19)	Loss 0.95 (0.95)
		cls_loss 0.41 (0.41)	reg_loss 0.27 (0.27)
Epoch: [003][00020/00231]	Time 0.22 (1.21)	Loss 0.56 (0.75)
		cls_loss 0.27 (0.34)	reg_loss 0.15 (0.21)
Epoch: [003][00030/00231]	Time 0.23 (0.88)	Loss 0.70 (0.74)
		cls_loss 0.32 (0.34)	reg_loss 0.19 (0.20)
Epoch: [003][00040/00231]	Time 0.21 (0.71)	Loss 0.76 (0.74)
		cls_loss 0.36 (0.34)	reg_loss 0.20 (0.20)
Epoch: [003][00050/00231]	Time 0.20 (0.61)	Loss 0.66 (0.73)
		cls_loss 0.31 (0.34)	reg_loss 0.17 (0.20)
Epoch: [003][00060/00231]	Time 0.20 (0.54)	Loss 1.11 (0.79)
		cls_loss 0.54 (0.37)	reg_loss 0.28 (0.21)
Epoch: [003][00070/00231]	Time 0.22 (0.50)	Loss 0.70 (0.78)
		cls_loss 0.33 (0.37)	reg_loss 0.18 (0.21)
Epoch: [003][00080/00231]	Time 0.21 (0.46)	Loss 0.82 (0.78)
		cls_loss 0.40 (0.37)	reg_loss 0.21 (0.21)
Epoch: [003][00090/00231]	Time 0.22 (0.43)	Loss 0.98 (0.80)
		cls_loss 0.43 (0.38)	reg_loss 0.27 (0.21)
Epoch: [003][00100/00231]	Time 0.22 (0.41)	Loss 1.23 (0.85)
		cls_loss 0.55 (0.39)	reg_loss 0.34 (0.23)
Epoch: [003][00110/00231]	Time 0.22 (0.39)	Loss 0.77 (0.84)
		cls_loss 0.38 (0.39)	reg_loss 0.19 (0.22)
Epoch: [003][00120/00231]	Time 0.22 (0.38)	Loss 0.59 (0.82)
		cls_loss 0.28 (0.38)	reg_loss 0.16 (0.22)
Epoch: [003][00130/00231]	Time 0.22 (0.37)	Loss 0.56 (0.80)
		cls_loss 0.29 (0.38)	reg_loss 0.14 (0.21)
Epoch: [003][00140/00231]	Time 0.22 (0.36)	Loss 0.63 (0.79)
		cls_loss 0.27 (0.37)	reg_loss 0.18 (0.21)
Epoch: [003][00150/00231]	Time 0.22 (0.35)	Loss 1.05 (0.81)
		cls_loss 0.45 (0.37)	reg_loss 0.30 (0.22)
Epoch: [003][00160/00231]	Time 0.22 (0.34)	Loss 0.74 (0.80)
		cls_loss 0.36 (0.37)	reg_loss 0.19 (0.21)
Epoch: [003][00170/00231]	Time 0.22 (0.33)	Loss 0.96 (0.81)
		cls_loss 0.40 (0.37)	reg_loss 0.28 (0.22)
Epoch: [003][00180/00231]	Time 0.22 (0.33)	Loss 0.89 (0.82)
		cls_loss 0.43 (0.38)	reg_loss 0.23 (0.22)
Epoch: [003][00190/00231]	Time 0.22 (0.32)	Loss 1.07 (0.83)
		cls_loss 0.48 (0.38)	reg_loss 0.29 (0.22)
Epoch: [003][00200/00231]	Time 0.22 (0.31)	Loss 1.12 (0.84)
		cls_loss 0.50 (0.39)	reg_loss 0.31 (0.23)
Epoch: [003][00210/00231]	Time 0.22 (0.31)	Loss 0.62 (0.83)
		cls_loss 0.32 (0.39)	reg_loss 0.15 (0.22)
Epoch: [003][00220/00231]	Time 0.22 (0.31)	Loss 0.88 (0.83)
		cls_loss 0.40 (0.39)	reg_loss 0.24 (0.22)
Epoch: [003][00230/00231]	Time 0.18 (0.30)	Loss 0.64 (0.83)
		cls_loss 0.31 (0.38)	reg_loss 0.17 (0.22)
[Train]: Epoch 3 finished with lr=0.00080069


[Train]: Epoch 4 started
Epoch: [004][00010/00231]	Time 0.25 (0.25)	Loss 0.75 (0.75)
		cls_loss 0.37 (0.37)	reg_loss 0.19 (0.19)
Epoch: [004][00020/00231]	Time 0.20 (0.23)	Loss 0.49 (0.62)
		cls_loss 0.23 (0.30)	reg_loss 0.13 (0.16)
Epoch: [004][00030/00231]	Time 0.21 (0.22)	Loss 0.98 (0.74)
		cls_loss 0.47 (0.35)	reg_loss 0.26 (0.19)
Epoch: [004][00040/00231]	Time 0.21 (0.22)	Loss 0.53 (0.69)
		cls_loss 0.27 (0.33)	reg_loss 0.13 (0.18)
Epoch: [004][00050/00231]	Time 0.21 (0.22)	Loss 0.45 (0.64)
		cls_loss 0.23 (0.31)	reg_loss 0.11 (0.16)
Epoch: [004][00060/00231]	Time 0.21 (0.21)	Loss 0.75 (0.66)
		cls_loss 0.33 (0.32)	reg_loss 0.21 (0.17)
Epoch: [004][00070/00231]	Time 0.21 (0.21)	Loss 0.50 (0.64)
		cls_loss 0.22 (0.30)	reg_loss 0.14 (0.17)
Epoch: [004][00080/00231]	Time 0.22 (0.21)	Loss 1.24 (0.71)
		cls_loss 0.56 (0.34)	reg_loss 0.34 (0.19)
Epoch: [004][00090/00231]	Time 0.22 (0.21)	Loss 0.91 (0.73)
		cls_loss 0.44 (0.35)	reg_loss 0.24 (0.19)
Epoch: [004][00100/00231]	Time 0.22 (0.22)	Loss 0.38 (0.70)
		cls_loss 0.20 (0.33)	reg_loss 0.09 (0.18)
Epoch: [004][00110/00231]	Time 0.22 (0.22)	Loss 0.52 (0.68)
		cls_loss 0.27 (0.33)	reg_loss 0.13 (0.18)
Epoch: [004][00120/00231]	Time 0.22 (0.22)	Loss 0.71 (0.68)
		cls_loss 0.35 (0.33)	reg_loss 0.18 (0.18)
Epoch: [004][00130/00231]	Time 0.22 (0.22)	Loss 0.72 (0.69)
		cls_loss 0.33 (0.33)	reg_loss 0.19 (0.18)
Epoch: [004][00140/00231]	Time 0.22 (0.22)	Loss 0.52 (0.68)
		cls_loss 0.27 (0.32)	reg_loss 0.13 (0.18)
Epoch: [004][00150/00231]	Time 0.22 (0.22)	Loss 0.80 (0.68)
		cls_loss 0.37 (0.33)	reg_loss 0.21 (0.18)
Epoch: [004][00160/00231]	Time 0.21 (0.22)	Loss 1.29 (0.72)
		cls_loss 0.59 (0.34)	reg_loss 0.35 (0.19)
Epoch: [004][00170/00231]	Time 0.22 (0.22)	Loss 0.53 (0.71)
		cls_loss 0.25 (0.34)	reg_loss 0.14 (0.19)
Epoch: [004][00180/00231]	Time 0.22 (0.22)	Loss 0.69 (0.71)
		cls_loss 0.32 (0.34)	reg_loss 0.19 (0.19)
Epoch: [004][00190/00231]	Time 0.22 (0.22)	Loss 0.82 (0.71)
		cls_loss 0.41 (0.34)	reg_loss 0.21 (0.19)
Epoch: [004][00200/00231]	Time 0.22 (0.22)	Loss 1.17 (0.74)
		cls_loss 0.52 (0.35)	reg_loss 0.33 (0.19)
Epoch: [004][00210/00231]	Time 0.22 (0.22)	Loss 0.81 (0.74)
		cls_loss 0.39 (0.35)	reg_loss 0.21 (0.19)
Epoch: [004][00220/00231]	Time 0.22 (0.22)	Loss 0.38 (0.72)
		cls_loss 0.21 (0.35)	reg_loss 0.09 (0.19)
Epoch: [004][00230/00231]	Time 0.18 (0.22)	Loss 0.95 (0.73)
		cls_loss 0.45 (0.35)	reg_loss 0.25 (0.19)
[Train]: Epoch 4 finished with lr=0.00100000


[Train]: Epoch 5 started
Epoch: [005][00010/00231]	Time 0.29 (0.29)	Loss 0.47 (0.47)
		cls_loss 0.23 (0.23)	reg_loss 0.12 (0.12)
Epoch: [005][00020/00231]	Time 0.22 (0.26)	Loss 1.15 (0.81)
		cls_loss 0.52 (0.37)	reg_loss 0.32 (0.22)
Epoch: [005][00030/00231]	Time 0.22 (0.24)	Loss 0.78 (0.80)
		cls_loss 0.37 (0.37)	reg_loss 0.21 (0.22)
Epoch: [005][00040/00231]	Time 0.57 (0.33)	Loss 0.46 (0.72)
		cls_loss 0.24 (0.34)	reg_loss 0.11 (0.19)
Epoch: [005][00050/00231]	Time 0.65 (0.39)	Loss 0.58 (0.69)
		cls_loss 0.29 (0.33)	reg_loss 0.14 (0.18)
Epoch: [005][00060/00231]	Time 0.22 (0.36)	Loss 1.21 (0.78)
		cls_loss 0.52 (0.36)	reg_loss 0.34 (0.21)
Epoch: [005][00070/00231]	Time 0.21 (0.34)	Loss 0.98 (0.81)
		cls_loss 0.48 (0.38)	reg_loss 0.25 (0.21)
Epoch: [005][00080/00231]	Time 0.20 (0.32)	Loss 0.67 (0.79)
		cls_loss 0.32 (0.37)	reg_loss 0.17 (0.21)
Epoch: [005][00090/00231]	Time 0.21 (0.31)	Loss 0.63 (0.77)
		cls_loss 0.31 (0.36)	reg_loss 0.16 (0.20)
Epoch: [005][00100/00231]	Time 0.20 (0.30)	Loss 0.49 (0.74)
		cls_loss 0.24 (0.35)	reg_loss 0.12 (0.19)
Epoch: [005][00110/00231]	Time 0.21 (0.29)	Loss 0.98 (0.76)
		cls_loss 0.43 (0.36)	reg_loss 0.27 (0.20)
Epoch: [005][00120/00231]	Time 0.22 (0.29)	Loss 0.91 (0.78)
		cls_loss 0.42 (0.36)	reg_loss 0.25 (0.21)
Epoch: [005][00130/00231]	Time 0.22 (0.28)	Loss 0.75 (0.77)
		cls_loss 0.36 (0.36)	reg_loss 0.19 (0.20)
Epoch: [005][00140/00231]	Time 0.21 (0.28)	Loss 1.31 (0.81)
		cls_loss 0.61 (0.38)	reg_loss 0.35 (0.22)
Epoch: [005][00150/00231]	Time 0.22 (0.27)	Loss 0.86 (0.81)
		cls_loss 0.42 (0.38)	reg_loss 0.22 (0.22)
Epoch: [005][00160/00231]	Time 0.22 (0.27)	Loss 0.75 (0.81)
		cls_loss 0.37 (0.38)	reg_loss 0.19 (0.21)
Epoch: [005][00170/00231]	Time 0.22 (0.27)	Loss 0.81 (0.81)
		cls_loss 0.39 (0.38)	reg_loss 0.21 (0.21)
Epoch: [005][00180/00231]	Time 0.22 (0.26)	Loss 0.95 (0.82)
		cls_loss 0.45 (0.39)	reg_loss 0.25 (0.22)
Epoch: [005][00190/00231]	Time 0.22 (0.26)	Loss 1.59 (0.86)
		cls_loss 0.76 (0.41)	reg_loss 0.41 (0.23)
Epoch: [005][00200/00231]	Time 0.22 (0.26)	Loss 0.58 (0.85)
		cls_loss 0.27 (0.40)	reg_loss 0.16 (0.22)
Epoch: [005][00210/00231]	Time 0.22 (0.26)	Loss 0.68 (0.84)
		cls_loss 0.32 (0.40)	reg_loss 0.18 (0.22)
Epoch: [005][00220/00231]	Time 0.22 (0.25)	Loss 0.55 (0.82)
		cls_loss 0.29 (0.39)	reg_loss 0.13 (0.22)
Epoch: [005][00230/00231]	Time 0.18 (0.25)	Loss 0.79 (0.82)
		cls_loss 0.36 (0.39)	reg_loss 0.21 (0.22)
[Train]: Epoch 5 finished with lr=0.00097553


[Train]: Epoch 6 started
Epoch: [006][00010/00231]	Time 0.25 (0.25)	Loss 0.56 (0.56)
		cls_loss 0.23 (0.23)	reg_loss 0.16 (0.16)
Epoch: [006][00020/00231]	Time 0.21 (0.23)	Loss 0.71 (0.64)
		cls_loss 0.35 (0.29)	reg_loss 0.18 (0.17)
Epoch: [006][00030/00231]	Time 0.22 (0.23)	Loss 0.83 (0.70)
		cls_loss 0.40 (0.33)	reg_loss 0.22 (0.19)
Epoch: [006][00040/00231]	Time 0.22 (0.22)	Loss 0.87 (0.74)
		cls_loss 0.44 (0.36)	reg_loss 0.22 (0.19)
Epoch: [006][00050/00231]	Time 0.22 (0.22)	Loss 0.88 (0.77)
		cls_loss 0.42 (0.37)	reg_loss 0.23 (0.20)
Epoch: [006][00060/00231]	Time 0.22 (0.22)	Loss 1.12 (0.83)
		cls_loss 0.54 (0.40)	reg_loss 0.29 (0.22)
Epoch: [006][00070/00231]	Time 0.22 (0.22)	Loss 0.59 (0.79)
		cls_loss 0.29 (0.38)	reg_loss 0.15 (0.21)
Epoch: [006][00080/00231]	Time 0.22 (0.22)	Loss 0.44 (0.75)
		cls_loss 0.23 (0.36)	reg_loss 0.11 (0.19)
Epoch: [006][00090/00231]	Time 0.22 (0.22)	Loss 1.04 (0.78)
		cls_loss 0.46 (0.37)	reg_loss 0.29 (0.20)
Epoch: [006][00100/00231]	Time 0.22 (0.22)	Loss 0.92 (0.80)
		cls_loss 0.43 (0.38)	reg_loss 0.24 (0.21)
Epoch: [006][00110/00231]	Time 0.22 (0.22)	Loss 0.54 (0.77)
		cls_loss 0.27 (0.37)	reg_loss 0.14 (0.20)
Epoch: [006][00120/00231]	Time 0.19 (0.22)	Loss 0.92 (0.79)
		cls_loss 0.43 (0.38)	reg_loss 0.25 (0.21)
Epoch: [006][00130/00231]	Time 1.49 (0.32)	Loss 0.81 (0.79)
		cls_loss 0.40 (0.38)	reg_loss 0.21 (0.21)
Epoch: [006][00140/00231]	Time 0.37 (0.32)	Loss 0.69 (0.78)
		cls_loss 0.34 (0.37)	reg_loss 0.18 (0.20)
Epoch: [006][00150/00231]	Time 0.20 (0.31)	Loss 0.97 (0.79)
		cls_loss 0.46 (0.38)	reg_loss 0.25 (0.21)
Epoch: [006][00160/00231]	Time 0.20 (0.30)	Loss 0.94 (0.80)
		cls_loss 0.41 (0.38)	reg_loss 0.26 (0.21)
Epoch: [006][00170/00231]	Time 0.19 (0.30)	Loss 0.75 (0.80)
		cls_loss 0.35 (0.38)	reg_loss 0.20 (0.21)
Epoch: [006][00180/00231]	Time 0.20 (0.29)	Loss 0.75 (0.80)
		cls_loss 0.35 (0.38)	reg_loss 0.20 (0.21)
Epoch: [006][00190/00231]	Time 0.20 (0.29)	Loss 1.15 (0.82)
		cls_loss 0.57 (0.39)	reg_loss 0.29 (0.21)
Epoch: [006][00200/00231]	Time 0.19 (0.28)	Loss 0.59 (0.80)
		cls_loss 0.31 (0.38)	reg_loss 0.14 (0.21)
Epoch: [006][00210/00231]	Time 0.19 (0.28)	Loss 0.99 (0.81)
		cls_loss 0.51 (0.39)	reg_loss 0.24 (0.21)
Epoch: [006][00220/00231]	Time 0.19 (0.27)	Loss 0.86 (0.82)
		cls_loss 0.37 (0.39)	reg_loss 0.25 (0.21)
Epoch: [006][00230/00231]	Time 0.18 (0.27)	Loss 1.20 (0.83)
		cls_loss 0.51 (0.39)	reg_loss 0.35 (0.22)
[Train]: Epoch 6 finished with lr=0.00090451


[Train]: Epoch 7 started
Epoch: [007][00010/00231]	Time 0.25 (0.25)	Loss 0.52 (0.52)
		cls_loss 0.25 (0.25)	reg_loss 0.13 (0.13)
Epoch: [007][00020/00231]	Time 0.18 (0.22)	Loss 0.99 (0.75)
		cls_loss 0.44 (0.35)	reg_loss 0.27 (0.20)
Epoch: [007][00030/00231]	Time 0.20 (0.21)	Loss 0.85 (0.79)
		cls_loss 0.42 (0.37)	reg_loss 0.22 (0.21)
Epoch: [007][00040/00231]	Time 0.22 (0.21)	Loss 0.77 (0.78)
		cls_loss 0.38 (0.37)	reg_loss 0.20 (0.20)
Epoch: [007][00050/00231]	Time 0.21 (0.21)	Loss 0.75 (0.78)
		cls_loss 0.36 (0.37)	reg_loss 0.19 (0.20)
Epoch: [007][00060/00231]	Time 0.21 (0.21)	Loss 0.87 (0.79)
		cls_loss 0.40 (0.38)	reg_loss 0.24 (0.21)
Epoch: [007][00070/00231]	Time 0.21 (0.21)	Loss 1.17 (0.85)
		cls_loss 0.57 (0.40)	reg_loss 0.30 (0.22)
Epoch: [007][00080/00231]	Time 0.21 (0.21)	Loss 0.95 (0.86)
		cls_loss 0.41 (0.40)	reg_loss 0.27 (0.23)
Epoch: [007][00090/00231]	Time 0.21 (0.21)	Loss 0.91 (0.87)
		cls_loss 0.39 (0.40)	reg_loss 0.26 (0.23)
Epoch: [007][00100/00231]	Time 0.22 (0.21)	Loss 1.31 (0.91)
		cls_loss 0.58 (0.42)	reg_loss 0.36 (0.24)
Epoch: [007][00110/00231]	Time 0.22 (0.21)	Loss 1.06 (0.92)
		cls_loss 0.48 (0.43)	reg_loss 0.29 (0.25)
Epoch: [007][00120/00231]	Time 0.21 (0.21)	Loss 0.76 (0.91)
		cls_loss 0.33 (0.42)	reg_loss 0.21 (0.25)
Epoch: [007][00130/00231]	Time 0.21 (0.21)	Loss 0.97 (0.91)
		cls_loss 0.43 (0.42)	reg_loss 0.27 (0.25)
Epoch: [007][00140/00231]	Time 0.22 (0.21)	Loss 0.93 (0.92)
		cls_loss 0.40 (0.42)	reg_loss 0.26 (0.25)
Epoch: [007][00150/00231]	Time 0.21 (0.21)	Loss 0.81 (0.91)
		cls_loss 0.41 (0.42)	reg_loss 0.20 (0.25)
Epoch: [007][00160/00231]	Time 0.22 (0.21)	Loss 0.61 (0.89)
		cls_loss 0.30 (0.41)	reg_loss 0.16 (0.24)
Epoch: [007][00170/00231]	Time 0.21 (0.21)	Loss 0.91 (0.89)
		cls_loss 0.42 (0.41)	reg_loss 0.25 (0.24)
Epoch: [007][00180/00231]	Time 0.22 (0.21)	Loss 0.68 (0.88)
		cls_loss 0.29 (0.40)	reg_loss 0.19 (0.24)
Epoch: [007][00190/00231]	Time 0.21 (0.21)	Loss 0.54 (0.86)
		cls_loss 0.28 (0.40)	reg_loss 0.13 (0.23)
Epoch: [007][00200/00231]	Time 0.22 (0.21)	Loss 0.79 (0.86)
		cls_loss 0.38 (0.40)	reg_loss 0.21 (0.23)
Epoch: [007][00210/00231]	Time 0.22 (0.21)	Loss 0.64 (0.85)
		cls_loss 0.36 (0.39)	reg_loss 0.14 (0.23)
Epoch: [007][00220/00231]	Time 0.22 (0.21)	Loss 0.53 (0.83)
		cls_loss 0.27 (0.39)	reg_loss 0.13 (0.22)
Epoch: [007][00230/00231]	Time 0.18 (0.21)	Loss 0.67 (0.83)
		cls_loss 0.34 (0.39)	reg_loss 0.17 (0.22)
[Train]: Epoch 7 finished with lr=0.00079389


[Train]: Epoch 8 started
Epoch: [008][00010/00231]	Time 0.23 (0.23)	Loss 0.90 (0.90)
		cls_loss 0.46 (0.46)	reg_loss 0.22 (0.22)
Epoch: [008][00020/00231]	Time 1.10 (0.67)	Loss 0.79 (0.84)
		cls_loss 0.38 (0.42)	reg_loss 0.21 (0.21)
Epoch: [008][00030/00231]	Time 0.19 (0.51)	Loss 1.26 (0.98)
		cls_loss 0.54 (0.46)	reg_loss 0.36 (0.26)
Epoch: [008][00040/00231]	Time 0.18 (0.42)	Loss 0.82 (0.94)
		cls_loss 0.40 (0.44)	reg_loss 0.21 (0.25)
Epoch: [008][00050/00231]	Time 0.21 (0.38)	Loss 0.45 (0.85)
		cls_loss 0.24 (0.40)	reg_loss 0.10 (0.22)
Epoch: [008][00060/00231]	Time 0.20 (0.35)	Loss 0.95 (0.86)
		cls_loss 0.42 (0.41)	reg_loss 0.26 (0.23)
Epoch: [008][00070/00231]	Time 0.20 (0.33)	Loss 0.61 (0.83)
		cls_loss 0.35 (0.40)	reg_loss 0.13 (0.21)
Epoch: [008][00080/00231]	Time 0.20 (0.31)	Loss 0.63 (0.80)
		cls_loss 0.30 (0.39)	reg_loss 0.17 (0.21)
Epoch: [008][00090/00231]	Time 0.20 (0.30)	Loss 0.85 (0.81)
		cls_loss 0.40 (0.39)	reg_loss 0.22 (0.21)
Epoch: [008][00100/00231]	Time 0.20 (0.29)	Loss 1.32 (0.86)
		cls_loss 0.61 (0.41)	reg_loss 0.35 (0.22)
Epoch: [008][00110/00231]	Time 0.21 (0.28)	Loss 0.62 (0.84)
		cls_loss 0.32 (0.40)	reg_loss 0.15 (0.22)
Epoch: [008][00120/00231]	Time 0.21 (0.28)	Loss 0.72 (0.83)
		cls_loss 0.36 (0.40)	reg_loss 0.18 (0.21)
Epoch: [008][00130/00231]	Time 0.21 (0.27)	Loss 0.42 (0.80)
		cls_loss 0.20 (0.38)	reg_loss 0.11 (0.21)
Epoch: [008][00140/00231]	Time 0.21 (0.27)	Loss 0.72 (0.79)
		cls_loss 0.34 (0.38)	reg_loss 0.19 (0.21)
Epoch: [008][00150/00231]	Time 0.22 (0.27)	Loss 0.90 (0.80)
		cls_loss 0.45 (0.39)	reg_loss 0.23 (0.21)
Epoch: [008][00160/00231]	Time 0.21 (0.26)	Loss 0.76 (0.80)
		cls_loss 0.34 (0.38)	reg_loss 0.21 (0.21)
Epoch: [008][00170/00231]	Time 0.21 (0.26)	Loss 0.80 (0.80)
		cls_loss 0.35 (0.38)	reg_loss 0.22 (0.21)
Epoch: [008][00180/00231]	Time 0.21 (0.26)	Loss 0.78 (0.80)
		cls_loss 0.42 (0.38)	reg_loss 0.18 (0.21)
Epoch: [008][00190/00231]	Time 0.21 (0.25)	Loss 1.72 (0.84)
		cls_loss 0.77 (0.40)	reg_loss 0.48 (0.22)
Epoch: [008][00200/00231]	Time 0.22 (0.25)	Loss 0.63 (0.83)
		cls_loss 0.29 (0.40)	reg_loss 0.17 (0.22)
Epoch: [008][00210/00231]	Time 0.21 (0.25)	Loss 0.71 (0.83)
		cls_loss 0.36 (0.40)	reg_loss 0.17 (0.22)
Epoch: [008][00220/00231]	Time 0.21 (0.25)	Loss 0.91 (0.83)
		cls_loss 0.40 (0.40)	reg_loss 0.26 (0.22)
Epoch: [008][00230/00231]	Time 0.18 (0.25)	Loss 0.77 (0.83)
		cls_loss 0.38 (0.40)	reg_loss 0.20 (0.22)
[Train]: Epoch 8 finished with lr=0.00065451


[Train]: Epoch 9 started
Epoch: [009][00010/00231]	Time 0.25 (0.25)	Loss 0.49 (0.49)
		cls_loss 0.26 (0.26)	reg_loss 0.12 (0.12)
Epoch: [009][00020/00231]	Time 0.22 (0.23)	Loss 0.69 (0.59)
		cls_loss 0.37 (0.31)	reg_loss 0.16 (0.14)
Epoch: [009][00030/00231]	Time 0.21 (0.23)	Loss 0.93 (0.70)
		cls_loss 0.45 (0.36)	reg_loss 0.24 (0.17)
Epoch: [009][00040/00231]	Time 0.22 (0.23)	Loss 1.04 (0.79)
		cls_loss 0.48 (0.39)	reg_loss 0.28 (0.20)
Epoch: [009][00050/00231]	Time 0.21 (0.22)	Loss 0.62 (0.76)
		cls_loss 0.32 (0.38)	reg_loss 0.15 (0.19)
Epoch: [009][00060/00231]	Time 0.22 (0.22)	Loss 0.72 (0.75)
		cls_loss 0.36 (0.37)	reg_loss 0.18 (0.19)
Epoch: [009][00070/00231]	Time 0.21 (0.22)	Loss 0.83 (0.76)
		cls_loss 0.40 (0.38)	reg_loss 0.22 (0.19)
Epoch: [009][00080/00231]	Time 0.22 (0.22)	Loss 0.59 (0.74)
		cls_loss 0.29 (0.37)	reg_loss 0.15 (0.19)
Epoch: [009][00090/00231]	Time 0.22 (0.22)	Loss 0.74 (0.74)
		cls_loss 0.36 (0.37)	reg_loss 0.19 (0.19)
Epoch: [009][00100/00231]	Time 0.22 (0.22)	Loss 0.42 (0.71)
		cls_loss 0.24 (0.35)	reg_loss 0.09 (0.18)
Epoch: [009][00110/00231]	Time 0.21 (0.22)	Loss 0.56 (0.69)
		cls_loss 0.24 (0.34)	reg_loss 0.16 (0.18)
Epoch: [009][00120/00231]	Time 0.22 (0.22)	Loss 0.56 (0.68)
		cls_loss 0.28 (0.34)	reg_loss 0.14 (0.17)
Epoch: [009][00130/00231]	Time 0.22 (0.22)	Loss 0.94 (0.70)
		cls_loss 0.41 (0.34)	reg_loss 0.27 (0.18)
Epoch: [009][00140/00231]	Time 0.22 (0.22)	Loss 0.47 (0.69)
		cls_loss 0.25 (0.34)	reg_loss 0.11 (0.18)
Epoch: [009][00150/00231]	Time 0.21 (0.22)	Loss 0.59 (0.68)
		cls_loss 0.28 (0.33)	reg_loss 0.16 (0.17)
Epoch: [009][00160/00231]	Time 0.21 (0.22)	Loss 0.94 (0.70)
		cls_loss 0.44 (0.34)	reg_loss 0.25 (0.18)
Epoch: [009][00170/00231]	Time 0.21 (0.22)	Loss 1.26 (0.73)
		cls_loss 0.64 (0.36)	reg_loss 0.31 (0.19)
Epoch: [009][00180/00231]	Time 0.22 (0.22)	Loss 0.61 (0.72)
		cls_loss 0.31 (0.35)	reg_loss 0.15 (0.18)
Epoch: [009][00190/00231]	Time 0.22 (0.22)	Loss 0.82 (0.73)
		cls_loss 0.40 (0.36)	reg_loss 0.21 (0.19)
Epoch: [009][00200/00231]	Time 0.22 (0.22)	Loss 0.53 (0.72)
		cls_loss 0.26 (0.35)	reg_loss 0.14 (0.18)
Epoch: [009][00210/00231]	Time 0.22 (0.22)	Loss 1.05 (0.73)
		cls_loss 0.43 (0.36)	reg_loss 0.31 (0.19)
Epoch: [009][00220/00231]	Time 0.21 (0.22)	Loss 0.61 (0.73)
		cls_loss 0.30 (0.35)	reg_loss 0.15 (0.19)
Epoch: [009][00230/00231]	Time 0.18 (0.22)	Loss 0.62 (0.72)
		cls_loss 0.30 (0.35)	reg_loss 0.16 (0.19)
[Train]: Epoch 9 finished with lr=0.00050001


[Train]: Epoch 10 started
Epoch: [010][00010/00231]	Time 0.26 (0.26)	Loss 0.50 (0.50)
		cls_loss 0.26 (0.26)	reg_loss 0.12 (0.12)
Epoch: [010][00020/00231]	Time 0.19 (0.23)	Loss 0.48 (0.49)
		cls_loss 0.24 (0.25)	reg_loss 0.12 (0.12)
Epoch: [010][00030/00231]	Time 0.19 (0.22)	Loss 0.81 (0.60)
		cls_loss 0.39 (0.30)	reg_loss 0.21 (0.15)
Epoch: [010][00040/00231]	Time 0.19 (0.21)	Loss 0.93 (0.68)
		cls_loss 0.41 (0.33)	reg_loss 0.26 (0.18)
Epoch: [010][00050/00231]	Time 0.18 (0.20)	Loss 0.52 (0.65)
		cls_loss 0.28 (0.32)	reg_loss 0.12 (0.16)
Epoch: [010][00060/00231]	Time 2.12 (0.52)	Loss 0.63 (0.64)
		cls_loss 0.28 (0.31)	reg_loss 0.17 (0.17)
Epoch: [010][00070/00231]	Time 0.18 (0.47)	Loss 0.77 (0.66)
		cls_loss 0.37 (0.32)	reg_loss 0.20 (0.17)
Epoch: [010][00080/00231]	Time 0.72 (0.50)	Loss 0.65 (0.66)
		cls_loss 0.29 (0.32)	reg_loss 0.18 (0.17)
Epoch: [010][00090/00231]	Time 0.21 (0.47)	Loss 1.26 (0.73)
		cls_loss 0.60 (0.35)	reg_loss 0.33 (0.19)
Epoch: [010][00100/00231]	Time 0.19 (0.44)	Loss 0.95 (0.75)
		cls_loss 0.41 (0.35)	reg_loss 0.27 (0.20)
Epoch: [010][00110/00231]	Time 0.19 (0.42)	Loss 0.63 (0.74)
		cls_loss 0.37 (0.36)	reg_loss 0.13 (0.19)
Epoch: [010][00120/00231]	Time 0.40 (0.42)	Loss 0.78 (0.74)
		cls_loss 0.39 (0.36)	reg_loss 0.20 (0.19)
Epoch: [010][00130/00231]	Time 0.20 (0.40)	Loss 0.63 (0.73)
		cls_loss 0.32 (0.35)	reg_loss 0.16 (0.19)
Epoch: [010][00140/00231]	Time 0.23 (0.39)	Loss 0.62 (0.73)
		cls_loss 0.32 (0.35)	reg_loss 0.15 (0.19)
Epoch: [010][00150/00231]	Time 0.20 (0.38)	Loss 0.56 (0.71)
		cls_loss 0.26 (0.35)	reg_loss 0.15 (0.18)
Epoch: [010][00160/00231]	Time 0.25 (0.37)	Loss 0.74 (0.72)
		cls_loss 0.34 (0.35)	reg_loss 0.20 (0.19)
Epoch: [010][00170/00231]	Time 1.12 (0.41)	Loss 0.65 (0.71)
		cls_loss 0.32 (0.34)	reg_loss 0.17 (0.18)
Epoch: [010][00180/00231]	Time 0.20 (0.40)	Loss 0.84 (0.72)
		cls_loss 0.37 (0.35)	reg_loss 0.24 (0.19)
Epoch: [010][00190/00231]	Time 0.20 (0.39)	Loss 0.56 (0.71)
		cls_loss 0.30 (0.34)	reg_loss 0.13 (0.18)
Epoch: [010][00200/00231]	Time 0.20 (0.38)	Loss 0.78 (0.72)
		cls_loss 0.38 (0.34)	reg_loss 0.20 (0.19)
Epoch: [010][00210/00231]	Time 0.20 (0.37)	Loss 0.71 (0.71)
		cls_loss 0.34 (0.34)	reg_loss 0.18 (0.19)
Epoch: [010][00220/00231]	Time 0.19 (0.36)	Loss 0.85 (0.72)
		cls_loss 0.35 (0.35)	reg_loss 0.25 (0.19)
Epoch: [010][00230/00231]	Time 0.17 (0.36)	Loss 0.71 (0.72)
		cls_loss 0.33 (0.34)	reg_loss 0.19 (0.19)
[Train]: Epoch 10 finished with lr=0.00034550


[Train]: Epoch 11 started
Epoch: [011][00010/00231]	Time 0.25 (0.25)	Loss 0.71 (0.71)
		cls_loss 0.33 (0.33)	reg_loss 0.19 (0.19)
Epoch: [011][00020/00231]	Time 0.19 (0.22)	Loss 1.06 (0.89)
		cls_loss 0.51 (0.42)	reg_loss 0.28 (0.23)
Epoch: [011][00030/00231]	Time 0.20 (0.21)	Loss 0.63 (0.80)
		cls_loss 0.27 (0.37)	reg_loss 0.18 (0.22)
Epoch: [011][00040/00231]	Time 0.21 (0.21)	Loss 0.46 (0.72)
		cls_loss 0.24 (0.34)	reg_loss 0.11 (0.19)
Epoch: [011][00050/00231]	Time 0.21 (0.21)	Loss 0.76 (0.73)
		cls_loss 0.32 (0.33)	reg_loss 0.22 (0.20)
Epoch: [011][00060/00231]	Time 0.22 (0.21)	Loss 0.81 (0.74)
		cls_loss 0.35 (0.34)	reg_loss 0.23 (0.20)
Epoch: [011][00070/00231]	Time 0.22 (0.21)	Loss 0.77 (0.75)
		cls_loss 0.38 (0.34)	reg_loss 0.20 (0.20)
Epoch: [011][00080/00231]	Time 0.22 (0.21)	Loss 0.42 (0.70)
		cls_loss 0.21 (0.33)	reg_loss 0.10 (0.19)
Epoch: [011][00090/00231]	Time 0.22 (0.21)	Loss 1.50 (0.79)
		cls_loss 0.74 (0.37)	reg_loss 0.38 (0.21)
Epoch: [011][00100/00231]	Time 0.22 (0.21)	Loss 1.06 (0.82)
		cls_loss 0.49 (0.38)	reg_loss 0.29 (0.22)
Epoch: [011][00110/00231]	Time 0.22 (0.22)	Loss 0.83 (0.82)
		cls_loss 0.41 (0.39)	reg_loss 0.21 (0.22)
Epoch: [011][00120/00231]	Time 0.22 (0.22)	Loss 0.68 (0.81)
		cls_loss 0.30 (0.38)	reg_loss 0.19 (0.21)
Epoch: [011][00130/00231]	Time 0.22 (0.22)	Loss 0.82 (0.81)
		cls_loss 0.39 (0.38)	reg_loss 0.21 (0.21)
Epoch: [011][00140/00231]	Time 0.22 (0.22)	Loss 0.68 (0.80)
		cls_loss 0.36 (0.38)	reg_loss 0.16 (0.21)
Epoch: [011][00150/00231]	Time 0.22 (0.22)	Loss 0.57 (0.79)
		cls_loss 0.27 (0.37)	reg_loss 0.15 (0.21)
Epoch: [011][00160/00231]	Time 0.22 (0.22)	Loss 0.39 (0.76)
		cls_loss 0.22 (0.36)	reg_loss 0.09 (0.20)
Epoch: [011][00170/00231]	Time 0.22 (0.22)	Loss 1.08 (0.78)
		cls_loss 0.48 (0.37)	reg_loss 0.30 (0.21)
Epoch: [011][00180/00231]	Time 0.22 (0.22)	Loss 0.59 (0.77)
		cls_loss 0.27 (0.36)	reg_loss 0.16 (0.20)
Epoch: [011][00190/00231]	Time 0.23 (0.22)	Loss 0.80 (0.77)
		cls_loss 0.35 (0.36)	reg_loss 0.23 (0.20)
Epoch: [011][00200/00231]	Time 0.22 (0.22)	Loss 0.65 (0.77)
		cls_loss 0.33 (0.36)	reg_loss 0.16 (0.20)
Epoch: [011][00210/00231]	Time 0.22 (0.22)	Loss 0.57 (0.76)
		cls_loss 0.29 (0.36)	reg_loss 0.14 (0.20)
Epoch: [011][00220/00231]	Time 0.22 (0.22)	Loss 0.78 (0.76)
		cls_loss 0.41 (0.36)	reg_loss 0.19 (0.20)
Epoch: [011][00230/00231]	Time 0.18 (0.22)	Loss 0.57 (0.75)
		cls_loss 0.31 (0.36)	reg_loss 0.13 (0.20)
[Train]: Epoch 11 finished with lr=0.00020612


[Train]: Epoch 12 started
Epoch: [012][00010/00231]	Time 0.28 (0.28)	Loss 0.45 (0.45)
		cls_loss 0.21 (0.21)	reg_loss 0.12 (0.12)
Epoch: [012][00020/00231]	Time 0.22 (0.25)	Loss 0.57 (0.51)
		cls_loss 0.26 (0.24)	reg_loss 0.15 (0.13)
Epoch: [012][00030/00231]	Time 0.22 (0.24)	Loss 1.06 (0.69)
		cls_loss 0.46 (0.31)	reg_loss 0.30 (0.19)
Epoch: [012][00040/00231]	Time 0.22 (0.24)	Loss 1.30 (0.84)
		cls_loss 0.56 (0.37)	reg_loss 0.37 (0.23)
Epoch: [012][00050/00231]	Time 0.22 (0.23)	Loss 0.76 (0.83)
		cls_loss 0.34 (0.37)	reg_loss 0.21 (0.23)
Epoch: [012][00060/00231]	Time 0.22 (0.23)	Loss 1.24 (0.89)
		cls_loss 0.58 (0.40)	reg_loss 0.33 (0.25)
Epoch: [012][00070/00231]	Time 0.22 (0.23)	Loss 0.82 (0.88)
		cls_loss 0.39 (0.40)	reg_loss 0.21 (0.24)
Epoch: [012][00080/00231]	Time 0.22 (0.23)	Loss 0.90 (0.89)
		cls_loss 0.39 (0.40)	reg_loss 0.25 (0.24)
Epoch: [012][00090/00231]	Time 0.22 (0.23)	Loss 1.01 (0.90)
		cls_loss 0.48 (0.41)	reg_loss 0.27 (0.25)
Epoch: [012][00100/00231]	Time 0.22 (0.23)	Loss 0.83 (0.89)
		cls_loss 0.36 (0.40)	reg_loss 0.23 (0.24)
Epoch: [012][00110/00231]	Time 0.22 (0.23)	Loss 0.42 (0.85)
		cls_loss 0.25 (0.39)	reg_loss 0.08 (0.23)
Epoch: [012][00120/00231]	Time 0.22 (0.22)	Loss 0.49 (0.82)
		cls_loss 0.25 (0.38)	reg_loss 0.12 (0.22)
Epoch: [012][00130/00231]	Time 0.22 (0.22)	Loss 0.65 (0.81)
		cls_loss 0.29 (0.37)	reg_loss 0.18 (0.22)
Epoch: [012][00140/00231]	Time 0.22 (0.22)	Loss 0.86 (0.81)
		cls_loss 0.36 (0.37)	reg_loss 0.25 (0.22)
Epoch: [012][00150/00231]	Time 0.22 (0.22)	Loss 0.99 (0.82)
		cls_loss 0.44 (0.37)	reg_loss 0.28 (0.22)
Epoch: [012][00160/00231]	Time 0.22 (0.22)	Loss 0.51 (0.80)
		cls_loss 0.25 (0.37)	reg_loss 0.13 (0.22)
Epoch: [012][00170/00231]	Time 0.22 (0.22)	Loss 0.67 (0.79)
		cls_loss 0.31 (0.36)	reg_loss 0.18 (0.22)
Epoch: [012][00180/00231]	Time 0.22 (0.22)	Loss 0.71 (0.79)
		cls_loss 0.36 (0.36)	reg_loss 0.17 (0.21)
Epoch: [012][00190/00231]	Time 0.22 (0.22)	Loss 0.42 (0.77)
		cls_loss 0.20 (0.35)	reg_loss 0.11 (0.21)
Epoch: [012][00200/00231]	Time 0.22 (0.22)	Loss 0.92 (0.78)
		cls_loss 0.41 (0.36)	reg_loss 0.25 (0.21)
Epoch: [012][00210/00231]	Time 0.22 (0.22)	Loss 0.76 (0.78)
		cls_loss 0.36 (0.36)	reg_loss 0.20 (0.21)
Epoch: [012][00220/00231]	Time 0.22 (0.22)	Loss 0.75 (0.78)
		cls_loss 0.36 (0.36)	reg_loss 0.20 (0.21)
Epoch: [012][00230/00231]	Time 0.18 (0.22)	Loss 1.02 (0.79)
		cls_loss 0.49 (0.36)	reg_loss 0.26 (0.21)
[Train]: Epoch 12 finished with lr=0.00009550


[Train]: Epoch 13 started
Epoch: [013][00010/00231]	Time 0.29 (0.29)	Loss 0.69 (0.69)
		cls_loss 0.31 (0.31)	reg_loss 0.19 (0.19)
Epoch: [013][00020/00231]	Time 0.22 (0.26)	Loss 0.83 (0.76)
		cls_loss 0.40 (0.36)	reg_loss 0.21 (0.20)
Epoch: [013][00030/00231]	Time 0.22 (0.24)	Loss 0.68 (0.73)
		cls_loss 0.31 (0.34)	reg_loss 0.19 (0.20)
Epoch: [013][00040/00231]	Time 0.22 (0.24)	Loss 0.99 (0.80)
		cls_loss 0.47 (0.37)	reg_loss 0.26 (0.21)
Epoch: [013][00050/00231]	Time 0.22 (0.23)	Loss 0.50 (0.74)
		cls_loss 0.24 (0.35)	reg_loss 0.13 (0.19)
Epoch: [013][00060/00231]	Time 0.22 (0.23)	Loss 0.94 (0.77)
		cls_loss 0.43 (0.36)	reg_loss 0.25 (0.20)
Epoch: [013][00070/00231]	Time 0.22 (0.23)	Loss 0.37 (0.71)
		cls_loss 0.21 (0.34)	reg_loss 0.08 (0.19)
Epoch: [013][00080/00231]	Time 0.22 (0.23)	Loss 0.94 (0.74)
		cls_loss 0.44 (0.35)	reg_loss 0.25 (0.20)
Epoch: [013][00090/00231]	Time 0.22 (0.23)	Loss 0.49 (0.71)
		cls_loss 0.24 (0.34)	reg_loss 0.12 (0.19)
Epoch: [013][00100/00231]	Time 0.22 (0.23)	Loss 0.79 (0.72)
		cls_loss 0.36 (0.34)	reg_loss 0.22 (0.19)
Epoch: [013][00110/00231]	Time 0.22 (0.23)	Loss 0.59 (0.71)
		cls_loss 0.28 (0.34)	reg_loss 0.16 (0.19)
Epoch: [013][00120/00231]	Time 0.22 (0.23)	Loss 0.59 (0.70)
		cls_loss 0.30 (0.33)	reg_loss 0.15 (0.18)
Epoch: [013][00130/00231]	Time 0.22 (0.22)	Loss 0.64 (0.70)
		cls_loss 0.31 (0.33)	reg_loss 0.16 (0.18)
Epoch: [013][00140/00231]	Time 0.22 (0.22)	Loss 0.79 (0.70)
		cls_loss 0.41 (0.34)	reg_loss 0.19 (0.18)
Epoch: [013][00150/00231]	Time 0.22 (0.22)	Loss 1.04 (0.73)
		cls_loss 0.51 (0.35)	reg_loss 0.27 (0.19)
Epoch: [013][00160/00231]	Time 0.22 (0.22)	Loss 0.64 (0.72)
		cls_loss 0.31 (0.35)	reg_loss 0.17 (0.19)
Epoch: [013][00170/00231]	Time 0.22 (0.22)	Loss 0.48 (0.71)
		cls_loss 0.22 (0.34)	reg_loss 0.13 (0.18)
Epoch: [013][00180/00231]	Time 0.19 (0.22)	Loss 0.38 (0.69)
		cls_loss 0.17 (0.33)	reg_loss 0.11 (0.18)
Epoch: [013][00190/00231]	Time 3.82 (0.41)	Loss 0.95 (0.70)
		cls_loss 0.41 (0.33)	reg_loss 0.27 (0.18)
Epoch: [013][00200/00231]	Time 0.22 (0.40)	Loss 0.79 (0.71)
		cls_loss 0.39 (0.34)	reg_loss 0.20 (0.18)
Epoch: [013][00210/00231]	Time 0.22 (0.39)	Loss 0.62 (0.70)
		cls_loss 0.32 (0.34)	reg_loss 0.15 (0.18)
Epoch: [013][00220/00231]	Time 0.21 (0.38)	Loss 0.69 (0.70)
		cls_loss 0.29 (0.33)	reg_loss 0.20 (0.18)
Epoch: [013][00230/00231]	Time 0.18 (0.38)	Loss 0.46 (0.69)
		cls_loss 0.27 (0.33)	reg_loss 0.09 (0.18)
[Train]: Epoch 13 finished with lr=0.00002448


[Train]: Epoch 14 started
Epoch: [014][00010/00231]	Time 0.27 (0.27)	Loss 0.52 (0.52)
		cls_loss 0.24 (0.24)	reg_loss 0.14 (0.14)
Epoch: [014][00020/00231]	Time 0.20 (0.24)	Loss 1.07 (0.80)
		cls_loss 0.47 (0.36)	reg_loss 0.30 (0.22)
Epoch: [014][00030/00231]	Time 0.21 (0.23)	Loss 0.56 (0.72)
		cls_loss 0.26 (0.32)	reg_loss 0.15 (0.20)
Epoch: [014][00040/00231]	Time 0.20 (0.22)	Loss 0.48 (0.66)
		cls_loss 0.22 (0.30)	reg_loss 0.13 (0.18)
Epoch: [014][00050/00231]	Time 0.21 (0.22)	Loss 0.50 (0.63)
		cls_loss 0.22 (0.28)	reg_loss 0.14 (0.17)
Epoch: [014][00060/00231]	Time 0.21 (0.22)	Loss 0.66 (0.63)
		cls_loss 0.32 (0.29)	reg_loss 0.17 (0.17)
Epoch: [014][00070/00231]	Time 0.21 (0.22)	Loss 0.62 (0.63)
		cls_loss 0.29 (0.29)	reg_loss 0.16 (0.17)
Epoch: [014][00080/00231]	Time 0.21 (0.21)	Loss 0.61 (0.63)
		cls_loss 0.28 (0.29)	reg_loss 0.16 (0.17)
Epoch: [014][00090/00231]	Time 0.22 (0.21)	Loss 0.53 (0.62)
		cls_loss 0.25 (0.28)	reg_loss 0.14 (0.17)
Epoch: [014][00100/00231]	Time 0.22 (0.21)	Loss 0.52 (0.61)
		cls_loss 0.27 (0.28)	reg_loss 0.12 (0.16)
Epoch: [014][00110/00231]	Time 0.22 (0.22)	Loss 0.44 (0.59)
		cls_loss 0.22 (0.28)	reg_loss 0.11 (0.16)
Epoch: [014][00120/00231]	Time 0.22 (0.22)	Loss 0.89 (0.62)
		cls_loss 0.38 (0.29)	reg_loss 0.26 (0.17)
Epoch: [014][00130/00231]	Time 0.22 (0.22)	Loss 0.57 (0.61)
		cls_loss 0.29 (0.29)	reg_loss 0.14 (0.16)
Epoch: [014][00140/00231]	Time 0.22 (0.22)	Loss 0.68 (0.62)
		cls_loss 0.36 (0.29)	reg_loss 0.16 (0.16)
Epoch: [014][00150/00231]	Time 0.22 (0.22)	Loss 0.66 (0.62)
		cls_loss 0.33 (0.29)	reg_loss 0.17 (0.16)
Epoch: [014][00160/00231]	Time 0.22 (0.22)	Loss 0.56 (0.62)
		cls_loss 0.28 (0.29)	reg_loss 0.14 (0.16)
Epoch: [014][00170/00231]	Time 0.22 (0.22)	Loss 0.50 (0.61)
		cls_loss 0.23 (0.29)	reg_loss 0.13 (0.16)
Epoch: [014][00180/00231]	Time 0.22 (0.22)	Loss 0.57 (0.61)
		cls_loss 0.25 (0.29)	reg_loss 0.16 (0.16)
Epoch: [014][00190/00231]	Time 0.22 (0.22)	Loss 0.70 (0.61)
		cls_loss 0.34 (0.29)	reg_loss 0.18 (0.16)
Epoch: [014][00200/00231]	Time 0.22 (0.22)	Loss 0.90 (0.63)
		cls_loss 0.46 (0.30)	reg_loss 0.22 (0.16)
Epoch: [014][00210/00231]	Time 0.22 (0.22)	Loss 0.74 (0.63)
		cls_loss 0.35 (0.30)	reg_loss 0.19 (0.17)
Epoch: [014][00220/00231]	Time 0.21 (0.22)	Loss 0.66 (0.63)
		cls_loss 0.30 (0.30)	reg_loss 0.18 (0.17)
Epoch: [014][00230/00231]	Time 0.18 (0.21)	Loss 0.93 (0.65)
		cls_loss 0.45 (0.31)	reg_loss 0.24 (0.17)
[Train]: Epoch 14 finished with lr=0.00000001

All done!
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
=> loading checkpoint './ckpt/anet_i3d_reproduce/epoch_015.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/04555]	Time 0.98 (0.98)
Test: [00020/04555]	Time 0.04 (0.51)
Test: [00030/04555]	Time 0.04 (0.35)
Test: [00040/04555]	Time 0.04 (0.27)
Test: [00050/04555]	Time 0.08 (0.23)
Test: [00060/04555]	Time 0.04 (0.20)
Test: [00070/04555]	Time 0.04 (0.18)
Test: [00080/04555]	Time 0.04 (0.16)
Test: [00090/04555]	Time 0.04 (0.15)
Test: [00100/04555]	Time 0.04 (0.14)
Test: [00110/04555]	Time 0.04 (0.13)
Test: [00120/04555]	Time 0.05 (0.12)
Test: [00130/04555]	Time 0.04 (0.12)
Test: [00140/04555]	Time 0.04 (0.11)
Test: [00150/04555]	Time 0.04 (0.10)
Test: [00160/04555]	Time 0.08 (0.10)
Test: [00170/04555]	Time 0.04 (0.10)
Test: [00180/04555]	Time 0.04 (0.10)
Test: [00190/04555]	Time 0.04 (0.09)
Test: [00200/04555]	Time 0.04 (0.09)
Test: [00210/04555]	Time 0.04 (0.09)
Test: [00220/04555]	Time 0.14 (0.09)
Test: [00230/04555]	Time 0.20 (0.10)
Test: [00240/04555]	Time 0.04 (0.09)
Test: [00250/04555]	Time 0.04 (0.09)
Test: [00260/04555]	Time 0.04 (0.09)
Test: [00270/04555]	Time 0.06 (0.09)
Test: [00280/04555]	Time 0.04 (0.09)
Test: [00290/04555]	Time 0.04 (0.08)
Test: [00300/04555]	Time 0.04 (0.08)
Test: [00310/04555]	Time 0.04 (0.08)
Test: [00320/04555]	Time 0.04 (0.08)
Test: [00330/04555]	Time 0.04 (0.08)
Test: [00340/04555]	Time 0.23 (0.08)
Test: [00350/04555]	Time 0.24 (0.09)
Test: [00360/04555]	Time 0.24 (0.09)
Test: [00370/04555]	Time 0.12 (0.09)
Test: [00380/04555]	Time 0.38 (0.10)
Test: [00390/04555]	Time 0.39 (0.11)
Test: [00400/04555]	Time 0.06 (0.11)
Test: [00410/04555]	Time 0.04 (0.10)
Test: [00420/04555]	Time 0.04 (0.10)
Test: [00430/04555]	Time 0.04 (0.10)
Test: [00440/04555]	Time 0.13 (0.10)
Test: [00450/04555]	Time 0.04 (0.10)
Test: [00460/04555]	Time 0.04 (0.10)
Test: [00470/04555]	Time 0.04 (0.10)
Test: [00480/04555]	Time 0.04 (0.10)
Test: [00490/04555]	Time 0.04 (0.10)
Test: [00500/04555]	Time 0.04 (0.09)
Test: [00510/04555]	Time 0.04 (0.09)
Test: [00520/04555]	Time 0.04 (0.09)
Test: [00530/04555]	Time 0.04 (0.09)
Test: [00540/04555]	Time 0.06 (0.09)
Test: [00550/04555]	Time 0.07 (0.09)
Test: [00560/04555]	Time 0.04 (0.09)
Test: [00570/04555]	Time 0.04 (0.09)
Test: [00580/04555]	Time 0.04 (0.09)
Test: [00590/04555]	Time 0.04 (0.09)
Test: [00600/04555]	Time 0.04 (0.09)
Test: [00610/04555]	Time 0.05 (0.09)
Test: [00620/04555]	Time 0.04 (0.08)
Test: [00630/04555]	Time 0.10 (0.08)
Test: [00640/04555]	Time 0.05 (0.08)
Test: [00650/04555]	Time 0.23 (0.09)
Test: [00660/04555]	Time 0.04 (0.09)
Test: [00670/04555]	Time 0.04 (0.08)
Test: [00680/04555]	Time 0.04 (0.08)
Test: [00690/04555]	Time 0.04 (0.08)
Test: [00700/04555]	Time 0.04 (0.08)
Test: [00710/04555]	Time 0.04 (0.08)
Test: [00720/04555]	Time 0.08 (0.08)
Test: [00730/04555]	Time 0.04 (0.08)
Test: [00740/04555]	Time 0.09 (0.08)
Test: [00750/04555]	Time 0.08 (0.08)
Test: [00760/04555]	Time 0.08 (0.08)
Test: [00770/04555]	Time 0.11 (0.08)
Test: [00780/04555]	Time 0.04 (0.08)
Test: [00790/04555]	Time 0.04 (0.08)
Test: [00800/04555]	Time 0.04 (0.08)
Test: [00810/04555]	Time 0.07 (0.08)
Test: [00820/04555]	Time 0.06 (0.08)
Test: [00830/04555]	Time 0.07 (0.08)
Test: [00840/04555]	Time 0.04 (0.08)
Test: [00850/04555]	Time 0.07 (0.08)
Test: [00860/04555]	Time 0.04 (0.08)
Test: [00870/04555]	Time 0.07 (0.08)
Test: [00880/04555]	Time 0.06 (0.08)
Test: [00890/04555]	Time 0.09 (0.08)
Test: [00900/04555]	Time 0.09 (0.08)
Test: [00910/04555]	Time 0.04 (0.08)
Test: [00920/04555]	Time 0.04 (0.08)
Test: [00930/04555]	Time 0.04 (0.08)
Test: [00940/04555]	Time 0.04 (0.08)
Test: [00950/04555]	Time 0.04 (0.08)
Test: [00960/04555]	Time 0.04 (0.08)
Test: [00970/04555]	Time 0.04 (0.08)
Test: [00980/04555]	Time 0.04 (0.08)
Test: [00990/04555]	Time 0.04 (0.08)
Test: [01000/04555]	Time 0.04 (0.07)
Test: [01010/04555]	Time 0.04 (0.07)
Test: [01020/04555]	Time 0.04 (0.07)
Test: [01030/04555]	Time 0.04 (0.07)
Test: [01040/04555]	Time 0.06 (0.07)
Test: [01050/04555]	Time 0.24 (0.08)
Test: [01060/04555]	Time 0.21 (0.08)
Test: [01070/04555]	Time 0.04 (0.08)
Test: [01080/04555]	Time 0.04 (0.08)
Test: [01090/04555]	Time 0.04 (0.08)
Test: [01100/04555]	Time 0.04 (0.08)
Test: [01110/04555]	Time 0.04 (0.07)
Test: [01120/04555]	Time 0.05 (0.07)
Test: [01130/04555]	Time 0.04 (0.07)
Test: [01140/04555]	Time 0.37 (0.08)
Test: [01150/04555]	Time 0.10 (0.08)
Test: [01160/04555]	Time 0.14 (0.08)
Test: [01170/04555]	Time 0.04 (0.08)
Test: [01180/04555]	Time 0.14 (0.08)
Test: [01190/04555]	Time 0.13 (0.08)
Test: [01200/04555]	Time 0.07 (0.08)
Test: [01210/04555]	Time 0.04 (0.08)
Test: [01220/04555]	Time 0.08 (0.08)
Test: [01230/04555]	Time 0.08 (0.08)
Test: [01240/04555]	Time 0.05 (0.08)
Test: [01250/04555]	Time 0.04 (0.08)
Test: [01260/04555]	Time 0.10 (0.08)
Test: [01270/04555]	Time 0.08 (0.08)
Test: [01280/04555]	Time 0.06 (0.08)
Test: [01290/04555]	Time 0.04 (0.08)
Test: [01300/04555]	Time 0.05 (0.08)
Test: [01310/04555]	Time 0.04 (0.08)
Test: [01320/04555]	Time 0.04 (0.08)
Test: [01330/04555]	Time 0.04 (0.08)
Test: [01340/04555]	Time 0.04 (0.08)
Test: [01350/04555]	Time 0.04 (0.08)
Test: [01360/04555]	Time 0.04 (0.08)
Test: [01370/04555]	Time 0.04 (0.08)
Test: [01380/04555]	Time 0.04 (0.07)
Test: [01390/04555]	Time 0.07 (0.07)
Test: [01400/04555]	Time 0.04 (0.07)
Test: [01410/04555]	Time 0.08 (0.07)
Test: [01420/04555]	Time 0.17 (0.08)
Test: [01430/04555]	Time 0.04 (0.07)
Test: [01440/04555]	Time 0.04 (0.07)
Test: [01450/04555]	Time 0.04 (0.07)
Test: [01460/04555]	Time 0.04 (0.07)
Test: [01470/04555]	Time 0.04 (0.07)
Test: [01480/04555]	Time 0.04 (0.07)
Test: [01490/04555]	Time 0.04 (0.07)
Test: [01500/04555]	Time 0.04 (0.07)
Test: [01510/04555]	Time 0.04 (0.07)
Test: [01520/04555]	Time 0.04 (0.07)
Test: [01530/04555]	Time 0.06 (0.07)
Test: [01540/04555]	Time 0.05 (0.07)
Test: [01550/04555]	Time 0.05 (0.07)
Test: [01560/04555]	Time 0.04 (0.07)
Test: [01570/04555]	Time 0.04 (0.07)
Test: [01580/04555]	Time 0.04 (0.07)
Test: [01590/04555]	Time 0.06 (0.07)
Test: [01600/04555]	Time 0.04 (0.07)
Test: [01610/04555]	Time 0.04 (0.07)
Test: [01620/04555]	Time 0.04 (0.07)
Test: [01630/04555]	Time 0.04 (0.07)
Test: [01640/04555]	Time 0.04 (0.07)
Test: [01650/04555]	Time 0.21 (0.07)
Test: [01660/04555]	Time 0.24 (0.07)
Test: [01670/04555]	Time 0.24 (0.07)
Test: [01680/04555]	Time 0.13 (0.07)
Test: [01690/04555]	Time 0.04 (0.07)
Test: [01700/04555]	Time 0.04 (0.07)
Test: [01710/04555]	Time 0.04 (0.07)
Test: [01720/04555]	Time 0.04 (0.07)
Test: [01730/04555]	Time 0.17 (0.07)
Test: [01740/04555]	Time 0.08 (0.07)
Test: [01750/04555]	Time 0.04 (0.07)
Test: [01760/04555]	Time 0.20 (0.07)
Test: [01770/04555]	Time 0.18 (0.07)
Test: [01780/04555]	Time 0.04 (0.07)
Test: [01790/04555]	Time 0.04 (0.07)
Test: [01800/04555]	Time 0.04 (0.07)
Test: [01810/04555]	Time 0.04 (0.07)
Test: [01820/04555]	Time 0.04 (0.07)
Test: [01830/04555]	Time 0.04 (0.07)
Test: [01840/04555]	Time 0.04 (0.07)
Test: [01850/04555]	Time 0.04 (0.07)
Test: [01860/04555]	Time 0.04 (0.07)
Test: [01870/04555]	Time 0.04 (0.07)
Test: [01880/04555]	Time 0.04 (0.07)
Test: [01890/04555]	Time 0.04 (0.07)
Test: [01900/04555]	Time 0.04 (0.07)
Test: [01910/04555]	Time 0.04 (0.07)
Test: [01920/04555]	Time 0.04 (0.07)
Test: [01930/04555]	Time 0.04 (0.07)
Test: [01940/04555]	Time 0.04 (0.07)
Test: [01950/04555]	Time 0.04 (0.07)
Test: [01960/04555]	Time 0.04 (0.07)
Test: [01970/04555]	Time 0.04 (0.07)
Test: [01980/04555]	Time 0.04 (0.07)
Test: [01990/04555]	Time 0.04 (0.07)
Test: [02000/04555]	Time 0.04 (0.07)
Test: [02010/04555]	Time 0.04 (0.07)
Test: [02020/04555]	Time 0.04 (0.07)
Test: [02030/04555]	Time 0.04 (0.07)
Test: [02040/04555]	Time 0.04 (0.07)
Test: [02050/04555]	Time 0.04 (0.07)
Test: [02060/04555]	Time 0.04 (0.07)
Test: [02070/04555]	Time 0.04 (0.07)
Test: [02080/04555]	Time 0.04 (0.07)
Test: [02090/04555]	Time 0.04 (0.07)
Test: [02100/04555]	Time 0.04 (0.07)
Test: [02110/04555]	Time 0.04 (0.07)
Test: [02120/04555]	Time 0.04 (0.07)
Test: [02130/04555]	Time 0.04 (0.07)
Test: [02140/04555]	Time 0.04 (0.07)
Test: [02150/04555]	Time 0.04 (0.07)
Test: [02160/04555]	Time 0.04 (0.07)
Test: [02170/04555]	Time 0.04 (0.07)
Test: [02180/04555]	Time 0.04 (0.07)
Test: [02190/04555]	Time 0.04 (0.07)
Test: [02200/04555]	Time 0.04 (0.07)
Test: [02210/04555]	Time 0.04 (0.07)
Test: [02220/04555]	Time 0.04 (0.07)
Test: [02230/04555]	Time 0.04 (0.07)
Test: [02240/04555]	Time 0.04 (0.07)
Test: [02250/04555]	Time 0.04 (0.07)
Test: [02260/04555]	Time 0.04 (0.07)
Test: [02270/04555]	Time 0.04 (0.07)
Test: [02280/04555]	Time 0.04 (0.07)
Test: [02290/04555]	Time 0.04 (0.07)
Test: [02300/04555]	Time 0.04 (0.07)
Test: [02310/04555]	Time 0.04 (0.07)
Test: [02320/04555]	Time 0.04 (0.07)
Test: [02330/04555]	Time 0.04 (0.07)
Test: [02340/04555]	Time 0.04 (0.07)
Test: [02350/04555]	Time 0.04 (0.07)
Test: [02360/04555]	Time 0.04 (0.07)
Test: [02370/04555]	Time 0.04 (0.07)
Test: [02380/04555]	Time 0.04 (0.07)
Test: [02390/04555]	Time 0.04 (0.07)
Test: [02400/04555]	Time 0.04 (0.07)
Test: [02410/04555]	Time 0.04 (0.07)
Test: [02420/04555]	Time 0.04 (0.07)
Test: [02430/04555]	Time 0.04 (0.07)
Test: [02440/04555]	Time 0.04 (0.06)
Test: [02450/04555]	Time 0.04 (0.06)
Test: [02460/04555]	Time 0.04 (0.06)
Test: [02470/04555]	Time 0.04 (0.06)
Test: [02480/04555]	Time 0.04 (0.06)
Test: [02490/04555]	Time 0.04 (0.06)
Test: [02500/04555]	Time 0.04 (0.06)
Test: [02510/04555]	Time 0.04 (0.06)
Test: [02520/04555]	Time 0.04 (0.06)
Test: [02530/04555]	Time 0.04 (0.06)
Test: [02540/04555]	Time 0.04 (0.06)
Test: [02550/04555]	Time 0.04 (0.06)
Test: [02560/04555]	Time 0.10 (0.06)
Test: [02570/04555]	Time 0.14 (0.06)
Test: [02580/04555]	Time 0.04 (0.06)
Test: [02590/04555]	Time 0.04 (0.06)
Test: [02600/04555]	Time 0.04 (0.06)
Test: [02610/04555]	Time 0.04 (0.06)
Test: [02620/04555]	Time 0.04 (0.06)
Test: [02630/04555]	Time 0.04 (0.06)
Test: [02640/04555]	Time 0.04 (0.06)
Test: [02650/04555]	Time 0.04 (0.06)
Test: [02660/04555]	Time 0.04 (0.06)
Test: [02670/04555]	Time 0.04 (0.06)
Test: [02680/04555]	Time 0.04 (0.06)
Test: [02690/04555]	Time 0.04 (0.06)
Test: [02700/04555]	Time 0.04 (0.06)
Test: [02710/04555]	Time 0.04 (0.06)
Test: [02720/04555]	Time 0.04 (0.06)
Test: [02730/04555]	Time 0.04 (0.06)
Test: [02740/04555]	Time 0.04 (0.06)
Test: [02750/04555]	Time 0.04 (0.06)
Test: [02760/04555]	Time 0.04 (0.06)
Test: [02770/04555]	Time 0.04 (0.06)
Test: [02780/04555]	Time 0.04 (0.06)
Test: [02790/04555]	Time 0.04 (0.06)
Test: [02800/04555]	Time 0.04 (0.06)
Test: [02810/04555]	Time 0.04 (0.06)
Test: [02820/04555]	Time 0.04 (0.06)
Test: [02830/04555]	Time 0.04 (0.06)
Test: [02840/04555]	Time 0.04 (0.06)
Test: [02850/04555]	Time 0.04 (0.06)
Test: [02860/04555]	Time 0.04 (0.06)
Test: [02870/04555]	Time 0.04 (0.06)
Test: [02880/04555]	Time 0.04 (0.06)
Test: [02890/04555]	Time 0.04 (0.06)
Test: [02900/04555]	Time 0.04 (0.06)
Test: [02910/04555]	Time 0.04 (0.06)
Test: [02920/04555]	Time 0.05 (0.06)
Test: [02930/04555]	Time 0.04 (0.06)
Test: [02940/04555]	Time 0.04 (0.06)
Test: [02950/04555]	Time 0.04 (0.06)
Test: [02960/04555]	Time 0.04 (0.06)
Test: [02970/04555]	Time 0.05 (0.06)
Test: [02980/04555]	Time 0.04 (0.06)
Test: [02990/04555]	Time 0.04 (0.06)
Test: [03000/04555]	Time 0.04 (0.06)
Test: [03010/04555]	Time 0.04 (0.06)
Test: [03020/04555]	Time 0.04 (0.06)
Test: [03030/04555]	Time 0.04 (0.06)
Test: [03040/04555]	Time 0.04 (0.06)
Test: [03050/04555]	Time 0.04 (0.06)
Test: [03060/04555]	Time 0.04 (0.06)
Test: [03070/04555]	Time 0.04 (0.06)
Test: [03080/04555]	Time 0.04 (0.06)
Test: [03090/04555]	Time 0.04 (0.06)
Test: [03100/04555]	Time 0.04 (0.06)
Test: [03110/04555]	Time 0.04 (0.06)
Test: [03120/04555]	Time 0.04 (0.06)
Test: [03130/04555]	Time 0.04 (0.06)
Test: [03140/04555]	Time 0.05 (0.06)
Test: [03150/04555]	Time 0.04 (0.06)
Test: [03160/04555]	Time 0.04 (0.06)
Test: [03170/04555]	Time 0.04 (0.06)
Test: [03180/04555]	Time 0.04 (0.06)
Test: [03190/04555]	Time 0.04 (0.06)
Test: [03200/04555]	Time 0.04 (0.06)
Test: [03210/04555]	Time 0.04 (0.06)
Test: [03220/04555]	Time 0.04 (0.06)
Test: [03230/04555]	Time 0.04 (0.06)
Test: [03240/04555]	Time 0.04 (0.06)
Test: [03250/04555]	Time 0.04 (0.06)
Test: [03260/04555]	Time 0.04 (0.06)
Test: [03270/04555]	Time 0.04 (0.06)
Test: [03280/04555]	Time 0.04 (0.06)
Test: [03290/04555]	Time 0.04 (0.06)
Test: [03300/04555]	Time 0.04 (0.06)
Test: [03310/04555]	Time 0.04 (0.06)
Test: [03320/04555]	Time 0.04 (0.06)
Test: [03330/04555]	Time 0.04 (0.06)
Test: [03340/04555]	Time 0.04 (0.06)
Test: [03350/04555]	Time 0.13 (0.06)
Test: [03360/04555]	Time 0.12 (0.06)
Test: [03370/04555]	Time 0.27 (0.06)
Test: [03380/04555]	Time 0.40 (0.06)
Test: [03390/04555]	Time 0.09 (0.06)
Test: [03400/04555]	Time 0.04 (0.06)
Test: [03410/04555]	Time 0.04 (0.06)
Test: [03420/04555]	Time 0.04 (0.06)
Test: [03430/04555]	Time 0.04 (0.06)
Test: [03440/04555]	Time 0.05 (0.06)
Test: [03450/04555]	Time 0.05 (0.06)
Test: [03460/04555]	Time 0.04 (0.06)
Test: [03470/04555]	Time 0.04 (0.06)
Test: [03480/04555]	Time 0.04 (0.06)
Test: [03490/04555]	Time 0.10 (0.06)
Test: [03500/04555]	Time 0.08 (0.06)
Test: [03510/04555]	Time 0.05 (0.06)
Test: [03520/04555]	Time 0.04 (0.06)
Test: [03530/04555]	Time 0.06 (0.06)
Test: [03540/04555]	Time 0.05 (0.06)
Test: [03550/04555]	Time 0.04 (0.06)
Test: [03560/04555]	Time 0.04 (0.06)
Test: [03570/04555]	Time 0.05 (0.06)
Test: [03580/04555]	Time 0.05 (0.06)
Test: [03590/04555]	Time 0.04 (0.06)
Test: [03600/04555]	Time 0.04 (0.06)
Test: [03610/04555]	Time 0.04 (0.06)
Test: [03620/04555]	Time 0.04 (0.06)
Test: [03630/04555]	Time 0.04 (0.06)
Test: [03640/04555]	Time 0.04 (0.06)
Test: [03650/04555]	Time 0.04 (0.06)
Test: [03660/04555]	Time 0.04 (0.06)
Test: [03670/04555]	Time 0.04 (0.06)
Test: [03680/04555]	Time 0.04 (0.06)
Test: [03690/04555]	Time 0.04 (0.06)
Test: [03700/04555]	Time 0.04 (0.06)
Test: [03710/04555]	Time 0.04 (0.06)
Test: [03720/04555]	Time 0.04 (0.06)
Test: [03730/04555]	Time 0.04 (0.06)
Test: [03740/04555]	Time 0.14 (0.06)
Test: [03750/04555]	Time 0.04 (0.06)
Test: [03760/04555]	Time 0.04 (0.06)
Test: [03770/04555]	Time 0.04 (0.06)
Test: [03780/04555]	Time 0.04 (0.06)
Test: [03790/04555]	Time 0.04 (0.06)
Test: [03800/04555]	Time 0.04 (0.06)
Test: [03810/04555]	Time 0.04 (0.06)
Test: [03820/04555]	Time 0.15 (0.06)
Test: [03830/04555]	Time 0.05 (0.06)
Test: [03840/04555]	Time 0.04 (0.06)
Test: [03850/04555]	Time 0.04 (0.06)
Test: [03860/04555]	Time 0.04 (0.06)
Test: [03870/04555]	Time 0.04 (0.06)
Test: [03880/04555]	Time 0.04 (0.06)
Test: [03890/04555]	Time 0.04 (0.06)
Test: [03900/04555]	Time 0.04 (0.06)
Test: [03910/04555]	Time 0.04 (0.06)
Test: [03920/04555]	Time 0.10 (0.06)
Test: [03930/04555]	Time 0.04 (0.06)
Test: [03940/04555]	Time 0.04 (0.06)
Test: [03950/04555]	Time 0.04 (0.06)
Test: [03960/04555]	Time 0.10 (0.06)
Test: [03970/04555]	Time 0.07 (0.06)
Test: [03980/04555]	Time 0.04 (0.06)
Test: [03990/04555]	Time 0.04 (0.06)
Test: [04000/04555]	Time 0.04 (0.06)
Test: [04010/04555]	Time 0.04 (0.06)
Test: [04020/04555]	Time 0.04 (0.06)
Test: [04030/04555]	Time 0.17 (0.06)
Test: [04040/04555]	Time 0.08 (0.06)
Test: [04050/04555]	Time 0.04 (0.06)
Test: [04060/04555]	Time 0.04 (0.06)
Test: [04070/04555]	Time 0.06 (0.06)
Test: [04080/04555]	Time 0.04 (0.06)
Test: [04090/04555]	Time 0.04 (0.06)
Test: [04100/04555]	Time 0.04 (0.06)
Test: [04110/04555]	Time 0.04 (0.06)
Test: [04120/04555]	Time 0.04 (0.06)
Test: [04130/04555]	Time 0.04 (0.06)
Test: [04140/04555]	Time 0.04 (0.06)
Test: [04150/04555]	Time 0.04 (0.06)
Test: [04160/04555]	Time 0.04 (0.06)
Test: [04170/04555]	Time 0.04 (0.06)
Test: [04180/04555]	Time 0.04 (0.06)
Test: [04190/04555]	Time 0.04 (0.06)
Test: [04200/04555]	Time 0.04 (0.06)
Test: [04210/04555]	Time 0.04 (0.06)
Test: [04220/04555]	Time 0.08 (0.06)
Test: [04230/04555]	Time 0.04 (0.06)
Test: [04240/04555]	Time 0.04 (0.06)
Test: [04250/04555]	Time 0.04 (0.06)
Test: [04260/04555]	Time 0.04 (0.06)
Test: [04270/04555]	Time 0.04 (0.06)
Test: [04280/04555]	Time 0.04 (0.06)
Test: [04290/04555]	Time 0.04 (0.06)
Test: [04300/04555]	Time 0.04 (0.06)
Test: [04310/04555]	Time 0.04 (0.06)
Test: [04320/04555]	Time 0.04 (0.06)
Test: [04330/04555]	Time 0.04 (0.06)
Test: [04340/04555]	Time 0.04 (0.06)
Test: [04350/04555]	Time 0.04 (0.06)
Test: [04360/04555]	Time 0.04 (0.06)
Test: [04370/04555]	Time 0.04 (0.06)
Test: [04380/04555]	Time 0.04 (0.06)
Test: [04390/04555]	Time 0.04 (0.06)
Test: [04400/04555]	Time 0.04 (0.06)
Test: [04410/04555]	Time 0.04 (0.06)
Test: [04420/04555]	Time 0.04 (0.06)
Test: [04430/04555]	Time 0.04 (0.06)
Test: [04440/04555]	Time 0.04 (0.06)
Test: [04450/04555]	Time 0.04 (0.06)
Test: [04460/04555]	Time 0.08 (0.06)
Test: [04470/04555]	Time 0.24 (0.06)
Test: [04480/04555]	Time 0.05 (0.06)
Test: [04490/04555]	Time 0.04 (0.06)
Test: [04500/04555]	Time 0.04 (0.06)
Test: [04510/04555]	Time 0.04 (0.06)
Test: [04520/04555]	Time 0.04 (0.06)
Test: [04530/04555]	Time 0.04 (0.06)
Test: [04540/04555]	Time 0.04 (0.06)
Test: [04550/04555]	Time 0.04 (0.06)
[RESULTS] Action detection results on anet1.3_i3d_filtered.

|tIoU = 0.50: mAP = 53.59 (%) Recall@1x = 60.24 (%) Recall@5x = 81.39 (%) 
|tIoU = 0.55: mAP = 50.51 (%) Recall@1x = 57.55 (%) Recall@5x = 78.24 (%) 
|tIoU = 0.60: mAP = 47.27 (%) Recall@1x = 54.79 (%) Recall@5x = 74.75 (%) 
|tIoU = 0.65: mAP = 43.73 (%) Recall@1x = 51.92 (%) Recall@5x = 70.33 (%) 
|tIoU = 0.70: mAP = 40.00 (%) Recall@1x = 48.42 (%) Recall@5x = 64.98 (%) 
|tIoU = 0.75: mAP = 35.61 (%) Recall@1x = 44.55 (%) Recall@5x = 58.31 (%) 
|tIoU = 0.80: mAP = 30.22 (%) Recall@1x = 39.34 (%) Recall@5x = 50.33 (%) 
|tIoU = 0.85: mAP = 23.97 (%) Recall@1x = 33.06 (%) Recall@5x = 40.63 (%) 
|tIoU = 0.90: mAP = 15.86 (%) Recall@1x = 24.29 (%) Recall@5x = 28.41 (%) 
|tIoU = 0.95: mAP = 4.64 (%) Recall@1x = 9.61 (%) Recall@5x = 10.85 (%) 
Average mAP: 34.54 (%)
All done! Total time: 521.93 sec
Looking for a split for p=0.4
Found split for p=0.4 [3700 videos]
Moving sampled images to a separate folder
Finished sampling
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00231]	Time 1.04 (1.04)	Loss 1.65 (1.65)
		cls_loss 0.50 (0.50)	reg_loss 0.58 (0.58)
Epoch: [000][00020/00231]	Time 0.27 (0.66)	Loss 2.02 (1.84)
		cls_loss 0.62 (0.56)	reg_loss 0.70 (0.64)
Epoch: [000][00030/00231]	Time 0.19 (0.50)	Loss 1.35 (1.67)
		cls_loss 0.41 (0.51)	reg_loss 0.47 (0.58)
Epoch: [000][00040/00231]	Time 0.20 (0.43)	Loss 1.51 (1.63)
		cls_loss 0.44 (0.49)	reg_loss 0.53 (0.57)
Epoch: [000][00050/00231]	Time 0.19 (0.38)	Loss 1.79 (1.66)
		cls_loss 0.72 (0.54)	reg_loss 0.54 (0.56)
Epoch: [000][00060/00231]	Time 0.19 (0.35)	Loss 1.09 (1.57)
		cls_loss 0.50 (0.53)	reg_loss 0.30 (0.52)
Epoch: [000][00070/00231]	Time 0.19 (0.33)	Loss 0.94 (1.48)
		cls_loss 0.45 (0.52)	reg_loss 0.24 (0.48)
Epoch: [000][00080/00231]	Time 0.21 (0.31)	Loss 1.00 (1.42)
		cls_loss 0.46 (0.51)	reg_loss 0.27 (0.45)
Epoch: [000][00090/00231]	Time 0.22 (0.30)	Loss 0.84 (1.36)
		cls_loss 0.44 (0.50)	reg_loss 0.20 (0.43)
Epoch: [000][00100/00231]	Time 0.22 (0.29)	Loss 1.19 (1.34)
		cls_loss 0.59 (0.51)	reg_loss 0.30 (0.41)
Epoch: [000][00110/00231]	Time 0.22 (0.29)	Loss 1.16 (1.32)
		cls_loss 0.50 (0.51)	reg_loss 0.33 (0.41)
Epoch: [000][00120/00231]	Time 0.22 (0.28)	Loss 0.93 (1.29)
		cls_loss 0.44 (0.51)	reg_loss 0.25 (0.39)
Epoch: [000][00130/00231]	Time 0.22 (0.28)	Loss 0.91 (1.26)
		cls_loss 0.45 (0.50)	reg_loss 0.23 (0.38)
Epoch: [000][00140/00231]	Time 0.22 (0.27)	Loss 0.96 (1.24)
		cls_loss 0.44 (0.50)	reg_loss 0.26 (0.37)
Epoch: [000][00150/00231]	Time 0.22 (0.27)	Loss 0.84 (1.21)
		cls_loss 0.39 (0.49)	reg_loss 0.23 (0.36)
Epoch: [000][00160/00231]	Time 0.22 (0.27)	Loss 1.46 (1.23)
		cls_loss 0.66 (0.50)	reg_loss 0.40 (0.36)
Epoch: [000][00170/00231]	Time 0.22 (0.26)	Loss 0.78 (1.20)
		cls_loss 0.37 (0.49)	reg_loss 0.21 (0.35)
Epoch: [000][00180/00231]	Time 0.22 (0.26)	Loss 0.62 (1.17)
		cls_loss 0.31 (0.48)	reg_loss 0.16 (0.34)
Epoch: [000][00190/00231]	Time 0.22 (0.26)	Loss 0.67 (1.14)
		cls_loss 0.37 (0.48)	reg_loss 0.15 (0.33)
Epoch: [000][00200/00231]	Time 0.22 (0.26)	Loss 0.76 (1.13)
		cls_loss 0.35 (0.47)	reg_loss 0.21 (0.33)
Epoch: [000][00210/00231]	Time 0.22 (0.26)	Loss 0.54 (1.10)
		cls_loss 0.26 (0.46)	reg_loss 0.14 (0.32)
Epoch: [000][00220/00231]	Time 0.22 (0.25)	Loss 1.17 (1.10)
		cls_loss 0.54 (0.46)	reg_loss 0.32 (0.32)
Epoch: [000][00230/00231]	Time 0.18 (0.25)	Loss 1.47 (1.12)
		cls_loss 0.72 (0.48)	reg_loss 0.38 (0.32)
[Train]: Epoch 0 finished with lr=0.00020017


[Train]: Epoch 1 started
Epoch: [001][00010/00231]	Time 0.23 (0.23)	Loss 1.29 (1.29)
		cls_loss 0.55 (0.55)	reg_loss 0.37 (0.37)
Epoch: [001][00020/00231]	Time 0.19 (0.21)	Loss 0.70 (0.99)
		cls_loss 0.36 (0.45)	reg_loss 0.17 (0.27)
Epoch: [001][00030/00231]	Time 0.21 (0.21)	Loss 0.84 (0.94)
		cls_loss 0.41 (0.44)	reg_loss 0.21 (0.25)
Epoch: [001][00040/00231]	Time 0.22 (0.21)	Loss 1.17 (1.00)
		cls_loss 0.53 (0.46)	reg_loss 0.32 (0.27)
Epoch: [001][00050/00231]	Time 0.22 (0.21)	Loss 1.06 (1.01)
		cls_loss 0.46 (0.46)	reg_loss 0.30 (0.27)
Epoch: [001][00060/00231]	Time 0.21 (0.21)	Loss 1.28 (1.06)
		cls_loss 0.50 (0.47)	reg_loss 0.39 (0.29)
Epoch: [001][00070/00231]	Time 0.21 (0.21)	Loss 0.78 (1.02)
		cls_loss 0.36 (0.45)	reg_loss 0.21 (0.28)
Epoch: [001][00080/00231]	Time 0.22 (0.21)	Loss 0.80 (0.99)
		cls_loss 0.38 (0.44)	reg_loss 0.21 (0.27)
Epoch: [001][00090/00231]	Time 0.22 (0.21)	Loss 1.14 (1.01)
		cls_loss 0.50 (0.45)	reg_loss 0.32 (0.28)
Epoch: [001][00100/00231]	Time 0.22 (0.21)	Loss 0.96 (1.00)
		cls_loss 0.45 (0.45)	reg_loss 0.26 (0.28)
Epoch: [001][00110/00231]	Time 0.22 (0.21)	Loss 1.10 (1.01)
		cls_loss 0.51 (0.45)	reg_loss 0.30 (0.28)
Epoch: [001][00120/00231]	Time 0.22 (0.21)	Loss 0.81 (0.99)
		cls_loss 0.38 (0.45)	reg_loss 0.22 (0.27)
Epoch: [001][00130/00231]	Time 0.21 (0.21)	Loss 0.95 (0.99)
		cls_loss 0.44 (0.45)	reg_loss 0.25 (0.27)
Epoch: [001][00140/00231]	Time 0.22 (0.21)	Loss 1.19 (1.00)
		cls_loss 0.54 (0.45)	reg_loss 0.32 (0.27)
Epoch: [001][00150/00231]	Time 0.22 (0.21)	Loss 0.64 (0.98)
		cls_loss 0.28 (0.44)	reg_loss 0.18 (0.27)
Epoch: [001][00160/00231]	Time 0.22 (0.21)	Loss 0.65 (0.96)
		cls_loss 0.31 (0.44)	reg_loss 0.17 (0.26)
Epoch: [001][00170/00231]	Time 0.22 (0.22)	Loss 0.98 (0.96)
		cls_loss 0.43 (0.44)	reg_loss 0.28 (0.26)
Epoch: [001][00180/00231]	Time 0.23 (0.22)	Loss 0.69 (0.95)
		cls_loss 0.32 (0.43)	reg_loss 0.18 (0.26)
Epoch: [001][00190/00231]	Time 1.36 (0.28)	Loss 1.08 (0.95)
		cls_loss 0.48 (0.43)	reg_loss 0.30 (0.26)
Epoch: [001][00200/00231]	Time 0.20 (0.27)	Loss 1.47 (0.98)
		cls_loss 0.64 (0.44)	reg_loss 0.42 (0.27)
Epoch: [001][00210/00231]	Time 0.20 (0.27)	Loss 0.88 (0.97)
		cls_loss 0.41 (0.44)	reg_loss 0.23 (0.27)
Epoch: [001][00220/00231]	Time 0.21 (0.27)	Loss 1.11 (0.98)
		cls_loss 0.51 (0.44)	reg_loss 0.30 (0.27)
Epoch: [001][00230/00231]	Time 0.23 (0.26)	Loss 0.92 (0.98)
		cls_loss 0.42 (0.44)	reg_loss 0.25 (0.27)
[Train]: Epoch 1 finished with lr=0.00040035


[Train]: Epoch 2 started
Epoch: [002][00010/00231]	Time 0.23 (0.23)	Loss 0.65 (0.65)
		cls_loss 0.31 (0.31)	reg_loss 0.17 (0.17)
Epoch: [002][00020/00231]	Time 0.19 (0.21)	Loss 1.64 (1.14)
		cls_loss 0.75 (0.53)	reg_loss 0.44 (0.31)
Epoch: [002][00030/00231]	Time 0.18 (0.20)	Loss 0.60 (0.96)
		cls_loss 0.30 (0.45)	reg_loss 0.15 (0.25)
Epoch: [002][00040/00231]	Time 0.19 (0.20)	Loss 0.67 (0.89)
		cls_loss 0.31 (0.42)	reg_loss 0.18 (0.24)
Epoch: [002][00050/00231]	Time 0.18 (0.19)	Loss 0.66 (0.84)
		cls_loss 0.35 (0.40)	reg_loss 0.16 (0.22)
Epoch: [002][00060/00231]	Time 0.19 (0.19)	Loss 0.99 (0.87)
		cls_loss 0.47 (0.41)	reg_loss 0.26 (0.23)
Epoch: [002][00070/00231]	Time 0.20 (0.19)	Loss 1.34 (0.93)
		cls_loss 0.54 (0.43)	reg_loss 0.40 (0.25)
Epoch: [002][00080/00231]	Time 0.20 (0.19)	Loss 0.68 (0.90)
		cls_loss 0.36 (0.42)	reg_loss 0.16 (0.24)
Epoch: [002][00090/00231]	Time 0.20 (0.20)	Loss 0.94 (0.91)
		cls_loss 0.40 (0.42)	reg_loss 0.27 (0.24)
Epoch: [002][00100/00231]	Time 0.21 (0.20)	Loss 0.46 (0.86)
		cls_loss 0.24 (0.40)	reg_loss 0.11 (0.23)
Epoch: [002][00110/00231]	Time 0.21 (0.20)	Loss 0.96 (0.87)
		cls_loss 0.45 (0.41)	reg_loss 0.25 (0.23)
Epoch: [002][00120/00231]	Time 0.22 (0.20)	Loss 0.67 (0.85)
		cls_loss 0.30 (0.40)	reg_loss 0.19 (0.23)
Epoch: [002][00130/00231]	Time 0.22 (0.20)	Loss 0.77 (0.85)
		cls_loss 0.36 (0.39)	reg_loss 0.20 (0.23)
Epoch: [002][00140/00231]	Time 0.22 (0.20)	Loss 0.78 (0.84)
		cls_loss 0.34 (0.39)	reg_loss 0.22 (0.23)
Epoch: [002][00150/00231]	Time 0.22 (0.20)	Loss 0.74 (0.84)
		cls_loss 0.39 (0.39)	reg_loss 0.18 (0.22)
Epoch: [002][00160/00231]	Time 0.21 (0.20)	Loss 1.13 (0.85)
		cls_loss 0.60 (0.40)	reg_loss 0.27 (0.23)
Epoch: [002][00170/00231]	Time 0.22 (0.20)	Loss 0.92 (0.86)
		cls_loss 0.42 (0.40)	reg_loss 0.25 (0.23)
Epoch: [002][00180/00231]	Time 0.22 (0.21)	Loss 1.25 (0.88)
		cls_loss 0.64 (0.42)	reg_loss 0.31 (0.23)
Epoch: [002][00190/00231]	Time 0.22 (0.21)	Loss 0.89 (0.88)
		cls_loss 0.45 (0.42)	reg_loss 0.22 (0.23)
Epoch: [002][00200/00231]	Time 0.22 (0.21)	Loss 0.87 (0.88)
		cls_loss 0.42 (0.42)	reg_loss 0.22 (0.23)
Epoch: [002][00210/00231]	Time 0.21 (0.21)	Loss 0.64 (0.87)
		cls_loss 0.30 (0.41)	reg_loss 0.17 (0.23)
Epoch: [002][00220/00231]	Time 0.62 (0.23)	Loss 1.28 (0.89)
		cls_loss 0.58 (0.42)	reg_loss 0.35 (0.23)
Epoch: [002][00230/00231]	Time 0.17 (0.22)	Loss 0.64 (0.88)
		cls_loss 0.28 (0.42)	reg_loss 0.18 (0.23)
[Train]: Epoch 2 finished with lr=0.00060052


[Train]: Epoch 3 started
Epoch: [003][00010/00231]	Time 0.25 (0.25)	Loss 0.94 (0.94)
		cls_loss 0.46 (0.46)	reg_loss 0.24 (0.24)
Epoch: [003][00020/00231]	Time 0.21 (0.23)	Loss 1.08 (1.01)
		cls_loss 0.48 (0.47)	reg_loss 0.30 (0.27)
Epoch: [003][00030/00231]	Time 0.20 (0.22)	Loss 0.69 (0.91)
		cls_loss 0.35 (0.43)	reg_loss 0.17 (0.24)
Epoch: [003][00040/00231]	Time 0.20 (0.21)	Loss 0.67 (0.85)
		cls_loss 0.30 (0.40)	reg_loss 0.18 (0.22)
Epoch: [003][00050/00231]	Time 0.20 (0.21)	Loss 0.59 (0.79)
		cls_loss 0.28 (0.38)	reg_loss 0.15 (0.21)
Epoch: [003][00060/00231]	Time 0.21 (0.21)	Loss 1.12 (0.85)
		cls_loss 0.49 (0.39)	reg_loss 0.31 (0.23)
Epoch: [003][00070/00231]	Time 0.21 (0.21)	Loss 0.89 (0.85)
		cls_loss 0.40 (0.40)	reg_loss 0.24 (0.23)
Epoch: [003][00080/00231]	Time 0.21 (0.21)	Loss 0.75 (0.84)
		cls_loss 0.30 (0.38)	reg_loss 0.23 (0.23)
Epoch: [003][00090/00231]	Time 0.21 (0.21)	Loss 0.69 (0.82)
		cls_loss 0.34 (0.38)	reg_loss 0.17 (0.22)
Epoch: [003][00100/00231]	Time 0.19 (0.21)	Loss 0.44 (0.79)
		cls_loss 0.25 (0.37)	reg_loss 0.10 (0.21)
Epoch: [003][00110/00231]	Time 0.20 (0.21)	Loss 0.93 (0.80)
		cls_loss 0.43 (0.37)	reg_loss 0.25 (0.21)
Epoch: [003][00120/00231]	Time 0.21 (0.21)	Loss 1.26 (0.84)
		cls_loss 0.61 (0.39)	reg_loss 0.32 (0.22)
Epoch: [003][00130/00231]	Time 0.21 (0.21)	Loss 0.74 (0.83)
		cls_loss 0.37 (0.39)	reg_loss 0.19 (0.22)
Epoch: [003][00140/00231]	Time 0.21 (0.21)	Loss 1.17 (0.85)
		cls_loss 0.55 (0.40)	reg_loss 0.31 (0.23)
Epoch: [003][00150/00231]	Time 0.20 (0.21)	Loss 1.05 (0.87)
		cls_loss 0.50 (0.41)	reg_loss 0.28 (0.23)
Epoch: [003][00160/00231]	Time 0.21 (0.21)	Loss 1.92 (0.93)
		cls_loss 0.97 (0.44)	reg_loss 0.47 (0.24)
Epoch: [003][00170/00231]	Time 0.21 (0.21)	Loss 0.53 (0.91)
		cls_loss 0.25 (0.43)	reg_loss 0.14 (0.24)
Epoch: [003][00180/00231]	Time 0.22 (0.21)	Loss 1.69 (0.95)
		cls_loss 0.87 (0.46)	reg_loss 0.41 (0.25)
Epoch: [003][00190/00231]	Time 0.22 (0.21)	Loss 0.77 (0.94)
		cls_loss 0.37 (0.45)	reg_loss 0.20 (0.25)
Epoch: [003][00200/00231]	Time 0.22 (0.21)	Loss 0.94 (0.94)
		cls_loss 0.42 (0.45)	reg_loss 0.26 (0.25)
Epoch: [003][00210/00231]	Time 0.22 (0.21)	Loss 0.83 (0.94)
		cls_loss 0.41 (0.45)	reg_loss 0.21 (0.24)
Epoch: [003][00220/00231]	Time 0.21 (0.21)	Loss 0.67 (0.93)
		cls_loss 0.34 (0.44)	reg_loss 0.17 (0.24)
Epoch: [003][00230/00231]	Time 0.18 (0.21)	Loss 0.98 (0.93)
		cls_loss 0.43 (0.44)	reg_loss 0.28 (0.24)
[Train]: Epoch 3 finished with lr=0.00080069


[Train]: Epoch 4 started
Epoch: [004][00010/00231]	Time 0.24 (0.24)	Loss 1.66 (1.66)
		cls_loss 0.75 (0.75)	reg_loss 0.46 (0.46)
Epoch: [004][00020/00231]	Time 0.19 (0.21)	Loss 0.82 (1.24)
		cls_loss 0.42 (0.58)	reg_loss 0.20 (0.33)
Epoch: [004][00030/00231]	Time 0.19 (0.21)	Loss 0.50 (0.99)
		cls_loss 0.26 (0.48)	reg_loss 0.12 (0.26)
Epoch: [004][00040/00231]	Time 0.20 (0.21)	Loss 0.48 (0.86)
		cls_loss 0.25 (0.42)	reg_loss 0.12 (0.22)
Epoch: [004][00050/00231]	Time 0.21 (0.21)	Loss 0.93 (0.88)
		cls_loss 0.40 (0.42)	reg_loss 0.26 (0.23)
Epoch: [004][00060/00231]	Time 0.21 (0.21)	Loss 0.81 (0.87)
		cls_loss 0.40 (0.41)	reg_loss 0.20 (0.23)
Epoch: [004][00070/00231]	Time 0.22 (0.21)	Loss 0.82 (0.86)
		cls_loss 0.37 (0.41)	reg_loss 0.23 (0.23)
Epoch: [004][00080/00231]	Time 0.22 (0.21)	Loss 1.21 (0.90)
		cls_loss 0.50 (0.42)	reg_loss 0.36 (0.24)
Epoch: [004][00090/00231]	Time 0.22 (0.21)	Loss 1.37 (0.96)
		cls_loss 0.67 (0.45)	reg_loss 0.35 (0.25)
Epoch: [004][00100/00231]	Time 0.22 (0.21)	Loss 1.20 (0.98)
		cls_loss 0.55 (0.46)	reg_loss 0.32 (0.26)
Epoch: [004][00110/00231]	Time 0.22 (0.21)	Loss 0.83 (0.97)
		cls_loss 0.43 (0.45)	reg_loss 0.20 (0.26)
Epoch: [004][00120/00231]	Time 0.22 (0.21)	Loss 0.65 (0.94)
		cls_loss 0.29 (0.44)	reg_loss 0.18 (0.25)
Epoch: [004][00130/00231]	Time 0.22 (0.21)	Loss 0.80 (0.93)
		cls_loss 0.34 (0.43)	reg_loss 0.23 (0.25)
Epoch: [004][00140/00231]	Time 0.22 (0.21)	Loss 0.70 (0.91)
		cls_loss 0.32 (0.42)	reg_loss 0.19 (0.24)
Epoch: [004][00150/00231]	Time 0.22 (0.21)	Loss 0.49 (0.88)
		cls_loss 0.24 (0.41)	reg_loss 0.13 (0.24)
Epoch: [004][00160/00231]	Time 0.22 (0.21)	Loss 0.78 (0.88)
		cls_loss 0.38 (0.41)	reg_loss 0.20 (0.23)
Epoch: [004][00170/00231]	Time 0.22 (0.21)	Loss 1.28 (0.90)
		cls_loss 0.61 (0.42)	reg_loss 0.34 (0.24)
Epoch: [004][00180/00231]	Time 0.22 (0.21)	Loss 0.72 (0.89)
		cls_loss 0.37 (0.42)	reg_loss 0.17 (0.24)
Epoch: [004][00190/00231]	Time 0.22 (0.21)	Loss 0.62 (0.88)
		cls_loss 0.30 (0.41)	reg_loss 0.16 (0.23)
Epoch: [004][00200/00231]	Time 0.22 (0.21)	Loss 0.85 (0.88)
		cls_loss 0.38 (0.41)	reg_loss 0.23 (0.23)
Epoch: [004][00210/00231]	Time 0.22 (0.21)	Loss 1.01 (0.88)
		cls_loss 0.45 (0.41)	reg_loss 0.28 (0.23)
Epoch: [004][00220/00231]	Time 0.22 (0.22)	Loss 0.86 (0.88)
		cls_loss 0.40 (0.41)	reg_loss 0.23 (0.23)
Epoch: [004][00230/00231]	Time 0.18 (0.21)	Loss 1.19 (0.89)
		cls_loss 0.50 (0.42)	reg_loss 0.34 (0.24)
[Train]: Epoch 4 finished with lr=0.00100000


[Train]: Epoch 5 started
Epoch: [005][00010/00231]	Time 0.26 (0.26)	Loss 0.79 (0.79)
		cls_loss 0.40 (0.40)	reg_loss 0.19 (0.19)
Epoch: [005][00020/00231]	Time 0.20 (0.23)	Loss 1.12 (0.95)
		cls_loss 0.56 (0.48)	reg_loss 0.28 (0.24)
Epoch: [005][00030/00231]	Time 0.20 (0.22)	Loss 0.99 (0.97)
		cls_loss 0.45 (0.47)	reg_loss 0.27 (0.25)
Epoch: [005][00040/00231]	Time 0.21 (0.22)	Loss 0.91 (0.95)
		cls_loss 0.41 (0.45)	reg_loss 0.25 (0.25)
Epoch: [005][00050/00231]	Time 0.22 (0.22)	Loss 1.57 (1.08)
		cls_loss 0.74 (0.51)	reg_loss 0.42 (0.28)
Epoch: [005][00060/00231]	Time 0.22 (0.22)	Loss 0.69 (1.01)
		cls_loss 0.29 (0.47)	reg_loss 0.20 (0.27)
Epoch: [005][00070/00231]	Time 0.22 (0.22)	Loss 0.43 (0.93)
		cls_loss 0.22 (0.44)	reg_loss 0.10 (0.25)
Epoch: [005][00080/00231]	Time 0.22 (0.22)	Loss 0.99 (0.94)
		cls_loss 0.44 (0.44)	reg_loss 0.28 (0.25)
Epoch: [005][00090/00231]	Time 0.22 (0.22)	Loss 0.51 (0.89)
		cls_loss 0.22 (0.42)	reg_loss 0.14 (0.24)
Epoch: [005][00100/00231]	Time 0.22 (0.22)	Loss 0.58 (0.86)
		cls_loss 0.29 (0.40)	reg_loss 0.15 (0.23)
Epoch: [005][00110/00231]	Time 0.22 (0.22)	Loss 0.58 (0.83)
		cls_loss 0.30 (0.39)	reg_loss 0.14 (0.22)
Epoch: [005][00120/00231]	Time 0.22 (0.22)	Loss 0.94 (0.84)
		cls_loss 0.43 (0.40)	reg_loss 0.25 (0.22)
Epoch: [005][00130/00231]	Time 0.19 (0.22)	Loss 0.67 (0.83)
		cls_loss 0.31 (0.39)	reg_loss 0.18 (0.22)
Epoch: [005][00140/00231]	Time 1.52 (0.31)	Loss 0.82 (0.83)
		cls_loss 0.40 (0.39)	reg_loss 0.21 (0.22)
Epoch: [005][00150/00231]	Time 0.22 (0.30)	Loss 0.58 (0.81)
		cls_loss 0.26 (0.38)	reg_loss 0.16 (0.22)
Epoch: [005][00160/00231]	Time 0.22 (0.30)	Loss 0.58 (0.80)
		cls_loss 0.34 (0.38)	reg_loss 0.12 (0.21)
Epoch: [005][00170/00231]	Time 0.20 (0.29)	Loss 0.71 (0.79)
		cls_loss 0.33 (0.38)	reg_loss 0.19 (0.21)
Epoch: [005][00180/00231]	Time 1.53 (0.36)	Loss 1.06 (0.81)
		cls_loss 0.45 (0.38)	reg_loss 0.30 (0.21)
Epoch: [005][00190/00231]	Time 0.20 (0.35)	Loss 0.93 (0.81)
		cls_loss 0.44 (0.38)	reg_loss 0.24 (0.22)
Epoch: [005][00200/00231]	Time 0.21 (0.34)	Loss 0.53 (0.80)
		cls_loss 0.25 (0.38)	reg_loss 0.14 (0.21)
Epoch: [005][00210/00231]	Time 0.20 (0.34)	Loss 1.04 (0.81)
		cls_loss 0.47 (0.38)	reg_loss 0.28 (0.21)
Epoch: [005][00220/00231]	Time 0.21 (0.33)	Loss 1.25 (0.83)
		cls_loss 0.56 (0.39)	reg_loss 0.34 (0.22)
Epoch: [005][00230/00231]	Time 0.17 (0.33)	Loss 1.20 (0.85)
		cls_loss 0.56 (0.40)	reg_loss 0.32 (0.22)
[Train]: Epoch 5 finished with lr=0.00097553


[Train]: Epoch 6 started
Epoch: [006][00010/00231]	Time 0.22 (0.22)	Loss 0.52 (0.52)
		cls_loss 0.28 (0.28)	reg_loss 0.12 (0.12)
Epoch: [006][00020/00231]	Time 0.17 (0.20)	Loss 0.66 (0.59)
		cls_loss 0.29 (0.28)	reg_loss 0.19 (0.15)
Epoch: [006][00030/00231]	Time 0.18 (0.19)	Loss 0.84 (0.67)
		cls_loss 0.40 (0.32)	reg_loss 0.22 (0.18)
Epoch: [006][00040/00231]	Time 0.20 (0.19)	Loss 0.61 (0.66)
		cls_loss 0.32 (0.32)	reg_loss 0.15 (0.17)
Epoch: [006][00050/00231]	Time 0.20 (0.19)	Loss 1.09 (0.74)
		cls_loss 0.44 (0.35)	reg_loss 0.32 (0.20)
Epoch: [006][00060/00231]	Time 0.19 (0.19)	Loss 0.71 (0.74)
		cls_loss 0.38 (0.35)	reg_loss 0.16 (0.19)
Epoch: [006][00070/00231]	Time 0.20 (0.19)	Loss 0.59 (0.72)
		cls_loss 0.30 (0.34)	reg_loss 0.14 (0.19)
Epoch: [006][00080/00231]	Time 0.20 (0.19)	Loss 0.82 (0.73)
		cls_loss 0.38 (0.35)	reg_loss 0.22 (0.19)
Epoch: [006][00090/00231]	Time 0.21 (0.20)	Loss 0.45 (0.70)
		cls_loss 0.22 (0.33)	reg_loss 0.12 (0.18)
Epoch: [006][00100/00231]	Time 0.22 (0.20)	Loss 0.77 (0.71)
		cls_loss 0.35 (0.34)	reg_loss 0.21 (0.19)
Epoch: [006][00110/00231]	Time 0.22 (0.20)	Loss 0.55 (0.69)
		cls_loss 0.28 (0.33)	reg_loss 0.13 (0.18)
Epoch: [006][00120/00231]	Time 0.22 (0.20)	Loss 1.40 (0.75)
		cls_loss 0.57 (0.35)	reg_loss 0.41 (0.20)
Epoch: [006][00130/00231]	Time 0.22 (0.20)	Loss 0.49 (0.73)
		cls_loss 0.22 (0.34)	reg_loss 0.14 (0.20)
Epoch: [006][00140/00231]	Time 0.22 (0.20)	Loss 0.97 (0.75)
		cls_loss 0.48 (0.35)	reg_loss 0.25 (0.20)
Epoch: [006][00150/00231]	Time 0.22 (0.21)	Loss 0.95 (0.76)
		cls_loss 0.39 (0.35)	reg_loss 0.28 (0.20)
Epoch: [006][00160/00231]	Time 0.22 (0.21)	Loss 1.00 (0.78)
		cls_loss 0.49 (0.36)	reg_loss 0.25 (0.21)
Epoch: [006][00170/00231]	Time 0.22 (0.21)	Loss 0.51 (0.76)
		cls_loss 0.25 (0.36)	reg_loss 0.13 (0.20)
Epoch: [006][00180/00231]	Time 0.22 (0.21)	Loss 1.30 (0.79)
		cls_loss 0.57 (0.37)	reg_loss 0.36 (0.21)
Epoch: [006][00190/00231]	Time 0.22 (0.21)	Loss 0.46 (0.77)
		cls_loss 0.24 (0.36)	reg_loss 0.11 (0.21)
Epoch: [006][00200/00231]	Time 0.22 (0.21)	Loss 0.74 (0.77)
		cls_loss 0.35 (0.36)	reg_loss 0.20 (0.21)
Epoch: [006][00210/00231]	Time 0.22 (0.21)	Loss 0.70 (0.77)
		cls_loss 0.33 (0.36)	reg_loss 0.18 (0.20)
Epoch: [006][00220/00231]	Time 0.22 (0.21)	Loss 0.76 (0.77)
		cls_loss 0.36 (0.36)	reg_loss 0.20 (0.20)
Epoch: [006][00230/00231]	Time 0.18 (0.21)	Loss 0.74 (0.77)
		cls_loss 0.34 (0.36)	reg_loss 0.20 (0.20)
[Train]: Epoch 6 finished with lr=0.00090451


[Train]: Epoch 7 started
Epoch: [007][00010/00231]	Time 0.25 (0.25)	Loss 0.64 (0.64)
		cls_loss 0.32 (0.32)	reg_loss 0.16 (0.16)
Epoch: [007][00020/00231]	Time 0.19 (0.22)	Loss 0.77 (0.70)
		cls_loss 0.36 (0.34)	reg_loss 0.21 (0.18)
Epoch: [007][00030/00231]	Time 0.20 (0.22)	Loss 0.91 (0.77)
		cls_loss 0.44 (0.37)	reg_loss 0.24 (0.20)
Epoch: [007][00040/00231]	Time 0.21 (0.21)	Loss 0.99 (0.83)
		cls_loss 0.43 (0.39)	reg_loss 0.28 (0.22)
Epoch: [007][00050/00231]	Time 0.20 (0.21)	Loss 0.79 (0.82)
		cls_loss 0.38 (0.39)	reg_loss 0.20 (0.22)
Epoch: [007][00060/00231]	Time 0.21 (0.21)	Loss 0.77 (0.81)
		cls_loss 0.36 (0.38)	reg_loss 0.21 (0.22)
Epoch: [007][00070/00231]	Time 0.21 (0.21)	Loss 1.01 (0.84)
		cls_loss 0.49 (0.40)	reg_loss 0.26 (0.22)
Epoch: [007][00080/00231]	Time 0.21 (0.21)	Loss 0.67 (0.82)
		cls_loss 0.30 (0.38)	reg_loss 0.19 (0.22)
Epoch: [007][00090/00231]	Time 0.21 (0.21)	Loss 0.97 (0.84)
		cls_loss 0.39 (0.39)	reg_loss 0.29 (0.23)
Epoch: [007][00100/00231]	Time 0.22 (0.21)	Loss 0.79 (0.83)
		cls_loss 0.37 (0.38)	reg_loss 0.21 (0.22)
Epoch: [007][00110/00231]	Time 0.22 (0.21)	Loss 0.67 (0.82)
		cls_loss 0.32 (0.38)	reg_loss 0.17 (0.22)
Epoch: [007][00120/00231]	Time 0.22 (0.21)	Loss 0.86 (0.82)
		cls_loss 0.40 (0.38)	reg_loss 0.23 (0.22)
Epoch: [007][00130/00231]	Time 0.22 (0.21)	Loss 0.32 (0.78)
		cls_loss 0.16 (0.36)	reg_loss 0.08 (0.21)
Epoch: [007][00140/00231]	Time 0.22 (0.21)	Loss 0.78 (0.78)
		cls_loss 0.34 (0.36)	reg_loss 0.22 (0.21)
Epoch: [007][00150/00231]	Time 0.22 (0.21)	Loss 0.66 (0.77)
		cls_loss 0.33 (0.36)	reg_loss 0.16 (0.21)
Epoch: [007][00160/00231]	Time 0.22 (0.21)	Loss 0.71 (0.77)
		cls_loss 0.32 (0.36)	reg_loss 0.19 (0.21)
Epoch: [007][00170/00231]	Time 0.22 (0.21)	Loss 0.57 (0.76)
		cls_loss 0.31 (0.35)	reg_loss 0.13 (0.20)
Epoch: [007][00180/00231]	Time 0.22 (0.21)	Loss 0.84 (0.76)
		cls_loss 0.36 (0.36)	reg_loss 0.24 (0.20)
Epoch: [007][00190/00231]	Time 0.22 (0.22)	Loss 0.71 (0.76)
		cls_loss 0.30 (0.35)	reg_loss 0.20 (0.20)
Epoch: [007][00200/00231]	Time 0.22 (0.22)	Loss 1.06 (0.77)
		cls_loss 0.48 (0.36)	reg_loss 0.29 (0.21)
Epoch: [007][00210/00231]	Time 0.22 (0.22)	Loss 0.81 (0.78)
		cls_loss 0.42 (0.36)	reg_loss 0.20 (0.21)
Epoch: [007][00220/00231]	Time 0.22 (0.22)	Loss 1.00 (0.79)
		cls_loss 0.45 (0.37)	reg_loss 0.28 (0.21)
Epoch: [007][00230/00231]	Time 0.18 (0.21)	Loss 0.72 (0.78)
		cls_loss 0.34 (0.36)	reg_loss 0.19 (0.21)
[Train]: Epoch 7 finished with lr=0.00079389


[Train]: Epoch 8 started
Epoch: [008][00010/00231]	Time 0.28 (0.28)	Loss 0.88 (0.88)
		cls_loss 0.43 (0.43)	reg_loss 0.23 (0.23)
Epoch: [008][00020/00231]	Time 0.22 (0.25)	Loss 1.13 (1.00)
		cls_loss 0.49 (0.46)	reg_loss 0.32 (0.27)
Epoch: [008][00030/00231]	Time 0.22 (0.24)	Loss 0.95 (0.99)
		cls_loss 0.42 (0.45)	reg_loss 0.27 (0.27)
Epoch: [008][00040/00231]	Time 0.22 (0.23)	Loss 0.76 (0.93)
		cls_loss 0.40 (0.43)	reg_loss 0.18 (0.25)
Epoch: [008][00050/00231]	Time 0.22 (0.23)	Loss 0.56 (0.86)
		cls_loss 0.24 (0.40)	reg_loss 0.16 (0.23)
Epoch: [008][00060/00231]	Time 0.22 (0.23)	Loss 0.60 (0.81)
		cls_loss 0.29 (0.38)	reg_loss 0.16 (0.22)
Epoch: [008][00070/00231]	Time 0.22 (0.23)	Loss 0.96 (0.84)
		cls_loss 0.47 (0.39)	reg_loss 0.25 (0.22)
Epoch: [008][00080/00231]	Time 0.22 (0.22)	Loss 0.52 (0.80)
		cls_loss 0.27 (0.38)	reg_loss 0.13 (0.21)
Epoch: [008][00090/00231]	Time 0.22 (0.22)	Loss 0.63 (0.78)
		cls_loss 0.32 (0.37)	reg_loss 0.16 (0.20)
Epoch: [008][00100/00231]	Time 0.22 (0.22)	Loss 0.84 (0.78)
		cls_loss 0.37 (0.37)	reg_loss 0.23 (0.21)
Epoch: [008][00110/00231]	Time 0.22 (0.22)	Loss 1.02 (0.81)
		cls_loss 0.49 (0.38)	reg_loss 0.26 (0.21)
Epoch: [008][00120/00231]	Time 0.22 (0.22)	Loss 0.84 (0.81)
		cls_loss 0.36 (0.38)	reg_loss 0.24 (0.22)
Epoch: [008][00130/00231]	Time 0.22 (0.22)	Loss 0.86 (0.81)
		cls_loss 0.43 (0.38)	reg_loss 0.21 (0.21)
Epoch: [008][00140/00231]	Time 0.22 (0.22)	Loss 0.96 (0.82)
		cls_loss 0.46 (0.39)	reg_loss 0.25 (0.22)
Epoch: [008][00150/00231]	Time 0.22 (0.22)	Loss 0.83 (0.82)
		cls_loss 0.39 (0.39)	reg_loss 0.22 (0.22)
Epoch: [008][00160/00231]	Time 0.22 (0.22)	Loss 0.68 (0.81)
		cls_loss 0.30 (0.38)	reg_loss 0.19 (0.22)
Epoch: [008][00170/00231]	Time 0.22 (0.22)	Loss 0.53 (0.80)
		cls_loss 0.26 (0.38)	reg_loss 0.13 (0.21)
Epoch: [008][00180/00231]	Time 0.23 (0.22)	Loss 0.57 (0.79)
		cls_loss 0.31 (0.37)	reg_loss 0.13 (0.21)
Epoch: [008][00190/00231]	Time 0.92 (0.26)	Loss 0.81 (0.79)
		cls_loss 0.41 (0.37)	reg_loss 0.20 (0.21)
Epoch: [008][00200/00231]	Time 0.21 (0.26)	Loss 0.72 (0.78)
		cls_loss 0.31 (0.37)	reg_loss 0.21 (0.21)
Epoch: [008][00210/00231]	Time 0.20 (0.25)	Loss 0.67 (0.78)
		cls_loss 0.34 (0.37)	reg_loss 0.16 (0.20)
Epoch: [008][00220/00231]	Time 0.21 (0.25)	Loss 0.93 (0.78)
		cls_loss 0.45 (0.37)	reg_loss 0.24 (0.21)
Epoch: [008][00230/00231]	Time 1.68 (0.31)	Loss 0.66 (0.78)
		cls_loss 0.34 (0.37)	reg_loss 0.16 (0.20)
[Train]: Epoch 8 finished with lr=0.00065451


[Train]: Epoch 9 started
Epoch: [009][00010/00231]	Time 0.58 (0.58)	Loss 0.65 (0.65)
		cls_loss 0.34 (0.34)	reg_loss 0.16 (0.16)
Epoch: [009][00020/00231]	Time 0.20 (0.39)	Loss 0.82 (0.73)
		cls_loss 0.35 (0.34)	reg_loss 0.23 (0.20)
Epoch: [009][00030/00231]	Time 0.21 (0.33)	Loss 1.15 (0.87)
		cls_loss 0.53 (0.41)	reg_loss 0.31 (0.23)
Epoch: [009][00040/00231]	Time 0.19 (0.30)	Loss 0.81 (0.86)
		cls_loss 0.39 (0.40)	reg_loss 0.21 (0.23)
Epoch: [009][00050/00231]	Time 0.20 (0.28)	Loss 0.82 (0.85)
		cls_loss 0.42 (0.40)	reg_loss 0.20 (0.22)
Epoch: [009][00060/00231]	Time 0.19 (0.26)	Loss 1.02 (0.88)
		cls_loss 0.45 (0.41)	reg_loss 0.28 (0.23)
Epoch: [009][00070/00231]	Time 0.20 (0.25)	Loss 0.57 (0.83)
		cls_loss 0.27 (0.39)	reg_loss 0.15 (0.22)
Epoch: [009][00080/00231]	Time 0.20 (0.25)	Loss 0.90 (0.84)
		cls_loss 0.41 (0.40)	reg_loss 0.24 (0.22)
Epoch: [009][00090/00231]	Time 0.22 (0.24)	Loss 0.65 (0.82)
		cls_loss 0.32 (0.39)	reg_loss 0.17 (0.22)
Epoch: [009][00100/00231]	Time 0.22 (0.24)	Loss 0.95 (0.83)
		cls_loss 0.47 (0.40)	reg_loss 0.24 (0.22)
Epoch: [009][00110/00231]	Time 0.22 (0.24)	Loss 1.52 (0.90)
		cls_loss 0.63 (0.42)	reg_loss 0.45 (0.24)
Epoch: [009][00120/00231]	Time 0.21 (0.24)	Loss 0.46 (0.86)
		cls_loss 0.22 (0.40)	reg_loss 0.12 (0.23)
Epoch: [009][00130/00231]	Time 0.22 (0.24)	Loss 0.65 (0.84)
		cls_loss 0.33 (0.39)	reg_loss 0.16 (0.22)
Epoch: [009][00140/00231]	Time 0.22 (0.23)	Loss 0.61 (0.83)
		cls_loss 0.27 (0.39)	reg_loss 0.17 (0.22)
Epoch: [009][00150/00231]	Time 0.22 (0.23)	Loss 0.71 (0.82)
		cls_loss 0.36 (0.38)	reg_loss 0.18 (0.22)
Epoch: [009][00160/00231]	Time 0.22 (0.23)	Loss 1.26 (0.85)
		cls_loss 0.58 (0.40)	reg_loss 0.34 (0.23)
Epoch: [009][00170/00231]	Time 0.21 (0.23)	Loss 0.56 (0.83)
		cls_loss 0.29 (0.39)	reg_loss 0.14 (0.22)
Epoch: [009][00180/00231]	Time 0.22 (0.23)	Loss 1.57 (0.87)
		cls_loss 0.65 (0.40)	reg_loss 0.46 (0.23)
Epoch: [009][00190/00231]	Time 0.21 (0.23)	Loss 0.44 (0.85)
		cls_loss 0.19 (0.39)	reg_loss 0.12 (0.23)
Epoch: [009][00200/00231]	Time 0.21 (0.23)	Loss 0.80 (0.85)
		cls_loss 0.38 (0.39)	reg_loss 0.21 (0.23)
Epoch: [009][00210/00231]	Time 0.22 (0.23)	Loss 0.73 (0.84)
		cls_loss 0.36 (0.39)	reg_loss 0.18 (0.22)
Epoch: [009][00220/00231]	Time 0.22 (0.23)	Loss 1.18 (0.86)
		cls_loss 0.52 (0.40)	reg_loss 0.33 (0.23)
Epoch: [009][00230/00231]	Time 0.18 (0.23)	Loss 0.60 (0.85)
		cls_loss 0.29 (0.39)	reg_loss 0.16 (0.23)
[Train]: Epoch 9 finished with lr=0.00050001


[Train]: Epoch 10 started
Epoch: [010][00010/00231]	Time 0.25 (0.25)	Loss 0.56 (0.56)
		cls_loss 0.27 (0.27)	reg_loss 0.15 (0.15)
Epoch: [010][00020/00231]	Time 0.20 (0.22)	Loss 0.54 (0.55)
		cls_loss 0.28 (0.27)	reg_loss 0.13 (0.14)
Epoch: [010][00030/00231]	Time 0.22 (0.22)	Loss 0.79 (0.63)
		cls_loss 0.33 (0.29)	reg_loss 0.23 (0.17)
Epoch: [010][00040/00231]	Time 0.22 (0.22)	Loss 0.78 (0.67)
		cls_loss 0.36 (0.31)	reg_loss 0.21 (0.18)
Epoch: [010][00050/00231]	Time 0.22 (0.22)	Loss 0.80 (0.69)
		cls_loss 0.41 (0.33)	reg_loss 0.20 (0.18)
Epoch: [010][00060/00231]	Time 0.22 (0.22)	Loss 0.42 (0.65)
		cls_loss 0.24 (0.31)	reg_loss 0.09 (0.17)
Epoch: [010][00070/00231]	Time 0.22 (0.22)	Loss 0.73 (0.66)
		cls_loss 0.35 (0.32)	reg_loss 0.19 (0.17)
Epoch: [010][00080/00231]	Time 0.22 (0.22)	Loss 0.82 (0.68)
		cls_loss 0.36 (0.32)	reg_loss 0.23 (0.18)
Epoch: [010][00090/00231]	Time 0.22 (0.22)	Loss 0.75 (0.69)
		cls_loss 0.35 (0.33)	reg_loss 0.20 (0.18)
Epoch: [010][00100/00231]	Time 0.22 (0.22)	Loss 1.08 (0.73)
		cls_loss 0.49 (0.34)	reg_loss 0.30 (0.19)
Epoch: [010][00110/00231]	Time 0.22 (0.22)	Loss 0.65 (0.72)
		cls_loss 0.28 (0.34)	reg_loss 0.18 (0.19)
Epoch: [010][00120/00231]	Time 0.22 (0.22)	Loss 0.81 (0.73)
		cls_loss 0.38 (0.34)	reg_loss 0.22 (0.19)
Epoch: [010][00130/00231]	Time 0.22 (0.22)	Loss 1.02 (0.75)
		cls_loss 0.43 (0.35)	reg_loss 0.30 (0.20)
Epoch: [010][00140/00231]	Time 0.22 (0.22)	Loss 0.63 (0.74)
		cls_loss 0.35 (0.35)	reg_loss 0.14 (0.20)
Epoch: [010][00150/00231]	Time 0.22 (0.22)	Loss 0.77 (0.74)
		cls_loss 0.33 (0.35)	reg_loss 0.22 (0.20)
Epoch: [010][00160/00231]	Time 0.22 (0.22)	Loss 0.53 (0.73)
		cls_loss 0.28 (0.34)	reg_loss 0.12 (0.19)
Epoch: [010][00170/00231]	Time 0.22 (0.22)	Loss 1.21 (0.76)
		cls_loss 0.52 (0.35)	reg_loss 0.35 (0.20)
Epoch: [010][00180/00231]	Time 0.22 (0.22)	Loss 0.89 (0.76)
		cls_loss 0.39 (0.36)	reg_loss 0.25 (0.20)
Epoch: [010][00190/00231]	Time 0.22 (0.22)	Loss 0.82 (0.77)
		cls_loss 0.38 (0.36)	reg_loss 0.22 (0.21)
Epoch: [010][00200/00231]	Time 0.22 (0.22)	Loss 0.61 (0.76)
		cls_loss 0.28 (0.35)	reg_loss 0.17 (0.20)
Epoch: [010][00210/00231]	Time 0.22 (0.22)	Loss 0.31 (0.74)
		cls_loss 0.16 (0.34)	reg_loss 0.07 (0.20)
Epoch: [010][00220/00231]	Time 0.22 (0.22)	Loss 0.80 (0.74)
		cls_loss 0.37 (0.34)	reg_loss 0.22 (0.20)
Epoch: [010][00230/00231]	Time 0.18 (0.22)	Loss 0.50 (0.73)
		cls_loss 0.24 (0.34)	reg_loss 0.13 (0.20)
[Train]: Epoch 10 finished with lr=0.00034550


[Train]: Epoch 11 started
Epoch: [011][00010/00231]	Time 0.25 (0.25)	Loss 0.86 (0.86)
		cls_loss 0.42 (0.42)	reg_loss 0.22 (0.22)
Epoch: [011][00020/00231]	Time 0.21 (0.23)	Loss 0.71 (0.79)
		cls_loss 0.32 (0.37)	reg_loss 0.20 (0.21)
Epoch: [011][00030/00231]	Time 0.21 (0.23)	Loss 0.66 (0.75)
		cls_loss 0.31 (0.35)	reg_loss 0.18 (0.20)
Epoch: [011][00040/00231]	Time 0.21 (0.22)	Loss 0.81 (0.76)
		cls_loss 0.38 (0.36)	reg_loss 0.21 (0.20)
Epoch: [011][00050/00231]	Time 0.21 (0.22)	Loss 0.65 (0.74)
		cls_loss 0.31 (0.35)	reg_loss 0.17 (0.20)
Epoch: [011][00060/00231]	Time 0.22 (0.22)	Loss 0.81 (0.75)
		cls_loss 0.37 (0.35)	reg_loss 0.22 (0.20)
Epoch: [011][00070/00231]	Time 0.22 (0.22)	Loss 1.02 (0.79)
		cls_loss 0.49 (0.37)	reg_loss 0.26 (0.21)
Epoch: [011][00080/00231]	Time 0.22 (0.22)	Loss 0.50 (0.75)
		cls_loss 0.22 (0.35)	reg_loss 0.14 (0.20)
Epoch: [011][00090/00231]	Time 0.22 (0.22)	Loss 0.50 (0.72)
		cls_loss 0.28 (0.34)	reg_loss 0.11 (0.19)
Epoch: [011][00100/00231]	Time 0.22 (0.22)	Loss 0.62 (0.71)
		cls_loss 0.29 (0.34)	reg_loss 0.16 (0.19)
Epoch: [011][00110/00231]	Time 0.20 (0.22)	Loss 0.73 (0.72)
		cls_loss 0.35 (0.34)	reg_loss 0.19 (0.19)
Epoch: [011][00120/00231]	Time 0.87 (0.27)	Loss 0.60 (0.71)
		cls_loss 0.29 (0.34)	reg_loss 0.16 (0.19)
Epoch: [011][00130/00231]	Time 0.19 (0.27)	Loss 0.76 (0.71)
		cls_loss 0.35 (0.34)	reg_loss 0.21 (0.19)
Epoch: [011][00140/00231]	Time 0.20 (0.26)	Loss 0.27 (0.68)
		cls_loss 0.16 (0.32)	reg_loss 0.06 (0.18)
Epoch: [011][00150/00231]	Time 0.22 (0.26)	Loss 0.41 (0.66)
		cls_loss 0.20 (0.32)	reg_loss 0.11 (0.17)
Epoch: [011][00160/00231]	Time 0.22 (0.26)	Loss 0.90 (0.68)
		cls_loss 0.41 (0.32)	reg_loss 0.24 (0.18)
Epoch: [011][00170/00231]	Time 0.22 (0.25)	Loss 0.82 (0.68)
		cls_loss 0.37 (0.32)	reg_loss 0.22 (0.18)
Epoch: [011][00180/00231]	Time 0.22 (0.25)	Loss 0.52 (0.68)
		cls_loss 0.27 (0.32)	reg_loss 0.13 (0.18)
Epoch: [011][00190/00231]	Time 0.22 (0.25)	Loss 0.82 (0.68)
		cls_loss 0.40 (0.33)	reg_loss 0.21 (0.18)
Epoch: [011][00200/00231]	Time 0.22 (0.25)	Loss 0.28 (0.66)
		cls_loss 0.17 (0.32)	reg_loss 0.05 (0.17)
Epoch: [011][00210/00231]	Time 0.22 (0.25)	Loss 0.75 (0.67)
		cls_loss 0.36 (0.32)	reg_loss 0.19 (0.17)
Epoch: [011][00220/00231]	Time 0.22 (0.25)	Loss 0.79 (0.67)
		cls_loss 0.41 (0.32)	reg_loss 0.19 (0.17)
Epoch: [011][00230/00231]	Time 0.18 (0.24)	Loss 1.00 (0.69)
		cls_loss 0.46 (0.33)	reg_loss 0.27 (0.18)
[Train]: Epoch 11 finished with lr=0.00020612


[Train]: Epoch 12 started
Epoch: [012][00010/00231]	Time 0.25 (0.25)	Loss 0.43 (0.43)
		cls_loss 0.23 (0.23)	reg_loss 0.10 (0.10)
Epoch: [012][00020/00231]	Time 0.19 (0.22)	Loss 0.68 (0.56)
		cls_loss 0.32 (0.27)	reg_loss 0.18 (0.14)
Epoch: [012][00030/00231]	Time 0.21 (0.22)	Loss 0.71 (0.61)
		cls_loss 0.36 (0.30)	reg_loss 0.17 (0.15)
Epoch: [012][00040/00231]	Time 0.21 (0.21)	Loss 0.66 (0.62)
		cls_loss 0.34 (0.31)	reg_loss 0.16 (0.16)
Epoch: [012][00050/00231]	Time 0.22 (0.22)	Loss 0.50 (0.60)
		cls_loss 0.22 (0.29)	reg_loss 0.14 (0.15)
Epoch: [012][00060/00231]	Time 0.22 (0.22)	Loss 0.56 (0.59)
		cls_loss 0.28 (0.29)	reg_loss 0.14 (0.15)
Epoch: [012][00070/00231]	Time 0.22 (0.22)	Loss 0.63 (0.60)
		cls_loss 0.29 (0.29)	reg_loss 0.17 (0.15)
Epoch: [012][00080/00231]	Time 0.22 (0.22)	Loss 0.41 (0.57)
		cls_loss 0.20 (0.28)	reg_loss 0.11 (0.15)
Epoch: [012][00090/00231]	Time 0.22 (0.22)	Loss 0.51 (0.57)
		cls_loss 0.26 (0.28)	reg_loss 0.12 (0.14)
Epoch: [012][00100/00231]	Time 0.23 (0.22)	Loss 0.88 (0.60)
		cls_loss 0.38 (0.29)	reg_loss 0.25 (0.16)
Epoch: [012][00110/00231]	Time 0.22 (0.22)	Loss 0.53 (0.59)
		cls_loss 0.28 (0.29)	reg_loss 0.13 (0.15)
Epoch: [012][00120/00231]	Time 0.22 (0.22)	Loss 0.59 (0.59)
		cls_loss 0.34 (0.29)	reg_loss 0.13 (0.15)
Epoch: [012][00130/00231]	Time 0.21 (0.22)	Loss 0.55 (0.59)
		cls_loss 0.26 (0.29)	reg_loss 0.15 (0.15)
Epoch: [012][00140/00231]	Time 0.88 (0.26)	Loss 0.61 (0.59)
		cls_loss 0.31 (0.29)	reg_loss 0.15 (0.15)
Epoch: [012][00150/00231]	Time 0.46 (0.28)	Loss 0.74 (0.60)
		cls_loss 0.37 (0.29)	reg_loss 0.19 (0.15)
Epoch: [012][00160/00231]	Time 0.22 (0.27)	Loss 0.70 (0.61)
		cls_loss 0.34 (0.30)	reg_loss 0.18 (0.15)
Epoch: [012][00170/00231]	Time 0.22 (0.27)	Loss 1.08 (0.63)
		cls_loss 0.47 (0.31)	reg_loss 0.30 (0.16)
Epoch: [012][00180/00231]	Time 0.22 (0.27)	Loss 0.71 (0.64)
		cls_loss 0.35 (0.31)	reg_loss 0.18 (0.16)
Epoch: [012][00190/00231]	Time 0.22 (0.27)	Loss 0.62 (0.64)
		cls_loss 0.30 (0.31)	reg_loss 0.16 (0.16)
Epoch: [012][00200/00231]	Time 0.22 (0.26)	Loss 0.41 (0.63)
		cls_loss 0.20 (0.30)	reg_loss 0.11 (0.16)
Epoch: [012][00210/00231]	Time 0.22 (0.26)	Loss 0.51 (0.62)
		cls_loss 0.24 (0.30)	reg_loss 0.14 (0.16)
Epoch: [012][00220/00231]	Time 0.22 (0.26)	Loss 0.40 (0.61)
		cls_loss 0.20 (0.30)	reg_loss 0.10 (0.16)
Epoch: [012][00230/00231]	Time 0.18 (0.26)	Loss 0.35 (0.60)
		cls_loss 0.20 (0.29)	reg_loss 0.08 (0.15)
[Train]: Epoch 12 finished with lr=0.00009550


[Train]: Epoch 13 started
Epoch: [013][00010/00231]	Time 0.29 (0.29)	Loss 0.82 (0.82)
		cls_loss 0.42 (0.42)	reg_loss 0.20 (0.20)
Epoch: [013][00020/00231]	Time 0.22 (0.26)	Loss 0.77 (0.79)
		cls_loss 0.34 (0.38)	reg_loss 0.21 (0.21)
Epoch: [013][00030/00231]	Time 0.22 (0.24)	Loss 1.03 (0.87)
		cls_loss 0.48 (0.41)	reg_loss 0.28 (0.23)
Epoch: [013][00040/00231]	Time 0.22 (0.24)	Loss 0.85 (0.87)
		cls_loss 0.42 (0.41)	reg_loss 0.22 (0.23)
Epoch: [013][00050/00231]	Time 0.22 (0.23)	Loss 0.72 (0.84)
		cls_loss 0.35 (0.40)	reg_loss 0.19 (0.22)
Epoch: [013][00060/00231]	Time 0.22 (0.23)	Loss 0.29 (0.75)
		cls_loss 0.16 (0.36)	reg_loss 0.07 (0.19)
Epoch: [013][00070/00231]	Time 0.22 (0.23)	Loss 0.78 (0.75)
		cls_loss 0.38 (0.36)	reg_loss 0.20 (0.19)
Epoch: [013][00080/00231]	Time 0.22 (0.23)	Loss 0.85 (0.76)
		cls_loss 0.39 (0.37)	reg_loss 0.23 (0.20)
Epoch: [013][00090/00231]	Time 0.22 (0.23)	Loss 0.80 (0.77)
		cls_loss 0.36 (0.37)	reg_loss 0.22 (0.20)
Epoch: [013][00100/00231]	Time 0.22 (0.23)	Loss 0.30 (0.72)
		cls_loss 0.16 (0.34)	reg_loss 0.07 (0.19)
Epoch: [013][00110/00231]	Time 0.22 (0.23)	Loss 0.45 (0.70)
		cls_loss 0.24 (0.34)	reg_loss 0.10 (0.18)
Epoch: [013][00120/00231]	Time 0.22 (0.23)	Loss 0.50 (0.68)
		cls_loss 0.28 (0.33)	reg_loss 0.11 (0.17)
Epoch: [013][00130/00231]	Time 0.22 (0.22)	Loss 1.06 (0.71)
		cls_loss 0.51 (0.34)	reg_loss 0.28 (0.18)
Epoch: [013][00140/00231]	Time 0.22 (0.22)	Loss 1.34 (0.75)
		cls_loss 0.56 (0.36)	reg_loss 0.39 (0.20)
Epoch: [013][00150/00231]	Time 0.22 (0.22)	Loss 0.59 (0.74)
		cls_loss 0.29 (0.35)	reg_loss 0.15 (0.19)
Epoch: [013][00160/00231]	Time 0.22 (0.22)	Loss 1.04 (0.76)
		cls_loss 0.48 (0.36)	reg_loss 0.28 (0.20)
Epoch: [013][00170/00231]	Time 0.22 (0.22)	Loss 0.44 (0.74)
		cls_loss 0.21 (0.35)	reg_loss 0.12 (0.19)
Epoch: [013][00180/00231]	Time 0.22 (0.22)	Loss 0.90 (0.75)
		cls_loss 0.42 (0.36)	reg_loss 0.24 (0.20)
Epoch: [013][00190/00231]	Time 0.22 (0.22)	Loss 1.05 (0.77)
		cls_loss 0.50 (0.36)	reg_loss 0.27 (0.20)
Epoch: [013][00200/00231]	Time 0.22 (0.22)	Loss 0.41 (0.75)
		cls_loss 0.22 (0.36)	reg_loss 0.09 (0.20)
Epoch: [013][00210/00231]	Time 0.22 (0.22)	Loss 1.15 (0.77)
		cls_loss 0.55 (0.37)	reg_loss 0.30 (0.20)
Epoch: [013][00220/00231]	Time 0.22 (0.22)	Loss 0.74 (0.77)
		cls_loss 0.34 (0.37)	reg_loss 0.20 (0.20)
Epoch: [013][00230/00231]	Time 0.18 (0.22)	Loss 0.32 (0.75)
		cls_loss 0.16 (0.36)	reg_loss 0.08 (0.20)
[Train]: Epoch 13 finished with lr=0.00002448


[Train]: Epoch 14 started
Epoch: [014][00010/00231]	Time 0.29 (0.29)	Loss 0.53 (0.53)
		cls_loss 0.26 (0.26)	reg_loss 0.14 (0.14)
Epoch: [014][00020/00231]	Time 0.22 (0.26)	Loss 0.54 (0.53)
		cls_loss 0.26 (0.26)	reg_loss 0.14 (0.14)
Epoch: [014][00030/00231]	Time 0.22 (0.24)	Loss 0.46 (0.51)
		cls_loss 0.21 (0.24)	reg_loss 0.12 (0.13)
Epoch: [014][00040/00231]	Time 0.22 (0.24)	Loss 0.70 (0.56)
		cls_loss 0.30 (0.26)	reg_loss 0.20 (0.15)
Epoch: [014][00050/00231]	Time 0.22 (0.23)	Loss 0.57 (0.56)
		cls_loss 0.28 (0.26)	reg_loss 0.15 (0.15)
Epoch: [014][00060/00231]	Time 0.22 (0.23)	Loss 1.00 (0.63)
		cls_loss 0.51 (0.30)	reg_loss 0.25 (0.16)
Epoch: [014][00070/00231]	Time 0.22 (0.23)	Loss 0.52 (0.62)
		cls_loss 0.29 (0.30)	reg_loss 0.11 (0.16)
Epoch: [014][00080/00231]	Time 0.67 (0.28)	Loss 0.98 (0.66)
		cls_loss 0.41 (0.31)	reg_loss 0.29 (0.17)
Epoch: [014][00090/00231]	Time 0.21 (0.28)	Loss 0.58 (0.65)
		cls_loss 0.28 (0.31)	reg_loss 0.15 (0.17)
Epoch: [014][00100/00231]	Time 0.22 (0.27)	Loss 0.56 (0.64)
		cls_loss 0.30 (0.31)	reg_loss 0.13 (0.17)
Epoch: [014][00110/00231]	Time 0.22 (0.27)	Loss 0.43 (0.62)
		cls_loss 0.20 (0.30)	reg_loss 0.11 (0.16)
Epoch: [014][00120/00231]	Time 0.22 (0.26)	Loss 0.59 (0.62)
		cls_loss 0.30 (0.30)	reg_loss 0.14 (0.16)
Epoch: [014][00130/00231]	Time 0.21 (0.26)	Loss 0.81 (0.64)
		cls_loss 0.35 (0.30)	reg_loss 0.23 (0.17)
Epoch: [014][00140/00231]	Time 0.23 (0.26)	Loss 1.02 (0.66)
		cls_loss 0.46 (0.31)	reg_loss 0.28 (0.17)
Epoch: [014][00150/00231]	Time 0.26 (0.26)	Loss 0.64 (0.66)
		cls_loss 0.31 (0.31)	reg_loss 0.17 (0.17)
Epoch: [014][00160/00231]	Time 0.19 (0.25)	Loss 0.75 (0.67)
		cls_loss 0.34 (0.32)	reg_loss 0.21 (0.18)
Epoch: [014][00170/00231]	Time 0.20 (0.25)	Loss 0.47 (0.66)
		cls_loss 0.23 (0.31)	reg_loss 0.12 (0.17)
Epoch: [014][00180/00231]	Time 0.17 (0.25)	Loss 0.94 (0.67)
		cls_loss 0.35 (0.31)	reg_loss 0.29 (0.18)
Epoch: [014][00190/00231]	Time 0.34 (0.25)	Loss 0.56 (0.67)
		cls_loss 0.27 (0.31)	reg_loss 0.15 (0.18)
Epoch: [014][00200/00231]	Time 0.19 (0.25)	Loss 0.54 (0.66)
		cls_loss 0.28 (0.31)	reg_loss 0.13 (0.18)
Epoch: [014][00210/00231]	Time 0.20 (0.25)	Loss 0.77 (0.66)
		cls_loss 0.39 (0.31)	reg_loss 0.19 (0.18)
Epoch: [014][00220/00231]	Time 0.19 (0.24)	Loss 0.76 (0.67)
		cls_loss 0.36 (0.31)	reg_loss 0.20 (0.18)
Epoch: [014][00230/00231]	Time 0.18 (0.24)	Loss 0.44 (0.66)
		cls_loss 0.22 (0.31)	reg_loss 0.11 (0.17)
[Train]: Epoch 14 finished with lr=0.00000001

All done!
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
=> loading checkpoint './ckpt/anet_i3d_reproduce/epoch_015.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/04555]	Time 0.58 (0.58)
Test: [00020/04555]	Time 0.08 (0.33)
Test: [00030/04555]	Time 0.04 (0.23)
Test: [00040/04555]	Time 0.04 (0.18)
Test: [00050/04555]	Time 0.04 (0.16)
Test: [00060/04555]	Time 0.04 (0.14)
Test: [00070/04555]	Time 0.23 (0.15)
Test: [00080/04555]	Time 0.23 (0.16)
Test: [00090/04555]	Time 0.24 (0.17)
Test: [00100/04555]	Time 0.24 (0.18)
Test: [00110/04555]	Time 0.24 (0.18)
Test: [00120/04555]	Time 0.10 (0.17)
Test: [00130/04555]	Time 0.04 (0.16)
Test: [00140/04555]	Time 0.04 (0.16)
Test: [00150/04555]	Time 0.04 (0.15)
Test: [00160/04555]	Time 0.04 (0.14)
Test: [00170/04555]	Time 0.04 (0.14)
Test: [00180/04555]	Time 0.04 (0.13)
Test: [00190/04555]	Time 0.32 (0.14)
Test: [00200/04555]	Time 0.04 (0.13)
Test: [00210/04555]	Time 0.04 (0.13)
Test: [00220/04555]	Time 0.04 (0.13)
Test: [00230/04555]	Time 0.04 (0.12)
Test: [00240/04555]	Time 0.04 (0.12)
Test: [00250/04555]	Time 0.04 (0.12)
Test: [00260/04555]	Time 0.04 (0.11)
Test: [00270/04555]	Time 0.04 (0.11)
Test: [00280/04555]	Time 0.04 (0.11)
Test: [00290/04555]	Time 0.04 (0.11)
Test: [00300/04555]	Time 0.07 (0.10)
Test: [00310/04555]	Time 0.04 (0.10)
Test: [00320/04555]	Time 0.04 (0.10)
Test: [00330/04555]	Time 0.04 (0.10)
Test: [00340/04555]	Time 0.04 (0.10)
Test: [00350/04555]	Time 0.04 (0.09)
Test: [00360/04555]	Time 0.04 (0.09)
Test: [00370/04555]	Time 0.04 (0.09)
Test: [00380/04555]	Time 0.04 (0.09)
Test: [00390/04555]	Time 0.04 (0.09)
Test: [00400/04555]	Time 0.05 (0.09)
Test: [00410/04555]	Time 0.04 (0.09)
Test: [00420/04555]	Time 0.08 (0.09)
Test: [00430/04555]	Time 0.04 (0.09)
Test: [00440/04555]	Time 0.04 (0.08)
Test: [00450/04555]	Time 0.04 (0.08)
Test: [00460/04555]	Time 0.04 (0.08)
Test: [00470/04555]	Time 0.04 (0.08)
Test: [00480/04555]	Time 0.04 (0.08)
Test: [00490/04555]	Time 0.04 (0.08)
Test: [00500/04555]	Time 0.83 (0.09)
Test: [00510/04555]	Time 0.05 (0.09)
Test: [00520/04555]	Time 0.29 (0.10)
Test: [00530/04555]	Time 0.24 (0.10)
Test: [00540/04555]	Time 0.56 (0.11)
Test: [00550/04555]	Time 0.04 (0.11)
Test: [00560/04555]	Time 0.08 (0.11)
Test: [00570/04555]	Time 0.29 (0.11)
Test: [00580/04555]	Time 0.04 (0.11)
Test: [00590/04555]	Time 0.04 (0.11)
Test: [00600/04555]	Time 0.04 (0.11)
Test: [00610/04555]	Time 0.05 (0.11)
Test: [00620/04555]	Time 0.04 (0.10)
Test: [00630/04555]	Time 0.04 (0.10)
Test: [00640/04555]	Time 0.04 (0.10)
Test: [00650/04555]	Time 0.15 (0.10)
Test: [00660/04555]	Time 0.18 (0.10)
Test: [00670/04555]	Time 0.04 (0.10)
Test: [00680/04555]	Time 0.04 (0.10)
Test: [00690/04555]	Time 0.04 (0.10)
Test: [00700/04555]	Time 0.04 (0.10)
Test: [00710/04555]	Time 0.04 (0.10)
Test: [00720/04555]	Time 0.04 (0.10)
Test: [00730/04555]	Time 0.04 (0.10)
Test: [00740/04555]	Time 0.04 (0.10)
Test: [00750/04555]	Time 0.04 (0.10)
Test: [00760/04555]	Time 0.04 (0.10)
Test: [00770/04555]	Time 0.04 (0.10)
Test: [00780/04555]	Time 0.04 (0.09)
Test: [00790/04555]	Time 0.06 (0.09)
Test: [00800/04555]	Time 0.04 (0.09)
Test: [00810/04555]	Time 0.04 (0.09)
Test: [00820/04555]	Time 0.04 (0.09)
Test: [00830/04555]	Time 0.04 (0.09)
Test: [00840/04555]	Time 0.14 (0.09)
Test: [00850/04555]	Time 0.08 (0.09)
Test: [00860/04555]	Time 0.10 (0.09)
Test: [00870/04555]	Time 0.04 (0.09)
Test: [00880/04555]	Time 0.14 (0.09)
Test: [00890/04555]	Time 0.04 (0.09)
Test: [00900/04555]	Time 0.04 (0.09)
Test: [00910/04555]	Time 0.05 (0.09)
Test: [00920/04555]	Time 0.04 (0.09)
Test: [00930/04555]	Time 0.07 (0.09)
Test: [00940/04555]	Time 0.07 (0.09)
Test: [00950/04555]	Time 0.04 (0.09)
Test: [00960/04555]	Time 0.06 (0.09)
Test: [00970/04555]	Time 0.04 (0.09)
Test: [00980/04555]	Time 0.04 (0.09)
Test: [00990/04555]	Time 0.04 (0.09)
Test: [01000/04555]	Time 0.04 (0.09)
Test: [01010/04555]	Time 0.04 (0.09)
Test: [01020/04555]	Time 0.04 (0.09)
Test: [01030/04555]	Time 0.04 (0.09)
Test: [01040/04555]	Time 0.04 (0.08)
Test: [01050/04555]	Time 0.04 (0.08)
Test: [01060/04555]	Time 0.05 (0.08)
Test: [01070/04555]	Time 0.05 (0.08)
Test: [01080/04555]	Time 0.04 (0.08)
Test: [01090/04555]	Time 0.07 (0.08)
Test: [01100/04555]	Time 0.04 (0.08)
Test: [01110/04555]	Time 0.04 (0.08)
Test: [01120/04555]	Time 0.04 (0.08)
Test: [01130/04555]	Time 0.04 (0.08)
Test: [01140/04555]	Time 0.04 (0.08)
Test: [01150/04555]	Time 0.04 (0.08)
Test: [01160/04555]	Time 0.04 (0.08)
Test: [01170/04555]	Time 0.04 (0.08)
Test: [01180/04555]	Time 0.04 (0.08)
Test: [01190/04555]	Time 0.04 (0.08)
Test: [01200/04555]	Time 0.04 (0.08)
Test: [01210/04555]	Time 0.04 (0.08)
Test: [01220/04555]	Time 0.04 (0.08)
Test: [01230/04555]	Time 0.04 (0.08)
Test: [01240/04555]	Time 0.04 (0.08)
Test: [01250/04555]	Time 0.04 (0.08)
Test: [01260/04555]	Time 0.04 (0.08)
Test: [01270/04555]	Time 0.04 (0.08)
Test: [01280/04555]	Time 0.04 (0.08)
Test: [01290/04555]	Time 0.04 (0.08)
Test: [01300/04555]	Time 0.04 (0.08)
Test: [01310/04555]	Time 0.04 (0.08)
Test: [01320/04555]	Time 0.08 (0.08)
Test: [01330/04555]	Time 0.04 (0.08)
Test: [01340/04555]	Time 0.04 (0.08)
Test: [01350/04555]	Time 0.20 (0.08)
Test: [01360/04555]	Time 0.37 (0.08)
Test: [01370/04555]	Time 0.08 (0.08)
Test: [01380/04555]	Time 0.04 (0.08)
Test: [01390/04555]	Time 0.04 (0.08)
Test: [01400/04555]	Time 0.04 (0.08)
Test: [01410/04555]	Time 0.04 (0.08)
Test: [01420/04555]	Time 0.04 (0.08)
Test: [01430/04555]	Time 0.04 (0.08)
Test: [01440/04555]	Time 0.04 (0.08)
Test: [01450/04555]	Time 0.04 (0.08)
Test: [01460/04555]	Time 0.04 (0.08)
Test: [01470/04555]	Time 0.04 (0.08)
Test: [01480/04555]	Time 0.04 (0.08)
Test: [01490/04555]	Time 0.04 (0.07)
Test: [01500/04555]	Time 0.04 (0.07)
Test: [01510/04555]	Time 0.04 (0.07)
Test: [01520/04555]	Time 0.04 (0.07)
Test: [01530/04555]	Time 0.04 (0.07)
Test: [01540/04555]	Time 0.07 (0.07)
Test: [01550/04555]	Time 0.04 (0.07)
Test: [01560/04555]	Time 0.04 (0.07)
Test: [01570/04555]	Time 0.04 (0.07)
Test: [01580/04555]	Time 0.05 (0.07)
Test: [01590/04555]	Time 0.05 (0.07)
Test: [01600/04555]	Time 0.04 (0.07)
Test: [01610/04555]	Time 0.04 (0.07)
Test: [01620/04555]	Time 0.04 (0.07)
Test: [01630/04555]	Time 0.04 (0.07)
Test: [01640/04555]	Time 0.04 (0.07)
Test: [01650/04555]	Time 0.04 (0.07)
Test: [01660/04555]	Time 0.04 (0.07)
Test: [01670/04555]	Time 0.04 (0.07)
Test: [01680/04555]	Time 0.04 (0.07)
Test: [01690/04555]	Time 0.04 (0.07)
Test: [01700/04555]	Time 0.04 (0.07)
Test: [01710/04555]	Time 0.04 (0.07)
Test: [01720/04555]	Time 0.04 (0.07)
Test: [01730/04555]	Time 0.04 (0.07)
Test: [01740/04555]	Time 0.04 (0.07)
Test: [01750/04555]	Time 0.04 (0.07)
Test: [01760/04555]	Time 0.04 (0.07)
Test: [01770/04555]	Time 0.04 (0.07)
Test: [01780/04555]	Time 0.04 (0.07)
Test: [01790/04555]	Time 0.04 (0.07)
Test: [01800/04555]	Time 0.04 (0.07)
Test: [01810/04555]	Time 0.04 (0.07)
Test: [01820/04555]	Time 0.04 (0.07)
Test: [01830/04555]	Time 0.04 (0.07)
Test: [01840/04555]	Time 0.04 (0.07)
Test: [01850/04555]	Time 0.04 (0.07)
Test: [01860/04555]	Time 0.04 (0.07)
Test: [01870/04555]	Time 0.04 (0.07)
Test: [01880/04555]	Time 0.04 (0.07)
Test: [01890/04555]	Time 0.04 (0.07)
Test: [01900/04555]	Time 0.05 (0.07)
Test: [01910/04555]	Time 0.04 (0.07)
Test: [01920/04555]	Time 0.08 (0.07)
Test: [01930/04555]	Time 0.04 (0.07)
Test: [01940/04555]	Time 0.04 (0.07)
Test: [01950/04555]	Time 0.04 (0.07)
Test: [01960/04555]	Time 0.04 (0.07)
Test: [01970/04555]	Time 0.04 (0.07)
Test: [01980/04555]	Time 0.04 (0.07)
Test: [01990/04555]	Time 0.04 (0.07)
Test: [02000/04555]	Time 0.04 (0.07)
Test: [02010/04555]	Time 0.04 (0.07)
Test: [02020/04555]	Time 0.04 (0.07)
Test: [02030/04555]	Time 0.04 (0.07)
Test: [02040/04555]	Time 0.04 (0.07)
Test: [02050/04555]	Time 0.04 (0.07)
Test: [02060/04555]	Time 0.04 (0.07)
Test: [02070/04555]	Time 0.04 (0.07)
Test: [02080/04555]	Time 0.04 (0.07)
Test: [02090/04555]	Time 0.04 (0.06)
Test: [02100/04555]	Time 0.10 (0.07)
Test: [02110/04555]	Time 0.04 (0.06)
Test: [02120/04555]	Time 0.04 (0.06)
Test: [02130/04555]	Time 0.04 (0.06)
Test: [02140/04555]	Time 0.04 (0.06)
Test: [02150/04555]	Time 0.04 (0.06)
Test: [02160/04555]	Time 0.04 (0.06)
Test: [02170/04555]	Time 0.04 (0.06)
Test: [02180/04555]	Time 0.04 (0.06)
Test: [02190/04555]	Time 0.04 (0.06)
Test: [02200/04555]	Time 0.04 (0.06)
Test: [02210/04555]	Time 0.04 (0.06)
Test: [02220/04555]	Time 0.04 (0.06)
Test: [02230/04555]	Time 0.04 (0.06)
Test: [02240/04555]	Time 0.04 (0.06)
Test: [02250/04555]	Time 0.04 (0.06)
Test: [02260/04555]	Time 0.04 (0.06)
Test: [02270/04555]	Time 0.04 (0.06)
Test: [02280/04555]	Time 0.04 (0.06)
Test: [02290/04555]	Time 0.04 (0.06)
Test: [02300/04555]	Time 0.04 (0.06)
Test: [02310/04555]	Time 0.04 (0.06)
Test: [02320/04555]	Time 0.04 (0.06)
Test: [02330/04555]	Time 0.04 (0.06)
Test: [02340/04555]	Time 0.04 (0.06)
Test: [02350/04555]	Time 0.04 (0.06)
Test: [02360/04555]	Time 0.04 (0.06)
Test: [02370/04555]	Time 0.04 (0.06)
Test: [02380/04555]	Time 0.04 (0.06)
Test: [02390/04555]	Time 0.04 (0.06)
Test: [02400/04555]	Time 0.04 (0.06)
Test: [02410/04555]	Time 0.04 (0.06)
Test: [02420/04555]	Time 0.04 (0.06)
Test: [02430/04555]	Time 0.04 (0.06)
Test: [02440/04555]	Time 0.04 (0.06)
Test: [02450/04555]	Time 0.04 (0.06)
Test: [02460/04555]	Time 0.04 (0.06)
Test: [02470/04555]	Time 0.04 (0.06)
Test: [02480/04555]	Time 0.04 (0.06)
Test: [02490/04555]	Time 0.04 (0.06)
Test: [02500/04555]	Time 0.04 (0.06)
Test: [02510/04555]	Time 0.04 (0.06)
Test: [02520/04555]	Time 0.04 (0.06)
Test: [02530/04555]	Time 0.04 (0.06)
Test: [02540/04555]	Time 0.04 (0.06)
Test: [02550/04555]	Time 0.04 (0.06)
Test: [02560/04555]	Time 0.04 (0.06)
Test: [02570/04555]	Time 0.04 (0.06)
Test: [02580/04555]	Time 0.04 (0.06)
Test: [02590/04555]	Time 0.04 (0.06)
Test: [02600/04555]	Time 0.04 (0.06)
Test: [02610/04555]	Time 0.04 (0.06)
Test: [02620/04555]	Time 0.04 (0.06)
Test: [02630/04555]	Time 0.04 (0.06)
Test: [02640/04555]	Time 0.04 (0.06)
Test: [02650/04555]	Time 0.04 (0.06)
Test: [02660/04555]	Time 0.04 (0.06)
Test: [02670/04555]	Time 0.04 (0.06)
Test: [02680/04555]	Time 0.04 (0.06)
Test: [02690/04555]	Time 0.04 (0.06)
Test: [02700/04555]	Time 0.04 (0.06)
Test: [02710/04555]	Time 0.04 (0.06)
Test: [02720/04555]	Time 0.04 (0.06)
Test: [02730/04555]	Time 0.04 (0.06)
Test: [02740/04555]	Time 0.04 (0.06)
Test: [02750/04555]	Time 0.04 (0.06)
Test: [02760/04555]	Time 0.04 (0.06)
Test: [02770/04555]	Time 0.04 (0.06)
Test: [02780/04555]	Time 0.04 (0.06)
Test: [02790/04555]	Time 0.04 (0.06)
Test: [02800/04555]	Time 0.04 (0.06)
Test: [02810/04555]	Time 0.04 (0.06)
Test: [02820/04555]	Time 0.04 (0.06)
Test: [02830/04555]	Time 0.04 (0.06)
Test: [02840/04555]	Time 0.04 (0.06)
Test: [02850/04555]	Time 0.04 (0.06)
Test: [02860/04555]	Time 0.04 (0.06)
Test: [02870/04555]	Time 0.04 (0.06)
Test: [02880/04555]	Time 0.04 (0.06)
Test: [02890/04555]	Time 0.04 (0.06)
Test: [02900/04555]	Time 0.04 (0.06)
Test: [02910/04555]	Time 0.04 (0.06)
Test: [02920/04555]	Time 0.04 (0.06)
Test: [02930/04555]	Time 0.04 (0.06)
Test: [02940/04555]	Time 0.04 (0.06)
Test: [02950/04555]	Time 0.06 (0.06)
Test: [02960/04555]	Time 0.24 (0.06)
Test: [02970/04555]	Time 0.24 (0.06)
Test: [02980/04555]	Time 0.24 (0.06)
Test: [02990/04555]	Time 0.24 (0.06)
Test: [03000/04555]	Time 0.09 (0.06)
Test: [03010/04555]	Time 0.04 (0.06)
Test: [03020/04555]	Time 0.04 (0.06)
Test: [03030/04555]	Time 0.04 (0.06)
Test: [03040/04555]	Time 0.04 (0.06)
Test: [03050/04555]	Time 0.04 (0.06)
Test: [03060/04555]	Time 0.04 (0.06)
Test: [03070/04555]	Time 0.04 (0.06)
Test: [03080/04555]	Time 0.04 (0.06)
Test: [03090/04555]	Time 0.04 (0.06)
Test: [03100/04555]	Time 0.04 (0.06)
Test: [03110/04555]	Time 0.04 (0.06)
Test: [03120/04555]	Time 0.08 (0.06)
Test: [03130/04555]	Time 0.04 (0.06)
Test: [03140/04555]	Time 0.04 (0.06)
Test: [03150/04555]	Time 0.04 (0.06)
Test: [03160/04555]	Time 0.04 (0.06)
Test: [03170/04555]	Time 0.04 (0.06)
Test: [03180/04555]	Time 0.04 (0.06)
Test: [03190/04555]	Time 0.04 (0.06)
Test: [03200/04555]	Time 0.04 (0.06)
Test: [03210/04555]	Time 0.04 (0.06)
Test: [03220/04555]	Time 0.04 (0.06)
Test: [03230/04555]	Time 0.04 (0.06)
Test: [03240/04555]	Time 0.04 (0.06)
Test: [03250/04555]	Time 0.04 (0.06)
Test: [03260/04555]	Time 0.04 (0.06)
Test: [03270/04555]	Time 0.04 (0.06)
Test: [03280/04555]	Time 0.04 (0.06)
Test: [03290/04555]	Time 0.04 (0.06)
Test: [03300/04555]	Time 0.04 (0.06)
Test: [03310/04555]	Time 0.04 (0.06)
Test: [03320/04555]	Time 0.04 (0.06)
Test: [03330/04555]	Time 0.04 (0.06)
Test: [03340/04555]	Time 0.04 (0.06)
Test: [03350/04555]	Time 0.04 (0.06)
Test: [03360/04555]	Time 0.04 (0.06)
Test: [03370/04555]	Time 0.04 (0.06)
Test: [03380/04555]	Time 0.04 (0.06)
Test: [03390/04555]	Time 0.04 (0.06)
Test: [03400/04555]	Time 0.04 (0.06)
Test: [03410/04555]	Time 0.04 (0.06)
Test: [03420/04555]	Time 0.04 (0.06)
Test: [03430/04555]	Time 0.04 (0.06)
Test: [03440/04555]	Time 0.04 (0.06)
Test: [03450/04555]	Time 0.04 (0.06)
Test: [03460/04555]	Time 0.04 (0.06)
Test: [03470/04555]	Time 0.12 (0.06)
Test: [03480/04555]	Time 0.04 (0.06)
Test: [03490/04555]	Time 0.04 (0.06)
Test: [03500/04555]	Time 0.04 (0.06)
Test: [03510/04555]	Time 0.04 (0.06)
Test: [03520/04555]	Time 0.04 (0.06)
Test: [03530/04555]	Time 0.04 (0.06)
Test: [03540/04555]	Time 0.04 (0.06)
Test: [03550/04555]	Time 0.04 (0.06)
Test: [03560/04555]	Time 0.04 (0.06)
Test: [03570/04555]	Time 0.04 (0.06)
Test: [03580/04555]	Time 0.07 (0.06)
Test: [03590/04555]	Time 0.04 (0.06)
Test: [03600/04555]	Time 0.04 (0.06)
Test: [03610/04555]	Time 0.04 (0.06)
Test: [03620/04555]	Time 0.06 (0.06)
Test: [03630/04555]	Time 0.04 (0.06)
Test: [03640/04555]	Time 0.04 (0.06)
Test: [03650/04555]	Time 0.04 (0.06)
Test: [03660/04555]	Time 0.04 (0.06)
Test: [03670/04555]	Time 0.04 (0.06)
Test: [03680/04555]	Time 0.04 (0.06)
Test: [03690/04555]	Time 0.04 (0.06)
Test: [03700/04555]	Time 0.04 (0.06)
Test: [03710/04555]	Time 0.04 (0.06)
Test: [03720/04555]	Time 0.04 (0.06)
Test: [03730/04555]	Time 0.04 (0.06)
Test: [03740/04555]	Time 0.04 (0.06)
Test: [03750/04555]	Time 0.04 (0.06)
Test: [03760/04555]	Time 0.04 (0.06)
Test: [03770/04555]	Time 0.04 (0.06)
Test: [03780/04555]	Time 0.04 (0.06)
Test: [03790/04555]	Time 0.04 (0.06)
Test: [03800/04555]	Time 0.04 (0.06)
Test: [03810/04555]	Time 0.04 (0.06)
Test: [03820/04555]	Time 0.04 (0.06)
Test: [03830/04555]	Time 0.04 (0.06)
Test: [03840/04555]	Time 0.05 (0.06)
Test: [03850/04555]	Time 0.04 (0.06)
Test: [03860/04555]	Time 0.04 (0.06)
Test: [03870/04555]	Time 0.04 (0.06)
Test: [03880/04555]	Time 0.04 (0.06)
Test: [03890/04555]	Time 0.04 (0.06)
Test: [03900/04555]	Time 0.04 (0.06)
Test: [03910/04555]	Time 0.04 (0.06)
Test: [03920/04555]	Time 0.04 (0.06)
Test: [03930/04555]	Time 0.04 (0.06)
Test: [03940/04555]	Time 0.04 (0.06)
Test: [03950/04555]	Time 0.04 (0.06)
Test: [03960/04555]	Time 0.04 (0.06)
Test: [03970/04555]	Time 0.04 (0.06)
Test: [03980/04555]	Time 0.04 (0.06)
Test: [03990/04555]	Time 0.04 (0.06)
Test: [04000/04555]	Time 0.04 (0.06)
Test: [04010/04555]	Time 0.04 (0.06)
Test: [04020/04555]	Time 0.04 (0.06)
Test: [04030/04555]	Time 0.04 (0.05)
Test: [04040/04555]	Time 0.04 (0.05)
Test: [04050/04555]	Time 0.04 (0.05)
Test: [04060/04555]	Time 0.04 (0.05)
Test: [04070/04555]	Time 0.04 (0.05)
Test: [04080/04555]	Time 0.04 (0.05)
Test: [04090/04555]	Time 0.04 (0.05)
Test: [04100/04555]	Time 0.04 (0.05)
Test: [04110/04555]	Time 0.04 (0.05)
Test: [04120/04555]	Time 0.04 (0.05)
Test: [04130/04555]	Time 0.04 (0.05)
Test: [04140/04555]	Time 0.04 (0.05)
Test: [04150/04555]	Time 0.04 (0.05)
Test: [04160/04555]	Time 0.04 (0.05)
Test: [04170/04555]	Time 0.04 (0.05)
Test: [04180/04555]	Time 0.04 (0.05)
Test: [04190/04555]	Time 0.04 (0.05)
Test: [04200/04555]	Time 0.04 (0.05)
Test: [04210/04555]	Time 0.04 (0.05)
Test: [04220/04555]	Time 0.04 (0.05)
Test: [04230/04555]	Time 0.04 (0.05)
Test: [04240/04555]	Time 0.04 (0.05)
Test: [04250/04555]	Time 0.04 (0.05)
Test: [04260/04555]	Time 0.04 (0.05)
Test: [04270/04555]	Time 0.04 (0.05)
Test: [04280/04555]	Time 0.04 (0.05)
Test: [04290/04555]	Time 0.04 (0.05)
Test: [04300/04555]	Time 0.04 (0.05)
Test: [04310/04555]	Time 0.04 (0.05)
Test: [04320/04555]	Time 0.04 (0.05)
Test: [04330/04555]	Time 0.04 (0.05)
Test: [04340/04555]	Time 0.04 (0.05)
Test: [04350/04555]	Time 0.04 (0.05)
Test: [04360/04555]	Time 0.04 (0.05)
Test: [04370/04555]	Time 0.04 (0.05)
Test: [04380/04555]	Time 0.04 (0.05)
Test: [04390/04555]	Time 0.04 (0.05)
Test: [04400/04555]	Time 0.04 (0.05)
Test: [04410/04555]	Time 0.04 (0.05)
Test: [04420/04555]	Time 0.04 (0.05)
Test: [04430/04555]	Time 0.04 (0.05)
Test: [04440/04555]	Time 0.04 (0.05)
Test: [04450/04555]	Time 0.04 (0.05)
Test: [04460/04555]	Time 0.04 (0.05)
Test: [04470/04555]	Time 0.04 (0.05)
Test: [04480/04555]	Time 0.04 (0.05)
Test: [04490/04555]	Time 0.04 (0.05)
Test: [04500/04555]	Time 0.04 (0.05)
Test: [04510/04555]	Time 0.04 (0.05)
Test: [04520/04555]	Time 0.04 (0.05)
Test: [04530/04555]	Time 0.04 (0.05)
Test: [04540/04555]	Time 0.04 (0.05)
Test: [04550/04555]	Time 0.04 (0.05)
[RESULTS] Action detection results on anet1.3_i3d_filtered.

|tIoU = 0.50: mAP = 52.80 (%) Recall@1x = 59.98 (%) Recall@5x = 81.14 (%) 
|tIoU = 0.55: mAP = 49.88 (%) Recall@1x = 57.31 (%) Recall@5x = 78.34 (%) 
|tIoU = 0.60: mAP = 46.60 (%) Recall@1x = 54.53 (%) Recall@5x = 74.64 (%) 
|tIoU = 0.65: mAP = 43.14 (%) Recall@1x = 51.54 (%) Recall@5x = 70.34 (%) 
|tIoU = 0.70: mAP = 39.58 (%) Recall@1x = 48.29 (%) Recall@5x = 65.12 (%) 
|tIoU = 0.75: mAP = 35.34 (%) Recall@1x = 44.62 (%) Recall@5x = 58.52 (%) 
|tIoU = 0.80: mAP = 29.73 (%) Recall@1x = 39.41 (%) Recall@5x = 50.67 (%) 
|tIoU = 0.85: mAP = 23.93 (%) Recall@1x = 33.60 (%) Recall@5x = 40.94 (%) 
|tIoU = 0.90: mAP = 15.67 (%) Recall@1x = 24.27 (%) Recall@5x = 28.09 (%) 
|tIoU = 0.95: mAP = 5.28 (%) Recall@1x = 10.31 (%) Recall@5x = 11.40 (%) 
Average mAP: 34.20 (%)
All done! Total time: 553.03 sec
Looking for a split for p=0.4
Found split for p=0.4 [3700 videos]
Moving sampled images to a separate folder
Finished sampling
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00231]	Time 0.78 (0.78)	Loss 1.50 (1.50)
		cls_loss 0.46 (0.46)	reg_loss 0.52 (0.52)
Epoch: [000][00020/00231]	Time 0.23 (0.50)	Loss 2.26 (1.88)
		cls_loss 0.69 (0.57)	reg_loss 0.79 (0.65)
Epoch: [000][00030/00231]	Time 0.22 (0.41)	Loss 1.65 (1.81)
		cls_loss 0.52 (0.55)	reg_loss 0.57 (0.63)
Epoch: [000][00040/00231]	Time 0.22 (0.36)	Loss 2.36 (1.94)
		cls_loss 0.70 (0.59)	reg_loss 0.83 (0.68)
Epoch: [000][00050/00231]	Time 0.22 (0.33)	Loss 1.81 (1.92)
		cls_loss 0.60 (0.59)	reg_loss 0.61 (0.66)
Epoch: [000][00060/00231]	Time 0.22 (0.31)	Loss 1.01 (1.76)
		cls_loss 0.44 (0.57)	reg_loss 0.29 (0.60)
Epoch: [000][00070/00231]	Time 0.22 (0.30)	Loss 0.79 (1.63)
		cls_loss 0.42 (0.55)	reg_loss 0.19 (0.54)
Epoch: [000][00080/00231]	Time 0.22 (0.29)	Loss 0.77 (1.52)
		cls_loss 0.40 (0.53)	reg_loss 0.18 (0.50)
Epoch: [000][00090/00231]	Time 0.22 (0.28)	Loss 0.68 (1.43)
		cls_loss 0.31 (0.50)	reg_loss 0.18 (0.46)
Epoch: [000][00100/00231]	Time 0.22 (0.28)	Loss 1.77 (1.46)
		cls_loss 0.85 (0.54)	reg_loss 0.46 (0.46)
Epoch: [000][00110/00231]	Time 0.22 (0.27)	Loss 1.24 (1.44)
		cls_loss 0.59 (0.54)	reg_loss 0.32 (0.45)
Epoch: [000][00120/00231]	Time 0.22 (0.27)	Loss 0.72 (1.38)
		cls_loss 0.35 (0.53)	reg_loss 0.19 (0.43)
Epoch: [000][00130/00231]	Time 0.33 (0.27)	Loss 0.98 (1.35)
		cls_loss 0.47 (0.52)	reg_loss 0.26 (0.41)
Epoch: [000][00140/00231]	Time 0.22 (0.27)	Loss 0.84 (1.31)
		cls_loss 0.38 (0.51)	reg_loss 0.23 (0.40)
Epoch: [000][00150/00231]	Time 0.22 (0.27)	Loss 1.34 (1.31)
		cls_loss 0.63 (0.52)	reg_loss 0.35 (0.40)
Epoch: [000][00160/00231]	Time 0.22 (0.26)	Loss 0.47 (1.26)
		cls_loss 0.23 (0.50)	reg_loss 0.12 (0.38)
Epoch: [000][00170/00231]	Time 0.22 (0.26)	Loss 0.64 (1.22)
		cls_loss 0.32 (0.49)	reg_loss 0.16 (0.37)
Epoch: [000][00180/00231]	Time 0.22 (0.26)	Loss 0.85 (1.20)
		cls_loss 0.42 (0.49)	reg_loss 0.21 (0.36)
Epoch: [000][00190/00231]	Time 0.22 (0.26)	Loss 0.67 (1.18)
		cls_loss 0.33 (0.48)	reg_loss 0.17 (0.35)
Epoch: [000][00200/00231]	Time 0.22 (0.25)	Loss 0.57 (1.15)
		cls_loss 0.30 (0.47)	reg_loss 0.14 (0.34)
Epoch: [000][00210/00231]	Time 0.22 (0.25)	Loss 0.69 (1.12)
		cls_loss 0.32 (0.46)	reg_loss 0.18 (0.33)
Epoch: [000][00220/00231]	Time 0.22 (0.25)	Loss 1.30 (1.13)
		cls_loss 0.59 (0.47)	reg_loss 0.36 (0.33)
Epoch: [000][00230/00231]	Time 0.18 (0.25)	Loss 0.94 (1.12)
		cls_loss 0.46 (0.47)	reg_loss 0.24 (0.33)
[Train]: Epoch 0 finished with lr=0.00020017


[Train]: Epoch 1 started
Epoch: [001][00010/00231]	Time 0.25 (0.25)	Loss 0.75 (0.75)
		cls_loss 0.37 (0.37)	reg_loss 0.19 (0.19)
Epoch: [001][00020/00231]	Time 0.19 (0.22)	Loss 0.94 (0.84)
		cls_loss 0.46 (0.41)	reg_loss 0.24 (0.21)
Epoch: [001][00030/00231]	Time 0.19 (0.21)	Loss 0.61 (0.76)
		cls_loss 0.27 (0.37)	reg_loss 0.17 (0.20)
Epoch: [001][00040/00231]	Time 0.18 (0.20)	Loss 1.00 (0.82)
		cls_loss 0.45 (0.39)	reg_loss 0.27 (0.22)
Epoch: [001][00050/00231]	Time 0.89 (0.34)	Loss 0.77 (0.81)
		cls_loss 0.37 (0.39)	reg_loss 0.20 (0.21)
Epoch: [001][00060/00231]	Time 0.43 (0.36)	Loss 0.70 (0.79)
		cls_loss 0.35 (0.38)	reg_loss 0.18 (0.21)
Epoch: [001][00070/00231]	Time 0.19 (0.33)	Loss 0.33 (0.73)
		cls_loss 0.18 (0.35)	reg_loss 0.08 (0.19)
Epoch: [001][00080/00231]	Time 0.21 (0.32)	Loss 0.84 (0.74)
		cls_loss 0.38 (0.35)	reg_loss 0.23 (0.19)
Epoch: [001][00090/00231]	Time 0.21 (0.30)	Loss 0.96 (0.77)
		cls_loss 0.42 (0.36)	reg_loss 0.27 (0.20)
Epoch: [001][00100/00231]	Time 0.22 (0.30)	Loss 1.09 (0.80)
		cls_loss 0.49 (0.37)	reg_loss 0.30 (0.21)
Epoch: [001][00110/00231]	Time 0.22 (0.29)	Loss 0.53 (0.77)
		cls_loss 0.25 (0.36)	reg_loss 0.14 (0.21)
Epoch: [001][00120/00231]	Time 0.21 (0.28)	Loss 1.05 (0.80)
		cls_loss 0.47 (0.37)	reg_loss 0.29 (0.21)
Epoch: [001][00130/00231]	Time 0.22 (0.28)	Loss 0.84 (0.80)
		cls_loss 0.41 (0.38)	reg_loss 0.22 (0.21)
Epoch: [001][00140/00231]	Time 0.21 (0.27)	Loss 0.89 (0.81)
		cls_loss 0.44 (0.38)	reg_loss 0.23 (0.21)
Epoch: [001][00150/00231]	Time 0.22 (0.27)	Loss 0.97 (0.82)
		cls_loss 0.44 (0.38)	reg_loss 0.26 (0.22)
Epoch: [001][00160/00231]	Time 0.21 (0.27)	Loss 0.90 (0.82)
		cls_loss 0.43 (0.39)	reg_loss 0.23 (0.22)
Epoch: [001][00170/00231]	Time 0.22 (0.26)	Loss 0.70 (0.82)
		cls_loss 0.30 (0.38)	reg_loss 0.20 (0.22)
Epoch: [001][00180/00231]	Time 0.21 (0.26)	Loss 0.63 (0.81)
		cls_loss 0.30 (0.38)	reg_loss 0.17 (0.21)
Epoch: [001][00190/00231]	Time 0.22 (0.26)	Loss 1.03 (0.82)
		cls_loss 0.49 (0.38)	reg_loss 0.27 (0.22)
Epoch: [001][00200/00231]	Time 0.21 (0.26)	Loss 1.23 (0.84)
		cls_loss 0.57 (0.39)	reg_loss 0.33 (0.22)
Epoch: [001][00210/00231]	Time 0.20 (0.25)	Loss 0.78 (0.84)
		cls_loss 0.35 (0.39)	reg_loss 0.22 (0.22)
Epoch: [001][00220/00231]	Time 0.18 (0.25)	Loss 0.68 (0.83)
		cls_loss 0.30 (0.39)	reg_loss 0.19 (0.22)
Epoch: [001][00230/00231]	Time 0.18 (0.25)	Loss 1.01 (0.84)
		cls_loss 0.47 (0.39)	reg_loss 0.27 (0.22)
[Train]: Epoch 1 finished with lr=0.00040035


[Train]: Epoch 2 started
Epoch: [002][00010/00231]	Time 0.23 (0.23)	Loss 1.02 (1.02)
		cls_loss 0.47 (0.47)	reg_loss 0.27 (0.27)
Epoch: [002][00020/00231]	Time 0.19 (0.21)	Loss 0.73 (0.87)
		cls_loss 0.35 (0.41)	reg_loss 0.19 (0.23)
Epoch: [002][00030/00231]	Time 0.20 (0.21)	Loss 0.94 (0.89)
		cls_loss 0.46 (0.43)	reg_loss 0.24 (0.23)
Epoch: [002][00040/00231]	Time 0.20 (0.21)	Loss 0.68 (0.84)
		cls_loss 0.31 (0.40)	reg_loss 0.18 (0.22)
Epoch: [002][00050/00231]	Time 0.20 (0.21)	Loss 0.62 (0.80)
		cls_loss 0.30 (0.38)	reg_loss 0.16 (0.21)
Epoch: [002][00060/00231]	Time 0.20 (0.21)	Loss 1.01 (0.83)
		cls_loss 0.48 (0.40)	reg_loss 0.26 (0.22)
Epoch: [002][00070/00231]	Time 0.21 (0.21)	Loss 0.72 (0.82)
		cls_loss 0.31 (0.38)	reg_loss 0.20 (0.22)
Epoch: [002][00080/00231]	Time 0.21 (0.21)	Loss 1.23 (0.87)
		cls_loss 0.56 (0.41)	reg_loss 0.33 (0.23)
Epoch: [002][00090/00231]	Time 0.21 (0.21)	Loss 0.78 (0.86)
		cls_loss 0.36 (0.40)	reg_loss 0.21 (0.23)
Epoch: [002][00100/00231]	Time 0.21 (0.21)	Loss 1.39 (0.91)
		cls_loss 0.64 (0.43)	reg_loss 0.37 (0.24)
Epoch: [002][00110/00231]	Time 0.21 (0.21)	Loss 0.57 (0.88)
		cls_loss 0.25 (0.41)	reg_loss 0.16 (0.24)
Epoch: [002][00120/00231]	Time 0.21 (0.21)	Loss 1.10 (0.90)
		cls_loss 0.47 (0.41)	reg_loss 0.31 (0.24)
Epoch: [002][00130/00231]	Time 0.22 (0.21)	Loss 1.10 (0.91)
		cls_loss 0.49 (0.42)	reg_loss 0.30 (0.25)
Epoch: [002][00140/00231]	Time 0.21 (0.21)	Loss 0.73 (0.90)
		cls_loss 0.37 (0.42)	reg_loss 0.18 (0.24)
Epoch: [002][00150/00231]	Time 0.21 (0.21)	Loss 0.54 (0.88)
		cls_loss 0.26 (0.41)	reg_loss 0.14 (0.23)
Epoch: [002][00160/00231]	Time 0.21 (0.21)	Loss 0.96 (0.88)
		cls_loss 0.46 (0.41)	reg_loss 0.25 (0.24)
Epoch: [002][00170/00231]	Time 0.21 (0.21)	Loss 1.06 (0.89)
		cls_loss 0.48 (0.41)	reg_loss 0.29 (0.24)
Epoch: [002][00180/00231]	Time 0.21 (0.21)	Loss 1.02 (0.90)
		cls_loss 0.48 (0.42)	reg_loss 0.27 (0.24)
Epoch: [002][00190/00231]	Time 0.22 (0.21)	Loss 1.14 (0.91)
		cls_loss 0.53 (0.42)	reg_loss 0.30 (0.24)
Epoch: [002][00200/00231]	Time 0.21 (0.21)	Loss 0.44 (0.89)
		cls_loss 0.21 (0.41)	reg_loss 0.12 (0.24)
Epoch: [002][00210/00231]	Time 0.21 (0.21)	Loss 0.82 (0.88)
		cls_loss 0.36 (0.41)	reg_loss 0.23 (0.24)
Epoch: [002][00220/00231]	Time 0.21 (0.21)	Loss 0.93 (0.89)
		cls_loss 0.40 (0.41)	reg_loss 0.27 (0.24)
Epoch: [002][00230/00231]	Time 0.18 (0.21)	Loss 0.75 (0.88)
		cls_loss 0.32 (0.41)	reg_loss 0.21 (0.24)
[Train]: Epoch 2 finished with lr=0.00060052


[Train]: Epoch 3 started
Epoch: [003][00010/00231]	Time 0.26 (0.26)	Loss 0.59 (0.59)
		cls_loss 0.27 (0.27)	reg_loss 0.16 (0.16)
Epoch: [003][00020/00231]	Time 0.21 (0.23)	Loss 0.88 (0.73)
		cls_loss 0.37 (0.32)	reg_loss 0.26 (0.21)
Epoch: [003][00030/00231]	Time 0.20 (0.22)	Loss 1.25 (0.91)
		cls_loss 0.59 (0.41)	reg_loss 0.33 (0.25)
Epoch: [003][00040/00231]	Time 0.21 (0.22)	Loss 0.72 (0.86)
		cls_loss 0.31 (0.38)	reg_loss 0.21 (0.24)
Epoch: [003][00050/00231]	Time 0.20 (0.22)	Loss 0.92 (0.87)
		cls_loss 0.42 (0.39)	reg_loss 0.25 (0.24)
Epoch: [003][00060/00231]	Time 0.21 (0.22)	Loss 0.81 (0.86)
		cls_loss 0.39 (0.39)	reg_loss 0.21 (0.24)
Epoch: [003][00070/00231]	Time 0.21 (0.21)	Loss 0.95 (0.87)
		cls_loss 0.47 (0.40)	reg_loss 0.24 (0.24)
Epoch: [003][00080/00231]	Time 0.22 (0.21)	Loss 1.18 (0.91)
		cls_loss 0.54 (0.42)	reg_loss 0.32 (0.25)
Epoch: [003][00090/00231]	Time 0.22 (0.21)	Loss 1.22 (0.95)
		cls_loss 0.58 (0.44)	reg_loss 0.32 (0.25)
Epoch: [003][00100/00231]	Time 0.22 (0.21)	Loss 0.87 (0.94)
		cls_loss 0.37 (0.43)	reg_loss 0.25 (0.25)
Epoch: [003][00110/00231]	Time 0.22 (0.22)	Loss 1.00 (0.94)
		cls_loss 0.49 (0.44)	reg_loss 0.25 (0.25)
Epoch: [003][00120/00231]	Time 0.22 (0.22)	Loss 0.78 (0.93)
		cls_loss 0.39 (0.43)	reg_loss 0.20 (0.25)
Epoch: [003][00130/00231]	Time 0.49 (0.24)	Loss 0.60 (0.90)
		cls_loss 0.28 (0.42)	reg_loss 0.16 (0.24)
Epoch: [003][00140/00231]	Time 0.17 (0.23)	Loss 0.68 (0.89)
		cls_loss 0.32 (0.41)	reg_loss 0.18 (0.24)
Epoch: [003][00150/00231]	Time 0.18 (0.23)	Loss 0.95 (0.89)
		cls_loss 0.44 (0.42)	reg_loss 0.25 (0.24)
Epoch: [003][00160/00231]	Time 0.18 (0.23)	Loss 1.69 (0.94)
		cls_loss 0.79 (0.44)	reg_loss 0.45 (0.25)
Epoch: [003][00170/00231]	Time 0.17 (0.22)	Loss 1.01 (0.95)
		cls_loss 0.48 (0.44)	reg_loss 0.27 (0.25)
Epoch: [003][00180/00231]	Time 0.22 (0.22)	Loss 1.11 (0.96)
		cls_loss 0.51 (0.44)	reg_loss 0.30 (0.26)
Epoch: [003][00190/00231]	Time 0.22 (0.22)	Loss 0.59 (0.94)
		cls_loss 0.25 (0.43)	reg_loss 0.17 (0.25)
Epoch: [003][00200/00231]	Time 0.22 (0.22)	Loss 0.84 (0.93)
		cls_loss 0.43 (0.43)	reg_loss 0.21 (0.25)
Epoch: [003][00210/00231]	Time 0.22 (0.22)	Loss 1.19 (0.94)
		cls_loss 0.53 (0.44)	reg_loss 0.33 (0.25)
Epoch: [003][00220/00231]	Time 0.22 (0.22)	Loss 1.01 (0.95)
		cls_loss 0.48 (0.44)	reg_loss 0.26 (0.25)
Epoch: [003][00230/00231]	Time 0.18 (0.22)	Loss 0.73 (0.94)
		cls_loss 0.32 (0.44)	reg_loss 0.21 (0.25)
[Train]: Epoch 3 finished with lr=0.00080069


[Train]: Epoch 4 started
Epoch: [004][00010/00231]	Time 0.57 (0.57)	Loss 1.42 (1.42)
		cls_loss 0.70 (0.70)	reg_loss 0.36 (0.36)
Epoch: [004][00020/00231]	Time 0.21 (0.39)	Loss 0.80 (1.11)
		cls_loss 0.39 (0.55)	reg_loss 0.20 (0.28)
Epoch: [004][00030/00231]	Time 0.21 (0.33)	Loss 0.90 (1.04)
		cls_loss 0.41 (0.50)	reg_loss 0.24 (0.27)
Epoch: [004][00040/00231]	Time 0.21 (0.30)	Loss 1.09 (1.05)
		cls_loss 0.49 (0.50)	reg_loss 0.30 (0.28)
Epoch: [004][00050/00231]	Time 0.20 (0.28)	Loss 0.75 (0.99)
		cls_loss 0.37 (0.47)	reg_loss 0.19 (0.26)
Epoch: [004][00060/00231]	Time 0.20 (0.27)	Loss 0.56 (0.92)
		cls_loss 0.28 (0.44)	reg_loss 0.14 (0.24)
Epoch: [004][00070/00231]	Time 0.20 (0.26)	Loss 1.09 (0.94)
		cls_loss 0.49 (0.45)	reg_loss 0.30 (0.25)
Epoch: [004][00080/00231]	Time 0.20 (0.25)	Loss 0.93 (0.94)
		cls_loss 0.38 (0.44)	reg_loss 0.27 (0.25)
Epoch: [004][00090/00231]	Time 0.22 (0.25)	Loss 1.86 (1.04)
		cls_loss 0.82 (0.48)	reg_loss 0.52 (0.28)
Epoch: [004][00100/00231]	Time 0.22 (0.24)	Loss 0.87 (1.03)
		cls_loss 0.41 (0.47)	reg_loss 0.23 (0.28)
Epoch: [004][00110/00231]	Time 0.22 (0.24)	Loss 0.87 (1.01)
		cls_loss 0.45 (0.47)	reg_loss 0.21 (0.27)
Epoch: [004][00120/00231]	Time 0.22 (0.24)	Loss 1.11 (1.02)
		cls_loss 0.46 (0.47)	reg_loss 0.33 (0.27)
Epoch: [004][00130/00231]	Time 0.22 (0.24)	Loss 0.71 (1.00)
		cls_loss 0.35 (0.46)	reg_loss 0.18 (0.27)
Epoch: [004][00140/00231]	Time 0.22 (0.24)	Loss 0.75 (0.98)
		cls_loss 0.33 (0.45)	reg_loss 0.21 (0.26)
Epoch: [004][00150/00231]	Time 0.22 (0.24)	Loss 0.81 (0.97)
		cls_loss 0.38 (0.45)	reg_loss 0.22 (0.26)
Epoch: [004][00160/00231]	Time 0.22 (0.23)	Loss 0.58 (0.94)
		cls_loss 0.30 (0.44)	reg_loss 0.14 (0.25)
Epoch: [004][00170/00231]	Time 0.22 (0.23)	Loss 0.92 (0.94)
		cls_loss 0.40 (0.44)	reg_loss 0.26 (0.25)
Epoch: [004][00180/00231]	Time 0.22 (0.23)	Loss 0.84 (0.94)
		cls_loss 0.43 (0.44)	reg_loss 0.20 (0.25)
Epoch: [004][00190/00231]	Time 0.22 (0.23)	Loss 0.59 (0.92)
		cls_loss 0.28 (0.43)	reg_loss 0.15 (0.25)
Epoch: [004][00200/00231]	Time 0.22 (0.23)	Loss 0.56 (0.90)
		cls_loss 0.30 (0.42)	reg_loss 0.13 (0.24)
Epoch: [004][00210/00231]	Time 0.22 (0.23)	Loss 0.63 (0.89)
		cls_loss 0.28 (0.41)	reg_loss 0.18 (0.24)
Epoch: [004][00220/00231]	Time 0.90 (0.26)	Loss 1.12 (0.90)
		cls_loss 0.50 (0.42)	reg_loss 0.31 (0.24)
Epoch: [004][00230/00231]	Time 0.33 (0.26)	Loss 0.56 (0.88)
		cls_loss 0.27 (0.41)	reg_loss 0.14 (0.24)
[Train]: Epoch 4 finished with lr=0.00100000


[Train]: Epoch 5 started
Epoch: [005][00010/00231]	Time 0.29 (0.29)	Loss 0.87 (0.87)
		cls_loss 0.41 (0.41)	reg_loss 0.23 (0.23)
Epoch: [005][00020/00231]	Time 0.22 (0.25)	Loss 0.46 (0.67)
		cls_loss 0.24 (0.33)	reg_loss 0.11 (0.17)
Epoch: [005][00030/00231]	Time 0.22 (0.24)	Loss 0.70 (0.68)
		cls_loss 0.39 (0.35)	reg_loss 0.15 (0.16)
Epoch: [005][00040/00231]	Time 0.22 (0.24)	Loss 0.78 (0.70)
		cls_loss 0.37 (0.35)	reg_loss 0.20 (0.17)
Epoch: [005][00050/00231]	Time 0.22 (0.23)	Loss 1.60 (0.88)
		cls_loss 0.91 (0.47)	reg_loss 0.34 (0.21)
Epoch: [005][00060/00231]	Time 0.22 (0.23)	Loss 0.84 (0.87)
		cls_loss 0.37 (0.45)	reg_loss 0.24 (0.21)
Epoch: [005][00070/00231]	Time 0.22 (0.23)	Loss 0.48 (0.82)
		cls_loss 0.23 (0.42)	reg_loss 0.12 (0.20)
Epoch: [005][00080/00231]	Time 0.22 (0.23)	Loss 0.66 (0.80)
		cls_loss 0.31 (0.41)	reg_loss 0.18 (0.20)
Epoch: [005][00090/00231]	Time 0.22 (0.23)	Loss 0.92 (0.81)
		cls_loss 0.46 (0.41)	reg_loss 0.23 (0.20)
Epoch: [005][00100/00231]	Time 0.22 (0.23)	Loss 0.92 (0.82)
		cls_loss 0.44 (0.41)	reg_loss 0.24 (0.20)
Epoch: [005][00110/00231]	Time 0.22 (0.23)	Loss 1.25 (0.86)
		cls_loss 0.60 (0.43)	reg_loss 0.33 (0.21)
Epoch: [005][00120/00231]	Time 0.22 (0.23)	Loss 1.18 (0.89)
		cls_loss 0.52 (0.44)	reg_loss 0.33 (0.22)
Epoch: [005][00130/00231]	Time 0.22 (0.23)	Loss 1.11 (0.90)
		cls_loss 0.49 (0.44)	reg_loss 0.31 (0.23)
Epoch: [005][00140/00231]	Time 0.19 (0.22)	Loss 0.45 (0.87)
		cls_loss 0.23 (0.43)	reg_loss 0.11 (0.22)
Epoch: [005][00150/00231]	Time 0.25 (0.22)	Loss 0.82 (0.87)
		cls_loss 0.37 (0.42)	reg_loss 0.23 (0.22)
Epoch: [005][00160/00231]	Time 0.20 (0.22)	Loss 0.78 (0.86)
		cls_loss 0.36 (0.42)	reg_loss 0.21 (0.22)
Epoch: [005][00170/00231]	Time 0.22 (0.22)	Loss 0.65 (0.85)
		cls_loss 0.33 (0.41)	reg_loss 0.16 (0.22)
Epoch: [005][00180/00231]	Time 0.22 (0.22)	Loss 0.76 (0.85)
		cls_loss 0.35 (0.41)	reg_loss 0.20 (0.22)
Epoch: [005][00190/00231]	Time 0.22 (0.22)	Loss 0.71 (0.84)
		cls_loss 0.33 (0.41)	reg_loss 0.19 (0.22)
Epoch: [005][00200/00231]	Time 0.22 (0.22)	Loss 0.99 (0.85)
		cls_loss 0.46 (0.41)	reg_loss 0.26 (0.22)
Epoch: [005][00210/00231]	Time 0.22 (0.22)	Loss 0.81 (0.84)
		cls_loss 0.41 (0.41)	reg_loss 0.20 (0.22)
Epoch: [005][00220/00231]	Time 0.22 (0.22)	Loss 0.82 (0.84)
		cls_loss 0.37 (0.41)	reg_loss 0.23 (0.22)
Epoch: [005][00230/00231]	Time 0.18 (0.22)	Loss 0.70 (0.84)
		cls_loss 0.33 (0.40)	reg_loss 0.19 (0.22)
[Train]: Epoch 5 finished with lr=0.00097553


[Train]: Epoch 6 started
Epoch: [006][00010/00231]	Time 0.29 (0.29)	Loss 1.59 (1.59)
		cls_loss 0.82 (0.82)	reg_loss 0.38 (0.38)
Epoch: [006][00020/00231]	Time 0.22 (0.26)	Loss 0.63 (1.11)
		cls_loss 0.33 (0.58)	reg_loss 0.15 (0.27)
Epoch: [006][00030/00231]	Time 0.22 (0.25)	Loss 0.75 (0.99)
		cls_loss 0.37 (0.51)	reg_loss 0.19 (0.24)
Epoch: [006][00040/00231]	Time 0.22 (0.24)	Loss 0.61 (0.90)
		cls_loss 0.30 (0.46)	reg_loss 0.15 (0.22)
Epoch: [006][00050/00231]	Time 0.22 (0.24)	Loss 0.66 (0.85)
		cls_loss 0.29 (0.42)	reg_loss 0.18 (0.21)
Epoch: [006][00060/00231]	Time 0.22 (0.23)	Loss 0.91 (0.86)
		cls_loss 0.41 (0.42)	reg_loss 0.25 (0.22)
Epoch: [006][00070/00231]	Time 0.21 (0.23)	Loss 0.98 (0.88)
		cls_loss 0.46 (0.43)	reg_loss 0.26 (0.22)
Epoch: [006][00080/00231]	Time 0.61 (0.28)	Loss 0.84 (0.87)
		cls_loss 0.39 (0.42)	reg_loss 0.23 (0.22)
Epoch: [006][00090/00231]	Time 0.21 (0.27)	Loss 0.76 (0.86)
		cls_loss 0.37 (0.42)	reg_loss 0.19 (0.22)
Epoch: [006][00100/00231]	Time 0.25 (0.27)	Loss 0.87 (0.86)
		cls_loss 0.42 (0.42)	reg_loss 0.23 (0.22)
Epoch: [006][00110/00231]	Time 0.18 (0.26)	Loss 0.87 (0.86)
		cls_loss 0.43 (0.42)	reg_loss 0.22 (0.22)
Epoch: [006][00120/00231]	Time 0.97 (0.32)	Loss 0.92 (0.87)
		cls_loss 0.41 (0.42)	reg_loss 0.26 (0.22)
Epoch: [006][00130/00231]	Time 1.72 (0.43)	Loss 0.83 (0.86)
		cls_loss 0.35 (0.41)	reg_loss 0.24 (0.23)
Epoch: [006][00140/00231]	Time 0.26 (0.42)	Loss 0.53 (0.84)
		cls_loss 0.25 (0.40)	reg_loss 0.14 (0.22)
Epoch: [006][00150/00231]	Time 0.19 (0.40)	Loss 1.22 (0.86)
		cls_loss 0.58 (0.41)	reg_loss 0.32 (0.23)
Epoch: [006][00160/00231]	Time 0.21 (0.39)	Loss 0.74 (0.86)
		cls_loss 0.33 (0.41)	reg_loss 0.21 (0.22)
Epoch: [006][00170/00231]	Time 0.21 (0.38)	Loss 0.99 (0.86)
		cls_loss 0.47 (0.41)	reg_loss 0.26 (0.23)
Epoch: [006][00180/00231]	Time 0.21 (0.37)	Loss 0.57 (0.85)
		cls_loss 0.27 (0.40)	reg_loss 0.15 (0.22)
Epoch: [006][00190/00231]	Time 0.21 (0.36)	Loss 0.93 (0.85)
		cls_loss 0.39 (0.40)	reg_loss 0.27 (0.22)
Epoch: [006][00200/00231]	Time 0.21 (0.35)	Loss 1.35 (0.88)
		cls_loss 0.55 (0.41)	reg_loss 0.40 (0.23)
Epoch: [006][00210/00231]	Time 0.21 (0.35)	Loss 1.14 (0.89)
		cls_loss 0.54 (0.42)	reg_loss 0.30 (0.24)
Epoch: [006][00220/00231]	Time 0.21 (0.34)	Loss 1.33 (0.91)
		cls_loss 0.65 (0.43)	reg_loss 0.34 (0.24)
Epoch: [006][00230/00231]	Time 0.18 (0.33)	Loss 0.89 (0.91)
		cls_loss 0.41 (0.43)	reg_loss 0.24 (0.24)
[Train]: Epoch 6 finished with lr=0.00090451


[Train]: Epoch 7 started
Epoch: [007][00010/00231]	Time 0.26 (0.26)	Loss 0.71 (0.71)
		cls_loss 0.36 (0.36)	reg_loss 0.17 (0.17)
Epoch: [007][00020/00231]	Time 0.19 (0.23)	Loss 1.02 (0.86)
		cls_loss 0.46 (0.41)	reg_loss 0.28 (0.23)
Epoch: [007][00030/00231]	Time 0.19 (0.22)	Loss 0.67 (0.80)
		cls_loss 0.33 (0.38)	reg_loss 0.17 (0.21)
Epoch: [007][00040/00231]	Time 0.20 (0.21)	Loss 0.84 (0.81)
		cls_loss 0.38 (0.38)	reg_loss 0.23 (0.21)
Epoch: [007][00050/00231]	Time 0.21 (0.21)	Loss 1.22 (0.89)
		cls_loss 0.55 (0.42)	reg_loss 0.34 (0.24)
Epoch: [007][00060/00231]	Time 0.21 (0.21)	Loss 0.99 (0.91)
		cls_loss 0.46 (0.42)	reg_loss 0.26 (0.24)
Epoch: [007][00070/00231]	Time 0.20 (0.21)	Loss 0.71 (0.88)
		cls_loss 0.31 (0.41)	reg_loss 0.20 (0.24)
Epoch: [007][00080/00231]	Time 0.21 (0.21)	Loss 1.08 (0.90)
		cls_loss 0.49 (0.42)	reg_loss 0.29 (0.24)
Epoch: [007][00090/00231]	Time 0.21 (0.21)	Loss 0.59 (0.87)
		cls_loss 0.27 (0.40)	reg_loss 0.16 (0.23)
Epoch: [007][00100/00231]	Time 0.22 (0.21)	Loss 1.31 (0.91)
		cls_loss 0.60 (0.42)	reg_loss 0.35 (0.25)
Epoch: [007][00110/00231]	Time 0.22 (0.21)	Loss 1.26 (0.94)
		cls_loss 0.61 (0.44)	reg_loss 0.32 (0.25)
Epoch: [007][00120/00231]	Time 0.22 (0.21)	Loss 0.79 (0.93)
		cls_loss 0.37 (0.43)	reg_loss 0.21 (0.25)
Epoch: [007][00130/00231]	Time 0.22 (0.21)	Loss 0.72 (0.92)
		cls_loss 0.36 (0.43)	reg_loss 0.18 (0.24)
Epoch: [007][00140/00231]	Time 0.22 (0.21)	Loss 0.97 (0.92)
		cls_loss 0.43 (0.43)	reg_loss 0.27 (0.25)
Epoch: [007][00150/00231]	Time 0.22 (0.21)	Loss 0.69 (0.90)
		cls_loss 0.31 (0.42)	reg_loss 0.19 (0.24)
Epoch: [007][00160/00231]	Time 0.22 (0.21)	Loss 0.56 (0.88)
		cls_loss 0.27 (0.41)	reg_loss 0.15 (0.24)
Epoch: [007][00170/00231]	Time 0.22 (0.21)	Loss 0.50 (0.86)
		cls_loss 0.25 (0.40)	reg_loss 0.12 (0.23)
Epoch: [007][00180/00231]	Time 0.22 (0.21)	Loss 0.66 (0.85)
		cls_loss 0.28 (0.39)	reg_loss 0.19 (0.23)
Epoch: [007][00190/00231]	Time 0.22 (0.22)	Loss 0.76 (0.84)
		cls_loss 0.40 (0.40)	reg_loss 0.18 (0.22)
Epoch: [007][00200/00231]	Time 0.22 (0.22)	Loss 0.56 (0.83)
		cls_loss 0.29 (0.39)	reg_loss 0.13 (0.22)
Epoch: [007][00210/00231]	Time 0.22 (0.22)	Loss 0.91 (0.83)
		cls_loss 0.41 (0.39)	reg_loss 0.25 (0.22)
Epoch: [007][00220/00231]	Time 0.22 (0.22)	Loss 1.11 (0.85)
		cls_loss 0.52 (0.40)	reg_loss 0.29 (0.22)
Epoch: [007][00230/00231]	Time 0.78 (0.24)	Loss 0.99 (0.85)
		cls_loss 0.47 (0.40)	reg_loss 0.26 (0.23)
[Train]: Epoch 7 finished with lr=0.00079389


[Train]: Epoch 8 started
Epoch: [008][00010/00231]	Time 0.69 (0.69)	Loss 1.10 (1.10)
		cls_loss 0.50 (0.50)	reg_loss 0.30 (0.30)
Epoch: [008][00020/00231]	Time 0.20 (0.45)	Loss 0.57 (0.83)
		cls_loss 0.28 (0.39)	reg_loss 0.14 (0.22)
Epoch: [008][00030/00231]	Time 0.21 (0.37)	Loss 0.86 (0.84)
		cls_loss 0.40 (0.39)	reg_loss 0.23 (0.22)
Epoch: [008][00040/00231]	Time 0.21 (0.33)	Loss 1.04 (0.89)
		cls_loss 0.47 (0.41)	reg_loss 0.29 (0.24)
Epoch: [008][00050/00231]	Time 0.20 (0.30)	Loss 0.71 (0.86)
		cls_loss 0.31 (0.39)	reg_loss 0.20 (0.23)
Epoch: [008][00060/00231]	Time 0.21 (0.29)	Loss 0.64 (0.82)
		cls_loss 0.28 (0.37)	reg_loss 0.18 (0.22)
Epoch: [008][00070/00231]	Time 0.21 (0.28)	Loss 0.67 (0.80)
		cls_loss 0.33 (0.37)	reg_loss 0.17 (0.22)
Epoch: [008][00080/00231]	Time 0.22 (0.27)	Loss 0.80 (0.80)
		cls_loss 0.34 (0.36)	reg_loss 0.23 (0.22)
Epoch: [008][00090/00231]	Time 0.22 (0.26)	Loss 0.72 (0.79)
		cls_loss 0.35 (0.36)	reg_loss 0.19 (0.21)
Epoch: [008][00100/00231]	Time 0.22 (0.26)	Loss 1.06 (0.82)
		cls_loss 0.46 (0.37)	reg_loss 0.30 (0.22)
Epoch: [008][00110/00231]	Time 0.22 (0.26)	Loss 0.56 (0.79)
		cls_loss 0.25 (0.36)	reg_loss 0.15 (0.22)
Epoch: [008][00120/00231]	Time 0.22 (0.25)	Loss 0.90 (0.80)
		cls_loss 0.41 (0.37)	reg_loss 0.25 (0.22)
Epoch: [008][00130/00231]	Time 0.22 (0.25)	Loss 1.05 (0.82)
		cls_loss 0.49 (0.37)	reg_loss 0.28 (0.22)
Epoch: [008][00140/00231]	Time 0.22 (0.25)	Loss 0.73 (0.82)
		cls_loss 0.34 (0.37)	reg_loss 0.20 (0.22)
Epoch: [008][00150/00231]	Time 0.22 (0.25)	Loss 0.74 (0.81)
		cls_loss 0.34 (0.37)	reg_loss 0.20 (0.22)
Epoch: [008][00160/00231]	Time 0.19 (0.24)	Loss 0.58 (0.80)
		cls_loss 0.30 (0.37)	reg_loss 0.14 (0.22)
Epoch: [008][00170/00231]	Time 1.07 (0.29)	Loss 0.46 (0.78)
		cls_loss 0.22 (0.36)	reg_loss 0.12 (0.21)
Epoch: [008][00180/00231]	Time 0.22 (0.29)	Loss 1.07 (0.79)
		cls_loss 0.51 (0.37)	reg_loss 0.28 (0.21)
Epoch: [008][00190/00231]	Time 0.22 (0.28)	Loss 0.89 (0.80)
		cls_loss 0.43 (0.37)	reg_loss 0.23 (0.21)
Epoch: [008][00200/00231]	Time 0.22 (0.28)	Loss 0.50 (0.78)
		cls_loss 0.25 (0.36)	reg_loss 0.12 (0.21)
Epoch: [008][00210/00231]	Time 0.22 (0.28)	Loss 0.57 (0.77)
		cls_loss 0.29 (0.36)	reg_loss 0.14 (0.21)
Epoch: [008][00220/00231]	Time 0.21 (0.27)	Loss 1.24 (0.79)
		cls_loss 0.56 (0.37)	reg_loss 0.34 (0.21)
Epoch: [008][00230/00231]	Time 0.18 (0.27)	Loss 0.57 (0.78)
		cls_loss 0.25 (0.36)	reg_loss 0.16 (0.21)
[Train]: Epoch 8 finished with lr=0.00065451


[Train]: Epoch 9 started
Epoch: [009][00010/00231]	Time 0.24 (0.24)	Loss 0.75 (0.75)
		cls_loss 0.38 (0.38)	reg_loss 0.19 (0.19)
Epoch: [009][00020/00231]	Time 0.21 (0.23)	Loss 0.62 (0.69)
		cls_loss 0.33 (0.35)	reg_loss 0.15 (0.17)
Epoch: [009][00030/00231]	Time 0.22 (0.22)	Loss 1.03 (0.80)
		cls_loss 0.45 (0.39)	reg_loss 0.29 (0.21)
Epoch: [009][00040/00231]	Time 0.22 (0.22)	Loss 1.18 (0.89)
		cls_loss 0.56 (0.43)	reg_loss 0.31 (0.23)
Epoch: [009][00050/00231]	Time 0.22 (0.22)	Loss 0.74 (0.86)
		cls_loss 0.38 (0.42)	reg_loss 0.18 (0.22)
Epoch: [009][00060/00231]	Time 0.22 (0.22)	Loss 0.90 (0.87)
		cls_loss 0.44 (0.42)	reg_loss 0.23 (0.22)
Epoch: [009][00070/00231]	Time 0.22 (0.22)	Loss 0.80 (0.86)
		cls_loss 0.39 (0.42)	reg_loss 0.21 (0.22)
Epoch: [009][00080/00231]	Time 0.22 (0.22)	Loss 0.68 (0.84)
		cls_loss 0.33 (0.41)	reg_loss 0.17 (0.21)
Epoch: [009][00090/00231]	Time 0.22 (0.22)	Loss 0.48 (0.80)
		cls_loss 0.22 (0.39)	reg_loss 0.13 (0.20)
Epoch: [009][00100/00231]	Time 0.22 (0.22)	Loss 0.78 (0.80)
		cls_loss 0.40 (0.39)	reg_loss 0.19 (0.20)
Epoch: [009][00110/00231]	Time 0.22 (0.22)	Loss 1.14 (0.83)
		cls_loss 0.52 (0.40)	reg_loss 0.31 (0.21)
Epoch: [009][00120/00231]	Time 0.22 (0.22)	Loss 0.71 (0.82)
		cls_loss 0.30 (0.39)	reg_loss 0.20 (0.21)
Epoch: [009][00130/00231]	Time 0.22 (0.22)	Loss 0.98 (0.83)
		cls_loss 0.44 (0.40)	reg_loss 0.27 (0.22)
Epoch: [009][00140/00231]	Time 0.22 (0.22)	Loss 0.60 (0.81)
		cls_loss 0.30 (0.39)	reg_loss 0.15 (0.21)
Epoch: [009][00150/00231]	Time 0.22 (0.22)	Loss 1.00 (0.83)
		cls_loss 0.44 (0.39)	reg_loss 0.28 (0.22)
Epoch: [009][00160/00231]	Time 0.22 (0.22)	Loss 0.41 (0.80)
		cls_loss 0.24 (0.38)	reg_loss 0.08 (0.21)
Epoch: [009][00170/00231]	Time 0.22 (0.22)	Loss 1.23 (0.82)
		cls_loss 0.63 (0.40)	reg_loss 0.30 (0.21)
Epoch: [009][00180/00231]	Time 0.22 (0.22)	Loss 0.92 (0.83)
		cls_loss 0.43 (0.40)	reg_loss 0.24 (0.21)
Epoch: [009][00190/00231]	Time 0.21 (0.22)	Loss 1.42 (0.86)
		cls_loss 0.58 (0.41)	reg_loss 0.42 (0.23)
Epoch: [009][00200/00231]	Time 0.22 (0.22)	Loss 0.54 (0.85)
		cls_loss 0.26 (0.40)	reg_loss 0.14 (0.22)
Epoch: [009][00210/00231]	Time 0.22 (0.22)	Loss 0.96 (0.85)
		cls_loss 0.43 (0.40)	reg_loss 0.27 (0.22)
Epoch: [009][00220/00231]	Time 0.22 (0.22)	Loss 0.95 (0.86)
		cls_loss 0.45 (0.41)	reg_loss 0.25 (0.22)
Epoch: [009][00230/00231]	Time 0.18 (0.22)	Loss 0.75 (0.85)
		cls_loss 0.38 (0.40)	reg_loss 0.19 (0.22)
[Train]: Epoch 9 finished with lr=0.00050001


[Train]: Epoch 10 started
Epoch: [010][00010/00231]	Time 0.29 (0.29)	Loss 0.69 (0.69)
		cls_loss 0.34 (0.34)	reg_loss 0.17 (0.17)
Epoch: [010][00020/00231]	Time 0.22 (0.25)	Loss 0.84 (0.76)
		cls_loss 0.39 (0.37)	reg_loss 0.23 (0.20)
Epoch: [010][00030/00231]	Time 0.22 (0.24)	Loss 0.68 (0.74)
		cls_loss 0.33 (0.35)	reg_loss 0.18 (0.19)
Epoch: [010][00040/00231]	Time 0.22 (0.23)	Loss 0.97 (0.79)
		cls_loss 0.45 (0.38)	reg_loss 0.26 (0.21)
Epoch: [010][00050/00231]	Time 0.22 (0.23)	Loss 0.64 (0.76)
		cls_loss 0.30 (0.36)	reg_loss 0.17 (0.20)
Epoch: [010][00060/00231]	Time 0.22 (0.23)	Loss 0.80 (0.77)
		cls_loss 0.37 (0.36)	reg_loss 0.22 (0.20)
Epoch: [010][00070/00231]	Time 0.22 (0.23)	Loss 0.62 (0.75)
		cls_loss 0.27 (0.35)	reg_loss 0.17 (0.20)
Epoch: [010][00080/00231]	Time 0.22 (0.23)	Loss 0.81 (0.75)
		cls_loss 0.33 (0.35)	reg_loss 0.24 (0.20)
Epoch: [010][00090/00231]	Time 0.22 (0.23)	Loss 0.91 (0.77)
		cls_loss 0.41 (0.35)	reg_loss 0.25 (0.21)
Epoch: [010][00100/00231]	Time 0.22 (0.22)	Loss 0.63 (0.76)
		cls_loss 0.35 (0.35)	reg_loss 0.14 (0.20)
Epoch: [010][00110/00231]	Time 0.22 (0.22)	Loss 0.37 (0.72)
		cls_loss 0.18 (0.34)	reg_loss 0.10 (0.19)
Epoch: [010][00120/00231]	Time 0.21 (0.22)	Loss 0.68 (0.72)
		cls_loss 0.29 (0.33)	reg_loss 0.20 (0.19)
Epoch: [010][00130/00231]	Time 0.22 (0.22)	Loss 0.59 (0.71)
		cls_loss 0.30 (0.33)	reg_loss 0.15 (0.19)
Epoch: [010][00140/00231]	Time 0.22 (0.22)	Loss 0.59 (0.70)
		cls_loss 0.27 (0.33)	reg_loss 0.16 (0.19)
Epoch: [010][00150/00231]	Time 0.22 (0.22)	Loss 1.36 (0.74)
		cls_loss 0.56 (0.34)	reg_loss 0.40 (0.20)
Epoch: [010][00160/00231]	Time 0.22 (0.22)	Loss 0.82 (0.75)
		cls_loss 0.40 (0.35)	reg_loss 0.21 (0.20)
Epoch: [010][00170/00231]	Time 0.22 (0.22)	Loss 1.11 (0.77)
		cls_loss 0.50 (0.35)	reg_loss 0.30 (0.21)
Epoch: [010][00180/00231]	Time 0.22 (0.22)	Loss 1.03 (0.78)
		cls_loss 0.50 (0.36)	reg_loss 0.27 (0.21)
Epoch: [010][00190/00231]	Time 0.22 (0.22)	Loss 1.06 (0.80)
		cls_loss 0.50 (0.37)	reg_loss 0.28 (0.21)
Epoch: [010][00200/00231]	Time 0.22 (0.22)	Loss 1.12 (0.82)
		cls_loss 0.49 (0.38)	reg_loss 0.31 (0.22)
Epoch: [010][00210/00231]	Time 0.22 (0.22)	Loss 0.84 (0.82)
		cls_loss 0.37 (0.38)	reg_loss 0.23 (0.22)
Epoch: [010][00220/00231]	Time 0.22 (0.22)	Loss 0.57 (0.80)
		cls_loss 0.29 (0.37)	reg_loss 0.14 (0.22)
Epoch: [010][00230/00231]	Time 0.18 (0.22)	Loss 0.56 (0.79)
		cls_loss 0.27 (0.37)	reg_loss 0.14 (0.21)
[Train]: Epoch 10 finished with lr=0.00034550


[Train]: Epoch 11 started
Epoch: [011][00010/00231]	Time 0.25 (0.25)	Loss 0.63 (0.63)
		cls_loss 0.33 (0.33)	reg_loss 0.15 (0.15)
Epoch: [011][00020/00231]	Time 0.20 (0.23)	Loss 0.99 (0.81)
		cls_loss 0.44 (0.39)	reg_loss 0.27 (0.21)
Epoch: [011][00030/00231]	Time 0.21 (0.22)	Loss 0.77 (0.80)
		cls_loss 0.39 (0.39)	reg_loss 0.19 (0.21)
Epoch: [011][00040/00231]	Time 0.22 (0.22)	Loss 0.82 (0.80)
		cls_loss 0.37 (0.38)	reg_loss 0.22 (0.21)
Epoch: [011][00050/00231]	Time 0.21 (0.22)	Loss 0.84 (0.81)
		cls_loss 0.43 (0.39)	reg_loss 0.20 (0.21)
Epoch: [011][00060/00231]	Time 0.22 (0.22)	Loss 0.55 (0.77)
		cls_loss 0.25 (0.37)	reg_loss 0.15 (0.20)
Epoch: [011][00070/00231]	Time 0.21 (0.22)	Loss 0.57 (0.74)
		cls_loss 0.29 (0.36)	reg_loss 0.14 (0.19)
Epoch: [011][00080/00231]	Time 0.20 (0.22)	Loss 0.47 (0.71)
		cls_loss 0.25 (0.34)	reg_loss 0.11 (0.18)
Epoch: [011][00090/00231]	Time 0.27 (0.22)	Loss 0.51 (0.68)
		cls_loss 0.23 (0.33)	reg_loss 0.14 (0.18)
Epoch: [011][00100/00231]	Time 0.19 (0.22)	Loss 0.31 (0.65)
		cls_loss 0.17 (0.31)	reg_loss 0.07 (0.17)
Epoch: [011][00110/00231]	Time 0.19 (0.22)	Loss 1.02 (0.68)
		cls_loss 0.50 (0.33)	reg_loss 0.26 (0.17)
Epoch: [011][00120/00231]	Time 0.19 (0.21)	Loss 0.34 (0.65)
		cls_loss 0.19 (0.32)	reg_loss 0.07 (0.17)
Epoch: [011][00130/00231]	Time 0.96 (0.27)	Loss 0.80 (0.66)
		cls_loss 0.39 (0.32)	reg_loss 0.21 (0.17)
Epoch: [011][00140/00231]	Time 1.53 (0.36)	Loss 0.61 (0.66)
		cls_loss 0.31 (0.32)	reg_loss 0.15 (0.17)
Epoch: [011][00150/00231]	Time 0.19 (0.35)	Loss 0.59 (0.65)
		cls_loss 0.31 (0.32)	reg_loss 0.14 (0.17)
Epoch: [011][00160/00231]	Time 0.20 (0.34)	Loss 0.56 (0.65)
		cls_loss 0.28 (0.32)	reg_loss 0.14 (0.16)
Epoch: [011][00170/00231]	Time 0.22 (0.33)	Loss 0.61 (0.65)
		cls_loss 0.32 (0.32)	reg_loss 0.15 (0.16)
Epoch: [011][00180/00231]	Time 0.19 (0.33)	Loss 1.13 (0.67)
		cls_loss 0.50 (0.33)	reg_loss 0.32 (0.17)
Epoch: [011][00190/00231]	Time 0.25 (0.32)	Loss 0.47 (0.66)
		cls_loss 0.24 (0.32)	reg_loss 0.12 (0.17)
Epoch: [011][00200/00231]	Time 0.19 (0.31)	Loss 0.82 (0.67)
		cls_loss 0.37 (0.33)	reg_loss 0.22 (0.17)
Epoch: [011][00210/00231]	Time 0.20 (0.31)	Loss 0.49 (0.66)
		cls_loss 0.25 (0.32)	reg_loss 0.12 (0.17)
Epoch: [011][00220/00231]	Time 0.19 (0.30)	Loss 0.78 (0.67)
		cls_loss 0.37 (0.33)	reg_loss 0.20 (0.17)
Epoch: [011][00230/00231]	Time 0.18 (0.30)	Loss 0.92 (0.68)
		cls_loss 0.44 (0.33)	reg_loss 0.24 (0.17)
[Train]: Epoch 11 finished with lr=0.00020612


[Train]: Epoch 12 started
Epoch: [012][00010/00231]	Time 0.24 (0.24)	Loss 0.64 (0.64)
		cls_loss 0.31 (0.31)	reg_loss 0.16 (0.16)
Epoch: [012][00020/00231]	Time 0.20 (0.22)	Loss 0.83 (0.74)
		cls_loss 0.37 (0.34)	reg_loss 0.23 (0.20)
Epoch: [012][00030/00231]	Time 0.21 (0.21)	Loss 0.67 (0.71)
		cls_loss 0.31 (0.33)	reg_loss 0.18 (0.19)
Epoch: [012][00040/00231]	Time 0.20 (0.21)	Loss 0.71 (0.71)
		cls_loss 0.31 (0.33)	reg_loss 0.20 (0.19)
Epoch: [012][00050/00231]	Time 0.21 (0.21)	Loss 0.55 (0.68)
		cls_loss 0.26 (0.31)	reg_loss 0.14 (0.18)
Epoch: [012][00060/00231]	Time 0.21 (0.21)	Loss 0.43 (0.64)
		cls_loss 0.21 (0.30)	reg_loss 0.11 (0.17)
Epoch: [012][00070/00231]	Time 0.21 (0.21)	Loss 0.36 (0.60)
		cls_loss 0.19 (0.28)	reg_loss 0.08 (0.16)
Epoch: [012][00080/00231]	Time 0.21 (0.21)	Loss 0.94 (0.64)
		cls_loss 0.43 (0.30)	reg_loss 0.26 (0.17)
Epoch: [012][00090/00231]	Time 0.22 (0.21)	Loss 0.89 (0.67)
		cls_loss 0.43 (0.31)	reg_loss 0.23 (0.18)
Epoch: [012][00100/00231]	Time 0.22 (0.21)	Loss 0.52 (0.65)
		cls_loss 0.26 (0.31)	reg_loss 0.13 (0.17)
Epoch: [012][00110/00231]	Time 0.22 (0.21)	Loss 0.47 (0.64)
		cls_loss 0.22 (0.30)	reg_loss 0.13 (0.17)
Epoch: [012][00120/00231]	Time 0.22 (0.21)	Loss 0.84 (0.65)
		cls_loss 0.37 (0.31)	reg_loss 0.23 (0.17)
Epoch: [012][00130/00231]	Time 0.22 (0.21)	Loss 0.96 (0.68)
		cls_loss 0.46 (0.32)	reg_loss 0.25 (0.18)
Epoch: [012][00140/00231]	Time 0.22 (0.21)	Loss 0.71 (0.68)
		cls_loss 0.33 (0.32)	reg_loss 0.19 (0.18)
Epoch: [012][00150/00231]	Time 0.22 (0.21)	Loss 1.03 (0.70)
		cls_loss 0.49 (0.33)	reg_loss 0.27 (0.19)
Epoch: [012][00160/00231]	Time 0.22 (0.21)	Loss 0.69 (0.70)
		cls_loss 0.32 (0.33)	reg_loss 0.19 (0.19)
Epoch: [012][00170/00231]	Time 0.22 (0.21)	Loss 0.54 (0.69)
		cls_loss 0.25 (0.32)	reg_loss 0.14 (0.18)
Epoch: [012][00180/00231]	Time 0.22 (0.21)	Loss 0.79 (0.70)
		cls_loss 0.37 (0.33)	reg_loss 0.21 (0.19)
Epoch: [012][00190/00231]	Time 0.22 (0.21)	Loss 0.58 (0.69)
		cls_loss 0.28 (0.32)	reg_loss 0.15 (0.18)
Epoch: [012][00200/00231]	Time 0.22 (0.21)	Loss 0.81 (0.70)
		cls_loss 0.38 (0.33)	reg_loss 0.21 (0.19)
Epoch: [012][00210/00231]	Time 0.22 (0.21)	Loss 0.81 (0.70)
		cls_loss 0.38 (0.33)	reg_loss 0.21 (0.19)
Epoch: [012][00220/00231]	Time 0.22 (0.21)	Loss 0.79 (0.71)
		cls_loss 0.39 (0.33)	reg_loss 0.20 (0.19)
Epoch: [012][00230/00231]	Time 0.18 (0.21)	Loss 1.08 (0.72)
		cls_loss 0.50 (0.34)	reg_loss 0.29 (0.19)
[Train]: Epoch 12 finished with lr=0.00009550


[Train]: Epoch 13 started
Epoch: [013][00010/00231]	Time 0.27 (0.27)	Loss 0.72 (0.72)
		cls_loss 0.33 (0.33)	reg_loss 0.20 (0.20)
Epoch: [013][00020/00231]	Time 0.21 (0.24)	Loss 0.69 (0.71)
		cls_loss 0.35 (0.34)	reg_loss 0.17 (0.18)
Epoch: [013][00030/00231]	Time 0.20 (0.23)	Loss 0.79 (0.74)
		cls_loss 0.38 (0.35)	reg_loss 0.21 (0.19)
Epoch: [013][00040/00231]	Time 0.21 (0.22)	Loss 0.49 (0.67)
		cls_loss 0.25 (0.33)	reg_loss 0.12 (0.17)
Epoch: [013][00050/00231]	Time 0.21 (0.22)	Loss 0.84 (0.71)
		cls_loss 0.42 (0.35)	reg_loss 0.21 (0.18)
Epoch: [013][00060/00231]	Time 0.22 (0.22)	Loss 0.75 (0.71)
		cls_loss 0.35 (0.35)	reg_loss 0.20 (0.18)
Epoch: [013][00070/00231]	Time 0.22 (0.22)	Loss 0.54 (0.69)
		cls_loss 0.27 (0.34)	reg_loss 0.14 (0.18)
Epoch: [013][00080/00231]	Time 0.22 (0.22)	Loss 0.43 (0.66)
		cls_loss 0.21 (0.32)	reg_loss 0.11 (0.17)
Epoch: [013][00090/00231]	Time 0.22 (0.22)	Loss 0.67 (0.66)
		cls_loss 0.32 (0.32)	reg_loss 0.18 (0.17)
Epoch: [013][00100/00231]	Time 0.22 (0.22)	Loss 0.43 (0.64)
		cls_loss 0.18 (0.31)	reg_loss 0.13 (0.16)
Epoch: [013][00110/00231]	Time 0.22 (0.22)	Loss 0.66 (0.64)
		cls_loss 0.31 (0.31)	reg_loss 0.17 (0.17)
Epoch: [013][00120/00231]	Time 0.22 (0.22)	Loss 0.78 (0.65)
		cls_loss 0.36 (0.31)	reg_loss 0.21 (0.17)
Epoch: [013][00130/00231]	Time 0.22 (0.22)	Loss 0.62 (0.65)
		cls_loss 0.28 (0.31)	reg_loss 0.17 (0.17)
Epoch: [013][00140/00231]	Time 0.22 (0.22)	Loss 0.66 (0.65)
		cls_loss 0.32 (0.31)	reg_loss 0.17 (0.17)
Epoch: [013][00150/00231]	Time 0.22 (0.22)	Loss 0.37 (0.63)
		cls_loss 0.19 (0.30)	reg_loss 0.09 (0.16)
Epoch: [013][00160/00231]	Time 0.22 (0.22)	Loss 0.70 (0.63)
		cls_loss 0.36 (0.31)	reg_loss 0.17 (0.16)
Epoch: [013][00170/00231]	Time 0.22 (0.22)	Loss 0.43 (0.62)
		cls_loss 0.23 (0.30)	reg_loss 0.10 (0.16)
Epoch: [013][00180/00231]	Time 0.22 (0.22)	Loss 0.58 (0.62)
		cls_loss 0.27 (0.30)	reg_loss 0.15 (0.16)
Epoch: [013][00190/00231]	Time 0.22 (0.22)	Loss 0.86 (0.63)
		cls_loss 0.42 (0.31)	reg_loss 0.22 (0.16)
Epoch: [013][00200/00231]	Time 0.22 (0.22)	Loss 1.09 (0.66)
		cls_loss 0.54 (0.32)	reg_loss 0.28 (0.17)
Epoch: [013][00210/00231]	Time 0.22 (0.22)	Loss 0.89 (0.67)
		cls_loss 0.42 (0.32)	reg_loss 0.23 (0.17)
Epoch: [013][00220/00231]	Time 0.22 (0.22)	Loss 0.46 (0.66)
		cls_loss 0.22 (0.32)	reg_loss 0.12 (0.17)
Epoch: [013][00230/00231]	Time 0.18 (0.22)	Loss 0.85 (0.67)
		cls_loss 0.40 (0.32)	reg_loss 0.22 (0.17)
[Train]: Epoch 13 finished with lr=0.00002448


[Train]: Epoch 14 started
Epoch: [014][00010/00231]	Time 0.27 (0.27)	Loss 0.61 (0.61)
		cls_loss 0.30 (0.30)	reg_loss 0.16 (0.16)
Epoch: [014][00020/00231]	Time 0.20 (0.23)	Loss 0.69 (0.65)
		cls_loss 0.32 (0.31)	reg_loss 0.18 (0.17)
Epoch: [014][00030/00231]	Time 0.22 (0.23)	Loss 0.83 (0.71)
		cls_loss 0.40 (0.34)	reg_loss 0.21 (0.18)
Epoch: [014][00040/00231]	Time 0.21 (0.22)	Loss 0.53 (0.66)
		cls_loss 0.27 (0.32)	reg_loss 0.13 (0.17)
Epoch: [014][00050/00231]	Time 0.22 (0.22)	Loss 0.73 (0.68)
		cls_loss 0.36 (0.33)	reg_loss 0.18 (0.17)
Epoch: [014][00060/00231]	Time 0.22 (0.22)	Loss 0.78 (0.69)
		cls_loss 0.45 (0.35)	reg_loss 0.17 (0.17)
Epoch: [014][00070/00231]	Time 0.22 (0.22)	Loss 0.55 (0.67)
		cls_loss 0.25 (0.34)	reg_loss 0.15 (0.17)
Epoch: [014][00080/00231]	Time 0.21 (0.22)	Loss 0.75 (0.68)
		cls_loss 0.35 (0.34)	reg_loss 0.20 (0.17)
Epoch: [014][00090/00231]	Time 0.21 (0.22)	Loss 0.64 (0.68)
		cls_loss 0.30 (0.33)	reg_loss 0.17 (0.17)
Epoch: [014][00100/00231]	Time 0.22 (0.22)	Loss 0.52 (0.66)
		cls_loss 0.24 (0.33)	reg_loss 0.14 (0.17)
Epoch: [014][00110/00231]	Time 0.22 (0.22)	Loss 0.54 (0.65)
		cls_loss 0.26 (0.32)	reg_loss 0.14 (0.17)
Epoch: [014][00120/00231]	Time 0.22 (0.22)	Loss 0.84 (0.67)
		cls_loss 0.38 (0.32)	reg_loss 0.23 (0.17)
Epoch: [014][00130/00231]	Time 0.22 (0.22)	Loss 1.09 (0.70)
		cls_loss 0.43 (0.33)	reg_loss 0.33 (0.18)
Epoch: [014][00140/00231]	Time 0.22 (0.22)	Loss 0.83 (0.71)
		cls_loss 0.43 (0.34)	reg_loss 0.20 (0.19)
Epoch: [014][00150/00231]	Time 0.22 (0.22)	Loss 0.47 (0.69)
		cls_loss 0.22 (0.33)	reg_loss 0.12 (0.18)
Epoch: [014][00160/00231]	Time 0.19 (0.22)	Loss 0.47 (0.68)
		cls_loss 0.24 (0.33)	reg_loss 0.12 (0.18)
Epoch: [014][00170/00231]	Time 0.66 (0.24)	Loss 0.50 (0.67)
		cls_loss 0.26 (0.32)	reg_loss 0.12 (0.17)
Epoch: [014][00180/00231]	Time 0.20 (0.24)	Loss 0.85 (0.68)
		cls_loss 0.36 (0.32)	reg_loss 0.24 (0.18)
Epoch: [014][00190/00231]	Time 0.21 (0.24)	Loss 0.39 (0.66)
		cls_loss 0.20 (0.32)	reg_loss 0.09 (0.17)
Epoch: [014][00200/00231]	Time 0.20 (0.24)	Loss 0.66 (0.66)
		cls_loss 0.31 (0.32)	reg_loss 0.17 (0.17)
Epoch: [014][00210/00231]	Time 0.21 (0.24)	Loss 0.59 (0.66)
		cls_loss 0.28 (0.32)	reg_loss 0.15 (0.17)
Epoch: [014][00220/00231]	Time 0.20 (0.23)	Loss 0.78 (0.67)
		cls_loss 0.31 (0.32)	reg_loss 0.23 (0.18)
Epoch: [014][00230/00231]	Time 0.18 (0.23)	Loss 0.57 (0.66)
		cls_loss 0.26 (0.31)	reg_loss 0.16 (0.17)
[Train]: Epoch 14 finished with lr=0.00000001

All done!
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': 25,
             'downsample_rate': 1,
             'feat_folder': './data/anet_1.3/i3d_features',
             'feat_stride': 16,
             'file_ext': '.npy',
             'file_prefix': 'v_',
             'force_upsampling': True,
             'input_dim': 2048,
             'json_file': './data/anet_1.3/annotations/anet1.3_i3d_filtered.json',
             'max_seq_len': 192,
             'num_classes': 1,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'anet',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 16, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 256,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 256,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 256,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 1.0,
           'max_seq_len': 192,
           'n_head': 4,
           'n_mha_win_size': [7, 7, 7, 7, 7, -1],
           'num_classes': 1,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.001,
                        'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
                        'iou_threshold': 0.1,
                        'max_seg_num': 100,
                        'min_score': 0.001,
                        'multiclass_nms': False,
                        'nms_method': 'soft',
                        'nms_sigma': 0.75,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.9},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 200,
                         'label_smoothing': 0.1,
                         'loss_weight': 2.0},
           'use_abs_pe': True,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 10,
         'learning_rate': 0.001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.001,
              'ext_score_file': './data/anet_1.3/annotations/cuhk_val_simp_share.json',
              'iou_threshold': 0.1,
              'max_seg_num': 100,
              'min_score': 0.001,
              'multiclass_nms': False,
              'nms_method': 'soft',
              'nms_sigma': 0.75,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.9},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 200,
               'label_smoothing': 0.1,
               'loss_weight': 2.0},
 'train_split': ['training'],
 'val_split': ['validation']}
=> loading checkpoint './ckpt/anet_i3d_reproduce/epoch_015.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/04555]	Time 0.32 (0.32)
Test: [00020/04555]	Time 0.04 (0.18)
Test: [00030/04555]	Time 0.04 (0.13)
Test: [00040/04555]	Time 0.04 (0.11)
Test: [00050/04555]	Time 0.04 (0.09)
Test: [00060/04555]	Time 0.40 (0.15)
Test: [00070/04555]	Time 0.27 (0.16)
Test: [00080/04555]	Time 0.51 (0.21)
Test: [00090/04555]	Time 0.12 (0.20)
Test: [00100/04555]	Time 0.15 (0.19)
Test: [00110/04555]	Time 0.04 (0.18)
Test: [00120/04555]	Time 0.15 (0.18)
Test: [00130/04555]	Time 0.07 (0.17)
Test: [00140/04555]	Time 0.04 (0.16)
Test: [00150/04555]	Time 0.04 (0.15)
Test: [00160/04555]	Time 0.04 (0.14)
Test: [00170/04555]	Time 0.04 (0.14)
Test: [00180/04555]	Time 0.04 (0.13)
Test: [00190/04555]	Time 0.04 (0.13)
Test: [00200/04555]	Time 0.04 (0.12)
Test: [00210/04555]	Time 0.04 (0.12)
Test: [00220/04555]	Time 0.04 (0.11)
Test: [00230/04555]	Time 0.04 (0.11)
Test: [00240/04555]	Time 0.04 (0.11)
Test: [00250/04555]	Time 0.04 (0.11)
Test: [00260/04555]	Time 0.04 (0.10)
Test: [00270/04555]	Time 0.04 (0.10)
Test: [00280/04555]	Time 0.04 (0.10)
Test: [00290/04555]	Time 0.04 (0.10)
Test: [00300/04555]	Time 0.04 (0.09)
Test: [00310/04555]	Time 0.04 (0.09)
Test: [00320/04555]	Time 0.04 (0.09)
Test: [00330/04555]	Time 0.04 (0.09)
Test: [00340/04555]	Time 0.04 (0.09)
Test: [00350/04555]	Time 0.04 (0.09)
Test: [00360/04555]	Time 0.04 (0.08)
Test: [00370/04555]	Time 0.04 (0.08)
Test: [00380/04555]	Time 0.04 (0.08)
Test: [00390/04555]	Time 0.04 (0.08)
Test: [00400/04555]	Time 0.04 (0.08)
Test: [00410/04555]	Time 0.04 (0.08)
Test: [00420/04555]	Time 0.04 (0.08)
Test: [00430/04555]	Time 0.04 (0.08)
Test: [00440/04555]	Time 0.04 (0.08)
Test: [00450/04555]	Time 0.04 (0.08)
Test: [00460/04555]	Time 0.04 (0.07)
Test: [00470/04555]	Time 0.04 (0.07)
Test: [00480/04555]	Time 0.04 (0.07)
Test: [00490/04555]	Time 0.04 (0.07)
Test: [00500/04555]	Time 0.09 (0.07)
Test: [00510/04555]	Time 0.04 (0.07)
Test: [00520/04555]	Time 0.04 (0.07)
Test: [00530/04555]	Time 0.04 (0.07)
Test: [00540/04555]	Time 0.04 (0.07)
Test: [00550/04555]	Time 0.04 (0.07)
Test: [00560/04555]	Time 0.04 (0.07)
Test: [00570/04555]	Time 0.04 (0.07)
Test: [00580/04555]	Time 0.04 (0.07)
Test: [00590/04555]	Time 0.04 (0.07)
Test: [00600/04555]	Time 0.04 (0.07)
Test: [00610/04555]	Time 0.04 (0.07)
Test: [00620/04555]	Time 0.04 (0.07)
Test: [00630/04555]	Time 0.04 (0.07)
Test: [00640/04555]	Time 0.04 (0.07)
Test: [00650/04555]	Time 0.04 (0.06)
Test: [00660/04555]	Time 0.04 (0.06)
Test: [00670/04555]	Time 0.04 (0.06)
Test: [00680/04555]	Time 0.04 (0.06)
Test: [00690/04555]	Time 0.04 (0.06)
Test: [00700/04555]	Time 0.04 (0.06)
Test: [00710/04555]	Time 0.04 (0.06)
Test: [00720/04555]	Time 0.04 (0.06)
Test: [00730/04555]	Time 0.04 (0.06)
Test: [00740/04555]	Time 0.04 (0.06)
Test: [00750/04555]	Time 0.04 (0.06)
Test: [00760/04555]	Time 0.04 (0.06)
Test: [00770/04555]	Time 0.04 (0.06)
Test: [00780/04555]	Time 0.04 (0.06)
Test: [00790/04555]	Time 0.04 (0.06)
Test: [00800/04555]	Time 0.04 (0.06)
Test: [00810/04555]	Time 0.04 (0.06)
Test: [00820/04555]	Time 0.04 (0.06)
Test: [00830/04555]	Time 0.04 (0.06)
Test: [00840/04555]	Time 0.31 (0.06)
Test: [00850/04555]	Time 0.04 (0.06)
Test: [00860/04555]	Time 0.04 (0.06)
Test: [00870/04555]	Time 0.04 (0.06)
Test: [00880/04555]	Time 0.04 (0.06)
Test: [00890/04555]	Time 0.04 (0.06)
Test: [00900/04555]	Time 0.04 (0.06)
Test: [00910/04555]	Time 0.04 (0.06)
Test: [00920/04555]	Time 0.04 (0.06)
Test: [00930/04555]	Time 0.04 (0.06)
Test: [00940/04555]	Time 0.04 (0.06)
Test: [00950/04555]	Time 0.04 (0.06)
Test: [00960/04555]	Time 0.04 (0.06)
Test: [00970/04555]	Time 0.04 (0.06)
Test: [00980/04555]	Time 0.04 (0.06)
Test: [00990/04555]	Time 0.37 (0.06)
Test: [01000/04555]	Time 0.51 (0.07)
Test: [01010/04555]	Time 0.04 (0.07)
Test: [01020/04555]	Time 0.04 (0.07)
Test: [01030/04555]	Time 0.04 (0.07)
Test: [01040/04555]	Time 0.04 (0.07)
Test: [01050/04555]	Time 0.04 (0.06)
Test: [01060/04555]	Time 0.04 (0.06)
Test: [01070/04555]	Time 0.04 (0.06)
Test: [01080/04555]	Time 0.04 (0.06)
Test: [01090/04555]	Time 0.04 (0.06)
Test: [01100/04555]	Time 0.04 (0.06)
Test: [01110/04555]	Time 0.04 (0.06)
Test: [01120/04555]	Time 0.04 (0.06)
Test: [01130/04555]	Time 0.04 (0.06)
Test: [01140/04555]	Time 0.04 (0.06)
Test: [01150/04555]	Time 0.04 (0.06)
Test: [01160/04555]	Time 0.04 (0.06)
Test: [01170/04555]	Time 0.04 (0.06)
Test: [01180/04555]	Time 0.04 (0.06)
Test: [01190/04555]	Time 0.04 (0.06)
Test: [01200/04555]	Time 0.04 (0.06)
Test: [01210/04555]	Time 0.04 (0.06)
Test: [01220/04555]	Time 0.04 (0.06)
Test: [01230/04555]	Time 0.04 (0.06)
Test: [01240/04555]	Time 0.04 (0.06)
Test: [01250/04555]	Time 0.04 (0.06)
Test: [01260/04555]	Time 0.04 (0.06)
Test: [01270/04555]	Time 0.04 (0.06)
Test: [01280/04555]	Time 0.04 (0.06)
Test: [01290/04555]	Time 0.04 (0.06)
Test: [01300/04555]	Time 0.04 (0.06)
Test: [01310/04555]	Time 0.04 (0.06)
Test: [01320/04555]	Time 0.04 (0.06)
Test: [01330/04555]	Time 0.04 (0.06)
Test: [01340/04555]	Time 0.04 (0.06)
Test: [01350/04555]	Time 0.04 (0.06)
Test: [01360/04555]	Time 0.04 (0.06)
Test: [01370/04555]	Time 0.06 (0.06)
Test: [01380/04555]	Time 0.04 (0.06)
Test: [01390/04555]	Time 0.04 (0.06)
Test: [01400/04555]	Time 0.04 (0.06)
Test: [01410/04555]	Time 0.04 (0.06)
Test: [01420/04555]	Time 0.04 (0.06)
Test: [01430/04555]	Time 0.04 (0.06)
Test: [01440/04555]	Time 0.04 (0.06)
Test: [01450/04555]	Time 0.04 (0.06)
Test: [01460/04555]	Time 0.04 (0.06)
Test: [01470/04555]	Time 0.04 (0.06)
Test: [01480/04555]	Time 0.04 (0.06)
Test: [01490/04555]	Time 0.04 (0.06)
Test: [01500/04555]	Time 0.04 (0.06)
Test: [01510/04555]	Time 0.04 (0.06)
Test: [01520/04555]	Time 0.04 (0.06)
Test: [01530/04555]	Time 0.04 (0.06)
Test: [01540/04555]	Time 0.04 (0.06)
Test: [01550/04555]	Time 0.04 (0.06)
Test: [01560/04555]	Time 0.04 (0.06)
Test: [01570/04555]	Time 0.04 (0.06)
Test: [01580/04555]	Time 0.04 (0.06)
Test: [01590/04555]	Time 0.04 (0.06)
Test: [01600/04555]	Time 0.04 (0.06)
Test: [01610/04555]	Time 0.04 (0.06)
Test: [01620/04555]	Time 0.04 (0.06)
Test: [01630/04555]	Time 0.04 (0.06)
Test: [01640/04555]	Time 0.04 (0.06)
Test: [01650/04555]	Time 0.04 (0.06)
Test: [01660/04555]	Time 0.04 (0.05)
Test: [01670/04555]	Time 0.04 (0.05)
Test: [01680/04555]	Time 0.04 (0.05)
Test: [01690/04555]	Time 0.04 (0.05)
Test: [01700/04555]	Time 0.04 (0.05)
Test: [01710/04555]	Time 0.04 (0.05)
Test: [01720/04555]	Time 0.04 (0.05)
Test: [01730/04555]	Time 0.04 (0.05)
Test: [01740/04555]	Time 0.04 (0.05)
Test: [01750/04555]	Time 0.04 (0.05)
Test: [01760/04555]	Time 0.04 (0.05)
Test: [01770/04555]	Time 0.04 (0.05)
Test: [01780/04555]	Time 0.04 (0.05)
Test: [01790/04555]	Time 0.04 (0.05)
Test: [01800/04555]	Time 0.04 (0.05)
Test: [01810/04555]	Time 0.04 (0.05)
Test: [01820/04555]	Time 0.04 (0.05)
Test: [01830/04555]	Time 0.04 (0.05)
Test: [01840/04555]	Time 0.04 (0.05)
Test: [01850/04555]	Time 0.04 (0.05)
Test: [01860/04555]	Time 0.04 (0.05)
Test: [01870/04555]	Time 0.04 (0.05)
Test: [01880/04555]	Time 0.04 (0.05)
Test: [01890/04555]	Time 0.04 (0.05)
Test: [01900/04555]	Time 0.04 (0.05)
Test: [01910/04555]	Time 0.04 (0.05)
Test: [01920/04555]	Time 0.04 (0.05)
Test: [01930/04555]	Time 0.04 (0.05)
Test: [01940/04555]	Time 0.04 (0.05)
Test: [01950/04555]	Time 0.04 (0.05)
Test: [01960/04555]	Time 0.04 (0.05)
Test: [01970/04555]	Time 0.04 (0.05)
Test: [01980/04555]	Time 0.04 (0.05)
Test: [01990/04555]	Time 0.04 (0.05)
Test: [02000/04555]	Time 0.04 (0.05)
Test: [02010/04555]	Time 0.04 (0.05)
Test: [02020/04555]	Time 0.04 (0.05)
Test: [02030/04555]	Time 0.04 (0.05)
Test: [02040/04555]	Time 0.04 (0.05)
Test: [02050/04555]	Time 0.04 (0.05)
Test: [02060/04555]	Time 0.04 (0.05)
Test: [02070/04555]	Time 0.04 (0.05)
Test: [02080/04555]	Time 0.04 (0.05)
Test: [02090/04555]	Time 0.04 (0.05)
Test: [02100/04555]	Time 0.04 (0.05)
Test: [02110/04555]	Time 0.04 (0.05)
Test: [02120/04555]	Time 0.04 (0.05)
Test: [02130/04555]	Time 0.04 (0.05)
Test: [02140/04555]	Time 0.04 (0.05)
Test: [02150/04555]	Time 0.04 (0.05)
Test: [02160/04555]	Time 0.04 (0.05)
Test: [02170/04555]	Time 0.04 (0.05)
Test: [02180/04555]	Time 0.08 (0.05)
Test: [02190/04555]	Time 0.06 (0.05)
Test: [02200/04555]	Time 0.04 (0.05)
Test: [02210/04555]	Time 0.04 (0.05)
Test: [02220/04555]	Time 0.04 (0.05)
Test: [02230/04555]	Time 0.04 (0.05)
Test: [02240/04555]	Time 0.04 (0.05)
Test: [02250/04555]	Time 0.04 (0.05)
Test: [02260/04555]	Time 0.04 (0.05)
Test: [02270/04555]	Time 0.04 (0.05)
Test: [02280/04555]	Time 0.04 (0.05)
Test: [02290/04555]	Time 0.04 (0.05)
Test: [02300/04555]	Time 0.04 (0.05)
Test: [02310/04555]	Time 0.04 (0.05)
Test: [02320/04555]	Time 0.04 (0.05)
Test: [02330/04555]	Time 0.04 (0.05)
Test: [02340/04555]	Time 0.04 (0.05)
Test: [02350/04555]	Time 0.04 (0.05)
Test: [02360/04555]	Time 0.04 (0.05)
Test: [02370/04555]	Time 0.04 (0.05)
Test: [02380/04555]	Time 0.04 (0.05)
Test: [02390/04555]	Time 0.04 (0.05)
Test: [02400/04555]	Time 0.04 (0.05)
Test: [02410/04555]	Time 0.04 (0.05)
Test: [02420/04555]	Time 0.04 (0.05)
Test: [02430/04555]	Time 0.04 (0.05)
Test: [02440/04555]	Time 0.04 (0.05)
Test: [02450/04555]	Time 0.04 (0.05)
Test: [02460/04555]	Time 0.04 (0.05)
Test: [02470/04555]	Time 0.04 (0.05)
Test: [02480/04555]	Time 0.04 (0.05)
Test: [02490/04555]	Time 0.04 (0.05)
Test: [02500/04555]	Time 0.04 (0.05)
Test: [02510/04555]	Time 0.04 (0.05)
Test: [02520/04555]	Time 0.04 (0.05)
Test: [02530/04555]	Time 0.04 (0.05)
Test: [02540/04555]	Time 0.04 (0.05)
Test: [02550/04555]	Time 0.04 (0.05)
Test: [02560/04555]	Time 0.04 (0.05)
Test: [02570/04555]	Time 0.04 (0.05)
Test: [02580/04555]	Time 0.04 (0.05)
Test: [02590/04555]	Time 0.04 (0.05)
Test: [02600/04555]	Time 0.04 (0.05)
Test: [02610/04555]	Time 0.26 (0.05)
Test: [02620/04555]	Time 0.04 (0.05)
Test: [02630/04555]	Time 0.20 (0.05)
Test: [02640/04555]	Time 0.08 (0.05)
Test: [02650/04555]	Time 0.11 (0.05)
Test: [02660/04555]	Time 0.04 (0.05)
Test: [02670/04555]	Time 0.04 (0.05)
Test: [02680/04555]	Time 0.04 (0.05)
Test: [02690/04555]	Time 0.04 (0.05)
Test: [02700/04555]	Time 0.04 (0.05)
Test: [02710/04555]	Time 0.04 (0.05)
Test: [02720/04555]	Time 0.04 (0.05)
Test: [02730/04555]	Time 0.04 (0.05)
Test: [02740/04555]	Time 0.04 (0.05)
Test: [02750/04555]	Time 0.04 (0.05)
Test: [02760/04555]	Time 0.04 (0.05)
Test: [02770/04555]	Time 0.04 (0.05)
Test: [02780/04555]	Time 0.04 (0.05)
Test: [02790/04555]	Time 0.04 (0.05)
Test: [02800/04555]	Time 0.04 (0.05)
Test: [02810/04555]	Time 0.04 (0.05)
Test: [02820/04555]	Time 0.04 (0.05)
Test: [02830/04555]	Time 0.04 (0.05)
Test: [02840/04555]	Time 0.04 (0.05)
Test: [02850/04555]	Time 0.04 (0.05)
Test: [02860/04555]	Time 0.04 (0.05)
Test: [02870/04555]	Time 0.04 (0.05)
Test: [02880/04555]	Time 0.04 (0.05)
Test: [02890/04555]	Time 0.04 (0.05)
Test: [02900/04555]	Time 0.04 (0.05)
Test: [02910/04555]	Time 0.04 (0.05)
Test: [02920/04555]	Time 0.04 (0.05)
Test: [02930/04555]	Time 0.04 (0.05)
Test: [02940/04555]	Time 0.04 (0.05)
Test: [02950/04555]	Time 0.04 (0.05)
Test: [02960/04555]	Time 0.04 (0.05)
Test: [02970/04555]	Time 0.04 (0.05)
Test: [02980/04555]	Time 0.04 (0.05)
Test: [02990/04555]	Time 0.04 (0.05)
Test: [03000/04555]	Time 0.04 (0.05)
Test: [03010/04555]	Time 0.04 (0.05)
Test: [03020/04555]	Time 0.04 (0.05)
Test: [03030/04555]	Time 0.04 (0.05)
Test: [03040/04555]	Time 0.04 (0.05)
Test: [03050/04555]	Time 0.04 (0.05)
Test: [03060/04555]	Time 0.04 (0.05)
Test: [03070/04555]	Time 0.04 (0.05)
Test: [03080/04555]	Time 0.04 (0.05)
Test: [03090/04555]	Time 0.04 (0.05)
Test: [03100/04555]	Time 0.04 (0.05)
Test: [03110/04555]	Time 0.04 (0.05)
Test: [03120/04555]	Time 0.04 (0.05)
Test: [03130/04555]	Time 0.04 (0.05)
Test: [03140/04555]	Time 0.04 (0.05)
Test: [03150/04555]	Time 0.04 (0.05)
Test: [03160/04555]	Time 0.04 (0.05)
Test: [03170/04555]	Time 0.04 (0.05)
Test: [03180/04555]	Time 0.04 (0.05)
Test: [03190/04555]	Time 0.04 (0.05)
Test: [03200/04555]	Time 0.04 (0.05)
Test: [03210/04555]	Time 0.04 (0.05)
Test: [03220/04555]	Time 0.04 (0.05)
Test: [03230/04555]	Time 0.04 (0.05)
Test: [03240/04555]	Time 0.04 (0.05)
Test: [03250/04555]	Time 0.04 (0.05)
Test: [03260/04555]	Time 0.04 (0.05)
Test: [03270/04555]	Time 0.04 (0.05)
Test: [03280/04555]	Time 0.04 (0.05)
Test: [03290/04555]	Time 0.04 (0.05)
Test: [03300/04555]	Time 0.04 (0.05)
Test: [03310/04555]	Time 0.04 (0.05)
Test: [03320/04555]	Time 0.04 (0.05)
Test: [03330/04555]	Time 0.04 (0.05)
Test: [03340/04555]	Time 0.04 (0.05)
Test: [03350/04555]	Time 0.04 (0.05)
Test: [03360/04555]	Time 0.04 (0.05)
Test: [03370/04555]	Time 0.04 (0.05)
Test: [03380/04555]	Time 0.04 (0.05)
Test: [03390/04555]	Time 0.04 (0.05)
Test: [03400/04555]	Time 0.04 (0.05)
Test: [03410/04555]	Time 0.04 (0.05)
Test: [03420/04555]	Time 0.04 (0.05)
Test: [03430/04555]	Time 0.04 (0.05)
Test: [03440/04555]	Time 0.04 (0.05)
Test: [03450/04555]	Time 0.04 (0.05)
Test: [03460/04555]	Time 0.04 (0.05)
Test: [03470/04555]	Time 0.04 (0.05)
Test: [03480/04555]	Time 0.04 (0.05)
Test: [03490/04555]	Time 0.10 (0.05)
Test: [03500/04555]	Time 0.12 (0.05)
Test: [03510/04555]	Time 0.04 (0.05)
Test: [03520/04555]	Time 0.04 (0.05)
Test: [03530/04555]	Time 0.04 (0.05)
Test: [03540/04555]	Time 0.04 (0.05)
Test: [03550/04555]	Time 0.04 (0.05)
Test: [03560/04555]	Time 0.04 (0.05)
Test: [03570/04555]	Time 0.08 (0.05)
Test: [03580/04555]	Time 0.04 (0.05)
Test: [03590/04555]	Time 0.04 (0.05)
Test: [03600/04555]	Time 0.04 (0.05)
Test: [03610/04555]	Time 0.04 (0.05)
Test: [03620/04555]	Time 0.04 (0.05)
Test: [03630/04555]	Time 0.04 (0.05)
Test: [03640/04555]	Time 0.04 (0.05)
Test: [03650/04555]	Time 0.04 (0.05)
Test: [03660/04555]	Time 0.04 (0.05)
Test: [03670/04555]	Time 0.04 (0.05)
Test: [03680/04555]	Time 0.04 (0.05)
Test: [03690/04555]	Time 0.04 (0.05)
Test: [03700/04555]	Time 0.04 (0.05)
Test: [03710/04555]	Time 0.04 (0.05)
Test: [03720/04555]	Time 0.04 (0.05)
Test: [03730/04555]	Time 0.04 (0.05)
Test: [03740/04555]	Time 0.04 (0.05)
Test: [03750/04555]	Time 0.04 (0.05)
Test: [03760/04555]	Time 0.04 (0.05)
Test: [03770/04555]	Time 0.04 (0.05)
Test: [03780/04555]	Time 0.04 (0.05)
Test: [03790/04555]	Time 0.04 (0.05)
Test: [03800/04555]	Time 0.04 (0.05)
Test: [03810/04555]	Time 0.04 (0.05)
Test: [03820/04555]	Time 0.04 (0.05)
Test: [03830/04555]	Time 0.04 (0.05)
Test: [03840/04555]	Time 0.04 (0.05)
Test: [03850/04555]	Time 0.04 (0.05)
Test: [03860/04555]	Time 0.04 (0.05)
Test: [03870/04555]	Time 0.04 (0.05)
Test: [03880/04555]	Time 0.04 (0.05)
Test: [03890/04555]	Time 0.04 (0.05)
Test: [03900/04555]	Time 0.06 (0.05)
Test: [03910/04555]	Time 0.08 (0.05)
Test: [03920/04555]	Time 0.04 (0.05)
Test: [03930/04555]	Time 0.04 (0.05)
Test: [03940/04555]	Time 0.04 (0.05)
Test: [03950/04555]	Time 0.04 (0.05)
Test: [03960/04555]	Time 0.04 (0.05)
Test: [03970/04555]	Time 0.04 (0.05)
Test: [03980/04555]	Time 0.04 (0.05)
Test: [03990/04555]	Time 0.04 (0.05)
Test: [04000/04555]	Time 0.04 (0.05)
Test: [04010/04555]	Time 0.04 (0.05)
Test: [04020/04555]	Time 0.04 (0.05)
Test: [04030/04555]	Time 0.04 (0.05)
Test: [04040/04555]	Time 0.04 (0.05)
Test: [04050/04555]	Time 0.04 (0.05)
Test: [04060/04555]	Time 0.04 (0.05)
Test: [04070/04555]	Time 0.04 (0.05)
Test: [04080/04555]	Time 0.04 (0.05)
Test: [04090/04555]	Time 0.18 (0.05)
Test: [04100/04555]	Time 0.04 (0.05)
Test: [04110/04555]	Time 0.04 (0.05)
Test: [04120/04555]	Time 0.04 (0.05)
Test: [04130/04555]	Time 0.04 (0.05)
Test: [04140/04555]	Time 0.04 (0.05)
Test: [04150/04555]	Time 0.04 (0.05)
Test: [04160/04555]	Time 0.04 (0.05)
Test: [04170/04555]	Time 0.04 (0.05)
Test: [04180/04555]	Time 0.04 (0.05)
Test: [04190/04555]	Time 0.04 (0.05)
Test: [04200/04555]	Time 0.04 (0.05)
Test: [04210/04555]	Time 0.04 (0.05)
Test: [04220/04555]	Time 0.04 (0.05)
Test: [04230/04555]	Time 0.04 (0.05)
Test: [04240/04555]	Time 0.04 (0.05)
Test: [04250/04555]	Time 0.04 (0.05)
Test: [04260/04555]	Time 0.04 (0.05)
Test: [04270/04555]	Time 0.04 (0.05)
Test: [04280/04555]	Time 0.04 (0.05)
Test: [04290/04555]	Time 0.04 (0.05)
Test: [04300/04555]	Time 0.04 (0.05)
Test: [04310/04555]	Time 0.04 (0.05)
Test: [04320/04555]	Time 0.04 (0.05)
Test: [04330/04555]	Time 0.04 (0.05)
Test: [04340/04555]	Time 0.04 (0.05)
Test: [04350/04555]	Time 0.04 (0.05)
Test: [04360/04555]	Time 0.04 (0.05)
Test: [04370/04555]	Time 0.04 (0.05)
Test: [04380/04555]	Time 0.04 (0.05)
Test: [04390/04555]	Time 0.04 (0.05)
Test: [04400/04555]	Time 0.04 (0.05)
Test: [04410/04555]	Time 0.33 (0.05)
Test: [04420/04555]	Time 0.14 (0.05)
Test: [04430/04555]	Time 0.19 (0.05)
Test: [04440/04555]	Time 0.04 (0.05)
Test: [04450/04555]	Time 0.04 (0.05)
Test: [04460/04555]	Time 0.06 (0.05)
Test: [04470/04555]	Time 0.04 (0.05)
Test: [04480/04555]	Time 0.04 (0.05)
Test: [04490/04555]	Time 0.04 (0.05)
Test: [04500/04555]	Time 0.04 (0.05)
Test: [04510/04555]	Time 0.04 (0.05)
Test: [04520/04555]	Time 0.04 (0.05)
Test: [04530/04555]	Time 0.04 (0.05)
Test: [04540/04555]	Time 0.04 (0.05)
Test: [04550/04555]	Time 0.04 (0.05)
[RESULTS] Action detection results on anet1.3_i3d_filtered.

|tIoU = 0.50: mAP = 53.19 (%) Recall@1x = 60.24 (%) Recall@5x = 81.13 (%) 
|tIoU = 0.55: mAP = 50.15 (%) Recall@1x = 57.58 (%) Recall@5x = 78.03 (%) 
|tIoU = 0.60: mAP = 47.03 (%) Recall@1x = 54.57 (%) Recall@5x = 74.36 (%) 
|tIoU = 0.65: mAP = 43.41 (%) Recall@1x = 51.67 (%) Recall@5x = 70.27 (%) 
|tIoU = 0.70: mAP = 39.89 (%) Recall@1x = 48.45 (%) Recall@5x = 65.33 (%) 
|tIoU = 0.75: mAP = 35.26 (%) Recall@1x = 44.59 (%) Recall@5x = 58.70 (%) 
|tIoU = 0.80: mAP = 30.40 (%) Recall@1x = 39.93 (%) Recall@5x = 50.90 (%) 
|tIoU = 0.85: mAP = 24.36 (%) Recall@1x = 33.85 (%) Recall@5x = 41.09 (%) 
|tIoU = 0.90: mAP = 16.19 (%) Recall@1x = 24.99 (%) Recall@5x = 28.82 (%) 
|tIoU = 0.95: mAP = 5.12 (%) Recall@1x = 10.33 (%) Recall@5x = 11.47 (%) 
Average mAP: 34.50 (%)
All done! Total time: 435.65 sec
