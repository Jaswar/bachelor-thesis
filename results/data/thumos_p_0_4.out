Looking for a split for p=0.4
Found split for p=0.4
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00040]	Time 4.04 (4.04)	Loss 2.07 (2.07)
		cls_loss 1.23 (1.23)	reg_loss 0.84 (0.84)
Epoch: [000][00020/00040]	Time 0.23 (2.14)	Loss 0.31 (1.19)
		cls_loss 0.23 (0.73)	reg_loss 0.08 (0.46)
Epoch: [000][00030/00040]	Time 0.22 (1.50)	Loss 0.29 (0.89)
		cls_loss 0.21 (0.56)	reg_loss 0.08 (0.33)
[Train]: Epoch 0 finished with lr=0.00002010


[Train]: Epoch 1 started
Epoch: [001][00010/00040]	Time 0.29 (0.29)	Loss 0.59 (0.59)
		cls_loss 0.43 (0.43)	reg_loss 0.16 (0.16)
Epoch: [001][00020/00040]	Time 0.23 (0.26)	Loss 0.29 (0.44)
		cls_loss 0.21 (0.32)	reg_loss 0.08 (0.12)
Epoch: [001][00030/00040]	Time 0.22 (0.25)	Loss 0.34 (0.41)
		cls_loss 0.24 (0.29)	reg_loss 0.10 (0.11)
[Train]: Epoch 1 finished with lr=0.00004020


[Train]: Epoch 2 started
Epoch: [002][00010/00040]	Time 0.28 (0.28)	Loss 1.45 (1.45)
		cls_loss 1.06 (1.06)	reg_loss 0.39 (0.39)
Epoch: [002][00020/00040]	Time 0.22 (0.25)	Loss 0.24 (0.84)
		cls_loss 0.17 (0.61)	reg_loss 0.07 (0.23)
Epoch: [002][00030/00040]	Time 0.22 (0.24)	Loss 0.52 (0.74)
		cls_loss 0.39 (0.54)	reg_loss 0.14 (0.20)
[Train]: Epoch 2 finished with lr=0.00006030


[Train]: Epoch 3 started
Epoch: [003][00010/00040]	Time 0.28 (0.28)	Loss 1.72 (1.72)
		cls_loss 1.25 (1.25)	reg_loss 0.47 (0.47)
Epoch: [003][00020/00040]	Time 0.22 (0.25)	Loss 0.66 (1.19)
		cls_loss 0.45 (0.85)	reg_loss 0.21 (0.34)
Epoch: [003][00030/00040]	Time 0.23 (0.24)	Loss 1.19 (1.19)
		cls_loss 0.81 (0.84)	reg_loss 0.38 (0.35)
[Train]: Epoch 3 finished with lr=0.00008040


[Train]: Epoch 4 started
Epoch: [004][00010/00040]	Time 0.27 (0.27)	Loss 0.21 (0.21)
		cls_loss 0.15 (0.15)	reg_loss 0.05 (0.05)
Epoch: [004][00020/00040]	Time 0.23 (0.25)	Loss 0.29 (0.25)
		cls_loss 0.19 (0.17)	reg_loss 0.09 (0.07)
Epoch: [004][00030/00040]	Time 0.22 (0.24)	Loss 0.36 (0.28)
		cls_loss 0.27 (0.20)	reg_loss 0.09 (0.08)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00040]	Time 0.28 (0.28)	Loss 0.28 (0.28)
		cls_loss 0.20 (0.20)	reg_loss 0.08 (0.08)
Epoch: [005][00020/00040]	Time 0.22 (0.25)	Loss 0.90 (0.59)
		cls_loss 0.65 (0.43)	reg_loss 0.24 (0.16)
Epoch: [005][00030/00040]	Time 0.22 (0.24)	Loss 0.18 (0.45)
		cls_loss 0.13 (0.33)	reg_loss 0.05 (0.12)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00040]	Time 0.28 (0.28)	Loss 0.55 (0.55)
		cls_loss 0.35 (0.35)	reg_loss 0.20 (0.20)
Epoch: [006][00020/00040]	Time 0.22 (0.25)	Loss 0.80 (0.67)
		cls_loss 0.41 (0.38)	reg_loss 0.39 (0.29)
Epoch: [006][00030/00040]	Time 0.23 (0.24)	Loss 0.89 (0.75)
		cls_loss 0.62 (0.46)	reg_loss 0.27 (0.29)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00040]	Time 0.26 (0.26)	Loss 2.70 (2.70)
		cls_loss 1.66 (1.66)	reg_loss 1.04 (1.04)
Epoch: [007][00020/00040]	Time 0.21 (0.24)	Loss 0.41 (1.56)
		cls_loss 0.27 (0.97)	reg_loss 0.15 (0.59)
Epoch: [007][00030/00040]	Time 0.60 (0.36)	Loss 1.55 (1.56)
		cls_loss 0.82 (0.92)	reg_loss 0.73 (0.64)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00040]	Time 0.48 (0.48)	Loss 0.13 (0.13)
		cls_loss 0.08 (0.08)	reg_loss 0.05 (0.05)
Epoch: [008][00020/00040]	Time 0.22 (0.35)	Loss 0.17 (0.15)
		cls_loss 0.09 (0.09)	reg_loss 0.08 (0.06)
Epoch: [008][00030/00040]	Time 0.23 (0.31)	Loss 0.35 (0.22)
		cls_loss 0.21 (0.13)	reg_loss 0.14 (0.09)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00040]	Time 0.29 (0.29)	Loss 0.82 (0.82)
		cls_loss 0.45 (0.45)	reg_loss 0.37 (0.37)
Epoch: [009][00020/00040]	Time 0.23 (0.26)	Loss 0.50 (0.66)
		cls_loss 0.27 (0.36)	reg_loss 0.23 (0.30)
Epoch: [009][00030/00040]	Time 0.22 (0.25)	Loss 0.94 (0.75)
		cls_loss 0.48 (0.40)	reg_loss 0.46 (0.35)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00040]	Time 0.28 (0.28)	Loss 0.28 (0.28)
		cls_loss 0.20 (0.20)	reg_loss 0.08 (0.08)
Epoch: [010][00020/00040]	Time 0.23 (0.26)	Loss 0.63 (0.45)
		cls_loss 0.39 (0.29)	reg_loss 0.24 (0.16)
Epoch: [010][00030/00040]	Time 0.22 (0.24)	Loss 0.74 (0.55)
		cls_loss 0.46 (0.35)	reg_loss 0.28 (0.20)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00040]	Time 0.27 (0.27)	Loss 1.02 (1.02)
		cls_loss 0.62 (0.62)	reg_loss 0.40 (0.40)
Epoch: [011][00020/00040]	Time 0.23 (0.25)	Loss 0.40 (0.71)
		cls_loss 0.26 (0.44)	reg_loss 0.14 (0.27)
Epoch: [011][00030/00040]	Time 0.23 (0.24)	Loss 0.67 (0.70)
		cls_loss 0.38 (0.42)	reg_loss 0.30 (0.28)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00040]	Time 0.28 (0.28)	Loss 0.53 (0.53)
		cls_loss 0.34 (0.34)	reg_loss 0.19 (0.19)
Epoch: [012][00020/00040]	Time 0.22 (0.25)	Loss 0.24 (0.39)
		cls_loss 0.16 (0.25)	reg_loss 0.08 (0.14)
Epoch: [012][00030/00040]	Time 0.22 (0.24)	Loss 0.28 (0.35)
		cls_loss 0.17 (0.22)	reg_loss 0.11 (0.13)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00040]	Time 0.28 (0.28)	Loss 0.36 (0.36)
		cls_loss 0.21 (0.21)	reg_loss 0.15 (0.15)
Epoch: [013][00020/00040]	Time 0.23 (0.26)	Loss 0.74 (0.55)
		cls_loss 0.49 (0.35)	reg_loss 0.24 (0.20)
Epoch: [013][00030/00040]	Time 0.22 (0.24)	Loss 0.56 (0.55)
		cls_loss 0.36 (0.35)	reg_loss 0.21 (0.20)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00040]	Time 0.28 (0.28)	Loss 0.45 (0.45)
		cls_loss 0.25 (0.25)	reg_loss 0.20 (0.20)
Epoch: [014][00020/00040]	Time 0.22 (0.25)	Loss 0.50 (0.47)
		cls_loss 0.26 (0.25)	reg_loss 0.24 (0.22)
Epoch: [014][00030/00040]	Time 0.23 (0.24)	Loss 0.70 (0.55)
		cls_loss 0.47 (0.32)	reg_loss 0.23 (0.22)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00040]	Time 0.29 (0.29)	Loss 0.91 (0.91)
		cls_loss 0.57 (0.57)	reg_loss 0.34 (0.34)
Epoch: [015][00020/00040]	Time 0.23 (0.26)	Loss 0.93 (0.92)
		cls_loss 0.64 (0.61)	reg_loss 0.29 (0.31)
Epoch: [015][00030/00040]	Time 0.22 (0.25)	Loss 0.19 (0.68)
		cls_loss 0.11 (0.44)	reg_loss 0.08 (0.24)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00040]	Time 0.28 (0.28)	Loss 0.23 (0.23)
		cls_loss 0.16 (0.16)	reg_loss 0.07 (0.07)
Epoch: [016][00020/00040]	Time 0.23 (0.25)	Loss 0.65 (0.44)
		cls_loss 0.37 (0.26)	reg_loss 0.28 (0.17)
Epoch: [016][00030/00040]	Time 0.22 (0.24)	Loss 0.95 (0.61)
		cls_loss 0.47 (0.33)	reg_loss 0.48 (0.28)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00040]	Time 0.29 (0.29)	Loss 1.07 (1.07)
		cls_loss 0.50 (0.50)	reg_loss 0.57 (0.57)
Epoch: [017][00020/00040]	Time 0.23 (0.26)	Loss 0.42 (0.74)
		cls_loss 0.24 (0.37)	reg_loss 0.19 (0.38)
Epoch: [017][00030/00040]	Time 0.23 (0.25)	Loss 0.98 (0.82)
		cls_loss 0.55 (0.43)	reg_loss 0.44 (0.40)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00040]	Time 0.29 (0.29)	Loss 0.12 (0.12)
		cls_loss 0.07 (0.07)	reg_loss 0.05 (0.05)
Epoch: [018][00020/00040]	Time 0.22 (0.26)	Loss 0.32 (0.22)
		cls_loss 0.18 (0.13)	reg_loss 0.14 (0.09)
Epoch: [018][00030/00040]	Time 0.23 (0.25)	Loss 0.89 (0.44)
		cls_loss 0.61 (0.29)	reg_loss 0.28 (0.15)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00040]	Time 0.27 (0.27)	Loss 0.63 (0.63)
		cls_loss 0.36 (0.36)	reg_loss 0.27 (0.27)
Epoch: [019][00020/00040]	Time 0.22 (0.25)	Loss 0.45 (0.54)
		cls_loss 0.26 (0.31)	reg_loss 0.19 (0.23)
Epoch: [019][00030/00040]	Time 0.23 (0.24)	Loss 0.19 (0.42)
		cls_loss 0.11 (0.24)	reg_loss 0.09 (0.18)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00040]	Time 0.30 (0.30)	Loss 0.18 (0.18)
		cls_loss 0.12 (0.12)	reg_loss 0.06 (0.06)
Epoch: [020][00020/00040]	Time 0.22 (0.26)	Loss 0.24 (0.21)
		cls_loss 0.12 (0.12)	reg_loss 0.12 (0.09)
Epoch: [020][00030/00040]	Time 0.23 (0.25)	Loss 0.20 (0.21)
		cls_loss 0.13 (0.12)	reg_loss 0.08 (0.09)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00040]	Time 0.28 (0.28)	Loss 0.49 (0.49)
		cls_loss 0.28 (0.28)	reg_loss 0.20 (0.20)
Epoch: [021][00020/00040]	Time 0.23 (0.25)	Loss 0.28 (0.39)
		cls_loss 0.19 (0.24)	reg_loss 0.09 (0.15)
Epoch: [021][00030/00040]	Time 0.23 (0.25)	Loss 0.49 (0.42)
		cls_loss 0.26 (0.25)	reg_loss 0.22 (0.17)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00040]	Time 0.27 (0.27)	Loss 0.55 (0.55)
		cls_loss 0.28 (0.28)	reg_loss 0.27 (0.27)
Epoch: [022][00020/00040]	Time 0.23 (0.25)	Loss 0.66 (0.61)
		cls_loss 0.34 (0.31)	reg_loss 0.33 (0.30)
Epoch: [022][00030/00040]	Time 0.23 (0.24)	Loss 0.62 (0.61)
		cls_loss 0.35 (0.32)	reg_loss 0.26 (0.29)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00040]	Time 0.27 (0.27)	Loss 0.44 (0.44)
		cls_loss 0.23 (0.23)	reg_loss 0.21 (0.21)
Epoch: [023][00020/00040]	Time 0.23 (0.25)	Loss 0.78 (0.61)
		cls_loss 0.41 (0.32)	reg_loss 0.36 (0.28)
Epoch: [023][00030/00040]	Time 0.23 (0.24)	Loss 0.23 (0.48)
		cls_loss 0.12 (0.26)	reg_loss 0.11 (0.23)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00040]	Time 0.27 (0.27)	Loss 0.43 (0.43)
		cls_loss 0.22 (0.22)	reg_loss 0.21 (0.21)
Epoch: [024][00020/00040]	Time 0.23 (0.25)	Loss 0.73 (0.58)
		cls_loss 0.38 (0.30)	reg_loss 0.35 (0.28)
Epoch: [024][00030/00040]	Time 0.22 (0.24)	Loss 0.14 (0.44)
		cls_loss 0.10 (0.23)	reg_loss 0.04 (0.20)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00040]	Time 0.29 (0.29)	Loss 0.09 (0.09)
		cls_loss 0.05 (0.05)	reg_loss 0.04 (0.04)
Epoch: [025][00020/00040]	Time 0.22 (0.26)	Loss 0.18 (0.13)
		cls_loss 0.10 (0.07)	reg_loss 0.08 (0.06)
Epoch: [025][00030/00040]	Time 0.23 (0.25)	Loss 0.13 (0.13)
		cls_loss 0.08 (0.08)	reg_loss 0.05 (0.06)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00040]	Time 0.27 (0.27)	Loss 0.50 (0.50)
		cls_loss 0.26 (0.26)	reg_loss 0.24 (0.24)
Epoch: [026][00020/00040]	Time 0.97 (0.62)	Loss 0.25 (0.37)
		cls_loss 0.16 (0.21)	reg_loss 0.09 (0.17)
Epoch: [026][00030/00040]	Time 0.69 (0.64)	Loss 0.21 (0.32)
		cls_loss 0.12 (0.18)	reg_loss 0.08 (0.14)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00040]	Time 0.28 (0.28)	Loss 0.10 (0.10)
		cls_loss 0.06 (0.06)	reg_loss 0.04 (0.04)
Epoch: [027][00020/00040]	Time 0.23 (0.25)	Loss 0.60 (0.35)
		cls_loss 0.29 (0.18)	reg_loss 0.31 (0.17)
Epoch: [027][00030/00040]	Time 0.23 (0.25)	Loss 0.32 (0.34)
		cls_loss 0.17 (0.17)	reg_loss 0.15 (0.17)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00040]	Time 0.34 (0.34)	Loss 0.21 (0.21)
		cls_loss 0.11 (0.11)	reg_loss 0.10 (0.10)
Epoch: [028][00020/00040]	Time 0.22 (0.28)	Loss 0.87 (0.54)
		cls_loss 0.43 (0.27)	reg_loss 0.44 (0.27)
Epoch: [028][00030/00040]	Time 0.23 (0.26)	Loss 0.66 (0.58)
		cls_loss 0.34 (0.29)	reg_loss 0.32 (0.29)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00040]	Time 0.30 (0.30)	Loss 0.25 (0.25)
		cls_loss 0.14 (0.14)	reg_loss 0.11 (0.11)
Epoch: [029][00020/00040]	Time 0.22 (0.26)	Loss 0.16 (0.21)
		cls_loss 0.09 (0.12)	reg_loss 0.07 (0.09)
Epoch: [029][00030/00040]	Time 0.23 (0.25)	Loss 0.33 (0.25)
		cls_loss 0.18 (0.14)	reg_loss 0.16 (0.11)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00040]	Time 0.28 (0.28)	Loss 0.27 (0.27)
		cls_loss 0.13 (0.13)	reg_loss 0.14 (0.14)
Epoch: [030][00020/00040]	Time 0.22 (0.25)	Loss 0.62 (0.44)
		cls_loss 0.32 (0.22)	reg_loss 0.30 (0.22)
Epoch: [030][00030/00040]	Time 0.23 (0.24)	Loss 0.13 (0.34)
		cls_loss 0.07 (0.17)	reg_loss 0.06 (0.17)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00040]	Time 0.28 (0.28)	Loss 0.49 (0.49)
		cls_loss 0.25 (0.25)	reg_loss 0.25 (0.25)
Epoch: [031][00020/00040]	Time 0.23 (0.25)	Loss 0.21 (0.35)
		cls_loss 0.12 (0.18)	reg_loss 0.09 (0.17)
Epoch: [031][00030/00040]	Time 0.23 (0.24)	Loss 1.21 (0.64)
		cls_loss 0.57 (0.31)	reg_loss 0.64 (0.33)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00040]	Time 0.27 (0.27)	Loss 0.03 (0.03)
		cls_loss 0.02 (0.02)	reg_loss 0.01 (0.01)
Epoch: [032][00020/00040]	Time 0.23 (0.25)	Loss 0.34 (0.18)
		cls_loss 0.17 (0.09)	reg_loss 0.17 (0.09)
Epoch: [032][00030/00040]	Time 0.23 (0.24)	Loss 0.14 (0.17)
		cls_loss 0.09 (0.09)	reg_loss 0.05 (0.08)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00040]	Time 0.28 (0.28)	Loss 0.42 (0.42)
		cls_loss 0.23 (0.23)	reg_loss 0.19 (0.19)
Epoch: [033][00020/00040]	Time 0.22 (0.25)	Loss 0.45 (0.44)
		cls_loss 0.23 (0.23)	reg_loss 0.22 (0.21)
Epoch: [033][00030/00040]	Time 0.23 (0.24)	Loss 0.22 (0.36)
		cls_loss 0.13 (0.20)	reg_loss 0.09 (0.17)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00040]	Time 0.28 (0.28)	Loss 0.79 (0.79)
		cls_loss 0.44 (0.44)	reg_loss 0.36 (0.36)
Epoch: [034][00020/00040]	Time 0.22 (0.25)	Loss 0.15 (0.47)
		cls_loss 0.08 (0.26)	reg_loss 0.06 (0.21)
Epoch: [034][00030/00040]	Time 0.23 (0.25)	Loss 0.30 (0.41)
		cls_loss 0.16 (0.23)	reg_loss 0.13 (0.18)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.53 (0.53)
Test: [00020/00212]	Time 0.09 (0.31)
Test: [00030/00212]	Time 0.09 (0.24)
Test: [00040/00212]	Time 0.10 (0.20)
Test: [00050/00212]	Time 0.10 (0.18)
Test: [00060/00212]	Time 0.08 (0.16)
Test: [00070/00212]	Time 0.08 (0.15)
Test: [00080/00212]	Time 0.09 (0.14)
Test: [00090/00212]	Time 0.09 (0.14)
Test: [00100/00212]	Time 0.10 (0.13)
Test: [00110/00212]	Time 0.11 (0.13)
Test: [00120/00212]	Time 0.09 (0.13)
Test: [00130/00212]	Time 0.09 (0.13)
Test: [00140/00212]	Time 0.09 (0.12)
Test: [00150/00212]	Time 0.09 (0.12)
Test: [00160/00212]	Time 0.12 (0.12)
Test: [00170/00212]	Time 0.12 (0.12)
Test: [00180/00212]	Time 0.09 (0.12)
Test: [00190/00212]	Time 0.10 (0.12)
Test: [00200/00212]	Time 0.09 (0.12)
Test: [00210/00212]	Time 0.08 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 66.70 (%) Recall@1x = 76.61 (%) Recall@5x = 93.02 (%) 
|tIoU = 0.40: mAP = 60.29 (%) Recall@1x = 69.36 (%) Recall@5x = 90.24 (%) 
|tIoU = 0.50: mAP = 51.87 (%) Recall@1x = 61.66 (%) Recall@5x = 85.16 (%) 
|tIoU = 0.60: mAP = 39.29 (%) Recall@1x = 50.40 (%) Recall@5x = 71.90 (%) 
|tIoU = 0.70: mAP = 24.02 (%) Recall@1x = 36.80 (%) Recall@5x = 53.66 (%) 
Average mAP: 48.44 (%)
All done! Total time: 277.54 sec
Looking for a split for p=0.4
Found split for p=0.4
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00040]	Time 0.96 (0.96)	Loss 1.79 (1.79)
		cls_loss 1.12 (1.12)	reg_loss 0.67 (0.67)
Epoch: [000][00020/00040]	Time 0.23 (0.59)	Loss 0.19 (0.99)
		cls_loss 0.13 (0.63)	reg_loss 0.06 (0.36)
Epoch: [000][00030/00040]	Time 0.22 (0.47)	Loss 0.56 (0.85)
		cls_loss 0.43 (0.56)	reg_loss 0.13 (0.29)
[Train]: Epoch 0 finished with lr=0.00002010


[Train]: Epoch 1 started
Epoch: [001][00010/00040]	Time 0.28 (0.28)	Loss 0.65 (0.65)
		cls_loss 0.44 (0.44)	reg_loss 0.21 (0.21)
Epoch: [001][00020/00040]	Time 0.22 (0.25)	Loss 1.92 (1.29)
		cls_loss 1.44 (0.94)	reg_loss 0.48 (0.34)
Epoch: [001][00030/00040]	Time 0.23 (0.24)	Loss 0.56 (1.05)
		cls_loss 0.42 (0.77)	reg_loss 0.14 (0.28)
[Train]: Epoch 1 finished with lr=0.00004020


[Train]: Epoch 2 started
Epoch: [002][00010/00040]	Time 0.28 (0.28)	Loss 0.77 (0.77)
		cls_loss 0.54 (0.54)	reg_loss 0.23 (0.23)
Epoch: [002][00020/00040]	Time 0.23 (0.26)	Loss 1.26 (1.02)
		cls_loss 0.89 (0.71)	reg_loss 0.37 (0.30)
Epoch: [002][00030/00040]	Time 0.23 (0.25)	Loss 0.47 (0.83)
		cls_loss 0.35 (0.59)	reg_loss 0.12 (0.24)
[Train]: Epoch 2 finished with lr=0.00006030


[Train]: Epoch 3 started
Epoch: [003][00010/00040]	Time 0.29 (0.29)	Loss 1.38 (1.38)
		cls_loss 0.93 (0.93)	reg_loss 0.45 (0.45)
Epoch: [003][00020/00040]	Time 0.23 (0.26)	Loss 0.40 (0.89)
		cls_loss 0.30 (0.62)	reg_loss 0.10 (0.27)
Epoch: [003][00030/00040]	Time 0.23 (0.25)	Loss 0.35 (0.71)
		cls_loss 0.26 (0.50)	reg_loss 0.09 (0.21)
[Train]: Epoch 3 finished with lr=0.00008040


[Train]: Epoch 4 started
Epoch: [004][00010/00040]	Time 0.28 (0.28)	Loss 1.11 (1.11)
		cls_loss 0.69 (0.69)	reg_loss 0.42 (0.42)
Epoch: [004][00020/00040]	Time 0.22 (0.25)	Loss 0.89 (1.00)
		cls_loss 0.53 (0.61)	reg_loss 0.36 (0.39)
Epoch: [004][00030/00040]	Time 0.22 (0.24)	Loss 1.16 (1.05)
		cls_loss 0.64 (0.62)	reg_loss 0.52 (0.43)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00040]	Time 0.28 (0.28)	Loss 0.41 (0.41)
		cls_loss 0.28 (0.28)	reg_loss 0.14 (0.14)
Epoch: [005][00020/00040]	Time 0.22 (0.25)	Loss 0.12 (0.27)
		cls_loss 0.09 (0.18)	reg_loss 0.03 (0.08)
Epoch: [005][00030/00040]	Time 0.23 (0.24)	Loss 0.36 (0.30)
		cls_loss 0.25 (0.21)	reg_loss 0.11 (0.09)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00040]	Time 0.28 (0.28)	Loss 0.67 (0.67)
		cls_loss 0.46 (0.46)	reg_loss 0.21 (0.21)
Epoch: [006][00020/00040]	Time 0.22 (0.25)	Loss 0.95 (0.81)
		cls_loss 0.63 (0.55)	reg_loss 0.32 (0.27)
Epoch: [006][00030/00040]	Time 0.22 (0.24)	Loss 0.42 (0.68)
		cls_loss 0.27 (0.45)	reg_loss 0.15 (0.23)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00040]	Time 0.28 (0.28)	Loss 0.94 (0.94)
		cls_loss 0.60 (0.60)	reg_loss 0.34 (0.34)
Epoch: [007][00020/00040]	Time 0.23 (0.26)	Loss 0.60 (0.77)
		cls_loss 0.36 (0.48)	reg_loss 0.23 (0.29)
Epoch: [007][00030/00040]	Time 0.22 (0.24)	Loss 1.32 (0.95)
		cls_loss 0.71 (0.56)	reg_loss 0.61 (0.39)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00040]	Time 0.29 (0.29)	Loss 0.71 (0.71)
		cls_loss 0.39 (0.39)	reg_loss 0.32 (0.32)
Epoch: [008][00020/00040]	Time 0.23 (0.26)	Loss 1.06 (0.88)
		cls_loss 0.51 (0.45)	reg_loss 0.55 (0.44)
Epoch: [008][00030/00040]	Time 0.23 (0.25)	Loss 0.43 (0.73)
		cls_loss 0.25 (0.38)	reg_loss 0.19 (0.35)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00040]	Time 0.27 (0.27)	Loss 0.07 (0.07)
		cls_loss 0.04 (0.04)	reg_loss 0.03 (0.03)
Epoch: [009][00020/00040]	Time 0.23 (0.25)	Loss 0.83 (0.45)
		cls_loss 0.49 (0.26)	reg_loss 0.34 (0.19)
Epoch: [009][00030/00040]	Time 0.23 (0.24)	Loss 2.99 (1.30)
		cls_loss 2.02 (0.85)	reg_loss 0.96 (0.45)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00040]	Time 0.27 (0.27)	Loss 0.31 (0.31)
		cls_loss 0.19 (0.19)	reg_loss 0.12 (0.12)
Epoch: [010][00020/00040]	Time 0.23 (0.25)	Loss 0.83 (0.57)
		cls_loss 0.47 (0.33)	reg_loss 0.36 (0.24)
Epoch: [010][00030/00040]	Time 0.23 (0.24)	Loss 0.47 (0.54)
		cls_loss 0.26 (0.31)	reg_loss 0.21 (0.23)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00040]	Time 0.27 (0.27)	Loss 0.53 (0.53)
		cls_loss 0.32 (0.32)	reg_loss 0.21 (0.21)
Epoch: [011][00020/00040]	Time 0.72 (0.49)	Loss 0.86 (0.69)
		cls_loss 0.44 (0.38)	reg_loss 0.41 (0.31)
Epoch: [011][00030/00040]	Time 0.66 (0.55)	Loss 1.16 (0.85)
		cls_loss 0.76 (0.51)	reg_loss 0.40 (0.34)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00040]	Time 1.24 (1.24)	Loss 0.79 (0.79)
		cls_loss 0.44 (0.44)	reg_loss 0.35 (0.35)
Epoch: [012][00020/00040]	Time 0.70 (0.97)	Loss 0.40 (0.60)
		cls_loss 0.24 (0.34)	reg_loss 0.17 (0.26)
Epoch: [012][00030/00040]	Time 0.26 (0.73)	Loss 1.08 (0.76)
		cls_loss 0.80 (0.49)	reg_loss 0.27 (0.26)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00040]	Time 0.28 (0.28)	Loss 1.14 (1.14)
		cls_loss 0.67 (0.67)	reg_loss 0.47 (0.47)
Epoch: [013][00020/00040]	Time 0.23 (0.25)	Loss 0.47 (0.80)
		cls_loss 0.31 (0.49)	reg_loss 0.16 (0.31)
Epoch: [013][00030/00040]	Time 0.22 (0.24)	Loss 0.36 (0.66)
		cls_loss 0.20 (0.39)	reg_loss 0.16 (0.26)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00040]	Time 0.69 (0.69)	Loss 0.54 (0.54)
		cls_loss 0.31 (0.31)	reg_loss 0.23 (0.23)
Epoch: [014][00020/00040]	Time 0.23 (0.46)	Loss 1.83 (1.19)
		cls_loss 1.30 (0.80)	reg_loss 0.54 (0.38)
Epoch: [014][00030/00040]	Time 0.22 (0.38)	Loss 0.75 (1.04)
		cls_loss 0.47 (0.69)	reg_loss 0.28 (0.35)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00040]	Time 0.27 (0.27)	Loss 0.57 (0.57)
		cls_loss 0.32 (0.32)	reg_loss 0.25 (0.25)
Epoch: [015][00020/00040]	Time 0.23 (0.25)	Loss 0.73 (0.65)
		cls_loss 0.37 (0.35)	reg_loss 0.36 (0.30)
Epoch: [015][00030/00040]	Time 0.23 (0.24)	Loss 0.06 (0.45)
		cls_loss 0.03 (0.24)	reg_loss 0.02 (0.21)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00040]	Time 0.28 (0.28)	Loss 0.07 (0.07)
		cls_loss 0.04 (0.04)	reg_loss 0.03 (0.03)
Epoch: [016][00020/00040]	Time 0.23 (0.25)	Loss 0.27 (0.17)
		cls_loss 0.15 (0.09)	reg_loss 0.13 (0.08)
Epoch: [016][00030/00040]	Time 0.22 (0.24)	Loss 0.22 (0.19)
		cls_loss 0.12 (0.10)	reg_loss 0.10 (0.09)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00040]	Time 0.27 (0.27)	Loss 0.23 (0.23)
		cls_loss 0.12 (0.12)	reg_loss 0.11 (0.11)
Epoch: [017][00020/00040]	Time 0.23 (0.25)	Loss 0.41 (0.32)
		cls_loss 0.22 (0.17)	reg_loss 0.19 (0.15)
Epoch: [017][00030/00040]	Time 0.23 (0.24)	Loss 0.15 (0.26)
		cls_loss 0.07 (0.14)	reg_loss 0.07 (0.12)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00040]	Time 0.28 (0.28)	Loss 0.99 (0.99)
		cls_loss 0.67 (0.67)	reg_loss 0.33 (0.33)
Epoch: [018][00020/00040]	Time 0.23 (0.25)	Loss 0.17 (0.58)
		cls_loss 0.09 (0.38)	reg_loss 0.08 (0.20)
Epoch: [018][00030/00040]	Time 0.23 (0.24)	Loss 0.09 (0.42)
		cls_loss 0.06 (0.27)	reg_loss 0.03 (0.14)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00040]	Time 0.28 (0.28)	Loss 0.62 (0.62)
		cls_loss 0.33 (0.33)	reg_loss 0.29 (0.29)
Epoch: [019][00020/00040]	Time 0.22 (0.25)	Loss 0.41 (0.51)
		cls_loss 0.24 (0.29)	reg_loss 0.16 (0.23)
Epoch: [019][00030/00040]	Time 0.23 (0.24)	Loss 0.08 (0.37)
		cls_loss 0.05 (0.21)	reg_loss 0.03 (0.16)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00040]	Time 0.28 (0.28)	Loss 0.09 (0.09)
		cls_loss 0.06 (0.06)	reg_loss 0.03 (0.03)
Epoch: [020][00020/00040]	Time 0.23 (0.26)	Loss 0.20 (0.15)
		cls_loss 0.12 (0.09)	reg_loss 0.08 (0.06)
Epoch: [020][00030/00040]	Time 0.23 (0.25)	Loss 0.30 (0.20)
		cls_loss 0.17 (0.12)	reg_loss 0.13 (0.08)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00040]	Time 0.27 (0.27)	Loss 0.31 (0.31)
		cls_loss 0.17 (0.17)	reg_loss 0.14 (0.14)
Epoch: [021][00020/00040]	Time 0.23 (0.25)	Loss 0.29 (0.30)
		cls_loss 0.17 (0.17)	reg_loss 0.12 (0.13)
Epoch: [021][00030/00040]	Time 0.23 (0.24)	Loss 0.08 (0.23)
		cls_loss 0.04 (0.13)	reg_loss 0.03 (0.10)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00040]	Time 0.27 (0.27)	Loss 0.05 (0.05)
		cls_loss 0.03 (0.03)	reg_loss 0.02 (0.02)
Epoch: [022][00020/00040]	Time 0.23 (0.25)	Loss 0.58 (0.31)
		cls_loss 0.31 (0.17)	reg_loss 0.27 (0.14)
Epoch: [022][00030/00040]	Time 0.23 (0.24)	Loss 0.15 (0.26)
		cls_loss 0.08 (0.14)	reg_loss 0.07 (0.12)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00040]	Time 0.28 (0.28)	Loss 0.05 (0.05)
		cls_loss 0.03 (0.03)	reg_loss 0.02 (0.02)
Epoch: [023][00020/00040]	Time 0.22 (0.25)	Loss 0.45 (0.25)
		cls_loss 0.22 (0.13)	reg_loss 0.23 (0.12)
Epoch: [023][00030/00040]	Time 0.23 (0.25)	Loss 1.13 (0.54)
		cls_loss 0.52 (0.26)	reg_loss 0.61 (0.28)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00040]	Time 0.28 (0.28)	Loss 0.26 (0.26)
		cls_loss 0.16 (0.16)	reg_loss 0.10 (0.10)
Epoch: [024][00020/00040]	Time 0.23 (0.25)	Loss 0.42 (0.34)
		cls_loss 0.21 (0.18)	reg_loss 0.21 (0.15)
Epoch: [024][00030/00040]	Time 0.23 (0.25)	Loss 0.53 (0.40)
		cls_loss 0.27 (0.21)	reg_loss 0.26 (0.19)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00040]	Time 0.28 (0.28)	Loss 0.24 (0.24)
		cls_loss 0.13 (0.13)	reg_loss 0.12 (0.12)
Epoch: [025][00020/00040]	Time 0.23 (0.25)	Loss 1.17 (0.71)
		cls_loss 0.57 (0.35)	reg_loss 0.59 (0.35)
Epoch: [025][00030/00040]	Time 0.23 (0.24)	Loss 0.85 (0.75)
		cls_loss 0.44 (0.38)	reg_loss 0.42 (0.38)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00040]	Time 0.29 (0.29)	Loss 0.48 (0.48)
		cls_loss 0.24 (0.24)	reg_loss 0.24 (0.24)
Epoch: [026][00020/00040]	Time 0.23 (0.26)	Loss 0.21 (0.35)
		cls_loss 0.13 (0.19)	reg_loss 0.08 (0.16)
Epoch: [026][00030/00040]	Time 0.22 (0.25)	Loss 0.40 (0.36)
		cls_loss 0.20 (0.19)	reg_loss 0.20 (0.17)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00040]	Time 0.27 (0.27)	Loss 0.80 (0.80)
		cls_loss 0.38 (0.38)	reg_loss 0.42 (0.42)
Epoch: [027][00020/00040]	Time 0.23 (0.25)	Loss 0.13 (0.46)
		cls_loss 0.07 (0.22)	reg_loss 0.06 (0.24)
Epoch: [027][00030/00040]	Time 0.23 (0.24)	Loss 0.04 (0.32)
		cls_loss 0.02 (0.16)	reg_loss 0.02 (0.17)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00040]	Time 0.28 (0.28)	Loss 0.11 (0.11)
		cls_loss 0.06 (0.06)	reg_loss 0.05 (0.05)
Epoch: [028][00020/00040]	Time 0.23 (0.26)	Loss 0.21 (0.16)
		cls_loss 0.11 (0.08)	reg_loss 0.11 (0.08)
Epoch: [028][00030/00040]	Time 0.22 (0.25)	Loss 0.06 (0.13)
		cls_loss 0.04 (0.07)	reg_loss 0.02 (0.06)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00040]	Time 0.29 (0.29)	Loss 0.52 (0.52)
		cls_loss 0.27 (0.27)	reg_loss 0.25 (0.25)
Epoch: [029][00020/00040]	Time 0.23 (0.26)	Loss 0.06 (0.29)
		cls_loss 0.04 (0.16)	reg_loss 0.02 (0.13)
Epoch: [029][00030/00040]	Time 0.23 (0.25)	Loss 0.55 (0.38)
		cls_loss 0.28 (0.20)	reg_loss 0.26 (0.18)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00040]	Time 0.84 (0.84)	Loss 0.04 (0.04)
		cls_loss 0.02 (0.02)	reg_loss 0.01 (0.01)
Epoch: [030][00020/00040]	Time 0.53 (0.69)	Loss 0.20 (0.12)
		cls_loss 0.12 (0.07)	reg_loss 0.08 (0.05)
Epoch: [030][00030/00040]	Time 0.32 (0.56)	Loss 0.02 (0.08)
		cls_loss 0.01 (0.05)	reg_loss 0.01 (0.03)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00040]	Time 0.28 (0.28)	Loss 0.04 (0.04)
		cls_loss 0.02 (0.02)	reg_loss 0.02 (0.02)
Epoch: [031][00020/00040]	Time 0.23 (0.25)	Loss 0.16 (0.10)
		cls_loss 0.10 (0.06)	reg_loss 0.06 (0.04)
Epoch: [031][00030/00040]	Time 0.23 (0.25)	Loss 0.16 (0.12)
		cls_loss 0.10 (0.07)	reg_loss 0.06 (0.05)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00040]	Time 0.28 (0.28)	Loss 0.16 (0.16)
		cls_loss 0.09 (0.09)	reg_loss 0.07 (0.07)
Epoch: [032][00020/00040]	Time 0.23 (0.26)	Loss 0.18 (0.17)
		cls_loss 0.10 (0.10)	reg_loss 0.07 (0.07)
Epoch: [032][00030/00040]	Time 0.23 (0.25)	Loss 0.34 (0.23)
		cls_loss 0.18 (0.13)	reg_loss 0.15 (0.10)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00040]	Time 0.29 (0.29)	Loss 0.10 (0.10)
		cls_loss 0.05 (0.05)	reg_loss 0.05 (0.05)
Epoch: [033][00020/00040]	Time 0.23 (0.26)	Loss 0.10 (0.10)
		cls_loss 0.06 (0.05)	reg_loss 0.04 (0.05)
Epoch: [033][00030/00040]	Time 0.22 (0.25)	Loss 0.05 (0.08)
		cls_loss 0.03 (0.05)	reg_loss 0.02 (0.04)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00040]	Time 0.29 (0.29)	Loss 0.19 (0.19)
		cls_loss 0.10 (0.10)	reg_loss 0.08 (0.08)
Epoch: [034][00020/00040]	Time 0.22 (0.25)	Loss 0.98 (0.58)
		cls_loss 0.54 (0.32)	reg_loss 0.44 (0.26)
Epoch: [034][00030/00040]	Time 0.23 (0.25)	Loss 0.09 (0.42)
		cls_loss 0.05 (0.23)	reg_loss 0.04 (0.19)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.51 (0.51)
Test: [00020/00212]	Time 0.09 (0.30)
Test: [00030/00212]	Time 0.09 (0.23)
Test: [00040/00212]	Time 0.40 (0.27)
Test: [00050/00212]	Time 0.09 (0.23)
Test: [00060/00212]	Time 0.07 (0.21)
Test: [00070/00212]	Time 0.08 (0.19)
Test: [00080/00212]	Time 0.09 (0.18)
Test: [00090/00212]	Time 0.09 (0.17)
Test: [00100/00212]	Time 0.09 (0.16)
Test: [00110/00212]	Time 0.09 (0.15)
Test: [00120/00212]	Time 0.16 (0.15)
Test: [00130/00212]	Time 0.16 (0.15)
Test: [00140/00212]	Time 0.09 (0.15)
Test: [00150/00212]	Time 0.09 (0.15)
Test: [00160/00212]	Time 0.11 (0.14)
Test: [00170/00212]	Time 0.12 (0.14)
Test: [00180/00212]	Time 0.09 (0.14)
Test: [00190/00212]	Time 0.10 (0.14)
Test: [00200/00212]	Time 0.10 (0.14)
Test: [00210/00212]	Time 0.07 (0.13)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 63.85 (%) Recall@1x = 72.38 (%) Recall@5x = 93.41 (%) 
|tIoU = 0.40: mAP = 55.91 (%) Recall@1x = 64.13 (%) Recall@5x = 89.69 (%) 
|tIoU = 0.50: mAP = 47.32 (%) Recall@1x = 56.70 (%) Recall@5x = 83.44 (%) 
|tIoU = 0.60: mAP = 34.04 (%) Recall@1x = 45.14 (%) Recall@5x = 69.77 (%) 
|tIoU = 0.70: mAP = 19.85 (%) Recall@1x = 32.20 (%) Recall@5x = 50.06 (%) 
Average mAP: 44.19 (%)
All done! Total time: 242.20 sec
Looking for a split for p=0.4
Found split for p=0.4
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00040]	Time 0.99 (0.99)	Loss 0.61 (0.61)
		cls_loss 0.37 (0.37)	reg_loss 0.24 (0.24)
Epoch: [000][00020/00040]	Time 0.23 (0.61)	Loss 0.08 (0.34)
		cls_loss 0.06 (0.21)	reg_loss 0.02 (0.13)
Epoch: [000][00030/00040]	Time 0.23 (0.48)	Loss 0.31 (0.33)
		cls_loss 0.21 (0.21)	reg_loss 0.09 (0.12)
[Train]: Epoch 0 finished with lr=0.00002010


[Train]: Epoch 1 started
Epoch: [001][00010/00040]	Time 0.26 (0.26)	Loss 0.23 (0.23)
		cls_loss 0.17 (0.17)	reg_loss 0.06 (0.06)
Epoch: [001][00020/00040]	Time 0.23 (0.24)	Loss 1.10 (0.66)
		cls_loss 0.73 (0.45)	reg_loss 0.37 (0.21)
Epoch: [001][00030/00040]	Time 0.23 (0.24)	Loss 1.50 (0.94)
		cls_loss 0.95 (0.62)	reg_loss 0.55 (0.33)
[Train]: Epoch 1 finished with lr=0.00004020


[Train]: Epoch 2 started
Epoch: [002][00010/00040]	Time 0.26 (0.26)	Loss 0.84 (0.84)
		cls_loss 0.60 (0.60)	reg_loss 0.24 (0.24)
Epoch: [002][00020/00040]	Time 0.83 (0.54)	Loss 2.42 (1.63)
		cls_loss 1.67 (1.14)	reg_loss 0.75 (0.49)
Epoch: [002][00030/00040]	Time 1.17 (0.75)	Loss 0.40 (1.22)
		cls_loss 0.27 (0.85)	reg_loss 0.13 (0.37)
[Train]: Epoch 2 finished with lr=0.00006030


[Train]: Epoch 3 started
Epoch: [003][00010/00040]	Time 0.28 (0.28)	Loss 0.40 (0.40)
		cls_loss 0.30 (0.30)	reg_loss 0.10 (0.10)
Epoch: [003][00020/00040]	Time 0.22 (0.25)	Loss 0.15 (0.28)
		cls_loss 0.11 (0.20)	reg_loss 0.05 (0.07)
Epoch: [003][00030/00040]	Time 0.23 (0.24)	Loss 0.25 (0.27)
		cls_loss 0.20 (0.20)	reg_loss 0.05 (0.07)
[Train]: Epoch 3 finished with lr=0.00008040


[Train]: Epoch 4 started
Epoch: [004][00010/00040]	Time 0.27 (0.27)	Loss 1.14 (1.14)
		cls_loss 0.60 (0.60)	reg_loss 0.54 (0.54)
Epoch: [004][00020/00040]	Time 0.22 (0.25)	Loss 0.36 (0.75)
		cls_loss 0.24 (0.42)	reg_loss 0.11 (0.33)
Epoch: [004][00030/00040]	Time 0.22 (0.24)	Loss 1.15 (0.88)
		cls_loss 0.61 (0.49)	reg_loss 0.54 (0.40)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00040]	Time 0.28 (0.28)	Loss 0.18 (0.18)
		cls_loss 0.12 (0.12)	reg_loss 0.06 (0.06)
Epoch: [005][00020/00040]	Time 0.23 (0.25)	Loss 1.47 (0.82)
		cls_loss 0.86 (0.49)	reg_loss 0.61 (0.33)
Epoch: [005][00030/00040]	Time 0.22 (0.24)	Loss 1.20 (0.95)
		cls_loss 0.58 (0.52)	reg_loss 0.62 (0.43)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00040]	Time 0.28 (0.28)	Loss 2.10 (2.10)
		cls_loss 1.33 (1.33)	reg_loss 0.78 (0.78)
Epoch: [006][00020/00040]	Time 0.23 (0.25)	Loss 0.41 (1.25)
		cls_loss 0.22 (0.77)	reg_loss 0.19 (0.48)
Epoch: [006][00030/00040]	Time 0.23 (0.24)	Loss 0.19 (0.90)
		cls_loss 0.12 (0.56)	reg_loss 0.07 (0.34)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00040]	Time 0.29 (0.29)	Loss 0.47 (0.47)
		cls_loss 0.32 (0.32)	reg_loss 0.15 (0.15)
Epoch: [007][00020/00040]	Time 0.23 (0.26)	Loss 0.63 (0.55)
		cls_loss 0.42 (0.37)	reg_loss 0.22 (0.18)
Epoch: [007][00030/00040]	Time 0.22 (0.25)	Loss 0.04 (0.38)
		cls_loss 0.04 (0.26)	reg_loss 0.01 (0.13)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00040]	Time 0.27 (0.27)	Loss 0.64 (0.64)
		cls_loss 0.36 (0.36)	reg_loss 0.28 (0.28)
Epoch: [008][00020/00040]	Time 0.22 (0.25)	Loss 0.21 (0.42)
		cls_loss 0.15 (0.26)	reg_loss 0.05 (0.17)
Epoch: [008][00030/00040]	Time 0.23 (0.24)	Loss 0.90 (0.58)
		cls_loss 0.49 (0.33)	reg_loss 0.41 (0.25)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00040]	Time 0.27 (0.27)	Loss 0.56 (0.56)
		cls_loss 0.40 (0.40)	reg_loss 0.17 (0.17)
Epoch: [009][00020/00040]	Time 0.23 (0.25)	Loss 0.23 (0.39)
		cls_loss 0.13 (0.26)	reg_loss 0.10 (0.13)
Epoch: [009][00030/00040]	Time 0.23 (0.24)	Loss 0.22 (0.34)
		cls_loss 0.15 (0.23)	reg_loss 0.07 (0.11)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00040]	Time 0.28 (0.28)	Loss 0.11 (0.11)
		cls_loss 0.07 (0.07)	reg_loss 0.04 (0.04)
Epoch: [010][00020/00040]	Time 0.22 (0.25)	Loss 0.87 (0.49)
		cls_loss 0.53 (0.30)	reg_loss 0.34 (0.19)
Epoch: [010][00030/00040]	Time 0.23 (0.24)	Loss 0.83 (0.60)
		cls_loss 0.46 (0.35)	reg_loss 0.37 (0.25)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00040]	Time 0.28 (0.28)	Loss 1.01 (1.01)
		cls_loss 0.63 (0.63)	reg_loss 0.39 (0.39)
Epoch: [011][00020/00040]	Time 0.29 (0.29)	Loss 0.63 (0.82)
		cls_loss 0.35 (0.49)	reg_loss 0.29 (0.34)
Epoch: [011][00030/00040]	Time 0.22 (0.27)	Loss 0.22 (0.62)
		cls_loss 0.13 (0.37)	reg_loss 0.09 (0.26)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00040]	Time 0.29 (0.29)	Loss 1.69 (1.69)
		cls_loss 0.95 (0.95)	reg_loss 0.73 (0.73)
Epoch: [012][00020/00040]	Time 0.35 (0.32)	Loss 0.27 (0.98)
		cls_loss 0.19 (0.57)	reg_loss 0.08 (0.41)
Epoch: [012][00030/00040]	Time 0.23 (0.29)	Loss 1.32 (1.09)
		cls_loss 0.57 (0.57)	reg_loss 0.76 (0.52)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00040]	Time 0.28 (0.28)	Loss 1.55 (1.55)
		cls_loss 0.87 (0.87)	reg_loss 0.68 (0.68)
Epoch: [013][00020/00040]	Time 0.21 (0.24)	Loss 0.07 (0.81)
		cls_loss 0.04 (0.45)	reg_loss 0.03 (0.36)
Epoch: [013][00030/00040]	Time 0.43 (0.31)	Loss 0.22 (0.61)
		cls_loss 0.13 (0.35)	reg_loss 0.09 (0.27)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00040]	Time 0.28 (0.28)	Loss 0.77 (0.77)
		cls_loss 0.39 (0.39)	reg_loss 0.39 (0.39)
Epoch: [014][00020/00040]	Time 0.22 (0.25)	Loss 0.16 (0.47)
		cls_loss 0.13 (0.26)	reg_loss 0.04 (0.21)
Epoch: [014][00030/00040]	Time 0.24 (0.25)	Loss 0.61 (0.52)
		cls_loss 0.30 (0.27)	reg_loss 0.31 (0.25)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00040]	Time 0.29 (0.29)	Loss 0.68 (0.68)
		cls_loss 0.33 (0.33)	reg_loss 0.35 (0.35)
Epoch: [015][00020/00040]	Time 0.22 (0.26)	Loss 0.59 (0.64)
		cls_loss 0.40 (0.37)	reg_loss 0.19 (0.27)
Epoch: [015][00030/00040]	Time 0.22 (0.24)	Loss 0.72 (0.66)
		cls_loss 0.37 (0.37)	reg_loss 0.35 (0.30)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00040]	Time 0.27 (0.27)	Loss 0.36 (0.36)
		cls_loss 0.21 (0.21)	reg_loss 0.14 (0.14)
Epoch: [016][00020/00040]	Time 0.22 (0.25)	Loss 0.07 (0.21)
		cls_loss 0.04 (0.13)	reg_loss 0.03 (0.09)
Epoch: [016][00030/00040]	Time 0.23 (0.24)	Loss 0.19 (0.21)
		cls_loss 0.13 (0.13)	reg_loss 0.06 (0.08)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00040]	Time 0.26 (0.26)	Loss 0.10 (0.10)
		cls_loss 0.07 (0.07)	reg_loss 0.03 (0.03)
Epoch: [017][00020/00040]	Time 0.23 (0.25)	Loss 0.24 (0.17)
		cls_loss 0.15 (0.11)	reg_loss 0.08 (0.06)
Epoch: [017][00030/00040]	Time 0.23 (0.24)	Loss 0.87 (0.40)
		cls_loss 0.47 (0.23)	reg_loss 0.40 (0.17)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00040]	Time 0.28 (0.28)	Loss 0.33 (0.33)
		cls_loss 0.21 (0.21)	reg_loss 0.12 (0.12)
Epoch: [018][00020/00040]	Time 0.23 (0.25)	Loss 0.72 (0.52)
		cls_loss 0.42 (0.31)	reg_loss 0.30 (0.21)
Epoch: [018][00030/00040]	Time 0.23 (0.25)	Loss 0.37 (0.47)
		cls_loss 0.17 (0.27)	reg_loss 0.20 (0.21)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00040]	Time 0.28 (0.28)	Loss 1.14 (1.14)
		cls_loss 0.54 (0.54)	reg_loss 0.59 (0.59)
Epoch: [019][00020/00040]	Time 0.23 (0.25)	Loss 0.38 (0.76)
		cls_loss 0.21 (0.38)	reg_loss 0.16 (0.38)
Epoch: [019][00030/00040]	Time 0.23 (0.24)	Loss 0.43 (0.65)
		cls_loss 0.24 (0.33)	reg_loss 0.20 (0.32)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00040]	Time 2.36 (2.36)	Loss 0.81 (0.81)
		cls_loss 0.40 (0.40)	reg_loss 0.41 (0.41)
Epoch: [020][00020/00040]	Time 1.22 (1.79)	Loss 0.07 (0.44)
		cls_loss 0.04 (0.22)	reg_loss 0.03 (0.22)
Epoch: [020][00030/00040]	Time 1.38 (1.65)	Loss 0.83 (0.57)
		cls_loss 0.59 (0.34)	reg_loss 0.24 (0.23)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00040]	Time 0.28 (0.28)	Loss 0.97 (0.97)
		cls_loss 0.60 (0.60)	reg_loss 0.37 (0.37)
Epoch: [021][00020/00040]	Time 0.23 (0.25)	Loss 0.43 (0.70)
		cls_loss 0.22 (0.41)	reg_loss 0.21 (0.29)
Epoch: [021][00030/00040]	Time 0.22 (0.24)	Loss 0.10 (0.50)
		cls_loss 0.05 (0.29)	reg_loss 0.04 (0.21)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00040]	Time 0.27 (0.27)	Loss 0.40 (0.40)
		cls_loss 0.21 (0.21)	reg_loss 0.20 (0.20)
Epoch: [022][00020/00040]	Time 0.23 (0.25)	Loss 0.25 (0.33)
		cls_loss 0.13 (0.17)	reg_loss 0.12 (0.16)
Epoch: [022][00030/00040]	Time 0.23 (0.24)	Loss 0.11 (0.26)
		cls_loss 0.06 (0.13)	reg_loss 0.05 (0.12)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00040]	Time 0.28 (0.28)	Loss 0.52 (0.52)
		cls_loss 0.27 (0.27)	reg_loss 0.25 (0.25)
Epoch: [023][00020/00040]	Time 0.23 (0.25)	Loss 0.36 (0.44)
		cls_loss 0.20 (0.23)	reg_loss 0.16 (0.21)
Epoch: [023][00030/00040]	Time 0.22 (0.24)	Loss 0.07 (0.32)
		cls_loss 0.05 (0.17)	reg_loss 0.02 (0.15)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00040]	Time 0.28 (0.28)	Loss 0.71 (0.71)
		cls_loss 0.40 (0.40)	reg_loss 0.31 (0.31)
Epoch: [024][00020/00040]	Time 0.23 (0.26)	Loss 0.32 (0.52)
		cls_loss 0.18 (0.29)	reg_loss 0.15 (0.23)
Epoch: [024][00030/00040]	Time 0.22 (0.25)	Loss 1.46 (0.83)
		cls_loss 0.71 (0.43)	reg_loss 0.75 (0.40)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00040]	Time 0.27 (0.27)	Loss 0.54 (0.54)
		cls_loss 0.27 (0.27)	reg_loss 0.28 (0.28)
Epoch: [025][00020/00040]	Time 0.22 (0.25)	Loss 0.12 (0.33)
		cls_loss 0.06 (0.16)	reg_loss 0.05 (0.17)
Epoch: [025][00030/00040]	Time 0.23 (0.24)	Loss 0.57 (0.41)
		cls_loss 0.31 (0.21)	reg_loss 0.27 (0.20)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00040]	Time 0.27 (0.27)	Loss 0.34 (0.34)
		cls_loss 0.18 (0.18)	reg_loss 0.15 (0.15)
Epoch: [026][00020/00040]	Time 0.23 (0.25)	Loss 0.41 (0.37)
		cls_loss 0.24 (0.21)	reg_loss 0.16 (0.16)
Epoch: [026][00030/00040]	Time 0.23 (0.24)	Loss 0.42 (0.39)
		cls_loss 0.21 (0.21)	reg_loss 0.21 (0.17)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00040]	Time 0.28 (0.28)	Loss 0.22 (0.22)
		cls_loss 0.11 (0.11)	reg_loss 0.11 (0.11)
Epoch: [027][00020/00040]	Time 0.23 (0.25)	Loss 0.20 (0.21)
		cls_loss 0.11 (0.11)	reg_loss 0.09 (0.10)
Epoch: [027][00030/00040]	Time 0.22 (0.24)	Loss 0.46 (0.29)
		cls_loss 0.25 (0.16)	reg_loss 0.21 (0.14)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00040]	Time 0.27 (0.27)	Loss 0.13 (0.13)
		cls_loss 0.07 (0.07)	reg_loss 0.05 (0.05)
Epoch: [028][00020/00040]	Time 0.23 (0.25)	Loss 0.39 (0.26)
		cls_loss 0.21 (0.14)	reg_loss 0.18 (0.12)
Epoch: [028][00030/00040]	Time 0.23 (0.24)	Loss 0.44 (0.32)
		cls_loss 0.27 (0.18)	reg_loss 0.17 (0.13)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00040]	Time 0.27 (0.27)	Loss 0.25 (0.25)
		cls_loss 0.16 (0.16)	reg_loss 0.10 (0.10)
Epoch: [029][00020/00040]	Time 0.23 (0.25)	Loss 0.12 (0.19)
		cls_loss 0.07 (0.11)	reg_loss 0.05 (0.07)
Epoch: [029][00030/00040]	Time 0.23 (0.24)	Loss 0.23 (0.20)
		cls_loss 0.13 (0.12)	reg_loss 0.11 (0.08)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00040]	Time 0.29 (0.29)	Loss 0.46 (0.46)
		cls_loss 0.24 (0.24)	reg_loss 0.22 (0.22)
Epoch: [030][00020/00040]	Time 0.22 (0.26)	Loss 0.29 (0.37)
		cls_loss 0.20 (0.22)	reg_loss 0.08 (0.15)
Epoch: [030][00030/00040]	Time 0.23 (0.25)	Loss 0.34 (0.36)
		cls_loss 0.19 (0.21)	reg_loss 0.15 (0.15)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00040]	Time 0.28 (0.28)	Loss 0.18 (0.18)
		cls_loss 0.09 (0.09)	reg_loss 0.09 (0.09)
Epoch: [031][00020/00040]	Time 0.23 (0.25)	Loss 0.16 (0.17)
		cls_loss 0.11 (0.10)	reg_loss 0.05 (0.07)
Epoch: [031][00030/00040]	Time 0.23 (0.25)	Loss 0.22 (0.19)
		cls_loss 0.11 (0.10)	reg_loss 0.11 (0.08)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00040]	Time 0.28 (0.28)	Loss 0.21 (0.21)
		cls_loss 0.11 (0.11)	reg_loss 0.10 (0.10)
Epoch: [032][00020/00040]	Time 0.22 (0.25)	Loss 0.04 (0.13)
		cls_loss 0.03 (0.07)	reg_loss 0.01 (0.06)
Epoch: [032][00030/00040]	Time 0.23 (0.25)	Loss 0.23 (0.16)
		cls_loss 0.11 (0.08)	reg_loss 0.12 (0.08)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00040]	Time 0.28 (0.28)	Loss 0.67 (0.67)
		cls_loss 0.46 (0.46)	reg_loss 0.20 (0.20)
Epoch: [033][00020/00040]	Time 0.22 (0.25)	Loss 0.03 (0.35)
		cls_loss 0.02 (0.24)	reg_loss 0.01 (0.11)
Epoch: [033][00030/00040]	Time 0.24 (0.24)	Loss 0.14 (0.28)
		cls_loss 0.09 (0.19)	reg_loss 0.05 (0.09)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00040]	Time 0.28 (0.28)	Loss 0.21 (0.21)
		cls_loss 0.14 (0.14)	reg_loss 0.07 (0.07)
Epoch: [034][00020/00040]	Time 0.22 (0.25)	Loss 0.25 (0.23)
		cls_loss 0.13 (0.14)	reg_loss 0.11 (0.09)
Epoch: [034][00030/00040]	Time 0.22 (0.24)	Loss 0.52 (0.33)
		cls_loss 0.28 (0.18)	reg_loss 0.24 (0.14)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.51 (0.51)
Test: [00020/00212]	Time 0.09 (0.30)
Test: [00030/00212]	Time 0.09 (0.23)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.07 (0.16)
Test: [00070/00212]	Time 0.08 (0.15)
Test: [00080/00212]	Time 0.09 (0.14)
Test: [00090/00212]	Time 0.09 (0.13)
Test: [00100/00212]	Time 0.09 (0.13)
Test: [00110/00212]	Time 0.10 (0.13)
Test: [00120/00212]	Time 0.09 (0.12)
Test: [00130/00212]	Time 0.09 (0.12)
Test: [00140/00212]	Time 0.09 (0.12)
Test: [00150/00212]	Time 0.09 (0.12)
Test: [00160/00212]	Time 0.12 (0.12)
Test: [00170/00212]	Time 0.12 (0.12)
Test: [00180/00212]	Time 0.09 (0.12)
Test: [00190/00212]	Time 0.09 (0.11)
Test: [00200/00212]	Time 0.08 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 65.75 (%) Recall@1x = 74.48 (%) Recall@5x = 92.65 (%) 
|tIoU = 0.40: mAP = 58.70 (%) Recall@1x = 67.39 (%) Recall@5x = 89.08 (%) 
|tIoU = 0.50: mAP = 49.97 (%) Recall@1x = 59.06 (%) Recall@5x = 83.16 (%) 
|tIoU = 0.60: mAP = 38.00 (%) Recall@1x = 48.15 (%) Recall@5x = 70.08 (%) 
|tIoU = 0.70: mAP = 24.20 (%) Recall@1x = 36.09 (%) Recall@5x = 51.33 (%) 
Average mAP: 47.32 (%)
All done! Total time: 104.49 sec
Looking for a split for p=0.4
Found split for p=0.4
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00040]	Time 0.93 (0.93)	Loss 2.07 (2.07)
		cls_loss 1.24 (1.24)	reg_loss 0.83 (0.83)
Epoch: [000][00020/00040]	Time 0.24 (0.58)	Loss 1.44 (1.76)
		cls_loss 1.07 (1.16)	reg_loss 0.37 (0.60)
Epoch: [000][00030/00040]	Time 0.23 (0.46)	Loss 0.41 (1.31)
		cls_loss 0.30 (0.87)	reg_loss 0.11 (0.44)
[Train]: Epoch 0 finished with lr=0.00002010


[Train]: Epoch 1 started
Epoch: [001][00010/00040]	Time 0.28 (0.28)	Loss 2.70 (2.70)
		cls_loss 1.98 (1.98)	reg_loss 0.72 (0.72)
Epoch: [001][00020/00040]	Time 0.23 (0.25)	Loss 2.17 (2.43)
		cls_loss 1.66 (1.82)	reg_loss 0.51 (0.62)
Epoch: [001][00030/00040]	Time 0.23 (0.24)	Loss 0.98 (1.95)
		cls_loss 0.70 (1.45)	reg_loss 0.27 (0.50)
[Train]: Epoch 1 finished with lr=0.00004020


[Train]: Epoch 2 started
Epoch: [002][00010/00040]	Time 0.27 (0.27)	Loss 0.74 (0.74)
		cls_loss 0.56 (0.56)	reg_loss 0.18 (0.18)
Epoch: [002][00020/00040]	Time 0.23 (0.25)	Loss 2.36 (1.55)
		cls_loss 1.68 (1.12)	reg_loss 0.68 (0.43)
Epoch: [002][00030/00040]	Time 0.22 (0.24)	Loss 0.42 (1.17)
		cls_loss 0.32 (0.86)	reg_loss 0.10 (0.32)
[Train]: Epoch 2 finished with lr=0.00006030


[Train]: Epoch 3 started
Epoch: [003][00010/00040]	Time 0.27 (0.27)	Loss 1.75 (1.75)
		cls_loss 1.25 (1.25)	reg_loss 0.49 (0.49)
Epoch: [003][00020/00040]	Time 0.23 (0.25)	Loss 0.83 (1.29)
		cls_loss 0.58 (0.91)	reg_loss 0.25 (0.37)
Epoch: [003][00030/00040]	Time 0.23 (0.24)	Loss 0.47 (1.01)
		cls_loss 0.33 (0.72)	reg_loss 0.14 (0.29)
[Train]: Epoch 3 finished with lr=0.00008040


[Train]: Epoch 4 started
Epoch: [004][00010/00040]	Time 0.28 (0.28)	Loss 0.36 (0.36)
		cls_loss 0.29 (0.29)	reg_loss 0.07 (0.07)
Epoch: [004][00020/00040]	Time 0.30 (0.29)	Loss 2.18 (1.27)
		cls_loss 1.41 (0.85)	reg_loss 0.77 (0.42)
Epoch: [004][00030/00040]	Time 0.23 (0.27)	Loss 1.04 (1.19)
		cls_loss 0.75 (0.81)	reg_loss 0.29 (0.38)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00040]	Time 0.27 (0.27)	Loss 1.84 (1.84)
		cls_loss 1.09 (1.09)	reg_loss 0.76 (0.76)
Epoch: [005][00020/00040]	Time 0.23 (0.25)	Loss 0.86 (1.35)
		cls_loss 0.58 (0.83)	reg_loss 0.28 (0.52)
Epoch: [005][00030/00040]	Time 0.23 (0.24)	Loss 1.16 (1.29)
		cls_loss 0.75 (0.81)	reg_loss 0.41 (0.48)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00040]	Time 0.29 (0.29)	Loss 0.58 (0.58)
		cls_loss 0.36 (0.36)	reg_loss 0.22 (0.22)
Epoch: [006][00020/00040]	Time 0.79 (0.54)	Loss 0.08 (0.33)
		cls_loss 0.05 (0.20)	reg_loss 0.04 (0.13)
Epoch: [006][00030/00040]	Time 0.57 (0.55)	Loss 1.70 (0.79)
		cls_loss 1.09 (0.50)	reg_loss 0.60 (0.29)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00040]	Time 1.01 (1.01)	Loss 0.38 (0.38)
		cls_loss 0.24 (0.24)	reg_loss 0.14 (0.14)
Epoch: [007][00020/00040]	Time 0.23 (0.62)	Loss 1.28 (0.83)
		cls_loss 0.71 (0.47)	reg_loss 0.57 (0.36)
Epoch: [007][00030/00040]	Time 0.22 (0.49)	Loss 0.35 (0.67)
		cls_loss 0.25 (0.40)	reg_loss 0.10 (0.27)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00040]	Time 0.28 (0.28)	Loss 1.19 (1.19)
		cls_loss 0.78 (0.78)	reg_loss 0.41 (0.41)
Epoch: [008][00020/00040]	Time 0.23 (0.25)	Loss 1.19 (1.19)
		cls_loss 0.73 (0.76)	reg_loss 0.46 (0.43)
Epoch: [008][00030/00040]	Time 0.23 (0.25)	Loss 0.24 (0.87)
		cls_loss 0.15 (0.55)	reg_loss 0.09 (0.32)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00040]	Time 0.30 (0.30)	Loss 0.50 (0.50)
		cls_loss 0.37 (0.37)	reg_loss 0.13 (0.13)
Epoch: [009][00020/00040]	Time 0.22 (0.26)	Loss 0.26 (0.38)
		cls_loss 0.16 (0.27)	reg_loss 0.10 (0.11)
Epoch: [009][00030/00040]	Time 0.23 (0.25)	Loss 0.11 (0.29)
		cls_loss 0.07 (0.20)	reg_loss 0.04 (0.09)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00040]	Time 0.28 (0.28)	Loss 0.32 (0.32)
		cls_loss 0.22 (0.22)	reg_loss 0.09 (0.09)
Epoch: [010][00020/00040]	Time 0.23 (0.25)	Loss 0.29 (0.30)
		cls_loss 0.14 (0.18)	reg_loss 0.15 (0.12)
Epoch: [010][00030/00040]	Time 0.23 (0.24)	Loss 0.30 (0.30)
		cls_loss 0.19 (0.18)	reg_loss 0.11 (0.12)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00040]	Time 0.26 (0.26)	Loss 0.16 (0.16)
		cls_loss 0.10 (0.10)	reg_loss 0.06 (0.06)
Epoch: [011][00020/00040]	Time 0.23 (0.25)	Loss 0.67 (0.42)
		cls_loss 0.39 (0.25)	reg_loss 0.28 (0.17)
Epoch: [011][00030/00040]	Time 0.23 (0.24)	Loss 0.09 (0.31)
		cls_loss 0.05 (0.18)	reg_loss 0.04 (0.13)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00040]	Time 0.27 (0.27)	Loss 0.30 (0.30)
		cls_loss 0.22 (0.22)	reg_loss 0.08 (0.08)
Epoch: [012][00020/00040]	Time 0.22 (0.25)	Loss 0.12 (0.21)
		cls_loss 0.08 (0.15)	reg_loss 0.04 (0.06)
Epoch: [012][00030/00040]	Time 0.23 (0.24)	Loss 0.20 (0.21)
		cls_loss 0.12 (0.14)	reg_loss 0.08 (0.07)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00040]	Time 0.28 (0.28)	Loss 0.76 (0.76)
		cls_loss 0.39 (0.39)	reg_loss 0.37 (0.37)
Epoch: [013][00020/00040]	Time 0.23 (0.25)	Loss 0.93 (0.84)
		cls_loss 0.46 (0.43)	reg_loss 0.47 (0.42)
Epoch: [013][00030/00040]	Time 0.23 (0.25)	Loss 0.15 (0.61)
		cls_loss 0.08 (0.31)	reg_loss 0.07 (0.30)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00040]	Time 0.29 (0.29)	Loss 0.57 (0.57)
		cls_loss 0.35 (0.35)	reg_loss 0.22 (0.22)
Epoch: [014][00020/00040]	Time 0.23 (0.26)	Loss 0.07 (0.32)
		cls_loss 0.05 (0.20)	reg_loss 0.03 (0.12)
Epoch: [014][00030/00040]	Time 0.23 (0.25)	Loss 2.25 (0.96)
		cls_loss 1.74 (0.71)	reg_loss 0.51 (0.25)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00040]	Time 0.28 (0.28)	Loss 1.40 (1.40)
		cls_loss 0.98 (0.98)	reg_loss 0.43 (0.43)
Epoch: [015][00020/00040]	Time 0.23 (0.26)	Loss 0.84 (1.12)
		cls_loss 0.61 (0.79)	reg_loss 0.23 (0.33)
Epoch: [015][00030/00040]	Time 0.27 (0.26)	Loss 0.69 (0.98)
		cls_loss 0.43 (0.67)	reg_loss 0.26 (0.31)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00040]	Time 0.28 (0.28)	Loss 0.73 (0.73)
		cls_loss 0.40 (0.40)	reg_loss 0.33 (0.33)
Epoch: [016][00020/00040]	Time 0.23 (0.25)	Loss 1.25 (0.99)
		cls_loss 0.74 (0.57)	reg_loss 0.51 (0.42)
Epoch: [016][00030/00040]	Time 0.22 (0.24)	Loss 0.20 (0.73)
		cls_loss 0.12 (0.42)	reg_loss 0.08 (0.31)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00040]	Time 0.28 (0.28)	Loss 0.68 (0.68)
		cls_loss 0.41 (0.41)	reg_loss 0.26 (0.26)
Epoch: [017][00020/00040]	Time 0.30 (0.29)	Loss 0.10 (0.39)
		cls_loss 0.05 (0.23)	reg_loss 0.04 (0.15)
Epoch: [017][00030/00040]	Time 0.28 (0.29)	Loss 0.21 (0.33)
		cls_loss 0.12 (0.20)	reg_loss 0.09 (0.13)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00040]	Time 0.27 (0.27)	Loss 0.36 (0.36)
		cls_loss 0.24 (0.24)	reg_loss 0.12 (0.12)
Epoch: [018][00020/00040]	Time 0.23 (0.25)	Loss 0.31 (0.34)
		cls_loss 0.19 (0.22)	reg_loss 0.13 (0.12)
Epoch: [018][00030/00040]	Time 0.23 (0.24)	Loss 0.53 (0.40)
		cls_loss 0.34 (0.26)	reg_loss 0.19 (0.15)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00040]	Time 0.28 (0.28)	Loss 0.49 (0.49)
		cls_loss 0.26 (0.26)	reg_loss 0.22 (0.22)
Epoch: [019][00020/00040]	Time 0.23 (0.26)	Loss 0.22 (0.35)
		cls_loss 0.13 (0.20)	reg_loss 0.10 (0.16)
Epoch: [019][00030/00040]	Time 0.23 (0.25)	Loss 1.02 (0.58)
		cls_loss 0.52 (0.30)	reg_loss 0.50 (0.27)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00040]	Time 0.29 (0.29)	Loss 0.29 (0.29)
		cls_loss 0.18 (0.18)	reg_loss 0.12 (0.12)
Epoch: [020][00020/00040]	Time 0.23 (0.26)	Loss 0.42 (0.36)
		cls_loss 0.23 (0.21)	reg_loss 0.19 (0.15)
Epoch: [020][00030/00040]	Time 0.22 (0.25)	Loss 0.07 (0.26)
		cls_loss 0.04 (0.15)	reg_loss 0.03 (0.11)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00040]	Time 0.29 (0.29)	Loss 0.27 (0.27)
		cls_loss 0.14 (0.14)	reg_loss 0.13 (0.13)
Epoch: [021][00020/00040]	Time 0.22 (0.26)	Loss 0.06 (0.17)
		cls_loss 0.03 (0.09)	reg_loss 0.03 (0.08)
Epoch: [021][00030/00040]	Time 0.23 (0.25)	Loss 0.18 (0.17)
		cls_loss 0.09 (0.09)	reg_loss 0.09 (0.08)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00040]	Time 0.29 (0.29)	Loss 0.08 (0.08)
		cls_loss 0.05 (0.05)	reg_loss 0.04 (0.04)
Epoch: [022][00020/00040]	Time 0.22 (0.26)	Loss 0.58 (0.33)
		cls_loss 0.34 (0.19)	reg_loss 0.25 (0.14)
Epoch: [022][00030/00040]	Time 0.22 (0.25)	Loss 0.57 (0.41)
		cls_loss 0.28 (0.22)	reg_loss 0.29 (0.19)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00040]	Time 0.27 (0.27)	Loss 0.15 (0.15)
		cls_loss 0.08 (0.08)	reg_loss 0.07 (0.07)
Epoch: [023][00020/00040]	Time 0.23 (0.25)	Loss 0.22 (0.19)
		cls_loss 0.15 (0.11)	reg_loss 0.07 (0.07)
Epoch: [023][00030/00040]	Time 0.26 (0.25)	Loss 0.21 (0.20)
		cls_loss 0.11 (0.11)	reg_loss 0.10 (0.08)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00040]	Time 0.47 (0.47)	Loss 0.20 (0.20)
		cls_loss 0.11 (0.11)	reg_loss 0.09 (0.09)
Epoch: [024][00020/00040]	Time 0.39 (0.43)	Loss 0.29 (0.25)
		cls_loss 0.14 (0.12)	reg_loss 0.15 (0.12)
Epoch: [024][00030/00040]	Time 0.23 (0.37)	Loss 0.39 (0.29)
		cls_loss 0.19 (0.15)	reg_loss 0.20 (0.15)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00040]	Time 0.28 (0.28)	Loss 0.70 (0.70)
		cls_loss 0.37 (0.37)	reg_loss 0.33 (0.33)
Epoch: [025][00020/00040]	Time 0.23 (0.25)	Loss 0.15 (0.43)
		cls_loss 0.08 (0.23)	reg_loss 0.07 (0.20)
Epoch: [025][00030/00040]	Time 0.23 (0.25)	Loss 0.11 (0.32)
		cls_loss 0.06 (0.17)	reg_loss 0.05 (0.15)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00040]	Time 0.27 (0.27)	Loss 0.70 (0.70)
		cls_loss 0.37 (0.37)	reg_loss 0.33 (0.33)
Epoch: [026][00020/00040]	Time 0.23 (0.25)	Loss 0.17 (0.43)
		cls_loss 0.09 (0.23)	reg_loss 0.08 (0.20)
Epoch: [026][00030/00040]	Time 0.24 (0.24)	Loss 0.19 (0.35)
		cls_loss 0.11 (0.19)	reg_loss 0.08 (0.16)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00040]	Time 0.29 (0.29)	Loss 0.24 (0.24)
		cls_loss 0.13 (0.13)	reg_loss 0.11 (0.11)
Epoch: [027][00020/00040]	Time 0.22 (0.26)	Loss 0.80 (0.52)
		cls_loss 0.39 (0.26)	reg_loss 0.41 (0.26)
Epoch: [027][00030/00040]	Time 0.23 (0.25)	Loss 0.34 (0.46)
		cls_loss 0.17 (0.23)	reg_loss 0.17 (0.23)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00040]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.07 (0.07)	reg_loss 0.06 (0.06)
Epoch: [028][00020/00040]	Time 0.23 (0.25)	Loss 0.29 (0.21)
		cls_loss 0.15 (0.11)	reg_loss 0.15 (0.10)
Epoch: [028][00030/00040]	Time 0.22 (0.24)	Loss 0.25 (0.23)
		cls_loss 0.14 (0.12)	reg_loss 0.11 (0.11)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00040]	Time 0.29 (0.29)	Loss 0.11 (0.11)
		cls_loss 0.06 (0.06)	reg_loss 0.05 (0.05)
Epoch: [029][00020/00040]	Time 0.23 (0.26)	Loss 0.06 (0.09)
		cls_loss 0.04 (0.05)	reg_loss 0.02 (0.04)
Epoch: [029][00030/00040]	Time 0.23 (0.25)	Loss 0.45 (0.21)
		cls_loss 0.24 (0.11)	reg_loss 0.21 (0.09)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00040]	Time 0.27 (0.27)	Loss 0.25 (0.25)
		cls_loss 0.15 (0.15)	reg_loss 0.10 (0.10)
Epoch: [030][00020/00040]	Time 0.23 (0.25)	Loss 0.46 (0.35)
		cls_loss 0.24 (0.19)	reg_loss 0.22 (0.16)
Epoch: [030][00030/00040]	Time 0.23 (0.24)	Loss 0.43 (0.38)
		cls_loss 0.23 (0.20)	reg_loss 0.20 (0.17)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00040]	Time 0.30 (0.30)	Loss 0.05 (0.05)
		cls_loss 0.03 (0.03)	reg_loss 0.02 (0.02)
Epoch: [031][00020/00040]	Time 0.23 (0.26)	Loss 0.91 (0.48)
		cls_loss 0.51 (0.27)	reg_loss 0.40 (0.21)
Epoch: [031][00030/00040]	Time 0.23 (0.25)	Loss 0.23 (0.40)
		cls_loss 0.12 (0.22)	reg_loss 0.11 (0.18)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00040]	Time 0.29 (0.29)	Loss 0.25 (0.25)
		cls_loss 0.14 (0.14)	reg_loss 0.11 (0.11)
Epoch: [032][00020/00040]	Time 0.23 (0.26)	Loss 0.24 (0.25)
		cls_loss 0.14 (0.14)	reg_loss 0.10 (0.10)
Epoch: [032][00030/00040]	Time 0.23 (0.25)	Loss 0.59 (0.36)
		cls_loss 0.33 (0.20)	reg_loss 0.26 (0.16)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00040]	Time 0.27 (0.27)	Loss 0.04 (0.04)
		cls_loss 0.02 (0.02)	reg_loss 0.01 (0.01)
Epoch: [033][00020/00040]	Time 0.23 (0.25)	Loss 0.38 (0.21)
		cls_loss 0.22 (0.12)	reg_loss 0.16 (0.09)
Epoch: [033][00030/00040]	Time 0.23 (0.24)	Loss 0.80 (0.41)
		cls_loss 0.41 (0.22)	reg_loss 0.39 (0.19)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00040]	Time 0.28 (0.28)	Loss 0.09 (0.09)
		cls_loss 0.05 (0.05)	reg_loss 0.04 (0.04)
Epoch: [034][00020/00040]	Time 0.24 (0.26)	Loss 0.13 (0.11)
		cls_loss 0.07 (0.06)	reg_loss 0.06 (0.05)
Epoch: [034][00030/00040]	Time 0.23 (0.25)	Loss 0.19 (0.14)
		cls_loss 0.11 (0.08)	reg_loss 0.08 (0.06)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.51 (0.51)
Test: [00020/00212]	Time 0.09 (0.30)
Test: [00030/00212]	Time 0.09 (0.23)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.07 (0.16)
Test: [00070/00212]	Time 0.08 (0.15)
Test: [00080/00212]	Time 0.09 (0.14)
Test: [00090/00212]	Time 0.09 (0.13)
Test: [00100/00212]	Time 0.09 (0.13)
Test: [00110/00212]	Time 0.10 (0.13)
Test: [00120/00212]	Time 0.09 (0.12)
Test: [00130/00212]	Time 0.09 (0.12)
Test: [00140/00212]	Time 0.09 (0.12)
Test: [00150/00212]	Time 0.09 (0.12)
Test: [00160/00212]	Time 0.11 (0.12)
Test: [00170/00212]	Time 0.12 (0.12)
Test: [00180/00212]	Time 0.08 (0.12)
Test: [00190/00212]	Time 0.10 (0.11)
Test: [00200/00212]	Time 0.09 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 66.71 (%) Recall@1x = 75.83 (%) Recall@5x = 94.16 (%) 
|tIoU = 0.40: mAP = 59.51 (%) Recall@1x = 67.78 (%) Recall@5x = 90.40 (%) 
|tIoU = 0.50: mAP = 51.19 (%) Recall@1x = 60.36 (%) Recall@5x = 85.26 (%) 
|tIoU = 0.60: mAP = 38.98 (%) Recall@1x = 49.57 (%) Recall@5x = 73.51 (%) 
|tIoU = 0.70: mAP = 24.62 (%) Recall@1x = 37.49 (%) Recall@5x = 55.54 (%) 
Average mAP: 48.20 (%)
All done! Total time: 171.97 sec
Looking for a split for p=0.4
Found split for p=0.4
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00040]	Time 0.94 (0.94)	Loss 1.92 (1.92)
		cls_loss 1.22 (1.22)	reg_loss 0.70 (0.70)
Epoch: [000][00020/00040]	Time 0.24 (0.59)	Loss 0.98 (1.45)
		cls_loss 0.74 (0.98)	reg_loss 0.24 (0.47)
Epoch: [000][00030/00040]	Time 0.22 (0.46)	Loss 0.36 (1.08)
		cls_loss 0.27 (0.74)	reg_loss 0.09 (0.34)
[Train]: Epoch 0 finished with lr=0.00002010


[Train]: Epoch 1 started
Epoch: [001][00010/00040]	Time 0.27 (0.27)	Loss 3.09 (3.09)
		cls_loss 2.13 (2.13)	reg_loss 0.96 (0.96)
Epoch: [001][00020/00040]	Time 0.22 (0.25)	Loss 0.52 (1.81)
		cls_loss 0.36 (1.25)	reg_loss 0.16 (0.56)
Epoch: [001][00030/00040]	Time 0.22 (0.24)	Loss 2.26 (1.96)
		cls_loss 1.65 (1.38)	reg_loss 0.62 (0.58)
[Train]: Epoch 1 finished with lr=0.00004020


[Train]: Epoch 2 started
Epoch: [002][00010/00040]	Time 0.28 (0.28)	Loss 0.62 (0.62)
		cls_loss 0.40 (0.40)	reg_loss 0.22 (0.22)
Epoch: [002][00020/00040]	Time 0.22 (0.25)	Loss 1.05 (0.83)
		cls_loss 0.78 (0.59)	reg_loss 0.27 (0.25)
Epoch: [002][00030/00040]	Time 0.22 (0.24)	Loss 0.71 (0.79)
		cls_loss 0.50 (0.56)	reg_loss 0.21 (0.23)
[Train]: Epoch 2 finished with lr=0.00006030


[Train]: Epoch 3 started
Epoch: [003][00010/00040]	Time 0.28 (0.28)	Loss 1.60 (1.60)
		cls_loss 1.12 (1.12)	reg_loss 0.49 (0.49)
Epoch: [003][00020/00040]	Time 0.22 (0.25)	Loss 0.28 (0.94)
		cls_loss 0.22 (0.67)	reg_loss 0.06 (0.27)
Epoch: [003][00030/00040]	Time 0.22 (0.24)	Loss 1.44 (1.11)
		cls_loss 1.07 (0.80)	reg_loss 0.37 (0.31)
[Train]: Epoch 3 finished with lr=0.00008040


[Train]: Epoch 4 started
Epoch: [004][00010/00040]	Time 0.28 (0.28)	Loss 2.61 (2.61)
		cls_loss 1.81 (1.81)	reg_loss 0.80 (0.80)
Epoch: [004][00020/00040]	Time 0.22 (0.25)	Loss 1.10 (1.86)
		cls_loss 0.76 (1.28)	reg_loss 0.35 (0.57)
Epoch: [004][00030/00040]	Time 0.22 (0.24)	Loss 0.14 (1.29)
		cls_loss 0.09 (0.89)	reg_loss 0.05 (0.40)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00040]	Time 0.43 (0.43)	Loss 2.70 (2.70)
		cls_loss 1.70 (1.70)	reg_loss 1.00 (1.00)
Epoch: [005][00020/00040]	Time 0.50 (0.46)	Loss 0.92 (1.81)
		cls_loss 0.60 (1.15)	reg_loss 0.32 (0.66)
Epoch: [005][00030/00040]	Time 0.31 (0.41)	Loss 0.86 (1.49)
		cls_loss 0.53 (0.94)	reg_loss 0.34 (0.55)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00040]	Time 0.27 (0.27)	Loss 0.89 (0.89)
		cls_loss 0.52 (0.52)	reg_loss 0.37 (0.37)
Epoch: [006][00020/00040]	Time 0.23 (0.25)	Loss 0.40 (0.64)
		cls_loss 0.27 (0.39)	reg_loss 0.13 (0.25)
Epoch: [006][00030/00040]	Time 0.22 (0.24)	Loss 3.07 (1.45)
		cls_loss 2.08 (0.95)	reg_loss 0.99 (0.50)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00040]	Time 0.27 (0.27)	Loss 0.48 (0.48)
		cls_loss 0.31 (0.31)	reg_loss 0.17 (0.17)
Epoch: [007][00020/00040]	Time 0.23 (0.25)	Loss 1.69 (1.09)
		cls_loss 0.98 (0.64)	reg_loss 0.72 (0.44)
Epoch: [007][00030/00040]	Time 0.22 (0.24)	Loss 0.56 (0.91)
		cls_loss 0.33 (0.54)	reg_loss 0.23 (0.37)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00040]	Time 0.27 (0.27)	Loss 0.77 (0.77)
		cls_loss 0.55 (0.55)	reg_loss 0.22 (0.22)
Epoch: [008][00020/00040]	Time 0.22 (0.25)	Loss 0.21 (0.49)
		cls_loss 0.16 (0.35)	reg_loss 0.05 (0.14)
Epoch: [008][00030/00040]	Time 0.22 (0.24)	Loss 0.99 (0.66)
		cls_loss 0.62 (0.44)	reg_loss 0.37 (0.21)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00040]	Time 0.28 (0.28)	Loss 0.44 (0.44)
		cls_loss 0.27 (0.27)	reg_loss 0.17 (0.17)
Epoch: [009][00020/00040]	Time 0.23 (0.25)	Loss 0.31 (0.37)
		cls_loss 0.20 (0.24)	reg_loss 0.10 (0.14)
Epoch: [009][00030/00040]	Time 0.22 (0.24)	Loss 0.19 (0.31)
		cls_loss 0.11 (0.19)	reg_loss 0.08 (0.12)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00040]	Time 0.27 (0.27)	Loss 0.98 (0.98)
		cls_loss 0.60 (0.60)	reg_loss 0.38 (0.38)
Epoch: [010][00020/00040]	Time 0.23 (0.25)	Loss 0.41 (0.70)
		cls_loss 0.31 (0.46)	reg_loss 0.10 (0.24)
Epoch: [010][00030/00040]	Time 0.23 (0.24)	Loss 0.87 (0.75)
		cls_loss 0.51 (0.48)	reg_loss 0.35 (0.28)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00040]	Time 0.28 (0.28)	Loss 0.21 (0.21)
		cls_loss 0.14 (0.14)	reg_loss 0.07 (0.07)
Epoch: [011][00020/00040]	Time 0.22 (0.25)	Loss 1.51 (0.86)
		cls_loss 0.88 (0.51)	reg_loss 0.63 (0.35)
Epoch: [011][00030/00040]	Time 0.22 (0.24)	Loss 0.28 (0.67)
		cls_loss 0.15 (0.39)	reg_loss 0.13 (0.28)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00040]	Time 0.27 (0.27)	Loss 0.70 (0.70)
		cls_loss 0.45 (0.45)	reg_loss 0.25 (0.25)
Epoch: [012][00020/00040]	Time 0.23 (0.25)	Loss 0.43 (0.56)
		cls_loss 0.25 (0.35)	reg_loss 0.18 (0.22)
Epoch: [012][00030/00040]	Time 0.23 (0.24)	Loss 0.23 (0.45)
		cls_loss 0.15 (0.28)	reg_loss 0.08 (0.17)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00040]	Time 0.28 (0.28)	Loss 1.01 (1.01)
		cls_loss 0.58 (0.58)	reg_loss 0.43 (0.43)
Epoch: [013][00020/00040]	Time 0.22 (0.25)	Loss 1.53 (1.27)
		cls_loss 0.75 (0.67)	reg_loss 0.78 (0.60)
Epoch: [013][00030/00040]	Time 0.22 (0.24)	Loss 0.33 (0.96)
		cls_loss 0.18 (0.50)	reg_loss 0.15 (0.45)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00040]	Time 0.27 (0.27)	Loss 0.28 (0.28)
		cls_loss 0.20 (0.20)	reg_loss 0.08 (0.08)
Epoch: [014][00020/00040]	Time 0.23 (0.25)	Loss 0.83 (0.55)
		cls_loss 0.48 (0.34)	reg_loss 0.35 (0.22)
Epoch: [014][00030/00040]	Time 0.22 (0.24)	Loss 0.40 (0.50)
		cls_loss 0.26 (0.31)	reg_loss 0.14 (0.19)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00040]	Time 0.28 (0.28)	Loss 0.53 (0.53)
		cls_loss 0.29 (0.29)	reg_loss 0.24 (0.24)
Epoch: [015][00020/00040]	Time 0.22 (0.25)	Loss 0.28 (0.41)
		cls_loss 0.15 (0.22)	reg_loss 0.14 (0.19)
Epoch: [015][00030/00040]	Time 0.22 (0.24)	Loss 0.84 (0.55)
		cls_loss 0.46 (0.30)	reg_loss 0.38 (0.25)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00040]	Time 0.27 (0.27)	Loss 0.22 (0.22)
		cls_loss 0.15 (0.15)	reg_loss 0.07 (0.07)
Epoch: [016][00020/00040]	Time 0.22 (0.25)	Loss 1.32 (0.77)
		cls_loss 0.63 (0.39)	reg_loss 0.69 (0.38)
Epoch: [016][00030/00040]	Time 0.22 (0.24)	Loss 0.37 (0.63)
		cls_loss 0.22 (0.33)	reg_loss 0.15 (0.30)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00040]	Time 0.28 (0.28)	Loss 0.31 (0.31)
		cls_loss 0.21 (0.21)	reg_loss 0.10 (0.10)
Epoch: [017][00020/00040]	Time 0.22 (0.25)	Loss 0.37 (0.34)
		cls_loss 0.24 (0.23)	reg_loss 0.14 (0.12)
Epoch: [017][00030/00040]	Time 0.23 (0.24)	Loss 0.70 (0.46)
		cls_loss 0.42 (0.29)	reg_loss 0.29 (0.17)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00040]	Time 0.26 (0.26)	Loss 0.18 (0.18)
		cls_loss 0.11 (0.11)	reg_loss 0.07 (0.07)
Epoch: [018][00020/00040]	Time 0.23 (0.24)	Loss 0.16 (0.17)
		cls_loss 0.09 (0.10)	reg_loss 0.06 (0.07)
Epoch: [018][00030/00040]	Time 0.23 (0.24)	Loss 0.10 (0.15)
		cls_loss 0.06 (0.09)	reg_loss 0.04 (0.06)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00040]	Time 0.28 (0.28)	Loss 1.40 (1.40)
		cls_loss 0.82 (0.82)	reg_loss 0.59 (0.59)
Epoch: [019][00020/00040]	Time 0.22 (0.25)	Loss 0.68 (1.04)
		cls_loss 0.36 (0.59)	reg_loss 0.32 (0.45)
Epoch: [019][00030/00040]	Time 0.23 (0.24)	Loss 0.73 (0.94)
		cls_loss 0.43 (0.54)	reg_loss 0.30 (0.40)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00040]	Time 0.27 (0.27)	Loss 0.50 (0.50)
		cls_loss 0.35 (0.35)	reg_loss 0.15 (0.15)
Epoch: [020][00020/00040]	Time 0.22 (0.25)	Loss 0.12 (0.31)
		cls_loss 0.07 (0.21)	reg_loss 0.05 (0.10)
Epoch: [020][00030/00040]	Time 0.23 (0.24)	Loss 0.38 (0.33)
		cls_loss 0.22 (0.21)	reg_loss 0.15 (0.12)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00040]	Time 0.28 (0.28)	Loss 0.57 (0.57)
		cls_loss 0.31 (0.31)	reg_loss 0.26 (0.26)
Epoch: [021][00020/00040]	Time 0.22 (0.25)	Loss 0.59 (0.58)
		cls_loss 0.37 (0.34)	reg_loss 0.23 (0.24)
Epoch: [021][00030/00040]	Time 0.22 (0.24)	Loss 0.13 (0.43)
		cls_loss 0.07 (0.25)	reg_loss 0.06 (0.18)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00040]	Time 0.28 (0.28)	Loss 0.50 (0.50)
		cls_loss 0.28 (0.28)	reg_loss 0.22 (0.22)
Epoch: [022][00020/00040]	Time 0.23 (0.25)	Loss 0.26 (0.38)
		cls_loss 0.13 (0.21)	reg_loss 0.13 (0.17)
Epoch: [022][00030/00040]	Time 0.23 (0.24)	Loss 0.22 (0.33)
		cls_loss 0.14 (0.18)	reg_loss 0.08 (0.14)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00040]	Time 0.27 (0.27)	Loss 0.53 (0.53)
		cls_loss 0.29 (0.29)	reg_loss 0.24 (0.24)
Epoch: [023][00020/00040]	Time 0.22 (0.24)	Loss 0.10 (0.32)
		cls_loss 0.06 (0.17)	reg_loss 0.04 (0.14)
Epoch: [023][00030/00040]	Time 0.50 (0.33)	Loss 0.80 (0.48)
		cls_loss 0.43 (0.26)	reg_loss 0.37 (0.22)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00040]	Time 0.67 (0.67)	Loss 0.53 (0.53)
		cls_loss 0.29 (0.29)	reg_loss 0.24 (0.24)
Epoch: [024][00020/00040]	Time 0.22 (0.45)	Loss 0.09 (0.31)
		cls_loss 0.05 (0.17)	reg_loss 0.04 (0.14)
Epoch: [024][00030/00040]	Time 0.22 (0.37)	Loss 0.13 (0.25)
		cls_loss 0.07 (0.14)	reg_loss 0.05 (0.11)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00040]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.07 (0.07)	reg_loss 0.07 (0.07)
Epoch: [025][00020/00040]	Time 0.23 (0.25)	Loss 0.35 (0.24)
		cls_loss 0.18 (0.13)	reg_loss 0.17 (0.12)
Epoch: [025][00030/00040]	Time 0.22 (0.24)	Loss 0.32 (0.27)
		cls_loss 0.16 (0.14)	reg_loss 0.16 (0.13)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00040]	Time 0.28 (0.28)	Loss 1.01 (1.01)
		cls_loss 0.54 (0.54)	reg_loss 0.47 (0.47)
Epoch: [026][00020/00040]	Time 0.22 (0.25)	Loss 0.21 (0.61)
		cls_loss 0.11 (0.32)	reg_loss 0.10 (0.28)
Epoch: [026][00030/00040]	Time 0.22 (0.24)	Loss 0.03 (0.42)
		cls_loss 0.01 (0.22)	reg_loss 0.02 (0.20)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00040]	Time 0.27 (0.27)	Loss 0.11 (0.11)
		cls_loss 0.06 (0.06)	reg_loss 0.06 (0.06)
Epoch: [027][00020/00040]	Time 0.23 (0.25)	Loss 1.05 (0.58)
		cls_loss 0.46 (0.26)	reg_loss 0.58 (0.32)
Epoch: [027][00030/00040]	Time 0.22 (0.24)	Loss 0.14 (0.43)
		cls_loss 0.08 (0.20)	reg_loss 0.06 (0.23)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00040]	Time 0.27 (0.27)	Loss 0.16 (0.16)
		cls_loss 0.10 (0.10)	reg_loss 0.06 (0.06)
Epoch: [028][00020/00040]	Time 0.23 (0.25)	Loss 0.15 (0.15)
		cls_loss 0.10 (0.10)	reg_loss 0.05 (0.06)
Epoch: [028][00030/00040]	Time 0.22 (0.24)	Loss 0.42 (0.24)
		cls_loss 0.21 (0.14)	reg_loss 0.21 (0.11)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00040]	Time 0.28 (0.28)	Loss 0.08 (0.08)
		cls_loss 0.04 (0.04)	reg_loss 0.04 (0.04)
Epoch: [029][00020/00040]	Time 0.22 (0.25)	Loss 0.11 (0.09)
		cls_loss 0.07 (0.05)	reg_loss 0.04 (0.04)
Epoch: [029][00030/00040]	Time 0.23 (0.24)	Loss 0.75 (0.31)
		cls_loss 0.43 (0.18)	reg_loss 0.32 (0.13)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00040]	Time 0.28 (0.28)	Loss 0.28 (0.28)
		cls_loss 0.17 (0.17)	reg_loss 0.12 (0.12)
Epoch: [030][00020/00040]	Time 0.22 (0.25)	Loss 0.09 (0.19)
		cls_loss 0.05 (0.11)	reg_loss 0.04 (0.08)
Epoch: [030][00030/00040]	Time 0.22 (0.24)	Loss 0.45 (0.28)
		cls_loss 0.23 (0.15)	reg_loss 0.22 (0.12)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00040]	Time 0.28 (0.28)	Loss 0.11 (0.11)
		cls_loss 0.07 (0.07)	reg_loss 0.04 (0.04)
Epoch: [031][00020/00040]	Time 0.22 (0.25)	Loss 0.83 (0.47)
		cls_loss 0.38 (0.22)	reg_loss 0.45 (0.25)
Epoch: [031][00030/00040]	Time 0.23 (0.24)	Loss 0.32 (0.42)
		cls_loss 0.17 (0.21)	reg_loss 0.14 (0.21)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00040]	Time 0.28 (0.28)	Loss 0.51 (0.51)
		cls_loss 0.25 (0.25)	reg_loss 0.26 (0.26)
Epoch: [032][00020/00040]	Time 0.22 (0.25)	Loss 0.23 (0.37)
		cls_loss 0.14 (0.20)	reg_loss 0.09 (0.17)
Epoch: [032][00030/00040]	Time 0.23 (0.24)	Loss 0.20 (0.31)
		cls_loss 0.10 (0.17)	reg_loss 0.09 (0.15)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00040]	Time 0.27 (0.27)	Loss 0.30 (0.30)
		cls_loss 0.17 (0.17)	reg_loss 0.14 (0.14)
Epoch: [033][00020/00040]	Time 0.23 (0.25)	Loss 0.20 (0.25)
		cls_loss 0.11 (0.14)	reg_loss 0.09 (0.11)
Epoch: [033][00030/00040]	Time 0.22 (0.24)	Loss 0.20 (0.24)
		cls_loss 0.14 (0.14)	reg_loss 0.06 (0.10)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00040]	Time 0.28 (0.28)	Loss 0.31 (0.31)
		cls_loss 0.16 (0.16)	reg_loss 0.15 (0.15)
Epoch: [034][00020/00040]	Time 0.22 (0.25)	Loss 0.28 (0.29)
		cls_loss 0.16 (0.16)	reg_loss 0.12 (0.14)
Epoch: [034][00030/00040]	Time 0.23 (0.24)	Loss 0.11 (0.23)
		cls_loss 0.07 (0.13)	reg_loss 0.04 (0.11)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.52 (0.52)
Test: [00020/00212]	Time 0.09 (0.30)
Test: [00030/00212]	Time 0.09 (0.23)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.07 (0.16)
Test: [00070/00212]	Time 0.09 (0.15)
Test: [00080/00212]	Time 0.09 (0.14)
Test: [00090/00212]	Time 0.09 (0.14)
Test: [00100/00212]	Time 0.10 (0.13)
Test: [00110/00212]	Time 0.10 (0.13)
Test: [00120/00212]	Time 0.09 (0.13)
Test: [00130/00212]	Time 0.09 (0.12)
Test: [00140/00212]	Time 0.09 (0.12)
Test: [00150/00212]	Time 0.08 (0.12)
Test: [00160/00212]	Time 0.12 (0.12)
Test: [00170/00212]	Time 0.12 (0.12)
Test: [00180/00212]	Time 0.09 (0.12)
Test: [00190/00212]	Time 0.10 (0.12)
Test: [00200/00212]	Time 0.09 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 65.50 (%) Recall@1x = 77.08 (%) Recall@5x = 94.28 (%) 
|tIoU = 0.40: mAP = 58.82 (%) Recall@1x = 69.71 (%) Recall@5x = 90.79 (%) 
|tIoU = 0.50: mAP = 47.79 (%) Recall@1x = 59.89 (%) Recall@5x = 84.11 (%) 
|tIoU = 0.60: mAP = 36.59 (%) Recall@1x = 49.70 (%) Recall@5x = 72.89 (%) 
|tIoU = 0.70: mAP = 21.95 (%) Recall@1x = 35.71 (%) Recall@5x = 53.20 (%) 
Average mAP: 46.13 (%)
All done! Total time: 159.03 sec
