Looking for a split for p=1
Found split for p=1
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00100]	Time 3.71 (3.71)	Loss 1.85 (1.85)
		cls_loss 0.99 (0.99)	reg_loss 0.86 (0.86)
Epoch: [000][00020/00100]	Time 0.25 (1.98)	Loss 0.88 (1.37)
		cls_loss 0.56 (0.77)	reg_loss 0.32 (0.59)
Epoch: [000][00030/00100]	Time 0.23 (1.40)	Loss 2.30 (1.68)
		cls_loss 1.71 (1.09)	reg_loss 0.59 (0.59)
Epoch: [000][00040/00100]	Time 0.23 (1.10)	Loss 1.65 (1.67)
		cls_loss 1.27 (1.13)	reg_loss 0.38 (0.54)
Epoch: [000][00050/00100]	Time 0.23 (0.93)	Loss 1.14 (1.56)
		cls_loss 0.85 (1.08)	reg_loss 0.29 (0.49)
Epoch: [000][00060/00100]	Time 0.22 (0.81)	Loss 0.70 (1.42)
		cls_loss 0.52 (0.98)	reg_loss 0.18 (0.44)
Epoch: [000][00070/00100]	Time 0.23 (0.73)	Loss 1.96 (1.50)
		cls_loss 1.44 (1.05)	reg_loss 0.51 (0.45)
Epoch: [000][00080/00100]	Time 0.23 (0.67)	Loss 0.94 (1.43)
		cls_loss 0.72 (1.01)	reg_loss 0.22 (0.42)
Epoch: [000][00090/00100]	Time 0.23 (0.62)	Loss 0.47 (1.32)
		cls_loss 0.34 (0.93)	reg_loss 0.13 (0.39)
[Train]: Epoch 0 finished with lr=0.00002004


[Train]: Epoch 1 started
Epoch: [001][00010/00100]	Time 0.28 (0.28)	Loss 1.39 (1.39)
		cls_loss 0.87 (0.87)	reg_loss 0.52 (0.52)
Epoch: [001][00020/00100]	Time 0.23 (0.25)	Loss 0.61 (1.00)
		cls_loss 0.42 (0.65)	reg_loss 0.19 (0.35)
Epoch: [001][00030/00100]	Time 0.22 (0.24)	Loss 2.68 (1.56)
		cls_loss 1.80 (1.03)	reg_loss 0.88 (0.53)
Epoch: [001][00040/00100]	Time 0.23 (0.24)	Loss 1.84 (1.63)
		cls_loss 1.27 (1.09)	reg_loss 0.57 (0.54)
Epoch: [001][00050/00100]	Time 0.23 (0.24)	Loss 0.70 (1.44)
		cls_loss 0.43 (0.96)	reg_loss 0.27 (0.49)
Epoch: [001][00060/00100]	Time 0.23 (0.23)	Loss 0.66 (1.31)
		cls_loss 0.46 (0.87)	reg_loss 0.21 (0.44)
Epoch: [001][00070/00100]	Time 0.22 (0.23)	Loss 0.46 (1.19)
		cls_loss 0.32 (0.80)	reg_loss 0.13 (0.40)
Epoch: [001][00080/00100]	Time 0.23 (0.23)	Loss 0.31 (1.08)
		cls_loss 0.24 (0.73)	reg_loss 0.07 (0.35)
Epoch: [001][00090/00100]	Time 0.24 (0.23)	Loss 0.79 (1.05)
		cls_loss 0.61 (0.71)	reg_loss 0.19 (0.34)
[Train]: Epoch 1 finished with lr=0.00004008


[Train]: Epoch 2 started
Epoch: [002][00010/00100]	Time 0.29 (0.29)	Loss 2.17 (2.17)
		cls_loss 1.23 (1.23)	reg_loss 0.94 (0.94)
Epoch: [002][00020/00100]	Time 0.23 (0.26)	Loss 1.80 (1.99)
		cls_loss 1.01 (1.12)	reg_loss 0.79 (0.86)
Epoch: [002][00030/00100]	Time 0.23 (0.25)	Loss 1.71 (1.89)
		cls_loss 1.17 (1.14)	reg_loss 0.55 (0.76)
Epoch: [002][00040/00100]	Time 0.23 (0.24)	Loss 0.81 (1.62)
		cls_loss 0.61 (1.00)	reg_loss 0.21 (0.62)
Epoch: [002][00050/00100]	Time 0.23 (0.24)	Loss 1.25 (1.55)
		cls_loss 0.74 (0.95)	reg_loss 0.51 (0.60)
Epoch: [002][00060/00100]	Time 0.23 (0.24)	Loss 1.63 (1.56)
		cls_loss 1.11 (0.98)	reg_loss 0.53 (0.59)
Epoch: [002][00070/00100]	Time 0.23 (0.24)	Loss 1.48 (1.55)
		cls_loss 1.11 (1.00)	reg_loss 0.36 (0.55)
Epoch: [002][00080/00100]	Time 0.23 (0.24)	Loss 0.38 (1.40)
		cls_loss 0.27 (0.91)	reg_loss 0.11 (0.50)
Epoch: [002][00090/00100]	Time 0.23 (0.24)	Loss 0.81 (1.34)
		cls_loss 0.51 (0.86)	reg_loss 0.31 (0.48)
[Train]: Epoch 2 finished with lr=0.00006012


[Train]: Epoch 3 started
Epoch: [003][00010/00100]	Time 0.28 (0.28)	Loss 0.87 (0.87)
		cls_loss 0.57 (0.57)	reg_loss 0.29 (0.29)
Epoch: [003][00020/00100]	Time 0.23 (0.25)	Loss 1.60 (1.24)
		cls_loss 1.09 (0.83)	reg_loss 0.51 (0.40)
Epoch: [003][00030/00100]	Time 0.24 (0.25)	Loss 0.47 (0.98)
		cls_loss 0.29 (0.65)	reg_loss 0.17 (0.33)
Epoch: [003][00040/00100]	Time 0.22 (0.24)	Loss 1.22 (1.04)
		cls_loss 0.83 (0.70)	reg_loss 0.39 (0.34)
Epoch: [003][00050/00100]	Time 0.23 (0.24)	Loss 2.14 (1.26)
		cls_loss 1.42 (0.84)	reg_loss 0.72 (0.42)
Epoch: [003][00060/00100]	Time 0.24 (0.24)	Loss 0.54 (1.14)
		cls_loss 0.40 (0.77)	reg_loss 0.14 (0.37)
Epoch: [003][00070/00100]	Time 0.23 (0.24)	Loss 0.20 (1.01)
		cls_loss 0.15 (0.68)	reg_loss 0.05 (0.33)
Epoch: [003][00080/00100]	Time 0.23 (0.24)	Loss 1.77 (1.10)
		cls_loss 1.22 (0.75)	reg_loss 0.54 (0.35)
Epoch: [003][00090/00100]	Time 0.23 (0.24)	Loss 0.20 (1.00)
		cls_loss 0.14 (0.68)	reg_loss 0.06 (0.32)
[Train]: Epoch 3 finished with lr=0.00008016


[Train]: Epoch 4 started
Epoch: [004][00010/00100]	Time 0.30 (0.30)	Loss 0.10 (0.10)
		cls_loss 0.07 (0.07)	reg_loss 0.03 (0.03)
Epoch: [004][00020/00100]	Time 0.23 (0.27)	Loss 0.33 (0.22)
		cls_loss 0.24 (0.15)	reg_loss 0.09 (0.06)
Epoch: [004][00030/00100]	Time 0.22 (0.25)	Loss 1.38 (0.61)
		cls_loss 0.86 (0.39)	reg_loss 0.53 (0.22)
Epoch: [004][00040/00100]	Time 0.23 (0.25)	Loss 1.39 (0.80)
		cls_loss 0.76 (0.48)	reg_loss 0.63 (0.32)
Epoch: [004][00050/00100]	Time 0.23 (0.24)	Loss 1.18 (0.88)
		cls_loss 0.69 (0.52)	reg_loss 0.49 (0.36)
Epoch: [004][00060/00100]	Time 0.23 (0.24)	Loss 3.12 (1.25)
		cls_loss 2.12 (0.79)	reg_loss 1.00 (0.46)
Epoch: [004][00070/00100]	Time 0.22 (0.24)	Loss 0.38 (1.13)
		cls_loss 0.26 (0.71)	reg_loss 0.12 (0.41)
Epoch: [004][00080/00100]	Time 0.23 (0.24)	Loss 0.46 (1.04)
		cls_loss 0.31 (0.66)	reg_loss 0.16 (0.38)
Epoch: [004][00090/00100]	Time 0.24 (0.24)	Loss 0.31 (0.96)
		cls_loss 0.24 (0.61)	reg_loss 0.07 (0.35)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00100]	Time 0.30 (0.30)	Loss 0.70 (0.70)
		cls_loss 0.46 (0.46)	reg_loss 0.24 (0.24)
Epoch: [005][00020/00100]	Time 0.23 (0.26)	Loss 0.95 (0.82)
		cls_loss 0.55 (0.51)	reg_loss 0.40 (0.32)
Epoch: [005][00030/00100]	Time 0.23 (0.25)	Loss 1.17 (0.94)
		cls_loss 0.72 (0.58)	reg_loss 0.45 (0.36)
Epoch: [005][00040/00100]	Time 0.23 (0.24)	Loss 0.58 (0.85)
		cls_loss 0.37 (0.53)	reg_loss 0.21 (0.32)
Epoch: [005][00050/00100]	Time 0.23 (0.24)	Loss 0.15 (0.71)
		cls_loss 0.11 (0.44)	reg_loss 0.05 (0.27)
Epoch: [005][00060/00100]	Time 0.23 (0.24)	Loss 1.81 (0.89)
		cls_loss 1.02 (0.54)	reg_loss 0.80 (0.36)
Epoch: [005][00070/00100]	Time 0.23 (0.24)	Loss 0.40 (0.82)
		cls_loss 0.29 (0.50)	reg_loss 0.11 (0.32)
Epoch: [005][00080/00100]	Time 0.24 (0.24)	Loss 0.46 (0.78)
		cls_loss 0.28 (0.47)	reg_loss 0.18 (0.30)
Epoch: [005][00090/00100]	Time 0.23 (0.24)	Loss 0.35 (0.73)
		cls_loss 0.20 (0.44)	reg_loss 0.15 (0.29)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00100]	Time 0.29 (0.29)	Loss 0.82 (0.82)
		cls_loss 0.41 (0.41)	reg_loss 0.42 (0.42)
Epoch: [006][00020/00100]	Time 0.23 (0.26)	Loss 0.61 (0.72)
		cls_loss 0.36 (0.38)	reg_loss 0.26 (0.34)
Epoch: [006][00030/00100]	Time 0.23 (0.25)	Loss 0.49 (0.64)
		cls_loss 0.30 (0.35)	reg_loss 0.19 (0.29)
Epoch: [006][00040/00100]	Time 0.24 (0.25)	Loss 0.36 (0.57)
		cls_loss 0.20 (0.32)	reg_loss 0.15 (0.25)
Epoch: [006][00050/00100]	Time 0.23 (0.24)	Loss 0.64 (0.58)
		cls_loss 0.46 (0.34)	reg_loss 0.19 (0.24)
Epoch: [006][00060/00100]	Time 0.22 (0.24)	Loss 0.75 (0.61)
		cls_loss 0.41 (0.36)	reg_loss 0.34 (0.26)
Epoch: [006][00070/00100]	Time 0.23 (0.24)	Loss 0.57 (0.61)
		cls_loss 0.31 (0.35)	reg_loss 0.26 (0.26)
Epoch: [006][00080/00100]	Time 0.23 (0.24)	Loss 1.85 (0.76)
		cls_loss 1.15 (0.45)	reg_loss 0.70 (0.31)
Epoch: [006][00090/00100]	Time 0.23 (0.24)	Loss 0.13 (0.69)
		cls_loss 0.09 (0.41)	reg_loss 0.04 (0.28)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00100]	Time 0.29 (0.29)	Loss 0.71 (0.71)
		cls_loss 0.43 (0.43)	reg_loss 0.28 (0.28)
Epoch: [007][00020/00100]	Time 0.24 (0.26)	Loss 0.36 (0.53)
		cls_loss 0.25 (0.34)	reg_loss 0.11 (0.20)
Epoch: [007][00030/00100]	Time 0.23 (0.25)	Loss 0.27 (0.45)
		cls_loss 0.12 (0.27)	reg_loss 0.15 (0.18)
Epoch: [007][00040/00100]	Time 0.23 (0.25)	Loss 0.90 (0.56)
		cls_loss 0.50 (0.33)	reg_loss 0.40 (0.23)
Epoch: [007][00050/00100]	Time 0.23 (0.24)	Loss 0.56 (0.56)
		cls_loss 0.40 (0.34)	reg_loss 0.16 (0.22)
Epoch: [007][00060/00100]	Time 0.22 (0.24)	Loss 0.34 (0.52)
		cls_loss 0.22 (0.32)	reg_loss 0.11 (0.20)
Epoch: [007][00070/00100]	Time 0.24 (0.24)	Loss 0.30 (0.49)
		cls_loss 0.20 (0.30)	reg_loss 0.10 (0.19)
Epoch: [007][00080/00100]	Time 0.23 (0.24)	Loss 0.57 (0.50)
		cls_loss 0.36 (0.31)	reg_loss 0.21 (0.19)
Epoch: [007][00090/00100]	Time 0.23 (0.24)	Loss 0.59 (0.51)
		cls_loss 0.36 (0.32)	reg_loss 0.23 (0.19)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00100]	Time 0.30 (0.30)	Loss 0.52 (0.52)
		cls_loss 0.30 (0.30)	reg_loss 0.22 (0.22)
Epoch: [008][00020/00100]	Time 0.23 (0.26)	Loss 0.28 (0.40)
		cls_loss 0.17 (0.23)	reg_loss 0.12 (0.17)
Epoch: [008][00030/00100]	Time 0.23 (0.25)	Loss 1.51 (0.77)
		cls_loss 0.84 (0.44)	reg_loss 0.67 (0.34)
Epoch: [008][00040/00100]	Time 0.24 (0.25)	Loss 0.27 (0.65)
		cls_loss 0.19 (0.37)	reg_loss 0.08 (0.27)
Epoch: [008][00050/00100]	Time 0.23 (0.24)	Loss 0.98 (0.71)
		cls_loss 0.60 (0.42)	reg_loss 0.38 (0.29)
Epoch: [008][00060/00100]	Time 0.23 (0.24)	Loss 0.44 (0.67)
		cls_loss 0.28 (0.39)	reg_loss 0.17 (0.27)
Epoch: [008][00070/00100]	Time 0.23 (0.24)	Loss 0.45 (0.64)
		cls_loss 0.25 (0.37)	reg_loss 0.20 (0.26)
Epoch: [008][00080/00100]	Time 0.23 (0.24)	Loss 1.22 (0.71)
		cls_loss 0.74 (0.42)	reg_loss 0.48 (0.29)
Epoch: [008][00090/00100]	Time 0.23 (0.24)	Loss 0.24 (0.66)
		cls_loss 0.15 (0.39)	reg_loss 0.10 (0.27)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00100]	Time 0.28 (0.28)	Loss 0.45 (0.45)
		cls_loss 0.26 (0.26)	reg_loss 0.19 (0.19)
Epoch: [009][00020/00100]	Time 0.24 (0.26)	Loss 0.57 (0.51)
		cls_loss 0.35 (0.30)	reg_loss 0.22 (0.20)
Epoch: [009][00030/00100]	Time 0.23 (0.25)	Loss 1.53 (0.85)
		cls_loss 0.75 (0.45)	reg_loss 0.78 (0.40)
Epoch: [009][00040/00100]	Time 0.24 (0.25)	Loss 0.84 (0.85)
		cls_loss 0.57 (0.48)	reg_loss 0.28 (0.37)
Epoch: [009][00050/00100]	Time 0.23 (0.24)	Loss 0.76 (0.83)
		cls_loss 0.53 (0.49)	reg_loss 0.23 (0.34)
Epoch: [009][00060/00100]	Time 0.23 (0.24)	Loss 0.24 (0.73)
		cls_loss 0.17 (0.44)	reg_loss 0.07 (0.29)
Epoch: [009][00070/00100]	Time 0.23 (0.24)	Loss 0.49 (0.70)
		cls_loss 0.28 (0.42)	reg_loss 0.21 (0.28)
Epoch: [009][00080/00100]	Time 0.23 (0.24)	Loss 2.45 (0.92)
		cls_loss 1.69 (0.57)	reg_loss 0.77 (0.34)
Epoch: [009][00090/00100]	Time 0.23 (0.24)	Loss 0.29 (0.85)
		cls_loss 0.15 (0.53)	reg_loss 0.14 (0.32)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00100]	Time 0.28 (0.28)	Loss 0.44 (0.44)
		cls_loss 0.24 (0.24)	reg_loss 0.20 (0.20)
Epoch: [010][00020/00100]	Time 0.23 (0.26)	Loss 0.41 (0.42)
		cls_loss 0.29 (0.27)	reg_loss 0.12 (0.16)
Epoch: [010][00030/00100]	Time 0.24 (0.25)	Loss 0.23 (0.36)
		cls_loss 0.16 (0.23)	reg_loss 0.07 (0.13)
Epoch: [010][00040/00100]	Time 0.23 (0.25)	Loss 1.00 (0.52)
		cls_loss 0.57 (0.32)	reg_loss 0.43 (0.20)
Epoch: [010][00050/00100]	Time 0.23 (0.24)	Loss 0.25 (0.47)
		cls_loss 0.15 (0.28)	reg_loss 0.11 (0.19)
Epoch: [010][00060/00100]	Time 0.23 (0.24)	Loss 0.30 (0.44)
		cls_loss 0.18 (0.27)	reg_loss 0.12 (0.17)
Epoch: [010][00070/00100]	Time 0.23 (0.24)	Loss 1.47 (0.59)
		cls_loss 1.04 (0.38)	reg_loss 0.43 (0.21)
Epoch: [010][00080/00100]	Time 0.23 (0.24)	Loss 0.53 (0.58)
		cls_loss 0.35 (0.37)	reg_loss 0.18 (0.21)
Epoch: [010][00090/00100]	Time 0.24 (0.24)	Loss 0.30 (0.55)
		cls_loss 0.17 (0.35)	reg_loss 0.14 (0.20)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00100]	Time 0.29 (0.29)	Loss 0.23 (0.23)
		cls_loss 0.15 (0.15)	reg_loss 0.09 (0.09)
Epoch: [011][00020/00100]	Time 0.23 (0.26)	Loss 0.32 (0.28)
		cls_loss 0.17 (0.16)	reg_loss 0.15 (0.12)
Epoch: [011][00030/00100]	Time 0.23 (0.25)	Loss 0.16 (0.24)
		cls_loss 0.09 (0.14)	reg_loss 0.06 (0.10)
Epoch: [011][00040/00100]	Time 0.23 (0.25)	Loss 0.85 (0.39)
		cls_loss 0.49 (0.23)	reg_loss 0.36 (0.16)
Epoch: [011][00050/00100]	Time 0.23 (0.24)	Loss 0.25 (0.36)
		cls_loss 0.15 (0.21)	reg_loss 0.10 (0.15)
Epoch: [011][00060/00100]	Time 0.24 (0.24)	Loss 0.85 (0.44)
		cls_loss 0.44 (0.25)	reg_loss 0.40 (0.19)
Epoch: [011][00070/00100]	Time 0.23 (0.24)	Loss 1.27 (0.56)
		cls_loss 0.69 (0.31)	reg_loss 0.59 (0.25)
Epoch: [011][00080/00100]	Time 0.23 (0.24)	Loss 0.43 (0.55)
		cls_loss 0.23 (0.30)	reg_loss 0.20 (0.24)
Epoch: [011][00090/00100]	Time 0.24 (0.24)	Loss 0.43 (0.53)
		cls_loss 0.27 (0.30)	reg_loss 0.16 (0.23)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00100]	Time 0.30 (0.30)	Loss 0.48 (0.48)
		cls_loss 0.27 (0.27)	reg_loss 0.20 (0.20)
Epoch: [012][00020/00100]	Time 0.23 (0.26)	Loss 0.63 (0.55)
		cls_loss 0.39 (0.33)	reg_loss 0.24 (0.22)
Epoch: [012][00030/00100]	Time 0.24 (0.26)	Loss 0.62 (0.58)
		cls_loss 0.33 (0.33)	reg_loss 0.30 (0.25)
Epoch: [012][00040/00100]	Time 0.23 (0.25)	Loss 0.12 (0.46)
		cls_loss 0.07 (0.27)	reg_loss 0.05 (0.20)
Epoch: [012][00050/00100]	Time 0.23 (0.25)	Loss 0.66 (0.50)
		cls_loss 0.40 (0.29)	reg_loss 0.27 (0.21)
Epoch: [012][00060/00100]	Time 0.24 (0.24)	Loss 0.72 (0.54)
		cls_loss 0.44 (0.32)	reg_loss 0.28 (0.22)
Epoch: [012][00070/00100]	Time 0.23 (0.24)	Loss 1.17 (0.63)
		cls_loss 0.67 (0.37)	reg_loss 0.50 (0.26)
Epoch: [012][00080/00100]	Time 0.23 (0.24)	Loss 0.47 (0.61)
		cls_loss 0.27 (0.35)	reg_loss 0.20 (0.25)
Epoch: [012][00090/00100]	Time 0.23 (0.24)	Loss 0.11 (0.55)
		cls_loss 0.07 (0.32)	reg_loss 0.04 (0.23)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00100]	Time 0.27 (0.27)	Loss 0.36 (0.36)
		cls_loss 0.17 (0.17)	reg_loss 0.19 (0.19)
Epoch: [013][00020/00100]	Time 0.23 (0.25)	Loss 1.32 (0.84)
		cls_loss 0.71 (0.44)	reg_loss 0.62 (0.40)
Epoch: [013][00030/00100]	Time 0.23 (0.25)	Loss 0.42 (0.70)
		cls_loss 0.22 (0.37)	reg_loss 0.20 (0.33)
Epoch: [013][00040/00100]	Time 0.24 (0.24)	Loss 0.26 (0.59)
		cls_loss 0.16 (0.31)	reg_loss 0.11 (0.28)
Epoch: [013][00050/00100]	Time 0.22 (0.24)	Loss 0.11 (0.50)
		cls_loss 0.07 (0.27)	reg_loss 0.04 (0.23)
Epoch: [013][00060/00100]	Time 0.23 (0.24)	Loss 0.24 (0.45)
		cls_loss 0.15 (0.25)	reg_loss 0.09 (0.21)
Epoch: [013][00070/00100]	Time 0.24 (0.24)	Loss 0.09 (0.40)
		cls_loss 0.04 (0.22)	reg_loss 0.04 (0.18)
Epoch: [013][00080/00100]	Time 0.24 (0.24)	Loss 0.69 (0.44)
		cls_loss 0.37 (0.24)	reg_loss 0.32 (0.20)
Epoch: [013][00090/00100]	Time 0.23 (0.24)	Loss 0.19 (0.41)
		cls_loss 0.11 (0.22)	reg_loss 0.08 (0.19)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00100]	Time 0.28 (0.28)	Loss 0.35 (0.35)
		cls_loss 0.19 (0.19)	reg_loss 0.16 (0.16)
Epoch: [014][00020/00100]	Time 0.23 (0.26)	Loss 0.39 (0.37)
		cls_loss 0.20 (0.20)	reg_loss 0.19 (0.17)
Epoch: [014][00030/00100]	Time 0.24 (0.25)	Loss 0.23 (0.32)
		cls_loss 0.13 (0.17)	reg_loss 0.10 (0.15)
Epoch: [014][00040/00100]	Time 0.22 (0.24)	Loss 0.36 (0.33)
		cls_loss 0.22 (0.19)	reg_loss 0.14 (0.15)
Epoch: [014][00050/00100]	Time 0.30 (0.25)	Loss 0.41 (0.35)
		cls_loss 0.28 (0.20)	reg_loss 0.14 (0.14)
Epoch: [014][00060/00100]	Time 0.39 (0.28)	Loss 0.26 (0.33)
		cls_loss 0.19 (0.20)	reg_loss 0.08 (0.13)
Epoch: [014][00070/00100]	Time 0.23 (0.27)	Loss 1.13 (0.45)
		cls_loss 0.65 (0.27)	reg_loss 0.48 (0.18)
Epoch: [014][00080/00100]	Time 0.23 (0.27)	Loss 0.29 (0.43)
		cls_loss 0.15 (0.25)	reg_loss 0.14 (0.18)
Epoch: [014][00090/00100]	Time 0.23 (0.26)	Loss 0.35 (0.42)
		cls_loss 0.19 (0.24)	reg_loss 0.16 (0.17)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00100]	Time 0.52 (0.52)	Loss 0.15 (0.15)
		cls_loss 0.08 (0.08)	reg_loss 0.07 (0.07)
Epoch: [015][00020/00100]	Time 0.25 (0.39)	Loss 0.06 (0.10)
		cls_loss 0.03 (0.06)	reg_loss 0.02 (0.04)
Epoch: [015][00030/00100]	Time 0.23 (0.33)	Loss 0.38 (0.19)
		cls_loss 0.20 (0.11)	reg_loss 0.17 (0.09)
Epoch: [015][00040/00100]	Time 0.22 (0.31)	Loss 0.34 (0.23)
		cls_loss 0.19 (0.13)	reg_loss 0.15 (0.10)
Epoch: [015][00050/00100]	Time 0.44 (0.33)	Loss 0.30 (0.25)
		cls_loss 0.16 (0.13)	reg_loss 0.14 (0.11)
Epoch: [015][00060/00100]	Time 0.23 (0.32)	Loss 0.08 (0.22)
		cls_loss 0.04 (0.12)	reg_loss 0.04 (0.10)
Epoch: [015][00070/00100]	Time 0.23 (0.30)	Loss 0.64 (0.28)
		cls_loss 0.35 (0.15)	reg_loss 0.29 (0.13)
Epoch: [015][00080/00100]	Time 0.32 (0.31)	Loss 0.21 (0.27)
		cls_loss 0.12 (0.15)	reg_loss 0.09 (0.12)
Epoch: [015][00090/00100]	Time 0.23 (0.30)	Loss 0.28 (0.27)
		cls_loss 0.14 (0.15)	reg_loss 0.13 (0.12)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00100]	Time 0.52 (0.52)	Loss 0.13 (0.13)
		cls_loss 0.08 (0.08)	reg_loss 0.05 (0.05)
Epoch: [016][00020/00100]	Time 0.24 (0.38)	Loss 0.70 (0.42)
		cls_loss 0.38 (0.23)	reg_loss 0.32 (0.19)
Epoch: [016][00030/00100]	Time 0.23 (0.33)	Loss 0.51 (0.45)
		cls_loss 0.27 (0.24)	reg_loss 0.24 (0.20)
Epoch: [016][00040/00100]	Time 0.23 (0.30)	Loss 0.14 (0.37)
		cls_loss 0.07 (0.20)	reg_loss 0.07 (0.17)
Epoch: [016][00050/00100]	Time 0.23 (0.29)	Loss 0.26 (0.35)
		cls_loss 0.14 (0.19)	reg_loss 0.13 (0.16)
Epoch: [016][00060/00100]	Time 0.22 (0.28)	Loss 1.61 (0.56)
		cls_loss 0.90 (0.31)	reg_loss 0.70 (0.25)
Epoch: [016][00070/00100]	Time 0.23 (0.27)	Loss 0.61 (0.57)
		cls_loss 0.37 (0.31)	reg_loss 0.25 (0.25)
Epoch: [016][00080/00100]	Time 0.23 (0.26)	Loss 0.50 (0.56)
		cls_loss 0.30 (0.31)	reg_loss 0.20 (0.25)
Epoch: [016][00090/00100]	Time 0.23 (0.26)	Loss 0.25 (0.53)
		cls_loss 0.15 (0.29)	reg_loss 0.10 (0.23)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00100]	Time 0.28 (0.28)	Loss 0.12 (0.12)
		cls_loss 0.07 (0.07)	reg_loss 0.05 (0.05)
Epoch: [017][00020/00100]	Time 0.22 (0.25)	Loss 0.38 (0.25)
		cls_loss 0.24 (0.16)	reg_loss 0.14 (0.09)
Epoch: [017][00030/00100]	Time 0.23 (0.25)	Loss 0.48 (0.32)
		cls_loss 0.24 (0.19)	reg_loss 0.23 (0.14)
Epoch: [017][00040/00100]	Time 0.23 (0.24)	Loss 0.33 (0.33)
		cls_loss 0.18 (0.18)	reg_loss 0.15 (0.14)
Epoch: [017][00050/00100]	Time 0.22 (0.24)	Loss 0.48 (0.36)
		cls_loss 0.26 (0.20)	reg_loss 0.23 (0.16)
Epoch: [017][00060/00100]	Time 0.22 (0.24)	Loss 1.12 (0.48)
		cls_loss 0.68 (0.28)	reg_loss 0.44 (0.21)
Epoch: [017][00070/00100]	Time 0.23 (0.23)	Loss 0.63 (0.50)
		cls_loss 0.36 (0.29)	reg_loss 0.26 (0.21)
Epoch: [017][00080/00100]	Time 0.23 (0.23)	Loss 0.60 (0.52)
		cls_loss 0.32 (0.30)	reg_loss 0.28 (0.22)
Epoch: [017][00090/00100]	Time 0.23 (0.23)	Loss 0.39 (0.50)
		cls_loss 0.22 (0.29)	reg_loss 0.18 (0.22)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00100]	Time 0.29 (0.29)	Loss 0.83 (0.83)
		cls_loss 0.46 (0.46)	reg_loss 0.37 (0.37)
Epoch: [018][00020/00100]	Time 0.23 (0.26)	Loss 0.29 (0.56)
		cls_loss 0.18 (0.32)	reg_loss 0.11 (0.24)
Epoch: [018][00030/00100]	Time 0.23 (0.25)	Loss 0.31 (0.48)
		cls_loss 0.18 (0.27)	reg_loss 0.14 (0.21)
Epoch: [018][00040/00100]	Time 0.22 (0.24)	Loss 0.09 (0.38)
		cls_loss 0.05 (0.22)	reg_loss 0.04 (0.16)
Epoch: [018][00050/00100]	Time 0.23 (0.24)	Loss 0.31 (0.37)
		cls_loss 0.15 (0.20)	reg_loss 0.16 (0.16)
Epoch: [018][00060/00100]	Time 0.23 (0.24)	Loss 1.41 (0.54)
		cls_loss 0.72 (0.29)	reg_loss 0.69 (0.25)
Epoch: [018][00070/00100]	Time 0.23 (0.24)	Loss 1.45 (0.67)
		cls_loss 0.68 (0.35)	reg_loss 0.76 (0.33)
Epoch: [018][00080/00100]	Time 0.23 (0.24)	Loss 0.17 (0.61)
		cls_loss 0.09 (0.31)	reg_loss 0.08 (0.29)
Epoch: [018][00090/00100]	Time 0.23 (0.23)	Loss 0.17 (0.56)
		cls_loss 0.10 (0.29)	reg_loss 0.07 (0.27)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00100]	Time 0.27 (0.27)	Loss 0.10 (0.10)
		cls_loss 0.04 (0.04)	reg_loss 0.06 (0.06)
Epoch: [019][00020/00100]	Time 0.23 (0.25)	Loss 0.40 (0.25)
		cls_loss 0.24 (0.14)	reg_loss 0.16 (0.11)
Epoch: [019][00030/00100]	Time 0.23 (0.24)	Loss 0.23 (0.24)
		cls_loss 0.11 (0.13)	reg_loss 0.11 (0.11)
Epoch: [019][00040/00100]	Time 0.23 (0.24)	Loss 0.18 (0.23)
		cls_loss 0.10 (0.13)	reg_loss 0.08 (0.10)
Epoch: [019][00050/00100]	Time 0.23 (0.24)	Loss 0.04 (0.19)
		cls_loss 0.02 (0.10)	reg_loss 0.02 (0.08)
Epoch: [019][00060/00100]	Time 0.23 (0.23)	Loss 0.28 (0.20)
		cls_loss 0.16 (0.11)	reg_loss 0.12 (0.09)
Epoch: [019][00070/00100]	Time 0.22 (0.23)	Loss 0.38 (0.23)
		cls_loss 0.18 (0.12)	reg_loss 0.20 (0.11)
Epoch: [019][00080/00100]	Time 0.23 (0.23)	Loss 0.86 (0.31)
		cls_loss 0.53 (0.18)	reg_loss 0.33 (0.13)
Epoch: [019][00090/00100]	Time 0.23 (0.23)	Loss 0.24 (0.30)
		cls_loss 0.15 (0.17)	reg_loss 0.09 (0.13)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00100]	Time 0.29 (0.29)	Loss 0.38 (0.38)
		cls_loss 0.24 (0.24)	reg_loss 0.15 (0.15)
Epoch: [020][00020/00100]	Time 0.23 (0.26)	Loss 0.14 (0.26)
		cls_loss 0.07 (0.15)	reg_loss 0.07 (0.11)
Epoch: [020][00030/00100]	Time 0.23 (0.25)	Loss 0.15 (0.22)
		cls_loss 0.11 (0.14)	reg_loss 0.04 (0.09)
Epoch: [020][00040/00100]	Time 0.23 (0.24)	Loss 0.17 (0.21)
		cls_loss 0.10 (0.13)	reg_loss 0.07 (0.08)
Epoch: [020][00050/00100]	Time 0.22 (0.24)	Loss 0.03 (0.18)
		cls_loss 0.02 (0.11)	reg_loss 0.01 (0.07)
Epoch: [020][00060/00100]	Time 0.23 (0.24)	Loss 1.51 (0.40)
		cls_loss 0.88 (0.23)	reg_loss 0.63 (0.16)
Epoch: [020][00070/00100]	Time 0.22 (0.23)	Loss 0.86 (0.46)
		cls_loss 0.44 (0.26)	reg_loss 0.41 (0.20)
Epoch: [020][00080/00100]	Time 0.23 (0.23)	Loss 0.40 (0.45)
		cls_loss 0.22 (0.26)	reg_loss 0.18 (0.20)
Epoch: [020][00090/00100]	Time 0.23 (0.23)	Loss 0.09 (0.41)
		cls_loss 0.05 (0.24)	reg_loss 0.04 (0.18)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00100]	Time 0.27 (0.27)	Loss 0.14 (0.14)
		cls_loss 0.08 (0.08)	reg_loss 0.06 (0.06)
Epoch: [021][00020/00100]	Time 0.23 (0.25)	Loss 0.27 (0.20)
		cls_loss 0.17 (0.12)	reg_loss 0.10 (0.08)
Epoch: [021][00030/00100]	Time 0.23 (0.24)	Loss 0.52 (0.31)
		cls_loss 0.27 (0.17)	reg_loss 0.25 (0.14)
Epoch: [021][00040/00100]	Time 0.23 (0.24)	Loss 0.08 (0.25)
		cls_loss 0.04 (0.14)	reg_loss 0.03 (0.11)
Epoch: [021][00050/00100]	Time 0.23 (0.24)	Loss 0.23 (0.25)
		cls_loss 0.14 (0.14)	reg_loss 0.09 (0.11)
Epoch: [021][00060/00100]	Time 0.23 (0.24)	Loss 0.07 (0.22)
		cls_loss 0.04 (0.12)	reg_loss 0.03 (0.09)
Epoch: [021][00070/00100]	Time 0.23 (0.24)	Loss 0.21 (0.22)
		cls_loss 0.12 (0.12)	reg_loss 0.09 (0.09)
Epoch: [021][00080/00100]	Time 0.24 (0.24)	Loss 0.16 (0.21)
		cls_loss 0.12 (0.12)	reg_loss 0.05 (0.09)
Epoch: [021][00090/00100]	Time 0.23 (0.23)	Loss 0.35 (0.22)
		cls_loss 0.18 (0.13)	reg_loss 0.17 (0.10)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00100]	Time 0.28 (0.28)	Loss 0.38 (0.38)
		cls_loss 0.21 (0.21)	reg_loss 0.17 (0.17)
Epoch: [022][00020/00100]	Time 0.23 (0.25)	Loss 0.32 (0.35)
		cls_loss 0.18 (0.19)	reg_loss 0.14 (0.16)
Epoch: [022][00030/00100]	Time 0.23 (0.24)	Loss 0.16 (0.29)
		cls_loss 0.09 (0.16)	reg_loss 0.07 (0.13)
Epoch: [022][00040/00100]	Time 0.23 (0.24)	Loss 0.15 (0.25)
		cls_loss 0.09 (0.14)	reg_loss 0.07 (0.11)
Epoch: [022][00050/00100]	Time 0.23 (0.24)	Loss 0.43 (0.29)
		cls_loss 0.24 (0.16)	reg_loss 0.19 (0.13)
Epoch: [022][00060/00100]	Time 0.23 (0.24)	Loss 0.06 (0.25)
		cls_loss 0.04 (0.14)	reg_loss 0.02 (0.11)
Epoch: [022][00070/00100]	Time 0.23 (0.24)	Loss 0.59 (0.30)
		cls_loss 0.32 (0.17)	reg_loss 0.27 (0.13)
Epoch: [022][00080/00100]	Time 0.24 (0.24)	Loss 0.13 (0.28)
		cls_loss 0.07 (0.15)	reg_loss 0.06 (0.12)
Epoch: [022][00090/00100]	Time 0.23 (0.24)	Loss 0.09 (0.26)
		cls_loss 0.07 (0.15)	reg_loss 0.03 (0.11)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00100]	Time 0.28 (0.28)	Loss 0.39 (0.39)
		cls_loss 0.23 (0.23)	reg_loss 0.16 (0.16)
Epoch: [023][00020/00100]	Time 0.23 (0.25)	Loss 0.36 (0.38)
		cls_loss 0.20 (0.21)	reg_loss 0.16 (0.16)
Epoch: [023][00030/00100]	Time 0.23 (0.25)	Loss 0.05 (0.27)
		cls_loss 0.02 (0.15)	reg_loss 0.02 (0.12)
Epoch: [023][00040/00100]	Time 0.24 (0.24)	Loss 0.07 (0.22)
		cls_loss 0.04 (0.12)	reg_loss 0.03 (0.10)
Epoch: [023][00050/00100]	Time 0.23 (0.24)	Loss 0.59 (0.29)
		cls_loss 0.31 (0.16)	reg_loss 0.28 (0.13)
Epoch: [023][00060/00100]	Time 0.23 (0.24)	Loss 0.20 (0.28)
		cls_loss 0.10 (0.15)	reg_loss 0.10 (0.13)
Epoch: [023][00070/00100]	Time 0.23 (0.24)	Loss 0.57 (0.32)
		cls_loss 0.31 (0.17)	reg_loss 0.27 (0.15)
Epoch: [023][00080/00100]	Time 0.23 (0.24)	Loss 0.11 (0.29)
		cls_loss 0.07 (0.16)	reg_loss 0.04 (0.13)
Epoch: [023][00090/00100]	Time 0.23 (0.24)	Loss 0.08 (0.27)
		cls_loss 0.05 (0.15)	reg_loss 0.04 (0.12)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00100]	Time 0.27 (0.27)	Loss 0.50 (0.50)
		cls_loss 0.24 (0.24)	reg_loss 0.25 (0.25)
Epoch: [024][00020/00100]	Time 0.23 (0.25)	Loss 0.10 (0.30)
		cls_loss 0.05 (0.15)	reg_loss 0.05 (0.15)
Epoch: [024][00030/00100]	Time 0.23 (0.25)	Loss 0.17 (0.26)
		cls_loss 0.09 (0.13)	reg_loss 0.08 (0.13)
Epoch: [024][00040/00100]	Time 0.24 (0.24)	Loss 0.11 (0.22)
		cls_loss 0.06 (0.11)	reg_loss 0.05 (0.11)
Epoch: [024][00050/00100]	Time 0.23 (0.24)	Loss 0.85 (0.35)
		cls_loss 0.45 (0.18)	reg_loss 0.40 (0.17)
Epoch: [024][00060/00100]	Time 0.23 (0.24)	Loss 0.04 (0.30)
		cls_loss 0.02 (0.15)	reg_loss 0.01 (0.14)
Epoch: [024][00070/00100]	Time 0.23 (0.24)	Loss 0.40 (0.31)
		cls_loss 0.20 (0.16)	reg_loss 0.20 (0.15)
Epoch: [024][00080/00100]	Time 0.23 (0.24)	Loss 0.32 (0.31)
		cls_loss 0.16 (0.16)	reg_loss 0.16 (0.15)
Epoch: [024][00090/00100]	Time 0.23 (0.24)	Loss 0.51 (0.33)
		cls_loss 0.27 (0.17)	reg_loss 0.24 (0.16)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00100]	Time 0.29 (0.29)	Loss 0.20 (0.20)
		cls_loss 0.14 (0.14)	reg_loss 0.06 (0.06)
Epoch: [025][00020/00100]	Time 0.23 (0.26)	Loss 0.73 (0.46)
		cls_loss 0.35 (0.25)	reg_loss 0.37 (0.22)
Epoch: [025][00030/00100]	Time 0.23 (0.25)	Loss 0.16 (0.36)
		cls_loss 0.09 (0.19)	reg_loss 0.07 (0.17)
Epoch: [025][00040/00100]	Time 0.24 (0.25)	Loss 0.17 (0.31)
		cls_loss 0.08 (0.17)	reg_loss 0.09 (0.15)
Epoch: [025][00050/00100]	Time 0.24 (0.24)	Loss 0.17 (0.29)
		cls_loss 0.08 (0.15)	reg_loss 0.09 (0.14)
Epoch: [025][00060/00100]	Time 0.23 (0.24)	Loss 0.03 (0.24)
		cls_loss 0.02 (0.13)	reg_loss 0.01 (0.12)
Epoch: [025][00070/00100]	Time 0.23 (0.24)	Loss 0.09 (0.22)
		cls_loss 0.05 (0.12)	reg_loss 0.03 (0.10)
Epoch: [025][00080/00100]	Time 0.23 (0.24)	Loss 0.10 (0.21)
		cls_loss 0.05 (0.11)	reg_loss 0.04 (0.10)
Epoch: [025][00090/00100]	Time 0.23 (0.24)	Loss 0.79 (0.27)
		cls_loss 0.44 (0.15)	reg_loss 0.35 (0.12)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00100]	Time 0.28 (0.28)	Loss 0.54 (0.54)
		cls_loss 0.28 (0.28)	reg_loss 0.26 (0.26)
Epoch: [026][00020/00100]	Time 0.23 (0.25)	Loss 0.15 (0.35)
		cls_loss 0.08 (0.18)	reg_loss 0.07 (0.16)
Epoch: [026][00030/00100]	Time 0.23 (0.24)	Loss 0.33 (0.34)
		cls_loss 0.19 (0.18)	reg_loss 0.15 (0.16)
Epoch: [026][00040/00100]	Time 0.23 (0.24)	Loss 0.14 (0.29)
		cls_loss 0.08 (0.16)	reg_loss 0.06 (0.13)
Epoch: [026][00050/00100]	Time 0.24 (0.24)	Loss 0.05 (0.25)
		cls_loss 0.03 (0.13)	reg_loss 0.02 (0.11)
Epoch: [026][00060/00100]	Time 0.23 (0.24)	Loss 0.13 (0.23)
		cls_loss 0.07 (0.12)	reg_loss 0.05 (0.10)
Epoch: [026][00070/00100]	Time 0.23 (0.24)	Loss 0.26 (0.23)
		cls_loss 0.14 (0.13)	reg_loss 0.12 (0.11)
Epoch: [026][00080/00100]	Time 0.23 (0.24)	Loss 0.62 (0.28)
		cls_loss 0.36 (0.15)	reg_loss 0.26 (0.13)
Epoch: [026][00090/00100]	Time 0.23 (0.24)	Loss 0.09 (0.26)
		cls_loss 0.04 (0.14)	reg_loss 0.04 (0.12)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00100]	Time 0.30 (0.30)	Loss 0.24 (0.24)
		cls_loss 0.14 (0.14)	reg_loss 0.10 (0.10)
Epoch: [027][00020/00100]	Time 0.23 (0.26)	Loss 0.11 (0.17)
		cls_loss 0.05 (0.10)	reg_loss 0.06 (0.08)
Epoch: [027][00030/00100]	Time 0.24 (0.26)	Loss 0.65 (0.33)
		cls_loss 0.37 (0.19)	reg_loss 0.29 (0.15)
Epoch: [027][00040/00100]	Time 0.24 (0.25)	Loss 0.64 (0.41)
		cls_loss 0.33 (0.22)	reg_loss 0.31 (0.19)
Epoch: [027][00050/00100]	Time 0.24 (0.25)	Loss 0.03 (0.33)
		cls_loss 0.02 (0.18)	reg_loss 0.01 (0.15)
Epoch: [027][00060/00100]	Time 0.23 (0.25)	Loss 0.04 (0.29)
		cls_loss 0.02 (0.15)	reg_loss 0.02 (0.13)
Epoch: [027][00070/00100]	Time 0.23 (0.24)	Loss 0.41 (0.30)
		cls_loss 0.19 (0.16)	reg_loss 0.22 (0.14)
Epoch: [027][00080/00100]	Time 0.24 (0.24)	Loss 0.51 (0.33)
		cls_loss 0.27 (0.17)	reg_loss 0.24 (0.16)
Epoch: [027][00090/00100]	Time 0.24 (0.24)	Loss 0.35 (0.33)
		cls_loss 0.19 (0.18)	reg_loss 0.16 (0.16)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00100]	Time 0.29 (0.29)	Loss 0.70 (0.70)
		cls_loss 0.33 (0.33)	reg_loss 0.36 (0.36)
Epoch: [028][00020/00100]	Time 0.23 (0.26)	Loss 0.09 (0.40)
		cls_loss 0.06 (0.20)	reg_loss 0.04 (0.20)
Epoch: [028][00030/00100]	Time 0.23 (0.25)	Loss 0.12 (0.30)
		cls_loss 0.06 (0.15)	reg_loss 0.05 (0.15)
Epoch: [028][00040/00100]	Time 0.23 (0.25)	Loss 0.16 (0.27)
		cls_loss 0.08 (0.13)	reg_loss 0.09 (0.14)
Epoch: [028][00050/00100]	Time 0.24 (0.25)	Loss 0.03 (0.22)
		cls_loss 0.02 (0.11)	reg_loss 0.01 (0.11)
Epoch: [028][00060/00100]	Time 0.24 (0.25)	Loss 0.62 (0.29)
		cls_loss 0.34 (0.15)	reg_loss 0.28 (0.14)
Epoch: [028][00070/00100]	Time 0.23 (0.24)	Loss 0.24 (0.28)
		cls_loss 0.13 (0.15)	reg_loss 0.10 (0.13)
Epoch: [028][00080/00100]	Time 0.23 (0.24)	Loss 0.41 (0.30)
		cls_loss 0.24 (0.16)	reg_loss 0.17 (0.14)
Epoch: [028][00090/00100]	Time 0.23 (0.24)	Loss 0.08 (0.27)
		cls_loss 0.05 (0.15)	reg_loss 0.03 (0.13)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00100]	Time 0.28 (0.28)	Loss 0.56 (0.56)
		cls_loss 0.29 (0.29)	reg_loss 0.26 (0.26)
Epoch: [029][00020/00100]	Time 0.24 (0.26)	Loss 0.58 (0.57)
		cls_loss 0.33 (0.31)	reg_loss 0.25 (0.26)
Epoch: [029][00030/00100]	Time 0.24 (0.25)	Loss 0.31 (0.48)
		cls_loss 0.14 (0.25)	reg_loss 0.17 (0.23)
Epoch: [029][00040/00100]	Time 0.23 (0.24)	Loss 0.10 (0.39)
		cls_loss 0.05 (0.20)	reg_loss 0.05 (0.18)
Epoch: [029][00050/00100]	Time 0.24 (0.24)	Loss 0.13 (0.34)
		cls_loss 0.07 (0.18)	reg_loss 0.06 (0.16)
Epoch: [029][00060/00100]	Time 0.23 (0.24)	Loss 0.12 (0.30)
		cls_loss 0.06 (0.16)	reg_loss 0.06 (0.14)
Epoch: [029][00070/00100]	Time 0.23 (0.24)	Loss 0.20 (0.29)
		cls_loss 0.13 (0.15)	reg_loss 0.08 (0.13)
Epoch: [029][00080/00100]	Time 0.23 (0.24)	Loss 0.04 (0.26)
		cls_loss 0.03 (0.14)	reg_loss 0.02 (0.12)
Epoch: [029][00090/00100]	Time 0.23 (0.24)	Loss 0.17 (0.25)
		cls_loss 0.09 (0.13)	reg_loss 0.08 (0.11)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00100]	Time 0.28 (0.28)	Loss 0.06 (0.06)
		cls_loss 0.03 (0.03)	reg_loss 0.04 (0.04)
Epoch: [030][00020/00100]	Time 0.23 (0.26)	Loss 0.11 (0.09)
		cls_loss 0.06 (0.04)	reg_loss 0.05 (0.04)
Epoch: [030][00030/00100]	Time 0.23 (0.25)	Loss 0.31 (0.16)
		cls_loss 0.16 (0.08)	reg_loss 0.15 (0.08)
Epoch: [030][00040/00100]	Time 0.23 (0.24)	Loss 0.03 (0.13)
		cls_loss 0.02 (0.07)	reg_loss 0.01 (0.06)
Epoch: [030][00050/00100]	Time 0.23 (0.24)	Loss 0.14 (0.13)
		cls_loss 0.06 (0.07)	reg_loss 0.07 (0.06)
Epoch: [030][00060/00100]	Time 0.24 (0.24)	Loss 0.32 (0.16)
		cls_loss 0.19 (0.09)	reg_loss 0.12 (0.07)
Epoch: [030][00070/00100]	Time 0.23 (0.24)	Loss 0.11 (0.15)
		cls_loss 0.06 (0.08)	reg_loss 0.06 (0.07)
Epoch: [030][00080/00100]	Time 0.24 (0.24)	Loss 0.05 (0.14)
		cls_loss 0.03 (0.08)	reg_loss 0.02 (0.06)
Epoch: [030][00090/00100]	Time 0.23 (0.24)	Loss 0.63 (0.20)
		cls_loss 0.29 (0.10)	reg_loss 0.34 (0.10)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00100]	Time 0.28 (0.28)	Loss 0.08 (0.08)
		cls_loss 0.04 (0.04)	reg_loss 0.04 (0.04)
Epoch: [031][00020/00100]	Time 0.23 (0.26)	Loss 0.05 (0.07)
		cls_loss 0.02 (0.03)	reg_loss 0.03 (0.04)
Epoch: [031][00030/00100]	Time 0.24 (0.25)	Loss 0.12 (0.08)
		cls_loss 0.10 (0.05)	reg_loss 0.02 (0.03)
Epoch: [031][00040/00100]	Time 0.23 (0.25)	Loss 0.16 (0.10)
		cls_loss 0.10 (0.06)	reg_loss 0.07 (0.04)
Epoch: [031][00050/00100]	Time 0.24 (0.25)	Loss 0.53 (0.19)
		cls_loss 0.26 (0.10)	reg_loss 0.27 (0.09)
Epoch: [031][00060/00100]	Time 0.24 (0.24)	Loss 0.12 (0.18)
		cls_loss 0.05 (0.09)	reg_loss 0.06 (0.08)
Epoch: [031][00070/00100]	Time 0.23 (0.24)	Loss 0.39 (0.21)
		cls_loss 0.21 (0.11)	reg_loss 0.18 (0.10)
Epoch: [031][00080/00100]	Time 0.24 (0.24)	Loss 0.28 (0.22)
		cls_loss 0.16 (0.12)	reg_loss 0.12 (0.10)
Epoch: [031][00090/00100]	Time 0.24 (0.24)	Loss 0.07 (0.20)
		cls_loss 0.05 (0.11)	reg_loss 0.03 (0.09)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00100]	Time 0.30 (0.30)	Loss 0.07 (0.07)
		cls_loss 0.04 (0.04)	reg_loss 0.02 (0.02)
Epoch: [032][00020/00100]	Time 0.23 (0.27)	Loss 0.08 (0.07)
		cls_loss 0.05 (0.05)	reg_loss 0.03 (0.03)
Epoch: [032][00030/00100]	Time 0.23 (0.25)	Loss 0.05 (0.07)
		cls_loss 0.02 (0.04)	reg_loss 0.02 (0.03)
Epoch: [032][00040/00100]	Time 0.23 (0.25)	Loss 0.06 (0.06)
		cls_loss 0.04 (0.04)	reg_loss 0.02 (0.02)
Epoch: [032][00050/00100]	Time 0.23 (0.24)	Loss 0.26 (0.10)
		cls_loss 0.14 (0.06)	reg_loss 0.12 (0.04)
Epoch: [032][00060/00100]	Time 0.23 (0.24)	Loss 0.69 (0.20)
		cls_loss 0.33 (0.10)	reg_loss 0.36 (0.10)
Epoch: [032][00070/00100]	Time 0.24 (0.24)	Loss 0.26 (0.21)
		cls_loss 0.17 (0.11)	reg_loss 0.08 (0.09)
Epoch: [032][00080/00100]	Time 0.24 (0.24)	Loss 0.05 (0.19)
		cls_loss 0.02 (0.10)	reg_loss 0.02 (0.09)
Epoch: [032][00090/00100]	Time 0.23 (0.24)	Loss 0.38 (0.21)
		cls_loss 0.21 (0.12)	reg_loss 0.17 (0.09)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00100]	Time 0.27 (0.27)	Loss 0.16 (0.16)
		cls_loss 0.08 (0.08)	reg_loss 0.08 (0.08)
Epoch: [033][00020/00100]	Time 0.23 (0.25)	Loss 0.11 (0.13)
		cls_loss 0.06 (0.07)	reg_loss 0.04 (0.06)
Epoch: [033][00030/00100]	Time 0.24 (0.25)	Loss 0.05 (0.10)
		cls_loss 0.03 (0.06)	reg_loss 0.02 (0.05)
Epoch: [033][00040/00100]	Time 0.23 (0.24)	Loss 0.12 (0.11)
		cls_loss 0.06 (0.06)	reg_loss 0.06 (0.05)
Epoch: [033][00050/00100]	Time 0.23 (0.24)	Loss 0.18 (0.12)
		cls_loss 0.09 (0.07)	reg_loss 0.09 (0.06)
Epoch: [033][00060/00100]	Time 0.24 (0.24)	Loss 0.45 (0.18)
		cls_loss 0.24 (0.10)	reg_loss 0.21 (0.08)
Epoch: [033][00070/00100]	Time 0.23 (0.24)	Loss 0.07 (0.16)
		cls_loss 0.04 (0.09)	reg_loss 0.03 (0.07)
Epoch: [033][00080/00100]	Time 0.23 (0.24)	Loss 0.65 (0.22)
		cls_loss 0.35 (0.12)	reg_loss 0.30 (0.10)
Epoch: [033][00090/00100]	Time 0.23 (0.24)	Loss 0.17 (0.22)
		cls_loss 0.09 (0.12)	reg_loss 0.08 (0.10)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00100]	Time 0.29 (0.29)	Loss 0.12 (0.12)
		cls_loss 0.07 (0.07)	reg_loss 0.05 (0.05)
Epoch: [034][00020/00100]	Time 0.23 (0.26)	Loss 0.12 (0.12)
		cls_loss 0.06 (0.07)	reg_loss 0.06 (0.05)
Epoch: [034][00030/00100]	Time 0.23 (0.25)	Loss 0.96 (0.40)
		cls_loss 0.42 (0.18)	reg_loss 0.54 (0.21)
Epoch: [034][00040/00100]	Time 0.23 (0.25)	Loss 0.56 (0.44)
		cls_loss 0.27 (0.21)	reg_loss 0.29 (0.23)
Epoch: [034][00050/00100]	Time 0.23 (0.24)	Loss 0.50 (0.45)
		cls_loss 0.25 (0.21)	reg_loss 0.25 (0.24)
Epoch: [034][00060/00100]	Time 0.24 (0.24)	Loss 0.06 (0.39)
		cls_loss 0.03 (0.18)	reg_loss 0.03 (0.20)
Epoch: [034][00070/00100]	Time 0.23 (0.24)	Loss 0.22 (0.36)
		cls_loss 0.15 (0.18)	reg_loss 0.07 (0.18)
Epoch: [034][00080/00100]	Time 0.23 (0.24)	Loss 0.64 (0.40)
		cls_loss 0.32 (0.20)	reg_loss 0.32 (0.20)
Epoch: [034][00090/00100]	Time 0.24 (0.24)	Loss 0.57 (0.42)
		cls_loss 0.28 (0.21)	reg_loss 0.30 (0.21)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.53 (0.53)
Test: [00020/00212]	Time 0.08 (0.31)
Test: [00030/00212]	Time 0.08 (0.23)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.07 (0.16)
Test: [00070/00212]	Time 0.08 (0.15)
Test: [00080/00212]	Time 0.08 (0.14)
Test: [00090/00212]	Time 0.08 (0.13)
Test: [00100/00212]	Time 0.08 (0.13)
Test: [00110/00212]	Time 0.10 (0.12)
Test: [00120/00212]	Time 0.09 (0.12)
Test: [00130/00212]	Time 0.09 (0.12)
Test: [00140/00212]	Time 0.08 (0.12)
Test: [00150/00212]	Time 0.08 (0.11)
Test: [00160/00212]	Time 0.11 (0.11)
Test: [00170/00212]	Time 0.10 (0.11)
Test: [00180/00212]	Time 0.09 (0.11)
Test: [00190/00212]	Time 0.10 (0.11)
Test: [00200/00212]	Time 0.08 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 81.75 (%) Recall@1x = 83.23 (%) Recall@5x = 96.75 (%) 
|tIoU = 0.40: mAP = 77.32 (%) Recall@1x = 79.49 (%) Recall@5x = 95.04 (%) 
|tIoU = 0.50: mAP = 70.27 (%) Recall@1x = 73.76 (%) Recall@5x = 92.09 (%) 
|tIoU = 0.60: mAP = 58.20 (%) Recall@1x = 64.00 (%) Recall@5x = 83.95 (%) 
|tIoU = 0.70: mAP = 43.17 (%) Recall@1x = 51.91 (%) Recall@5x = 71.01 (%) 
Average mAP: 66.14 (%)
All done! Total time: 124.53 sec
Looking for a split for p=1
Found split for p=1
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00100]	Time 0.97 (0.97)	Loss 2.17 (2.17)
		cls_loss 1.19 (1.19)	reg_loss 0.98 (0.98)
Epoch: [000][00020/00100]	Time 0.24 (0.61)	Loss 1.35 (1.76)
		cls_loss 0.85 (1.02)	reg_loss 0.50 (0.74)
Epoch: [000][00030/00100]	Time 0.23 (0.48)	Loss 1.39 (1.64)
		cls_loss 1.03 (1.03)	reg_loss 0.35 (0.61)
Epoch: [000][00040/00100]	Time 0.22 (0.42)	Loss 0.64 (1.39)
		cls_loss 0.53 (0.90)	reg_loss 0.11 (0.49)
Epoch: [000][00050/00100]	Time 0.22 (0.38)	Loss 0.75 (1.26)
		cls_loss 0.56 (0.83)	reg_loss 0.19 (0.43)
Epoch: [000][00060/00100]	Time 0.23 (0.35)	Loss 1.12 (1.24)
		cls_loss 0.78 (0.82)	reg_loss 0.34 (0.41)
Epoch: [000][00070/00100]	Time 0.23 (0.33)	Loss 0.37 (1.11)
		cls_loss 0.27 (0.74)	reg_loss 0.10 (0.37)
Epoch: [000][00080/00100]	Time 0.23 (0.32)	Loss 0.61 (1.05)
		cls_loss 0.44 (0.71)	reg_loss 0.17 (0.34)
Epoch: [000][00090/00100]	Time 0.23 (0.31)	Loss 0.13 (0.95)
		cls_loss 0.10 (0.64)	reg_loss 0.04 (0.31)
[Train]: Epoch 0 finished with lr=0.00002004


[Train]: Epoch 1 started
Epoch: [001][00010/00100]	Time 0.29 (0.29)	Loss 1.84 (1.84)
		cls_loss 1.28 (1.28)	reg_loss 0.56 (0.56)
Epoch: [001][00020/00100]	Time 0.22 (0.26)	Loss 0.53 (1.18)
		cls_loss 0.37 (0.82)	reg_loss 0.16 (0.36)
Epoch: [001][00030/00100]	Time 0.23 (0.25)	Loss 1.79 (1.39)
		cls_loss 1.23 (0.96)	reg_loss 0.56 (0.43)
Epoch: [001][00040/00100]	Time 0.23 (0.25)	Loss 1.00 (1.29)
		cls_loss 0.70 (0.89)	reg_loss 0.29 (0.39)
Epoch: [001][00050/00100]	Time 0.23 (0.24)	Loss 0.57 (1.14)
		cls_loss 0.40 (0.80)	reg_loss 0.17 (0.35)
Epoch: [001][00060/00100]	Time 0.23 (0.24)	Loss 0.56 (1.05)
		cls_loss 0.40 (0.73)	reg_loss 0.16 (0.32)
Epoch: [001][00070/00100]	Time 0.23 (0.24)	Loss 0.64 (0.99)
		cls_loss 0.40 (0.68)	reg_loss 0.24 (0.31)
Epoch: [001][00080/00100]	Time 0.23 (0.24)	Loss 1.44 (1.05)
		cls_loss 0.93 (0.71)	reg_loss 0.51 (0.33)
Epoch: [001][00090/00100]	Time 0.22 (0.24)	Loss 0.29 (0.96)
		cls_loss 0.21 (0.66)	reg_loss 0.08 (0.30)
[Train]: Epoch 1 finished with lr=0.00004008


[Train]: Epoch 2 started
Epoch: [002][00010/00100]	Time 0.30 (0.30)	Loss 1.23 (1.23)
		cls_loss 0.78 (0.78)	reg_loss 0.45 (0.45)
Epoch: [002][00020/00100]	Time 0.23 (0.26)	Loss 1.23 (1.23)
		cls_loss 0.75 (0.77)	reg_loss 0.48 (0.46)
Epoch: [002][00030/00100]	Time 0.23 (0.25)	Loss 0.35 (0.94)
		cls_loss 0.23 (0.59)	reg_loss 0.13 (0.35)
Epoch: [002][00040/00100]	Time 0.23 (0.25)	Loss 0.31 (0.78)
		cls_loss 0.22 (0.50)	reg_loss 0.09 (0.28)
Epoch: [002][00050/00100]	Time 0.23 (0.24)	Loss 2.01 (1.03)
		cls_loss 1.32 (0.66)	reg_loss 0.69 (0.36)
Epoch: [002][00060/00100]	Time 0.23 (0.24)	Loss 0.73 (0.98)
		cls_loss 0.50 (0.63)	reg_loss 0.23 (0.34)
Epoch: [002][00070/00100]	Time 0.27 (0.24)	Loss 0.26 (0.87)
		cls_loss 0.16 (0.57)	reg_loss 0.10 (0.31)
Epoch: [002][00080/00100]	Time 0.22 (0.24)	Loss 0.47 (0.82)
		cls_loss 0.34 (0.54)	reg_loss 0.13 (0.29)
Epoch: [002][00090/00100]	Time 0.23 (0.24)	Loss 0.88 (0.83)
		cls_loss 0.62 (0.55)	reg_loss 0.25 (0.28)
[Train]: Epoch 2 finished with lr=0.00006012


[Train]: Epoch 3 started
Epoch: [003][00010/00100]	Time 0.27 (0.27)	Loss 1.53 (1.53)
		cls_loss 0.79 (0.79)	reg_loss 0.74 (0.74)
Epoch: [003][00020/00100]	Time 0.23 (0.25)	Loss 0.44 (0.98)
		cls_loss 0.27 (0.53)	reg_loss 0.17 (0.45)
Epoch: [003][00030/00100]	Time 0.23 (0.25)	Loss 0.70 (0.89)
		cls_loss 0.45 (0.50)	reg_loss 0.25 (0.39)
Epoch: [003][00040/00100]	Time 0.24 (0.24)	Loss 0.65 (0.83)
		cls_loss 0.40 (0.48)	reg_loss 0.25 (0.35)
Epoch: [003][00050/00100]	Time 0.22 (0.24)	Loss 0.17 (0.70)
		cls_loss 0.12 (0.40)	reg_loss 0.05 (0.29)
Epoch: [003][00060/00100]	Time 0.23 (0.24)	Loss 0.43 (0.65)
		cls_loss 0.28 (0.38)	reg_loss 0.15 (0.27)
Epoch: [003][00070/00100]	Time 0.24 (0.24)	Loss 1.05 (0.71)
		cls_loss 0.70 (0.43)	reg_loss 0.34 (0.28)
Epoch: [003][00080/00100]	Time 0.23 (0.24)	Loss 2.07 (0.88)
		cls_loss 1.17 (0.52)	reg_loss 0.90 (0.36)
Epoch: [003][00090/00100]	Time 0.22 (0.23)	Loss 0.18 (0.80)
		cls_loss 0.12 (0.48)	reg_loss 0.05 (0.32)
[Train]: Epoch 3 finished with lr=0.00008016


[Train]: Epoch 4 started
Epoch: [004][00010/00100]	Time 0.27 (0.27)	Loss 0.88 (0.88)
		cls_loss 0.48 (0.48)	reg_loss 0.40 (0.40)
Epoch: [004][00020/00100]	Time 0.22 (0.25)	Loss 0.55 (0.71)
		cls_loss 0.34 (0.41)	reg_loss 0.21 (0.30)
Epoch: [004][00030/00100]	Time 0.29 (0.26)	Loss 1.06 (0.83)
		cls_loss 0.77 (0.53)	reg_loss 0.29 (0.30)
Epoch: [004][00040/00100]	Time 0.39 (0.29)	Loss 1.98 (1.12)
		cls_loss 1.35 (0.73)	reg_loss 0.64 (0.38)
Epoch: [004][00050/00100]	Time 0.22 (0.28)	Loss 0.38 (0.97)
		cls_loss 0.25 (0.64)	reg_loss 0.14 (0.33)
Epoch: [004][00060/00100]	Time 0.23 (0.27)	Loss 1.41 (1.04)
		cls_loss 0.74 (0.65)	reg_loss 0.67 (0.39)
Epoch: [004][00070/00100]	Time 0.22 (0.26)	Loss 2.55 (1.26)
		cls_loss 1.69 (0.80)	reg_loss 0.85 (0.46)
Epoch: [004][00080/00100]	Time 0.22 (0.26)	Loss 0.52 (1.17)
		cls_loss 0.31 (0.74)	reg_loss 0.21 (0.43)
Epoch: [004][00090/00100]	Time 0.25 (0.26)	Loss 0.84 (1.13)
		cls_loss 0.52 (0.72)	reg_loss 0.32 (0.41)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00100]	Time 0.27 (0.27)	Loss 0.43 (0.43)
		cls_loss 0.31 (0.31)	reg_loss 0.13 (0.13)
Epoch: [005][00020/00100]	Time 0.23 (0.25)	Loss 0.29 (0.36)
		cls_loss 0.18 (0.24)	reg_loss 0.11 (0.12)
Epoch: [005][00030/00100]	Time 0.23 (0.24)	Loss 1.87 (0.86)
		cls_loss 1.19 (0.56)	reg_loss 0.69 (0.31)
Epoch: [005][00040/00100]	Time 0.23 (0.24)	Loss 0.64 (0.81)
		cls_loss 0.30 (0.49)	reg_loss 0.35 (0.32)
Epoch: [005][00050/00100]	Time 0.23 (0.24)	Loss 0.63 (0.77)
		cls_loss 0.37 (0.47)	reg_loss 0.26 (0.31)
Epoch: [005][00060/00100]	Time 0.23 (0.23)	Loss 1.10 (0.83)
		cls_loss 0.75 (0.51)	reg_loss 0.34 (0.31)
Epoch: [005][00070/00100]	Time 0.23 (0.23)	Loss 0.42 (0.77)
		cls_loss 0.29 (0.48)	reg_loss 0.13 (0.29)
Epoch: [005][00080/00100]	Time 0.23 (0.23)	Loss 0.55 (0.74)
		cls_loss 0.34 (0.47)	reg_loss 0.20 (0.28)
Epoch: [005][00090/00100]	Time 0.24 (0.23)	Loss 0.70 (0.74)
		cls_loss 0.48 (0.47)	reg_loss 0.22 (0.27)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00100]	Time 0.28 (0.28)	Loss 0.49 (0.49)
		cls_loss 0.28 (0.28)	reg_loss 0.21 (0.21)
Epoch: [006][00020/00100]	Time 0.23 (0.26)	Loss 0.43 (0.46)
		cls_loss 0.26 (0.27)	reg_loss 0.17 (0.19)
Epoch: [006][00030/00100]	Time 0.23 (0.25)	Loss 0.45 (0.46)
		cls_loss 0.30 (0.28)	reg_loss 0.16 (0.18)
Epoch: [006][00040/00100]	Time 0.23 (0.24)	Loss 0.51 (0.47)
		cls_loss 0.28 (0.28)	reg_loss 0.22 (0.19)
Epoch: [006][00050/00100]	Time 0.23 (0.24)	Loss 0.70 (0.52)
		cls_loss 0.54 (0.33)	reg_loss 0.16 (0.18)
Epoch: [006][00060/00100]	Time 0.22 (0.24)	Loss 1.50 (0.68)
		cls_loss 0.75 (0.40)	reg_loss 0.76 (0.28)
Epoch: [006][00070/00100]	Time 0.23 (0.24)	Loss 0.29 (0.63)
		cls_loss 0.19 (0.37)	reg_loss 0.10 (0.25)
Epoch: [006][00080/00100]	Time 0.24 (0.24)	Loss 0.28 (0.58)
		cls_loss 0.17 (0.35)	reg_loss 0.11 (0.24)
Epoch: [006][00090/00100]	Time 0.23 (0.24)	Loss 0.47 (0.57)
		cls_loss 0.27 (0.34)	reg_loss 0.20 (0.23)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00100]	Time 0.28 (0.28)	Loss 0.24 (0.24)
		cls_loss 0.16 (0.16)	reg_loss 0.08 (0.08)
Epoch: [007][00020/00100]	Time 0.23 (0.25)	Loss 0.54 (0.39)
		cls_loss 0.31 (0.23)	reg_loss 0.23 (0.16)
Epoch: [007][00030/00100]	Time 0.23 (0.25)	Loss 1.48 (0.75)
		cls_loss 0.94 (0.47)	reg_loss 0.54 (0.28)
Epoch: [007][00040/00100]	Time 0.23 (0.24)	Loss 1.46 (0.93)
		cls_loss 0.96 (0.59)	reg_loss 0.50 (0.34)
Epoch: [007][00050/00100]	Time 0.23 (0.24)	Loss 0.13 (0.77)
		cls_loss 0.08 (0.49)	reg_loss 0.05 (0.28)
Epoch: [007][00060/00100]	Time 0.23 (0.24)	Loss 0.29 (0.69)
		cls_loss 0.20 (0.44)	reg_loss 0.09 (0.25)
Epoch: [007][00070/00100]	Time 0.23 (0.24)	Loss 0.10 (0.61)
		cls_loss 0.08 (0.39)	reg_loss 0.02 (0.22)
Epoch: [007][00080/00100]	Time 0.24 (0.24)	Loss 0.55 (0.60)
		cls_loss 0.32 (0.38)	reg_loss 0.23 (0.22)
Epoch: [007][00090/00100]	Time 0.23 (0.24)	Loss 0.70 (0.61)
		cls_loss 0.39 (0.38)	reg_loss 0.31 (0.23)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00100]	Time 0.30 (0.30)	Loss 0.44 (0.44)
		cls_loss 0.24 (0.24)	reg_loss 0.20 (0.20)
Epoch: [008][00020/00100]	Time 0.23 (0.26)	Loss 0.14 (0.29)
		cls_loss 0.08 (0.16)	reg_loss 0.06 (0.13)
Epoch: [008][00030/00100]	Time 0.23 (0.25)	Loss 0.62 (0.40)
		cls_loss 0.35 (0.23)	reg_loss 0.27 (0.18)
Epoch: [008][00040/00100]	Time 0.23 (0.25)	Loss 0.23 (0.36)
		cls_loss 0.14 (0.20)	reg_loss 0.09 (0.15)
Epoch: [008][00050/00100]	Time 0.23 (0.24)	Loss 1.58 (0.60)
		cls_loss 0.83 (0.33)	reg_loss 0.75 (0.27)
Epoch: [008][00060/00100]	Time 0.23 (0.24)	Loss 1.66 (0.78)
		cls_loss 0.96 (0.44)	reg_loss 0.70 (0.34)
Epoch: [008][00070/00100]	Time 0.23 (0.24)	Loss 0.27 (0.71)
		cls_loss 0.15 (0.39)	reg_loss 0.12 (0.31)
Epoch: [008][00080/00100]	Time 0.23 (0.24)	Loss 0.42 (0.67)
		cls_loss 0.29 (0.38)	reg_loss 0.13 (0.29)
Epoch: [008][00090/00100]	Time 0.23 (0.24)	Loss 0.64 (0.67)
		cls_loss 0.46 (0.39)	reg_loss 0.17 (0.28)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00100]	Time 0.28 (0.28)	Loss 0.82 (0.82)
		cls_loss 0.55 (0.55)	reg_loss 0.26 (0.26)
Epoch: [009][00020/00100]	Time 0.23 (0.26)	Loss 0.52 (0.67)
		cls_loss 0.32 (0.43)	reg_loss 0.21 (0.23)
Epoch: [009][00030/00100]	Time 0.23 (0.25)	Loss 0.23 (0.52)
		cls_loss 0.12 (0.33)	reg_loss 0.11 (0.19)
Epoch: [009][00040/00100]	Time 0.22 (0.24)	Loss 0.73 (0.57)
		cls_loss 0.50 (0.37)	reg_loss 0.23 (0.20)
Epoch: [009][00050/00100]	Time 0.23 (0.24)	Loss 0.21 (0.50)
		cls_loss 0.13 (0.32)	reg_loss 0.08 (0.18)
Epoch: [009][00060/00100]	Time 0.23 (0.24)	Loss 0.19 (0.45)
		cls_loss 0.10 (0.29)	reg_loss 0.09 (0.16)
Epoch: [009][00070/00100]	Time 0.23 (0.24)	Loss 0.22 (0.42)
		cls_loss 0.12 (0.26)	reg_loss 0.10 (0.15)
Epoch: [009][00080/00100]	Time 0.23 (0.23)	Loss 1.14 (0.51)
		cls_loss 0.61 (0.31)	reg_loss 0.52 (0.20)
Epoch: [009][00090/00100]	Time 0.23 (0.23)	Loss 0.39 (0.49)
		cls_loss 0.26 (0.30)	reg_loss 0.13 (0.19)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00100]	Time 0.27 (0.27)	Loss 0.49 (0.49)
		cls_loss 0.31 (0.31)	reg_loss 0.18 (0.18)
Epoch: [010][00020/00100]	Time 0.23 (0.25)	Loss 1.62 (1.06)
		cls_loss 0.81 (0.56)	reg_loss 0.82 (0.50)
Epoch: [010][00030/00100]	Time 0.23 (0.24)	Loss 0.52 (0.88)
		cls_loss 0.34 (0.49)	reg_loss 0.18 (0.39)
Epoch: [010][00040/00100]	Time 0.23 (0.24)	Loss 1.08 (0.93)
		cls_loss 0.61 (0.52)	reg_loss 0.47 (0.41)
Epoch: [010][00050/00100]	Time 0.23 (0.24)	Loss 0.52 (0.85)
		cls_loss 0.28 (0.47)	reg_loss 0.24 (0.38)
Epoch: [010][00060/00100]	Time 0.23 (0.24)	Loss 0.75 (0.83)
		cls_loss 0.45 (0.47)	reg_loss 0.30 (0.36)
Epoch: [010][00070/00100]	Time 0.23 (0.24)	Loss 0.92 (0.84)
		cls_loss 0.58 (0.48)	reg_loss 0.34 (0.36)
Epoch: [010][00080/00100]	Time 0.23 (0.24)	Loss 1.86 (0.97)
		cls_loss 1.32 (0.59)	reg_loss 0.54 (0.38)
Epoch: [010][00090/00100]	Time 0.23 (0.23)	Loss 0.44 (0.91)
		cls_loss 0.29 (0.55)	reg_loss 0.15 (0.36)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00100]	Time 0.28 (0.28)	Loss 0.42 (0.42)
		cls_loss 0.30 (0.30)	reg_loss 0.12 (0.12)
Epoch: [011][00020/00100]	Time 0.23 (0.25)	Loss 0.39 (0.41)
		cls_loss 0.22 (0.26)	reg_loss 0.17 (0.15)
Epoch: [011][00030/00100]	Time 0.22 (0.24)	Loss 0.21 (0.34)
		cls_loss 0.13 (0.22)	reg_loss 0.08 (0.12)
Epoch: [011][00040/00100]	Time 0.23 (0.24)	Loss 0.30 (0.33)
		cls_loss 0.21 (0.21)	reg_loss 0.09 (0.12)
Epoch: [011][00050/00100]	Time 0.23 (0.24)	Loss 0.26 (0.32)
		cls_loss 0.16 (0.20)	reg_loss 0.10 (0.11)
Epoch: [011][00060/00100]	Time 0.23 (0.24)	Loss 1.14 (0.45)
		cls_loss 0.58 (0.26)	reg_loss 0.56 (0.19)
Epoch: [011][00070/00100]	Time 0.23 (0.23)	Loss 0.17 (0.41)
		cls_loss 0.11 (0.24)	reg_loss 0.07 (0.17)
Epoch: [011][00080/00100]	Time 0.23 (0.23)	Loss 0.19 (0.39)
		cls_loss 0.14 (0.23)	reg_loss 0.05 (0.16)
Epoch: [011][00090/00100]	Time 0.24 (0.23)	Loss 0.18 (0.36)
		cls_loss 0.11 (0.22)	reg_loss 0.07 (0.15)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00100]	Time 0.30 (0.30)	Loss 0.12 (0.12)
		cls_loss 0.08 (0.08)	reg_loss 0.04 (0.04)
Epoch: [012][00020/00100]	Time 0.23 (0.27)	Loss 0.11 (0.11)
		cls_loss 0.06 (0.07)	reg_loss 0.04 (0.04)
Epoch: [012][00030/00100]	Time 0.23 (0.25)	Loss 0.26 (0.16)
		cls_loss 0.14 (0.10)	reg_loss 0.11 (0.07)
Epoch: [012][00040/00100]	Time 0.23 (0.25)	Loss 0.28 (0.19)
		cls_loss 0.18 (0.12)	reg_loss 0.10 (0.08)
Epoch: [012][00050/00100]	Time 0.22 (0.24)	Loss 0.19 (0.19)
		cls_loss 0.12 (0.12)	reg_loss 0.07 (0.07)
Epoch: [012][00060/00100]	Time 0.23 (0.24)	Loss 0.31 (0.21)
		cls_loss 0.19 (0.13)	reg_loss 0.12 (0.08)
Epoch: [012][00070/00100]	Time 0.23 (0.24)	Loss 0.39 (0.24)
		cls_loss 0.24 (0.14)	reg_loss 0.16 (0.09)
Epoch: [012][00080/00100]	Time 0.23 (0.24)	Loss 0.29 (0.24)
		cls_loss 0.15 (0.15)	reg_loss 0.13 (0.10)
Epoch: [012][00090/00100]	Time 0.22 (0.24)	Loss 0.85 (0.31)
		cls_loss 0.57 (0.19)	reg_loss 0.28 (0.12)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00100]	Time 0.28 (0.28)	Loss 1.68 (1.68)
		cls_loss 0.85 (0.85)	reg_loss 0.82 (0.82)
Epoch: [013][00020/00100]	Time 0.23 (0.26)	Loss 0.26 (0.97)
		cls_loss 0.15 (0.50)	reg_loss 0.11 (0.47)
Epoch: [013][00030/00100]	Time 0.24 (0.25)	Loss 0.19 (0.71)
		cls_loss 0.11 (0.37)	reg_loss 0.08 (0.34)
Epoch: [013][00040/00100]	Time 0.23 (0.24)	Loss 0.44 (0.64)
		cls_loss 0.26 (0.34)	reg_loss 0.18 (0.30)
Epoch: [013][00050/00100]	Time 0.23 (0.24)	Loss 0.63 (0.64)
		cls_loss 0.38 (0.35)	reg_loss 0.25 (0.29)
Epoch: [013][00060/00100]	Time 0.23 (0.24)	Loss 0.22 (0.57)
		cls_loss 0.11 (0.31)	reg_loss 0.10 (0.26)
Epoch: [013][00070/00100]	Time 0.23 (0.24)	Loss 1.05 (0.64)
		cls_loss 0.73 (0.37)	reg_loss 0.33 (0.27)
Epoch: [013][00080/00100]	Time 0.24 (0.24)	Loss 1.06 (0.69)
		cls_loss 0.58 (0.40)	reg_loss 0.48 (0.29)
Epoch: [013][00090/00100]	Time 0.24 (0.24)	Loss 0.29 (0.65)
		cls_loss 0.14 (0.37)	reg_loss 0.14 (0.28)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00100]	Time 0.29 (0.29)	Loss 0.61 (0.61)
		cls_loss 0.42 (0.42)	reg_loss 0.19 (0.19)
Epoch: [014][00020/00100]	Time 0.23 (0.26)	Loss 1.67 (1.14)
		cls_loss 0.83 (0.62)	reg_loss 0.84 (0.52)
Epoch: [014][00030/00100]	Time 0.23 (0.25)	Loss 0.02 (0.77)
		cls_loss 0.02 (0.42)	reg_loss 0.01 (0.35)
Epoch: [014][00040/00100]	Time 0.23 (0.25)	Loss 0.21 (0.63)
		cls_loss 0.11 (0.34)	reg_loss 0.09 (0.28)
Epoch: [014][00050/00100]	Time 0.23 (0.24)	Loss 0.13 (0.53)
		cls_loss 0.08 (0.29)	reg_loss 0.05 (0.24)
Epoch: [014][00060/00100]	Time 0.23 (0.24)	Loss 0.83 (0.58)
		cls_loss 0.43 (0.31)	reg_loss 0.41 (0.27)
Epoch: [014][00070/00100]	Time 0.23 (0.24)	Loss 0.51 (0.57)
		cls_loss 0.28 (0.31)	reg_loss 0.23 (0.26)
Epoch: [014][00080/00100]	Time 0.24 (0.24)	Loss 0.27 (0.53)
		cls_loss 0.17 (0.29)	reg_loss 0.10 (0.24)
Epoch: [014][00090/00100]	Time 0.23 (0.24)	Loss 0.36 (0.51)
		cls_loss 0.20 (0.28)	reg_loss 0.17 (0.23)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00100]	Time 0.29 (0.29)	Loss 0.11 (0.11)
		cls_loss 0.06 (0.06)	reg_loss 0.05 (0.05)
Epoch: [015][00020/00100]	Time 0.23 (0.26)	Loss 0.17 (0.14)
		cls_loss 0.09 (0.08)	reg_loss 0.07 (0.06)
Epoch: [015][00030/00100]	Time 0.23 (0.25)	Loss 0.33 (0.20)
		cls_loss 0.22 (0.13)	reg_loss 0.11 (0.08)
Epoch: [015][00040/00100]	Time 0.23 (0.24)	Loss 0.42 (0.26)
		cls_loss 0.23 (0.15)	reg_loss 0.19 (0.11)
Epoch: [015][00050/00100]	Time 0.23 (0.24)	Loss 0.18 (0.24)
		cls_loss 0.10 (0.14)	reg_loss 0.08 (0.10)
Epoch: [015][00060/00100]	Time 0.24 (0.24)	Loss 0.15 (0.23)
		cls_loss 0.10 (0.13)	reg_loss 0.06 (0.10)
Epoch: [015][00070/00100]	Time 0.24 (0.24)	Loss 0.40 (0.25)
		cls_loss 0.26 (0.15)	reg_loss 0.14 (0.10)
Epoch: [015][00080/00100]	Time 0.23 (0.24)	Loss 0.15 (0.24)
		cls_loss 0.09 (0.14)	reg_loss 0.06 (0.10)
Epoch: [015][00090/00100]	Time 0.23 (0.24)	Loss 0.46 (0.26)
		cls_loss 0.25 (0.15)	reg_loss 0.21 (0.11)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00100]	Time 0.29 (0.29)	Loss 0.37 (0.37)
		cls_loss 0.23 (0.23)	reg_loss 0.15 (0.15)
Epoch: [016][00020/00100]	Time 0.23 (0.26)	Loss 0.49 (0.43)
		cls_loss 0.28 (0.25)	reg_loss 0.21 (0.18)
Epoch: [016][00030/00100]	Time 0.24 (0.25)	Loss 0.17 (0.34)
		cls_loss 0.11 (0.20)	reg_loss 0.06 (0.14)
Epoch: [016][00040/00100]	Time 0.23 (0.25)	Loss 0.59 (0.40)
		cls_loss 0.33 (0.24)	reg_loss 0.26 (0.17)
Epoch: [016][00050/00100]	Time 0.23 (0.24)	Loss 0.21 (0.37)
		cls_loss 0.12 (0.21)	reg_loss 0.09 (0.15)
Epoch: [016][00060/00100]	Time 0.23 (0.24)	Loss 0.20 (0.34)
		cls_loss 0.15 (0.20)	reg_loss 0.05 (0.14)
Epoch: [016][00070/00100]	Time 0.23 (0.24)	Loss 0.42 (0.35)
		cls_loss 0.25 (0.21)	reg_loss 0.17 (0.14)
Epoch: [016][00080/00100]	Time 0.24 (0.24)	Loss 0.21 (0.33)
		cls_loss 0.12 (0.20)	reg_loss 0.09 (0.13)
Epoch: [016][00090/00100]	Time 0.24 (0.24)	Loss 0.37 (0.34)
		cls_loss 0.21 (0.20)	reg_loss 0.17 (0.14)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00100]	Time 0.29 (0.29)	Loss 0.16 (0.16)
		cls_loss 0.10 (0.10)	reg_loss 0.06 (0.06)
Epoch: [017][00020/00100]	Time 0.23 (0.26)	Loss 0.40 (0.28)
		cls_loss 0.21 (0.15)	reg_loss 0.19 (0.13)
Epoch: [017][00030/00100]	Time 0.24 (0.25)	Loss 1.11 (0.56)
		cls_loss 0.52 (0.28)	reg_loss 0.59 (0.28)
Epoch: [017][00040/00100]	Time 0.24 (0.25)	Loss 0.47 (0.54)
		cls_loss 0.28 (0.28)	reg_loss 0.20 (0.26)
Epoch: [017][00050/00100]	Time 0.24 (0.25)	Loss 0.37 (0.50)
		cls_loss 0.21 (0.26)	reg_loss 0.16 (0.24)
Epoch: [017][00060/00100]	Time 0.23 (0.24)	Loss 0.15 (0.44)
		cls_loss 0.07 (0.23)	reg_loss 0.07 (0.21)
Epoch: [017][00070/00100]	Time 0.23 (0.24)	Loss 0.51 (0.45)
		cls_loss 0.29 (0.24)	reg_loss 0.22 (0.21)
Epoch: [017][00080/00100]	Time 0.23 (0.24)	Loss 0.29 (0.43)
		cls_loss 0.18 (0.23)	reg_loss 0.11 (0.20)
Epoch: [017][00090/00100]	Time 0.23 (0.24)	Loss 0.12 (0.40)
		cls_loss 0.09 (0.22)	reg_loss 0.03 (0.18)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00100]	Time 0.28 (0.28)	Loss 0.74 (0.74)
		cls_loss 0.40 (0.40)	reg_loss 0.34 (0.34)
Epoch: [018][00020/00100]	Time 0.23 (0.25)	Loss 0.29 (0.51)
		cls_loss 0.15 (0.28)	reg_loss 0.13 (0.24)
Epoch: [018][00030/00100]	Time 0.23 (0.25)	Loss 0.21 (0.41)
		cls_loss 0.11 (0.22)	reg_loss 0.10 (0.19)
Epoch: [018][00040/00100]	Time 0.23 (0.24)	Loss 0.86 (0.52)
		cls_loss 0.41 (0.27)	reg_loss 0.45 (0.26)
Epoch: [018][00050/00100]	Time 0.23 (0.24)	Loss 0.79 (0.58)
		cls_loss 0.48 (0.31)	reg_loss 0.31 (0.27)
Epoch: [018][00060/00100]	Time 0.23 (0.24)	Loss 0.88 (0.63)
		cls_loss 0.41 (0.33)	reg_loss 0.46 (0.30)
Epoch: [018][00070/00100]	Time 0.23 (0.24)	Loss 0.55 (0.62)
		cls_loss 0.30 (0.32)	reg_loss 0.26 (0.29)
Epoch: [018][00080/00100]	Time 0.23 (0.24)	Loss 0.46 (0.60)
		cls_loss 0.24 (0.31)	reg_loss 0.22 (0.28)
Epoch: [018][00090/00100]	Time 0.22 (0.24)	Loss 0.10 (0.54)
		cls_loss 0.06 (0.28)	reg_loss 0.04 (0.26)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00100]	Time 0.29 (0.29)	Loss 0.96 (0.96)
		cls_loss 0.49 (0.49)	reg_loss 0.47 (0.47)
Epoch: [019][00020/00100]	Time 0.23 (0.26)	Loss 0.41 (0.68)
		cls_loss 0.21 (0.35)	reg_loss 0.19 (0.33)
Epoch: [019][00030/00100]	Time 0.23 (0.25)	Loss 0.78 (0.72)
		cls_loss 0.39 (0.37)	reg_loss 0.39 (0.35)
Epoch: [019][00040/00100]	Time 0.24 (0.24)	Loss 0.23 (0.59)
		cls_loss 0.13 (0.31)	reg_loss 0.10 (0.29)
Epoch: [019][00050/00100]	Time 0.23 (0.24)	Loss 0.70 (0.62)
		cls_loss 0.34 (0.31)	reg_loss 0.37 (0.30)
Epoch: [019][00060/00100]	Time 0.23 (0.24)	Loss 0.41 (0.58)
		cls_loss 0.26 (0.30)	reg_loss 0.15 (0.28)
Epoch: [019][00070/00100]	Time 0.23 (0.24)	Loss 0.36 (0.55)
		cls_loss 0.18 (0.29)	reg_loss 0.18 (0.26)
Epoch: [019][00080/00100]	Time 0.23 (0.24)	Loss 0.08 (0.49)
		cls_loss 0.05 (0.26)	reg_loss 0.04 (0.24)
Epoch: [019][00090/00100]	Time 0.22 (0.24)	Loss 0.12 (0.45)
		cls_loss 0.05 (0.23)	reg_loss 0.06 (0.22)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00100]	Time 0.27 (0.27)	Loss 0.15 (0.15)
		cls_loss 0.10 (0.10)	reg_loss 0.04 (0.04)
Epoch: [020][00020/00100]	Time 0.23 (0.25)	Loss 0.25 (0.20)
		cls_loss 0.14 (0.12)	reg_loss 0.11 (0.08)
Epoch: [020][00030/00100]	Time 0.23 (0.25)	Loss 0.58 (0.33)
		cls_loss 0.30 (0.18)	reg_loss 0.28 (0.15)
Epoch: [020][00040/00100]	Time 0.23 (0.24)	Loss 0.12 (0.28)
		cls_loss 0.07 (0.15)	reg_loss 0.05 (0.12)
Epoch: [020][00050/00100]	Time 0.24 (0.24)	Loss 0.16 (0.25)
		cls_loss 0.08 (0.14)	reg_loss 0.08 (0.11)
Epoch: [020][00060/00100]	Time 0.23 (0.24)	Loss 0.18 (0.24)
		cls_loss 0.10 (0.13)	reg_loss 0.08 (0.11)
Epoch: [020][00070/00100]	Time 0.23 (0.24)	Loss 0.44 (0.27)
		cls_loss 0.25 (0.15)	reg_loss 0.19 (0.12)
Epoch: [020][00080/00100]	Time 0.23 (0.24)	Loss 0.36 (0.28)
		cls_loss 0.19 (0.15)	reg_loss 0.17 (0.13)
Epoch: [020][00090/00100]	Time 0.23 (0.24)	Loss 0.43 (0.30)
		cls_loss 0.23 (0.16)	reg_loss 0.20 (0.13)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00100]	Time 0.28 (0.28)	Loss 0.31 (0.31)
		cls_loss 0.17 (0.17)	reg_loss 0.14 (0.14)
Epoch: [021][00020/00100]	Time 0.23 (0.25)	Loss 0.12 (0.21)
		cls_loss 0.08 (0.12)	reg_loss 0.04 (0.09)
Epoch: [021][00030/00100]	Time 0.23 (0.24)	Loss 0.49 (0.31)
		cls_loss 0.32 (0.19)	reg_loss 0.17 (0.12)
Epoch: [021][00040/00100]	Time 0.23 (0.24)	Loss 0.13 (0.26)
		cls_loss 0.07 (0.16)	reg_loss 0.07 (0.10)
Epoch: [021][00050/00100]	Time 0.23 (0.24)	Loss 0.38 (0.29)
		cls_loss 0.19 (0.17)	reg_loss 0.19 (0.12)
Epoch: [021][00060/00100]	Time 0.24 (0.24)	Loss 0.58 (0.33)
		cls_loss 0.32 (0.19)	reg_loss 0.26 (0.14)
Epoch: [021][00070/00100]	Time 0.24 (0.24)	Loss 0.25 (0.32)
		cls_loss 0.14 (0.18)	reg_loss 0.11 (0.14)
Epoch: [021][00080/00100]	Time 0.23 (0.24)	Loss 0.14 (0.30)
		cls_loss 0.09 (0.17)	reg_loss 0.05 (0.13)
Epoch: [021][00090/00100]	Time 0.23 (0.24)	Loss 0.44 (0.31)
		cls_loss 0.23 (0.18)	reg_loss 0.21 (0.14)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00100]	Time 0.28 (0.28)	Loss 0.21 (0.21)
		cls_loss 0.11 (0.11)	reg_loss 0.10 (0.10)
Epoch: [022][00020/00100]	Time 0.23 (0.26)	Loss 0.26 (0.24)
		cls_loss 0.15 (0.13)	reg_loss 0.11 (0.11)
Epoch: [022][00030/00100]	Time 0.23 (0.25)	Loss 0.24 (0.24)
		cls_loss 0.17 (0.14)	reg_loss 0.07 (0.09)
Epoch: [022][00040/00100]	Time 0.23 (0.24)	Loss 0.12 (0.21)
		cls_loss 0.06 (0.12)	reg_loss 0.06 (0.08)
Epoch: [022][00050/00100]	Time 0.23 (0.24)	Loss 0.09 (0.19)
		cls_loss 0.04 (0.11)	reg_loss 0.05 (0.08)
Epoch: [022][00060/00100]	Time 0.23 (0.24)	Loss 1.04 (0.33)
		cls_loss 0.48 (0.17)	reg_loss 0.57 (0.16)
Epoch: [022][00070/00100]	Time 0.23 (0.24)	Loss 0.11 (0.30)
		cls_loss 0.06 (0.15)	reg_loss 0.05 (0.14)
Epoch: [022][00080/00100]	Time 0.24 (0.24)	Loss 0.35 (0.30)
		cls_loss 0.15 (0.15)	reg_loss 0.20 (0.15)
Epoch: [022][00090/00100]	Time 0.22 (0.24)	Loss 0.06 (0.28)
		cls_loss 0.03 (0.14)	reg_loss 0.03 (0.14)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00100]	Time 0.28 (0.28)	Loss 0.48 (0.48)
		cls_loss 0.25 (0.25)	reg_loss 0.23 (0.23)
Epoch: [023][00020/00100]	Time 0.23 (0.26)	Loss 0.21 (0.34)
		cls_loss 0.11 (0.18)	reg_loss 0.10 (0.17)
Epoch: [023][00030/00100]	Time 0.23 (0.25)	Loss 0.28 (0.32)
		cls_loss 0.15 (0.17)	reg_loss 0.13 (0.15)
Epoch: [023][00040/00100]	Time 0.23 (0.25)	Loss 0.12 (0.27)
		cls_loss 0.07 (0.15)	reg_loss 0.05 (0.13)
Epoch: [023][00050/00100]	Time 0.24 (0.24)	Loss 0.23 (0.27)
		cls_loss 0.11 (0.14)	reg_loss 0.12 (0.13)
Epoch: [023][00060/00100]	Time 0.23 (0.24)	Loss 0.10 (0.24)
		cls_loss 0.06 (0.13)	reg_loss 0.05 (0.11)
Epoch: [023][00070/00100]	Time 0.24 (0.24)	Loss 1.02 (0.35)
		cls_loss 0.50 (0.18)	reg_loss 0.52 (0.17)
Epoch: [023][00080/00100]	Time 0.32 (0.25)	Loss 1.21 (0.46)
		cls_loss 0.58 (0.23)	reg_loss 0.63 (0.23)
Epoch: [023][00090/00100]	Time 0.23 (0.25)	Loss 0.28 (0.44)
		cls_loss 0.14 (0.22)	reg_loss 0.14 (0.22)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00100]	Time 0.28 (0.28)	Loss 0.21 (0.21)
		cls_loss 0.10 (0.10)	reg_loss 0.11 (0.11)
Epoch: [024][00020/00100]	Time 0.24 (0.26)	Loss 1.46 (0.84)
		cls_loss 0.83 (0.47)	reg_loss 0.63 (0.37)
Epoch: [024][00030/00100]	Time 0.23 (0.25)	Loss 0.06 (0.58)
		cls_loss 0.03 (0.32)	reg_loss 0.02 (0.25)
Epoch: [024][00040/00100]	Time 0.23 (0.25)	Loss 0.07 (0.45)
		cls_loss 0.04 (0.25)	reg_loss 0.03 (0.20)
Epoch: [024][00050/00100]	Time 0.23 (0.24)	Loss 0.21 (0.40)
		cls_loss 0.12 (0.22)	reg_loss 0.09 (0.18)
Epoch: [024][00060/00100]	Time 0.24 (0.24)	Loss 0.51 (0.42)
		cls_loss 0.26 (0.23)	reg_loss 0.25 (0.19)
Epoch: [024][00070/00100]	Time 0.24 (0.24)	Loss 0.18 (0.39)
		cls_loss 0.10 (0.21)	reg_loss 0.08 (0.17)
Epoch: [024][00080/00100]	Time 0.23 (0.24)	Loss 0.07 (0.35)
		cls_loss 0.05 (0.19)	reg_loss 0.02 (0.16)
Epoch: [024][00090/00100]	Time 0.23 (0.24)	Loss 0.07 (0.32)
		cls_loss 0.04 (0.17)	reg_loss 0.03 (0.14)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00100]	Time 0.29 (0.29)	Loss 0.58 (0.58)
		cls_loss 0.30 (0.30)	reg_loss 0.28 (0.28)
Epoch: [025][00020/00100]	Time 0.23 (0.26)	Loss 0.18 (0.38)
		cls_loss 0.09 (0.19)	reg_loss 0.09 (0.18)
Epoch: [025][00030/00100]	Time 0.24 (0.25)	Loss 0.10 (0.29)
		cls_loss 0.06 (0.15)	reg_loss 0.05 (0.14)
Epoch: [025][00040/00100]	Time 0.24 (0.25)	Loss 0.63 (0.37)
		cls_loss 0.32 (0.19)	reg_loss 0.30 (0.18)
Epoch: [025][00050/00100]	Time 0.23 (0.25)	Loss 0.18 (0.33)
		cls_loss 0.10 (0.17)	reg_loss 0.08 (0.16)
Epoch: [025][00060/00100]	Time 0.24 (0.24)	Loss 0.18 (0.31)
		cls_loss 0.09 (0.16)	reg_loss 0.09 (0.15)
Epoch: [025][00070/00100]	Time 0.24 (0.24)	Loss 0.34 (0.31)
		cls_loss 0.19 (0.16)	reg_loss 0.15 (0.15)
Epoch: [025][00080/00100]	Time 0.24 (0.24)	Loss 0.34 (0.32)
		cls_loss 0.21 (0.17)	reg_loss 0.13 (0.15)
Epoch: [025][00090/00100]	Time 0.23 (0.24)	Loss 0.05 (0.29)
		cls_loss 0.03 (0.15)	reg_loss 0.02 (0.13)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00100]	Time 0.29 (0.29)	Loss 1.37 (1.37)
		cls_loss 0.63 (0.63)	reg_loss 0.74 (0.74)
Epoch: [026][00020/00100]	Time 0.23 (0.26)	Loss 0.33 (0.85)
		cls_loss 0.15 (0.39)	reg_loss 0.18 (0.46)
Epoch: [026][00030/00100]	Time 0.24 (0.25)	Loss 0.17 (0.62)
		cls_loss 0.09 (0.29)	reg_loss 0.08 (0.33)
Epoch: [026][00040/00100]	Time 0.23 (0.25)	Loss 0.09 (0.49)
		cls_loss 0.05 (0.23)	reg_loss 0.04 (0.26)
Epoch: [026][00050/00100]	Time 0.23 (0.24)	Loss 0.46 (0.48)
		cls_loss 0.27 (0.24)	reg_loss 0.19 (0.25)
Epoch: [026][00060/00100]	Time 0.23 (0.24)	Loss 0.09 (0.42)
		cls_loss 0.06 (0.21)	reg_loss 0.03 (0.21)
Epoch: [026][00070/00100]	Time 0.23 (0.24)	Loss 0.43 (0.42)
		cls_loss 0.23 (0.21)	reg_loss 0.20 (0.21)
Epoch: [026][00080/00100]	Time 0.24 (0.24)	Loss 0.33 (0.41)
		cls_loss 0.20 (0.21)	reg_loss 0.13 (0.20)
Epoch: [026][00090/00100]	Time 0.24 (0.24)	Loss 0.31 (0.40)
		cls_loss 0.19 (0.21)	reg_loss 0.11 (0.19)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00100]	Time 0.28 (0.28)	Loss 0.35 (0.35)
		cls_loss 0.17 (0.17)	reg_loss 0.17 (0.17)
Epoch: [027][00020/00100]	Time 0.24 (0.26)	Loss 0.33 (0.34)
		cls_loss 0.19 (0.18)	reg_loss 0.14 (0.16)
Epoch: [027][00030/00100]	Time 0.23 (0.25)	Loss 0.04 (0.24)
		cls_loss 0.02 (0.13)	reg_loss 0.02 (0.11)
Epoch: [027][00040/00100]	Time 0.23 (0.25)	Loss 0.37 (0.27)
		cls_loss 0.18 (0.14)	reg_loss 0.19 (0.13)
Epoch: [027][00050/00100]	Time 0.23 (0.24)	Loss 0.21 (0.26)
		cls_loss 0.12 (0.14)	reg_loss 0.09 (0.12)
Epoch: [027][00060/00100]	Time 0.23 (0.24)	Loss 0.03 (0.22)
		cls_loss 0.02 (0.12)	reg_loss 0.02 (0.10)
Epoch: [027][00070/00100]	Time 0.23 (0.24)	Loss 0.23 (0.22)
		cls_loss 0.10 (0.12)	reg_loss 0.13 (0.11)
Epoch: [027][00080/00100]	Time 0.24 (0.24)	Loss 0.09 (0.21)
		cls_loss 0.06 (0.11)	reg_loss 0.03 (0.10)
Epoch: [027][00090/00100]	Time 0.24 (0.24)	Loss 0.08 (0.19)
		cls_loss 0.05 (0.10)	reg_loss 0.03 (0.09)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00100]	Time 0.30 (0.30)	Loss 0.07 (0.07)
		cls_loss 0.04 (0.04)	reg_loss 0.03 (0.03)
Epoch: [028][00020/00100]	Time 0.23 (0.26)	Loss 0.63 (0.35)
		cls_loss 0.32 (0.18)	reg_loss 0.32 (0.17)
Epoch: [028][00030/00100]	Time 0.23 (0.25)	Loss 0.10 (0.27)
		cls_loss 0.05 (0.13)	reg_loss 0.05 (0.13)
Epoch: [028][00040/00100]	Time 0.23 (0.25)	Loss 0.11 (0.23)
		cls_loss 0.05 (0.11)	reg_loss 0.05 (0.11)
Epoch: [028][00050/00100]	Time 0.23 (0.24)	Loss 0.11 (0.20)
		cls_loss 0.06 (0.10)	reg_loss 0.05 (0.10)
Epoch: [028][00060/00100]	Time 0.23 (0.24)	Loss 0.07 (0.18)
		cls_loss 0.03 (0.09)	reg_loss 0.04 (0.09)
Epoch: [028][00070/00100]	Time 0.23 (0.24)	Loss 0.33 (0.20)
		cls_loss 0.24 (0.11)	reg_loss 0.10 (0.09)
Epoch: [028][00080/00100]	Time 0.23 (0.24)	Loss 0.24 (0.21)
		cls_loss 0.13 (0.11)	reg_loss 0.12 (0.09)
Epoch: [028][00090/00100]	Time 0.24 (0.24)	Loss 0.01 (0.19)
		cls_loss 0.01 (0.10)	reg_loss 0.00 (0.08)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00100]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.09 (0.09)	reg_loss 0.05 (0.05)
Epoch: [029][00020/00100]	Time 0.23 (0.26)	Loss 0.18 (0.16)
		cls_loss 0.10 (0.09)	reg_loss 0.09 (0.07)
Epoch: [029][00030/00100]	Time 0.23 (0.25)	Loss 0.09 (0.14)
		cls_loss 0.06 (0.08)	reg_loss 0.04 (0.06)
Epoch: [029][00040/00100]	Time 0.23 (0.24)	Loss 0.31 (0.18)
		cls_loss 0.19 (0.11)	reg_loss 0.12 (0.07)
Epoch: [029][00050/00100]	Time 0.23 (0.24)	Loss 0.08 (0.16)
		cls_loss 0.05 (0.10)	reg_loss 0.02 (0.06)
Epoch: [029][00060/00100]	Time 0.23 (0.24)	Loss 0.06 (0.14)
		cls_loss 0.03 (0.09)	reg_loss 0.03 (0.06)
Epoch: [029][00070/00100]	Time 0.23 (0.24)	Loss 0.04 (0.13)
		cls_loss 0.02 (0.08)	reg_loss 0.01 (0.05)
Epoch: [029][00080/00100]	Time 0.23 (0.24)	Loss 0.22 (0.14)
		cls_loss 0.11 (0.08)	reg_loss 0.11 (0.06)
Epoch: [029][00090/00100]	Time 0.24 (0.24)	Loss 0.11 (0.14)
		cls_loss 0.06 (0.08)	reg_loss 0.05 (0.06)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00100]	Time 0.28 (0.28)	Loss 0.61 (0.61)
		cls_loss 0.32 (0.32)	reg_loss 0.30 (0.30)
Epoch: [030][00020/00100]	Time 0.23 (0.25)	Loss 0.29 (0.45)
		cls_loss 0.17 (0.24)	reg_loss 0.12 (0.21)
Epoch: [030][00030/00100]	Time 0.23 (0.25)	Loss 0.68 (0.53)
		cls_loss 0.31 (0.27)	reg_loss 0.37 (0.26)
Epoch: [030][00040/00100]	Time 0.23 (0.24)	Loss 0.07 (0.42)
		cls_loss 0.04 (0.21)	reg_loss 0.03 (0.20)
Epoch: [030][00050/00100]	Time 0.24 (0.24)	Loss 0.35 (0.40)
		cls_loss 0.17 (0.20)	reg_loss 0.18 (0.20)
Epoch: [030][00060/00100]	Time 0.23 (0.24)	Loss 0.05 (0.34)
		cls_loss 0.03 (0.17)	reg_loss 0.02 (0.17)
Epoch: [030][00070/00100]	Time 0.23 (0.24)	Loss 0.09 (0.31)
		cls_loss 0.05 (0.16)	reg_loss 0.04 (0.15)
Epoch: [030][00080/00100]	Time 0.23 (0.24)	Loss 0.47 (0.33)
		cls_loss 0.30 (0.17)	reg_loss 0.17 (0.15)
Epoch: [030][00090/00100]	Time 0.23 (0.24)	Loss 0.16 (0.31)
		cls_loss 0.08 (0.16)	reg_loss 0.07 (0.14)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00100]	Time 0.28 (0.28)	Loss 0.10 (0.10)
		cls_loss 0.04 (0.04)	reg_loss 0.06 (0.06)
Epoch: [031][00020/00100]	Time 0.24 (0.26)	Loss 0.29 (0.20)
		cls_loss 0.16 (0.10)	reg_loss 0.13 (0.09)
Epoch: [031][00030/00100]	Time 0.23 (0.25)	Loss 0.30 (0.23)
		cls_loss 0.16 (0.12)	reg_loss 0.14 (0.11)
Epoch: [031][00040/00100]	Time 0.24 (0.25)	Loss 0.91 (0.40)
		cls_loss 0.42 (0.20)	reg_loss 0.48 (0.20)
Epoch: [031][00050/00100]	Time 0.23 (0.24)	Loss 0.72 (0.46)
		cls_loss 0.35 (0.23)	reg_loss 0.37 (0.24)
Epoch: [031][00060/00100]	Time 0.23 (0.24)	Loss 0.91 (0.54)
		cls_loss 0.43 (0.26)	reg_loss 0.48 (0.28)
Epoch: [031][00070/00100]	Time 0.23 (0.24)	Loss 0.09 (0.47)
		cls_loss 0.06 (0.23)	reg_loss 0.04 (0.24)
Epoch: [031][00080/00100]	Time 0.23 (0.24)	Loss 0.08 (0.42)
		cls_loss 0.04 (0.21)	reg_loss 0.04 (0.22)
Epoch: [031][00090/00100]	Time 0.23 (0.24)	Loss 0.02 (0.38)
		cls_loss 0.01 (0.19)	reg_loss 0.01 (0.19)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00100]	Time 0.29 (0.29)	Loss 0.11 (0.11)
		cls_loss 0.05 (0.05)	reg_loss 0.05 (0.05)
Epoch: [032][00020/00100]	Time 0.23 (0.26)	Loss 0.05 (0.08)
		cls_loss 0.03 (0.04)	reg_loss 0.02 (0.04)
Epoch: [032][00030/00100]	Time 0.24 (0.25)	Loss 0.30 (0.15)
		cls_loss 0.16 (0.08)	reg_loss 0.15 (0.07)
Epoch: [032][00040/00100]	Time 0.24 (0.25)	Loss 0.17 (0.16)
		cls_loss 0.10 (0.08)	reg_loss 0.07 (0.07)
Epoch: [032][00050/00100]	Time 0.24 (0.25)	Loss 0.24 (0.17)
		cls_loss 0.14 (0.10)	reg_loss 0.10 (0.08)
Epoch: [032][00060/00100]	Time 0.23 (0.24)	Loss 0.28 (0.19)
		cls_loss 0.15 (0.11)	reg_loss 0.13 (0.09)
Epoch: [032][00070/00100]	Time 0.23 (0.24)	Loss 0.02 (0.17)
		cls_loss 0.02 (0.09)	reg_loss 0.01 (0.07)
Epoch: [032][00080/00100]	Time 0.23 (0.24)	Loss 0.28 (0.18)
		cls_loss 0.18 (0.10)	reg_loss 0.10 (0.08)
Epoch: [032][00090/00100]	Time 0.23 (0.24)	Loss 0.14 (0.18)
		cls_loss 0.07 (0.10)	reg_loss 0.07 (0.08)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00100]	Time 0.30 (0.30)	Loss 0.26 (0.26)
		cls_loss 0.14 (0.14)	reg_loss 0.12 (0.12)
Epoch: [033][00020/00100]	Time 0.23 (0.27)	Loss 0.10 (0.18)
		cls_loss 0.05 (0.10)	reg_loss 0.05 (0.08)
Epoch: [033][00030/00100]	Time 0.23 (0.26)	Loss 0.36 (0.24)
		cls_loss 0.19 (0.13)	reg_loss 0.17 (0.11)
Epoch: [033][00040/00100]	Time 0.24 (0.25)	Loss 0.01 (0.18)
		cls_loss 0.01 (0.10)	reg_loss 0.00 (0.08)
Epoch: [033][00050/00100]	Time 0.23 (0.25)	Loss 0.73 (0.29)
		cls_loss 0.48 (0.17)	reg_loss 0.25 (0.12)
Epoch: [033][00060/00100]	Time 0.23 (0.25)	Loss 0.14 (0.27)
		cls_loss 0.07 (0.16)	reg_loss 0.07 (0.11)
Epoch: [033][00070/00100]	Time 0.23 (0.24)	Loss 0.16 (0.25)
		cls_loss 0.10 (0.15)	reg_loss 0.06 (0.10)
Epoch: [033][00080/00100]	Time 0.23 (0.24)	Loss 0.04 (0.23)
		cls_loss 0.03 (0.13)	reg_loss 0.02 (0.09)
Epoch: [033][00090/00100]	Time 0.23 (0.24)	Loss 0.04 (0.20)
		cls_loss 0.02 (0.12)	reg_loss 0.02 (0.08)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00100]	Time 0.28 (0.28)	Loss 0.24 (0.24)
		cls_loss 0.15 (0.15)	reg_loss 0.09 (0.09)
Epoch: [034][00020/00100]	Time 0.23 (0.26)	Loss 0.05 (0.15)
		cls_loss 0.03 (0.09)	reg_loss 0.02 (0.06)
Epoch: [034][00030/00100]	Time 0.23 (0.25)	Loss 0.22 (0.17)
		cls_loss 0.10 (0.09)	reg_loss 0.12 (0.08)
Epoch: [034][00040/00100]	Time 0.24 (0.24)	Loss 0.26 (0.19)
		cls_loss 0.15 (0.11)	reg_loss 0.11 (0.09)
Epoch: [034][00050/00100]	Time 0.23 (0.24)	Loss 0.21 (0.20)
		cls_loss 0.10 (0.11)	reg_loss 0.10 (0.09)
Epoch: [034][00060/00100]	Time 0.23 (0.24)	Loss 0.21 (0.20)
		cls_loss 0.12 (0.11)	reg_loss 0.08 (0.09)
Epoch: [034][00070/00100]	Time 0.23 (0.24)	Loss 0.46 (0.24)
		cls_loss 0.25 (0.13)	reg_loss 0.21 (0.11)
Epoch: [034][00080/00100]	Time 0.24 (0.24)	Loss 0.19 (0.23)
		cls_loss 0.11 (0.13)	reg_loss 0.09 (0.10)
Epoch: [034][00090/00100]	Time 0.23 (0.24)	Loss 0.08 (0.21)
		cls_loss 0.03 (0.12)	reg_loss 0.04 (0.10)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.68 (0.68)
Test: [00020/00212]	Time 0.08 (0.38)
Test: [00030/00212]	Time 0.08 (0.28)
Test: [00040/00212]	Time 0.10 (0.24)
Test: [00050/00212]	Time 0.09 (0.21)
Test: [00060/00212]	Time 0.08 (0.18)
Test: [00070/00212]	Time 0.08 (0.17)
Test: [00080/00212]	Time 0.08 (0.16)
Test: [00090/00212]	Time 0.09 (0.15)
Test: [00100/00212]	Time 0.08 (0.14)
Test: [00110/00212]	Time 0.11 (0.14)
Test: [00120/00212]	Time 0.08 (0.14)
Test: [00130/00212]	Time 0.09 (0.13)
Test: [00140/00212]	Time 0.08 (0.13)
Test: [00150/00212]	Time 0.08 (0.13)
Test: [00160/00212]	Time 0.11 (0.12)
Test: [00170/00212]	Time 0.11 (0.12)
Test: [00180/00212]	Time 0.08 (0.12)
Test: [00190/00212]	Time 0.10 (0.12)
Test: [00200/00212]	Time 0.09 (0.12)
Test: [00210/00212]	Time 0.07 (0.12)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 81.72 (%) Recall@1x = 83.79 (%) Recall@5x = 96.53 (%) 
|tIoU = 0.40: mAP = 77.52 (%) Recall@1x = 79.92 (%) Recall@5x = 94.68 (%) 
|tIoU = 0.50: mAP = 70.99 (%) Recall@1x = 74.51 (%) Recall@5x = 91.73 (%) 
|tIoU = 0.60: mAP = 58.30 (%) Recall@1x = 64.04 (%) Recall@5x = 84.08 (%) 
|tIoU = 0.70: mAP = 42.87 (%) Recall@1x = 52.25 (%) Recall@5x = 70.88 (%) 
Average mAP: 66.28 (%)
All done! Total time: 98.14 sec
Looking for a split for p=1
Found split for p=1
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00100]	Time 0.95 (0.95)	Loss 3.36 (3.36)
		cls_loss 1.84 (1.84)	reg_loss 1.52 (1.52)
Epoch: [000][00020/00100]	Time 0.26 (0.61)	Loss 0.41 (1.88)
		cls_loss 0.25 (1.04)	reg_loss 0.16 (0.84)
Epoch: [000][00030/00100]	Time 0.23 (0.48)	Loss 2.14 (1.97)
		cls_loss 1.57 (1.22)	reg_loss 0.56 (0.75)
Epoch: [000][00040/00100]	Time 0.23 (0.42)	Loss 2.21 (2.03)
		cls_loss 1.63 (1.32)	reg_loss 0.58 (0.71)
Epoch: [000][00050/00100]	Time 0.22 (0.38)	Loss 1.72 (1.97)
		cls_loss 1.22 (1.30)	reg_loss 0.50 (0.66)
Epoch: [000][00060/00100]	Time 0.22 (0.35)	Loss 0.71 (1.76)
		cls_loss 0.49 (1.17)	reg_loss 0.22 (0.59)
Epoch: [000][00070/00100]	Time 0.23 (0.33)	Loss 0.62 (1.59)
		cls_loss 0.45 (1.06)	reg_loss 0.17 (0.53)
Epoch: [000][00080/00100]	Time 0.23 (0.32)	Loss 2.95 (1.76)
		cls_loss 2.01 (1.18)	reg_loss 0.94 (0.58)
Epoch: [000][00090/00100]	Time 0.23 (0.31)	Loss 0.45 (1.62)
		cls_loss 0.32 (1.09)	reg_loss 0.12 (0.53)
[Train]: Epoch 0 finished with lr=0.00002004


[Train]: Epoch 1 started
Epoch: [001][00010/00100]	Time 0.28 (0.28)	Loss 0.97 (0.97)
		cls_loss 0.72 (0.72)	reg_loss 0.26 (0.26)
Epoch: [001][00020/00100]	Time 0.22 (0.25)	Loss 0.22 (0.60)
		cls_loss 0.16 (0.44)	reg_loss 0.06 (0.16)
Epoch: [001][00030/00100]	Time 0.22 (0.24)	Loss 0.25 (0.48)
		cls_loss 0.16 (0.34)	reg_loss 0.09 (0.14)
Epoch: [001][00040/00100]	Time 0.22 (0.23)	Loss 0.39 (0.46)
		cls_loss 0.29 (0.33)	reg_loss 0.10 (0.13)
Epoch: [001][00050/00100]	Time 0.31 (0.25)	Loss 1.71 (0.71)
		cls_loss 1.07 (0.48)	reg_loss 0.64 (0.23)
Epoch: [001][00060/00100]	Time 0.22 (0.25)	Loss 0.69 (0.71)
		cls_loss 0.49 (0.48)	reg_loss 0.20 (0.23)
Epoch: [001][00070/00100]	Time 0.23 (0.24)	Loss 1.37 (0.80)
		cls_loss 0.90 (0.54)	reg_loss 0.48 (0.26)
Epoch: [001][00080/00100]	Time 0.24 (0.24)	Loss 0.38 (0.75)
		cls_loss 0.25 (0.50)	reg_loss 0.13 (0.25)
Epoch: [001][00090/00100]	Time 0.23 (0.24)	Loss 0.61 (0.73)
		cls_loss 0.44 (0.50)	reg_loss 0.17 (0.24)
[Train]: Epoch 1 finished with lr=0.00004008


[Train]: Epoch 2 started
Epoch: [002][00010/00100]	Time 0.29 (0.29)	Loss 0.46 (0.46)
		cls_loss 0.34 (0.34)	reg_loss 0.12 (0.12)
Epoch: [002][00020/00100]	Time 0.22 (0.26)	Loss 0.36 (0.41)
		cls_loss 0.24 (0.29)	reg_loss 0.12 (0.12)
Epoch: [002][00030/00100]	Time 0.22 (0.25)	Loss 0.19 (0.34)
		cls_loss 0.14 (0.24)	reg_loss 0.06 (0.10)
Epoch: [002][00040/00100]	Time 0.23 (0.24)	Loss 2.04 (0.76)
		cls_loss 1.39 (0.53)	reg_loss 0.65 (0.24)
Epoch: [002][00050/00100]	Time 0.23 (0.24)	Loss 0.55 (0.72)
		cls_loss 0.39 (0.50)	reg_loss 0.16 (0.22)
Epoch: [002][00060/00100]	Time 0.23 (0.24)	Loss 0.57 (0.70)
		cls_loss 0.42 (0.49)	reg_loss 0.15 (0.21)
Epoch: [002][00070/00100]	Time 0.23 (0.23)	Loss 0.11 (0.61)
		cls_loss 0.07 (0.43)	reg_loss 0.03 (0.18)
Epoch: [002][00080/00100]	Time 0.22 (0.23)	Loss 0.22 (0.56)
		cls_loss 0.14 (0.39)	reg_loss 0.08 (0.17)
Epoch: [002][00090/00100]	Time 0.23 (0.23)	Loss 0.63 (0.57)
		cls_loss 0.48 (0.40)	reg_loss 0.15 (0.17)
[Train]: Epoch 2 finished with lr=0.00006012


[Train]: Epoch 3 started
Epoch: [003][00010/00100]	Time 0.29 (0.29)	Loss 2.66 (2.66)
		cls_loss 1.74 (1.74)	reg_loss 0.92 (0.92)
Epoch: [003][00020/00100]	Time 0.23 (0.26)	Loss 0.99 (1.82)
		cls_loss 0.67 (1.20)	reg_loss 0.32 (0.62)
Epoch: [003][00030/00100]	Time 0.23 (0.25)	Loss 0.53 (1.39)
		cls_loss 0.32 (0.91)	reg_loss 0.21 (0.48)
Epoch: [003][00040/00100]	Time 0.22 (0.24)	Loss 0.39 (1.14)
		cls_loss 0.27 (0.75)	reg_loss 0.12 (0.39)
Epoch: [003][00050/00100]	Time 0.23 (0.24)	Loss 1.01 (1.12)
		cls_loss 0.61 (0.72)	reg_loss 0.40 (0.39)
Epoch: [003][00060/00100]	Time 0.23 (0.24)	Loss 0.17 (0.96)
		cls_loss 0.09 (0.62)	reg_loss 0.08 (0.34)
Epoch: [003][00070/00100]	Time 0.22 (0.24)	Loss 0.40 (0.88)
		cls_loss 0.24 (0.56)	reg_loss 0.16 (0.32)
Epoch: [003][00080/00100]	Time 0.22 (0.23)	Loss 0.24 (0.80)
		cls_loss 0.16 (0.51)	reg_loss 0.08 (0.29)
Epoch: [003][00090/00100]	Time 0.23 (0.23)	Loss 0.19 (0.73)
		cls_loss 0.11 (0.47)	reg_loss 0.08 (0.26)
[Train]: Epoch 3 finished with lr=0.00008016


[Train]: Epoch 4 started
Epoch: [004][00010/00100]	Time 0.28 (0.28)	Loss 1.39 (1.39)
		cls_loss 0.73 (0.73)	reg_loss 0.66 (0.66)
Epoch: [004][00020/00100]	Time 0.23 (0.25)	Loss 0.87 (1.13)
		cls_loss 0.56 (0.64)	reg_loss 0.31 (0.48)
Epoch: [004][00030/00100]	Time 0.22 (0.24)	Loss 1.01 (1.09)
		cls_loss 0.64 (0.64)	reg_loss 0.37 (0.45)
Epoch: [004][00040/00100]	Time 0.23 (0.24)	Loss 0.60 (0.97)
		cls_loss 0.32 (0.56)	reg_loss 0.28 (0.40)
Epoch: [004][00050/00100]	Time 0.23 (0.24)	Loss 0.55 (0.88)
		cls_loss 0.45 (0.54)	reg_loss 0.10 (0.34)
Epoch: [004][00060/00100]	Time 0.23 (0.23)	Loss 0.21 (0.77)
		cls_loss 0.15 (0.47)	reg_loss 0.06 (0.30)
Epoch: [004][00070/00100]	Time 0.22 (0.23)	Loss 0.41 (0.72)
		cls_loss 0.24 (0.44)	reg_loss 0.17 (0.28)
Epoch: [004][00080/00100]	Time 0.23 (0.23)	Loss 1.94 (0.87)
		cls_loss 1.40 (0.56)	reg_loss 0.54 (0.31)
Epoch: [004][00090/00100]	Time 0.23 (0.23)	Loss 0.14 (0.79)
		cls_loss 0.08 (0.51)	reg_loss 0.06 (0.28)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00100]	Time 0.28 (0.28)	Loss 0.37 (0.37)
		cls_loss 0.20 (0.20)	reg_loss 0.17 (0.17)
Epoch: [005][00020/00100]	Time 0.24 (0.26)	Loss 1.10 (0.73)
		cls_loss 0.71 (0.46)	reg_loss 0.38 (0.28)
Epoch: [005][00030/00100]	Time 0.23 (0.25)	Loss 0.31 (0.59)
		cls_loss 0.20 (0.37)	reg_loss 0.12 (0.22)
Epoch: [005][00040/00100]	Time 0.23 (0.24)	Loss 1.03 (0.70)
		cls_loss 0.69 (0.45)	reg_loss 0.34 (0.25)
Epoch: [005][00050/00100]	Time 0.23 (0.24)	Loss 1.97 (0.96)
		cls_loss 1.39 (0.64)	reg_loss 0.58 (0.32)
Epoch: [005][00060/00100]	Time 0.22 (0.24)	Loss 0.11 (0.81)
		cls_loss 0.06 (0.54)	reg_loss 0.04 (0.27)
Epoch: [005][00070/00100]	Time 0.23 (0.24)	Loss 0.82 (0.82)
		cls_loss 0.56 (0.54)	reg_loss 0.26 (0.27)
Epoch: [005][00080/00100]	Time 0.23 (0.24)	Loss 1.16 (0.86)
		cls_loss 0.87 (0.59)	reg_loss 0.29 (0.27)
Epoch: [005][00090/00100]	Time 0.23 (0.24)	Loss 0.28 (0.79)
		cls_loss 0.17 (0.54)	reg_loss 0.11 (0.26)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00100]	Time 0.27 (0.27)	Loss 0.28 (0.28)
		cls_loss 0.17 (0.17)	reg_loss 0.11 (0.11)
Epoch: [006][00020/00100]	Time 0.23 (0.25)	Loss 0.56 (0.42)
		cls_loss 0.32 (0.24)	reg_loss 0.24 (0.18)
Epoch: [006][00030/00100]	Time 0.24 (0.24)	Loss 0.73 (0.52)
		cls_loss 0.46 (0.32)	reg_loss 0.26 (0.21)
Epoch: [006][00040/00100]	Time 0.23 (0.24)	Loss 0.29 (0.46)
		cls_loss 0.22 (0.29)	reg_loss 0.07 (0.17)
Epoch: [006][00050/00100]	Time 0.23 (0.24)	Loss 0.28 (0.43)
		cls_loss 0.19 (0.27)	reg_loss 0.09 (0.16)
Epoch: [006][00060/00100]	Time 0.23 (0.24)	Loss 0.20 (0.39)
		cls_loss 0.14 (0.25)	reg_loss 0.06 (0.14)
Epoch: [006][00070/00100]	Time 0.24 (0.24)	Loss 0.36 (0.38)
		cls_loss 0.21 (0.24)	reg_loss 0.15 (0.14)
Epoch: [006][00080/00100]	Time 0.24 (0.24)	Loss 0.27 (0.37)
		cls_loss 0.16 (0.23)	reg_loss 0.11 (0.14)
Epoch: [006][00090/00100]	Time 0.23 (0.24)	Loss 0.51 (0.39)
		cls_loss 0.31 (0.24)	reg_loss 0.20 (0.15)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00100]	Time 0.30 (0.30)	Loss 0.12 (0.12)
		cls_loss 0.07 (0.07)	reg_loss 0.05 (0.05)
Epoch: [007][00020/00100]	Time 0.23 (0.26)	Loss 0.38 (0.25)
		cls_loss 0.24 (0.15)	reg_loss 0.14 (0.09)
Epoch: [007][00030/00100]	Time 0.23 (0.25)	Loss 0.30 (0.26)
		cls_loss 0.19 (0.17)	reg_loss 0.11 (0.10)
Epoch: [007][00040/00100]	Time 0.22 (0.24)	Loss 0.34 (0.28)
		cls_loss 0.25 (0.19)	reg_loss 0.09 (0.10)
Epoch: [007][00050/00100]	Time 0.23 (0.24)	Loss 0.42 (0.31)
		cls_loss 0.25 (0.20)	reg_loss 0.18 (0.11)
Epoch: [007][00060/00100]	Time 0.22 (0.24)	Loss 1.01 (0.43)
		cls_loss 0.64 (0.27)	reg_loss 0.37 (0.15)
Epoch: [007][00070/00100]	Time 0.22 (0.24)	Loss 0.32 (0.41)
		cls_loss 0.18 (0.26)	reg_loss 0.14 (0.15)
Epoch: [007][00080/00100]	Time 0.22 (0.23)	Loss 1.66 (0.57)
		cls_loss 1.03 (0.35)	reg_loss 0.63 (0.21)
Epoch: [007][00090/00100]	Time 0.22 (0.23)	Loss 1.18 (0.63)
		cls_loss 0.73 (0.40)	reg_loss 0.45 (0.24)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00100]	Time 0.28 (0.28)	Loss 1.00 (1.00)
		cls_loss 0.58 (0.58)	reg_loss 0.42 (0.42)
Epoch: [008][00020/00100]	Time 0.23 (0.26)	Loss 0.37 (0.68)
		cls_loss 0.22 (0.40)	reg_loss 0.15 (0.28)
Epoch: [008][00030/00100]	Time 0.22 (0.25)	Loss 0.12 (0.49)
		cls_loss 0.07 (0.29)	reg_loss 0.04 (0.20)
Epoch: [008][00040/00100]	Time 0.23 (0.24)	Loss 0.44 (0.48)
		cls_loss 0.24 (0.28)	reg_loss 0.20 (0.20)
Epoch: [008][00050/00100]	Time 0.23 (0.24)	Loss 0.30 (0.44)
		cls_loss 0.20 (0.26)	reg_loss 0.10 (0.18)
Epoch: [008][00060/00100]	Time 0.22 (0.24)	Loss 0.54 (0.46)
		cls_loss 0.39 (0.28)	reg_loss 0.15 (0.18)
Epoch: [008][00070/00100]	Time 0.23 (0.23)	Loss 0.06 (0.40)
		cls_loss 0.04 (0.25)	reg_loss 0.03 (0.15)
Epoch: [008][00080/00100]	Time 0.23 (0.23)	Loss 0.39 (0.40)
		cls_loss 0.26 (0.25)	reg_loss 0.14 (0.15)
Epoch: [008][00090/00100]	Time 0.23 (0.23)	Loss 0.07 (0.37)
		cls_loss 0.04 (0.23)	reg_loss 0.03 (0.14)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00100]	Time 0.28 (0.28)	Loss 0.36 (0.36)
		cls_loss 0.25 (0.25)	reg_loss 0.10 (0.10)
Epoch: [009][00020/00100]	Time 0.23 (0.26)	Loss 0.69 (0.52)
		cls_loss 0.43 (0.34)	reg_loss 0.26 (0.18)
Epoch: [009][00030/00100]	Time 0.23 (0.25)	Loss 0.21 (0.42)
		cls_loss 0.13 (0.27)	reg_loss 0.08 (0.15)
Epoch: [009][00040/00100]	Time 0.23 (0.24)	Loss 0.45 (0.42)
		cls_loss 0.32 (0.28)	reg_loss 0.13 (0.14)
Epoch: [009][00050/00100]	Time 0.23 (0.24)	Loss 0.11 (0.36)
		cls_loss 0.06 (0.24)	reg_loss 0.05 (0.12)
Epoch: [009][00060/00100]	Time 0.23 (0.24)	Loss 0.24 (0.34)
		cls_loss 0.13 (0.22)	reg_loss 0.11 (0.12)
Epoch: [009][00070/00100]	Time 0.22 (0.23)	Loss 0.17 (0.32)
		cls_loss 0.12 (0.21)	reg_loss 0.05 (0.11)
Epoch: [009][00080/00100]	Time 0.23 (0.23)	Loss 0.29 (0.31)
		cls_loss 0.17 (0.20)	reg_loss 0.11 (0.11)
Epoch: [009][00090/00100]	Time 0.22 (0.23)	Loss 0.29 (0.31)
		cls_loss 0.15 (0.20)	reg_loss 0.13 (0.11)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00100]	Time 0.28 (0.28)	Loss 1.03 (1.03)
		cls_loss 0.67 (0.67)	reg_loss 0.36 (0.36)
Epoch: [010][00020/00100]	Time 0.22 (0.25)	Loss 0.07 (0.55)
		cls_loss 0.05 (0.36)	reg_loss 0.03 (0.19)
Epoch: [010][00030/00100]	Time 0.22 (0.24)	Loss 0.49 (0.53)
		cls_loss 0.31 (0.34)	reg_loss 0.18 (0.19)
Epoch: [010][00040/00100]	Time 0.23 (0.24)	Loss 0.42 (0.50)
		cls_loss 0.24 (0.32)	reg_loss 0.18 (0.19)
Epoch: [010][00050/00100]	Time 0.23 (0.24)	Loss 0.73 (0.55)
		cls_loss 0.43 (0.34)	reg_loss 0.30 (0.21)
Epoch: [010][00060/00100]	Time 0.22 (0.24)	Loss 0.67 (0.57)
		cls_loss 0.34 (0.34)	reg_loss 0.33 (0.23)
Epoch: [010][00070/00100]	Time 0.23 (0.23)	Loss 0.51 (0.56)
		cls_loss 0.29 (0.33)	reg_loss 0.22 (0.23)
Epoch: [010][00080/00100]	Time 0.24 (0.24)	Loss 0.42 (0.54)
		cls_loss 0.28 (0.33)	reg_loss 0.14 (0.22)
Epoch: [010][00090/00100]	Time 0.22 (0.23)	Loss 0.19 (0.50)
		cls_loss 0.11 (0.30)	reg_loss 0.08 (0.20)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00100]	Time 0.28 (0.28)	Loss 0.28 (0.28)
		cls_loss 0.15 (0.15)	reg_loss 0.13 (0.13)
Epoch: [011][00020/00100]	Time 0.22 (0.25)	Loss 0.24 (0.26)
		cls_loss 0.14 (0.15)	reg_loss 0.10 (0.11)
Epoch: [011][00030/00100]	Time 0.24 (0.25)	Loss 1.03 (0.52)
		cls_loss 0.52 (0.27)	reg_loss 0.51 (0.25)
Epoch: [011][00040/00100]	Time 0.23 (0.24)	Loss 1.19 (0.68)
		cls_loss 0.57 (0.35)	reg_loss 0.61 (0.34)
Epoch: [011][00050/00100]	Time 0.23 (0.24)	Loss 0.11 (0.57)
		cls_loss 0.08 (0.29)	reg_loss 0.03 (0.28)
Epoch: [011][00060/00100]	Time 0.23 (0.24)	Loss 0.51 (0.56)
		cls_loss 0.27 (0.29)	reg_loss 0.24 (0.27)
Epoch: [011][00070/00100]	Time 0.23 (0.24)	Loss 0.95 (0.61)
		cls_loss 0.63 (0.34)	reg_loss 0.31 (0.28)
Epoch: [011][00080/00100]	Time 0.23 (0.24)	Loss 1.57 (0.73)
		cls_loss 1.13 (0.44)	reg_loss 0.43 (0.30)
Epoch: [011][00090/00100]	Time 0.22 (0.23)	Loss 0.40 (0.70)
		cls_loss 0.25 (0.42)	reg_loss 0.15 (0.28)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00100]	Time 0.28 (0.28)	Loss 0.52 (0.52)
		cls_loss 0.28 (0.28)	reg_loss 0.24 (0.24)
Epoch: [012][00020/00100]	Time 0.23 (0.26)	Loss 0.30 (0.41)
		cls_loss 0.21 (0.24)	reg_loss 0.09 (0.17)
Epoch: [012][00030/00100]	Time 0.24 (0.25)	Loss 0.24 (0.35)
		cls_loss 0.14 (0.21)	reg_loss 0.10 (0.14)
Epoch: [012][00040/00100]	Time 0.24 (0.25)	Loss 0.96 (0.51)
		cls_loss 0.54 (0.29)	reg_loss 0.43 (0.21)
Epoch: [012][00050/00100]	Time 0.23 (0.24)	Loss 0.39 (0.48)
		cls_loss 0.22 (0.28)	reg_loss 0.17 (0.21)
Epoch: [012][00060/00100]	Time 0.23 (0.24)	Loss 0.17 (0.43)
		cls_loss 0.09 (0.24)	reg_loss 0.08 (0.19)
Epoch: [012][00070/00100]	Time 0.23 (0.24)	Loss 0.50 (0.44)
		cls_loss 0.31 (0.25)	reg_loss 0.19 (0.19)
Epoch: [012][00080/00100]	Time 0.23 (0.24)	Loss 1.92 (0.63)
		cls_loss 0.91 (0.34)	reg_loss 1.00 (0.29)
Epoch: [012][00090/00100]	Time 0.23 (0.24)	Loss 0.37 (0.60)
		cls_loss 0.24 (0.33)	reg_loss 0.13 (0.27)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00100]	Time 0.28 (0.28)	Loss 0.34 (0.34)
		cls_loss 0.18 (0.18)	reg_loss 0.16 (0.16)
Epoch: [013][00020/00100]	Time 0.23 (0.26)	Loss 0.27 (0.31)
		cls_loss 0.15 (0.17)	reg_loss 0.12 (0.14)
Epoch: [013][00030/00100]	Time 0.24 (0.25)	Loss 1.05 (0.55)
		cls_loss 0.70 (0.35)	reg_loss 0.34 (0.21)
Epoch: [013][00040/00100]	Time 0.24 (0.25)	Loss 0.16 (0.46)
		cls_loss 0.11 (0.29)	reg_loss 0.05 (0.17)
Epoch: [013][00050/00100]	Time 0.23 (0.24)	Loss 0.40 (0.44)
		cls_loss 0.24 (0.28)	reg_loss 0.16 (0.17)
Epoch: [013][00060/00100]	Time 0.23 (0.24)	Loss 0.48 (0.45)
		cls_loss 0.26 (0.28)	reg_loss 0.21 (0.17)
Epoch: [013][00070/00100]	Time 0.23 (0.24)	Loss 0.31 (0.43)
		cls_loss 0.18 (0.26)	reg_loss 0.14 (0.17)
Epoch: [013][00080/00100]	Time 0.24 (0.24)	Loss 0.48 (0.44)
		cls_loss 0.31 (0.27)	reg_loss 0.16 (0.17)
Epoch: [013][00090/00100]	Time 0.22 (0.24)	Loss 0.08 (0.40)
		cls_loss 0.05 (0.24)	reg_loss 0.03 (0.15)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00100]	Time 0.30 (0.30)	Loss 0.26 (0.26)
		cls_loss 0.16 (0.16)	reg_loss 0.10 (0.10)
Epoch: [014][00020/00100]	Time 0.23 (0.27)	Loss 0.27 (0.26)
		cls_loss 0.17 (0.16)	reg_loss 0.10 (0.10)
Epoch: [014][00030/00100]	Time 0.24 (0.26)	Loss 0.21 (0.25)
		cls_loss 0.11 (0.15)	reg_loss 0.10 (0.10)
Epoch: [014][00040/00100]	Time 0.23 (0.25)	Loss 0.04 (0.19)
		cls_loss 0.02 (0.11)	reg_loss 0.02 (0.08)
Epoch: [014][00050/00100]	Time 0.23 (0.25)	Loss 0.25 (0.20)
		cls_loss 0.15 (0.12)	reg_loss 0.10 (0.08)
Epoch: [014][00060/00100]	Time 0.23 (0.24)	Loss 0.52 (0.26)
		cls_loss 0.31 (0.15)	reg_loss 0.21 (0.10)
Epoch: [014][00070/00100]	Time 0.24 (0.24)	Loss 0.66 (0.32)
		cls_loss 0.43 (0.19)	reg_loss 0.24 (0.12)
Epoch: [014][00080/00100]	Time 0.23 (0.24)	Loss 0.66 (0.36)
		cls_loss 0.39 (0.22)	reg_loss 0.27 (0.14)
Epoch: [014][00090/00100]	Time 0.23 (0.24)	Loss 0.45 (0.37)
		cls_loss 0.25 (0.22)	reg_loss 0.20 (0.15)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00100]	Time 0.29 (0.29)	Loss 0.25 (0.25)
		cls_loss 0.16 (0.16)	reg_loss 0.09 (0.09)
Epoch: [015][00020/00100]	Time 0.23 (0.26)	Loss 0.11 (0.18)
		cls_loss 0.06 (0.11)	reg_loss 0.05 (0.07)
Epoch: [015][00030/00100]	Time 0.23 (0.25)	Loss 0.84 (0.40)
		cls_loss 0.43 (0.22)	reg_loss 0.41 (0.18)
Epoch: [015][00040/00100]	Time 0.24 (0.25)	Loss 0.16 (0.34)
		cls_loss 0.10 (0.19)	reg_loss 0.06 (0.15)
Epoch: [015][00050/00100]	Time 0.23 (0.25)	Loss 0.48 (0.37)
		cls_loss 0.32 (0.21)	reg_loss 0.16 (0.15)
Epoch: [015][00060/00100]	Time 0.23 (0.24)	Loss 0.34 (0.36)
		cls_loss 0.21 (0.21)	reg_loss 0.13 (0.15)
Epoch: [015][00070/00100]	Time 0.23 (0.24)	Loss 0.04 (0.32)
		cls_loss 0.03 (0.19)	reg_loss 0.02 (0.13)
Epoch: [015][00080/00100]	Time 0.23 (0.24)	Loss 0.43 (0.33)
		cls_loss 0.25 (0.20)	reg_loss 0.18 (0.14)
Epoch: [015][00090/00100]	Time 0.23 (0.24)	Loss 0.47 (0.35)
		cls_loss 0.27 (0.20)	reg_loss 0.20 (0.14)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00100]	Time 0.29 (0.29)	Loss 1.50 (1.50)
		cls_loss 0.74 (0.74)	reg_loss 0.77 (0.77)
Epoch: [016][00020/00100]	Time 0.23 (0.26)	Loss 0.43 (0.97)
		cls_loss 0.25 (0.49)	reg_loss 0.19 (0.48)
Epoch: [016][00030/00100]	Time 0.23 (0.25)	Loss 0.39 (0.78)
		cls_loss 0.25 (0.41)	reg_loss 0.14 (0.36)
Epoch: [016][00040/00100]	Time 0.23 (0.25)	Loss 0.32 (0.66)
		cls_loss 0.16 (0.35)	reg_loss 0.15 (0.31)
Epoch: [016][00050/00100]	Time 0.23 (0.24)	Loss 0.80 (0.69)
		cls_loss 0.40 (0.36)	reg_loss 0.40 (0.33)
Epoch: [016][00060/00100]	Time 0.24 (0.24)	Loss 0.07 (0.59)
		cls_loss 0.04 (0.31)	reg_loss 0.03 (0.28)
Epoch: [016][00070/00100]	Time 0.23 (0.24)	Loss 0.16 (0.52)
		cls_loss 0.09 (0.28)	reg_loss 0.07 (0.25)
Epoch: [016][00080/00100]	Time 0.23 (0.24)	Loss 0.80 (0.56)
		cls_loss 0.53 (0.31)	reg_loss 0.27 (0.25)
Epoch: [016][00090/00100]	Time 0.23 (0.24)	Loss 0.08 (0.51)
		cls_loss 0.05 (0.28)	reg_loss 0.03 (0.23)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00100]	Time 0.28 (0.28)	Loss 0.12 (0.12)
		cls_loss 0.08 (0.08)	reg_loss 0.04 (0.04)
Epoch: [017][00020/00100]	Time 0.23 (0.25)	Loss 0.81 (0.47)
		cls_loss 0.47 (0.28)	reg_loss 0.34 (0.19)
Epoch: [017][00030/00100]	Time 0.23 (0.25)	Loss 0.16 (0.36)
		cls_loss 0.09 (0.22)	reg_loss 0.07 (0.15)
Epoch: [017][00040/00100]	Time 0.24 (0.24)	Loss 0.27 (0.34)
		cls_loss 0.15 (0.20)	reg_loss 0.12 (0.14)
Epoch: [017][00050/00100]	Time 0.23 (0.24)	Loss 0.30 (0.33)
		cls_loss 0.16 (0.19)	reg_loss 0.14 (0.14)
Epoch: [017][00060/00100]	Time 0.23 (0.24)	Loss 0.33 (0.33)
		cls_loss 0.17 (0.19)	reg_loss 0.16 (0.14)
Epoch: [017][00070/00100]	Time 0.23 (0.24)	Loss 0.07 (0.29)
		cls_loss 0.03 (0.17)	reg_loss 0.03 (0.13)
Epoch: [017][00080/00100]	Time 0.23 (0.24)	Loss 0.33 (0.30)
		cls_loss 0.19 (0.17)	reg_loss 0.14 (0.13)
Epoch: [017][00090/00100]	Time 0.23 (0.24)	Loss 0.96 (0.37)
		cls_loss 0.54 (0.21)	reg_loss 0.43 (0.16)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00100]	Time 0.28 (0.28)	Loss 0.46 (0.46)
		cls_loss 0.27 (0.27)	reg_loss 0.20 (0.20)
Epoch: [018][00020/00100]	Time 0.23 (0.25)	Loss 0.38 (0.42)
		cls_loss 0.22 (0.24)	reg_loss 0.16 (0.18)
Epoch: [018][00030/00100]	Time 0.23 (0.24)	Loss 0.36 (0.40)
		cls_loss 0.17 (0.22)	reg_loss 0.18 (0.18)
Epoch: [018][00040/00100]	Time 0.24 (0.24)	Loss 0.52 (0.43)
		cls_loss 0.28 (0.24)	reg_loss 0.23 (0.19)
Epoch: [018][00050/00100]	Time 0.23 (0.24)	Loss 0.36 (0.41)
		cls_loss 0.19 (0.23)	reg_loss 0.17 (0.19)
Epoch: [018][00060/00100]	Time 0.23 (0.24)	Loss 0.15 (0.37)
		cls_loss 0.09 (0.20)	reg_loss 0.06 (0.17)
Epoch: [018][00070/00100]	Time 0.23 (0.24)	Loss 0.11 (0.33)
		cls_loss 0.06 (0.18)	reg_loss 0.05 (0.15)
Epoch: [018][00080/00100]	Time 0.23 (0.24)	Loss 0.39 (0.34)
		cls_loss 0.21 (0.19)	reg_loss 0.18 (0.15)
Epoch: [018][00090/00100]	Time 0.23 (0.24)	Loss 0.84 (0.39)
		cls_loss 0.40 (0.21)	reg_loss 0.44 (0.19)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00100]	Time 0.30 (0.30)	Loss 0.16 (0.16)
		cls_loss 0.09 (0.09)	reg_loss 0.07 (0.07)
Epoch: [019][00020/00100]	Time 0.24 (0.27)	Loss 0.56 (0.36)
		cls_loss 0.28 (0.19)	reg_loss 0.28 (0.17)
Epoch: [019][00030/00100]	Time 0.23 (0.26)	Loss 0.11 (0.28)
		cls_loss 0.07 (0.15)	reg_loss 0.04 (0.13)
Epoch: [019][00040/00100]	Time 0.23 (0.25)	Loss 0.25 (0.27)
		cls_loss 0.12 (0.14)	reg_loss 0.13 (0.13)
Epoch: [019][00050/00100]	Time 0.23 (0.25)	Loss 0.07 (0.23)
		cls_loss 0.03 (0.12)	reg_loss 0.04 (0.11)
Epoch: [019][00060/00100]	Time 0.23 (0.24)	Loss 0.39 (0.26)
		cls_loss 0.22 (0.14)	reg_loss 0.17 (0.12)
Epoch: [019][00070/00100]	Time 0.24 (0.24)	Loss 0.13 (0.24)
		cls_loss 0.05 (0.12)	reg_loss 0.07 (0.12)
Epoch: [019][00080/00100]	Time 0.23 (0.24)	Loss 0.52 (0.28)
		cls_loss 0.24 (0.14)	reg_loss 0.28 (0.14)
Epoch: [019][00090/00100]	Time 0.24 (0.24)	Loss 0.46 (0.30)
		cls_loss 0.24 (0.15)	reg_loss 0.22 (0.15)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00100]	Time 0.28 (0.28)	Loss 0.20 (0.20)
		cls_loss 0.12 (0.12)	reg_loss 0.08 (0.08)
Epoch: [020][00020/00100]	Time 0.23 (0.26)	Loss 0.35 (0.27)
		cls_loss 0.22 (0.17)	reg_loss 0.13 (0.10)
Epoch: [020][00030/00100]	Time 0.23 (0.25)	Loss 0.37 (0.31)
		cls_loss 0.20 (0.18)	reg_loss 0.17 (0.13)
Epoch: [020][00040/00100]	Time 0.24 (0.24)	Loss 0.47 (0.35)
		cls_loss 0.23 (0.19)	reg_loss 0.24 (0.15)
Epoch: [020][00050/00100]	Time 0.23 (0.24)	Loss 0.02 (0.28)
		cls_loss 0.01 (0.16)	reg_loss 0.01 (0.13)
Epoch: [020][00060/00100]	Time 0.23 (0.24)	Loss 0.04 (0.24)
		cls_loss 0.02 (0.13)	reg_loss 0.02 (0.11)
Epoch: [020][00070/00100]	Time 0.23 (0.24)	Loss 0.16 (0.23)
		cls_loss 0.09 (0.13)	reg_loss 0.07 (0.10)
Epoch: [020][00080/00100]	Time 0.23 (0.24)	Loss 0.12 (0.22)
		cls_loss 0.08 (0.12)	reg_loss 0.04 (0.10)
Epoch: [020][00090/00100]	Time 0.24 (0.24)	Loss 0.38 (0.23)
		cls_loss 0.21 (0.13)	reg_loss 0.16 (0.10)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00100]	Time 0.28 (0.28)	Loss 0.15 (0.15)
		cls_loss 0.08 (0.08)	reg_loss 0.07 (0.07)
Epoch: [021][00020/00100]	Time 0.24 (0.26)	Loss 0.75 (0.45)
		cls_loss 0.42 (0.25)	reg_loss 0.32 (0.19)
Epoch: [021][00030/00100]	Time 0.24 (0.25)	Loss 0.34 (0.41)
		cls_loss 0.19 (0.23)	reg_loss 0.15 (0.18)
Epoch: [021][00040/00100]	Time 0.23 (0.25)	Loss 0.18 (0.36)
		cls_loss 0.10 (0.20)	reg_loss 0.09 (0.16)
Epoch: [021][00050/00100]	Time 0.23 (0.24)	Loss 0.32 (0.35)
		cls_loss 0.17 (0.19)	reg_loss 0.16 (0.16)
Epoch: [021][00060/00100]	Time 0.23 (0.24)	Loss 0.12 (0.31)
		cls_loss 0.08 (0.17)	reg_loss 0.04 (0.14)
Epoch: [021][00070/00100]	Time 0.23 (0.24)	Loss 0.10 (0.28)
		cls_loss 0.05 (0.16)	reg_loss 0.05 (0.12)
Epoch: [021][00080/00100]	Time 0.24 (0.24)	Loss 0.20 (0.27)
		cls_loss 0.09 (0.15)	reg_loss 0.11 (0.12)
Epoch: [021][00090/00100]	Time 0.23 (0.24)	Loss 0.11 (0.25)
		cls_loss 0.06 (0.14)	reg_loss 0.06 (0.12)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00100]	Time 0.29 (0.29)	Loss 0.36 (0.36)
		cls_loss 0.18 (0.18)	reg_loss 0.18 (0.18)
Epoch: [022][00020/00100]	Time 0.23 (0.26)	Loss 0.46 (0.41)
		cls_loss 0.24 (0.21)	reg_loss 0.22 (0.20)
Epoch: [022][00030/00100]	Time 0.23 (0.25)	Loss 0.19 (0.33)
		cls_loss 0.09 (0.17)	reg_loss 0.09 (0.16)
Epoch: [022][00040/00100]	Time 0.24 (0.25)	Loss 0.28 (0.32)
		cls_loss 0.14 (0.16)	reg_loss 0.14 (0.16)
Epoch: [022][00050/00100]	Time 0.23 (0.24)	Loss 0.09 (0.27)
		cls_loss 0.05 (0.14)	reg_loss 0.04 (0.13)
Epoch: [022][00060/00100]	Time 0.23 (0.24)	Loss 0.85 (0.37)
		cls_loss 0.48 (0.20)	reg_loss 0.38 (0.17)
Epoch: [022][00070/00100]	Time 0.24 (0.24)	Loss 0.52 (0.39)
		cls_loss 0.35 (0.22)	reg_loss 0.17 (0.17)
Epoch: [022][00080/00100]	Time 0.23 (0.24)	Loss 0.77 (0.44)
		cls_loss 0.42 (0.24)	reg_loss 0.35 (0.20)
Epoch: [022][00090/00100]	Time 0.23 (0.24)	Loss 0.93 (0.49)
		cls_loss 0.46 (0.27)	reg_loss 0.46 (0.22)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00100]	Time 0.29 (0.29)	Loss 0.09 (0.09)
		cls_loss 0.05 (0.05)	reg_loss 0.04 (0.04)
Epoch: [023][00020/00100]	Time 0.23 (0.26)	Loss 0.92 (0.51)
		cls_loss 0.48 (0.26)	reg_loss 0.45 (0.24)
Epoch: [023][00030/00100]	Time 0.22 (0.25)	Loss 0.14 (0.38)
		cls_loss 0.07 (0.20)	reg_loss 0.06 (0.18)
Epoch: [023][00040/00100]	Time 0.23 (0.24)	Loss 1.24 (0.60)
		cls_loss 0.55 (0.29)	reg_loss 0.69 (0.31)
Epoch: [023][00050/00100]	Time 0.24 (0.24)	Loss 0.43 (0.57)
		cls_loss 0.23 (0.28)	reg_loss 0.21 (0.29)
Epoch: [023][00060/00100]	Time 0.23 (0.24)	Loss 0.22 (0.51)
		cls_loss 0.14 (0.25)	reg_loss 0.08 (0.25)
Epoch: [023][00070/00100]	Time 0.23 (0.24)	Loss 0.07 (0.45)
		cls_loss 0.04 (0.22)	reg_loss 0.04 (0.22)
Epoch: [023][00080/00100]	Time 0.24 (0.24)	Loss 0.51 (0.45)
		cls_loss 0.25 (0.23)	reg_loss 0.25 (0.23)
Epoch: [023][00090/00100]	Time 0.23 (0.24)	Loss 0.66 (0.48)
		cls_loss 0.31 (0.24)	reg_loss 0.34 (0.24)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00100]	Time 0.34 (0.34)	Loss 0.08 (0.08)
		cls_loss 0.06 (0.06)	reg_loss 0.02 (0.02)
Epoch: [024][00020/00100]	Time 0.23 (0.28)	Loss 0.52 (0.30)
		cls_loss 0.26 (0.16)	reg_loss 0.26 (0.14)
Epoch: [024][00030/00100]	Time 0.24 (0.27)	Loss 0.69 (0.43)
		cls_loss 0.35 (0.22)	reg_loss 0.34 (0.21)
Epoch: [024][00040/00100]	Time 0.23 (0.26)	Loss 0.15 (0.36)
		cls_loss 0.09 (0.19)	reg_loss 0.06 (0.17)
Epoch: [024][00050/00100]	Time 0.24 (0.25)	Loss 0.34 (0.35)
		cls_loss 0.17 (0.18)	reg_loss 0.17 (0.17)
Epoch: [024][00060/00100]	Time 0.23 (0.25)	Loss 0.49 (0.38)
		cls_loss 0.22 (0.19)	reg_loss 0.27 (0.19)
Epoch: [024][00070/00100]	Time 0.23 (0.25)	Loss 0.64 (0.41)
		cls_loss 0.36 (0.21)	reg_loss 0.27 (0.20)
Epoch: [024][00080/00100]	Time 0.23 (0.24)	Loss 0.80 (0.46)
		cls_loss 0.46 (0.24)	reg_loss 0.34 (0.22)
Epoch: [024][00090/00100]	Time 0.23 (0.24)	Loss 0.11 (0.42)
		cls_loss 0.06 (0.22)	reg_loss 0.05 (0.20)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00100]	Time 0.30 (0.30)	Loss 0.29 (0.29)
		cls_loss 0.16 (0.16)	reg_loss 0.13 (0.13)
Epoch: [025][00020/00100]	Time 0.24 (0.27)	Loss 0.12 (0.21)
		cls_loss 0.09 (0.12)	reg_loss 0.04 (0.08)
Epoch: [025][00030/00100]	Time 0.23 (0.26)	Loss 0.67 (0.36)
		cls_loss 0.44 (0.23)	reg_loss 0.23 (0.13)
Epoch: [025][00040/00100]	Time 0.23 (0.25)	Loss 0.19 (0.32)
		cls_loss 0.10 (0.20)	reg_loss 0.09 (0.12)
Epoch: [025][00050/00100]	Time 0.23 (0.25)	Loss 0.43 (0.34)
		cls_loss 0.23 (0.20)	reg_loss 0.21 (0.14)
Epoch: [025][00060/00100]	Time 0.23 (0.24)	Loss 0.08 (0.30)
		cls_loss 0.05 (0.18)	reg_loss 0.04 (0.12)
Epoch: [025][00070/00100]	Time 0.22 (0.24)	Loss 0.04 (0.26)
		cls_loss 0.02 (0.15)	reg_loss 0.02 (0.11)
Epoch: [025][00080/00100]	Time 0.24 (0.24)	Loss 0.37 (0.28)
		cls_loss 0.20 (0.16)	reg_loss 0.17 (0.11)
Epoch: [025][00090/00100]	Time 0.23 (0.24)	Loss 0.20 (0.27)
		cls_loss 0.10 (0.15)	reg_loss 0.10 (0.11)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00100]	Time 0.28 (0.28)	Loss 0.05 (0.05)
		cls_loss 0.03 (0.03)	reg_loss 0.02 (0.02)
Epoch: [026][00020/00100]	Time 0.23 (0.26)	Loss 0.38 (0.21)
		cls_loss 0.21 (0.12)	reg_loss 0.18 (0.10)
Epoch: [026][00030/00100]	Time 0.23 (0.25)	Loss 0.12 (0.18)
		cls_loss 0.09 (0.11)	reg_loss 0.03 (0.07)
Epoch: [026][00040/00100]	Time 0.24 (0.25)	Loss 0.26 (0.20)
		cls_loss 0.13 (0.11)	reg_loss 0.14 (0.09)
Epoch: [026][00050/00100]	Time 0.23 (0.24)	Loss 0.43 (0.25)
		cls_loss 0.22 (0.13)	reg_loss 0.21 (0.11)
Epoch: [026][00060/00100]	Time 0.23 (0.24)	Loss 0.66 (0.32)
		cls_loss 0.35 (0.17)	reg_loss 0.31 (0.15)
Epoch: [026][00070/00100]	Time 0.23 (0.24)	Loss 0.02 (0.27)
		cls_loss 0.01 (0.15)	reg_loss 0.01 (0.13)
Epoch: [026][00080/00100]	Time 0.23 (0.24)	Loss 0.07 (0.25)
		cls_loss 0.04 (0.13)	reg_loss 0.03 (0.11)
Epoch: [026][00090/00100]	Time 0.22 (0.24)	Loss 0.13 (0.24)
		cls_loss 0.08 (0.13)	reg_loss 0.06 (0.11)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00100]	Time 0.28 (0.28)	Loss 0.06 (0.06)
		cls_loss 0.03 (0.03)	reg_loss 0.03 (0.03)
Epoch: [027][00020/00100]	Time 0.23 (0.26)	Loss 0.64 (0.35)
		cls_loss 0.34 (0.19)	reg_loss 0.30 (0.16)
Epoch: [027][00030/00100]	Time 0.23 (0.25)	Loss 0.14 (0.28)
		cls_loss 0.08 (0.15)	reg_loss 0.06 (0.13)
Epoch: [027][00040/00100]	Time 0.23 (0.24)	Loss 0.31 (0.29)
		cls_loss 0.16 (0.15)	reg_loss 0.15 (0.13)
Epoch: [027][00050/00100]	Time 0.23 (0.24)	Loss 0.28 (0.29)
		cls_loss 0.15 (0.15)	reg_loss 0.12 (0.13)
Epoch: [027][00060/00100]	Time 0.23 (0.24)	Loss 0.20 (0.27)
		cls_loss 0.11 (0.15)	reg_loss 0.09 (0.12)
Epoch: [027][00070/00100]	Time 0.23 (0.24)	Loss 0.08 (0.24)
		cls_loss 0.04 (0.13)	reg_loss 0.04 (0.11)
Epoch: [027][00080/00100]	Time 0.23 (0.24)	Loss 0.28 (0.25)
		cls_loss 0.16 (0.14)	reg_loss 0.11 (0.11)
Epoch: [027][00090/00100]	Time 0.23 (0.24)	Loss 0.08 (0.23)
		cls_loss 0.04 (0.12)	reg_loss 0.04 (0.11)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00100]	Time 0.27 (0.27)	Loss 0.98 (0.98)
		cls_loss 0.48 (0.48)	reg_loss 0.50 (0.50)
Epoch: [028][00020/00100]	Time 0.24 (0.26)	Loss 0.45 (0.71)
		cls_loss 0.24 (0.36)	reg_loss 0.21 (0.35)
Epoch: [028][00030/00100]	Time 0.23 (0.25)	Loss 0.08 (0.50)
		cls_loss 0.05 (0.26)	reg_loss 0.03 (0.25)
Epoch: [028][00040/00100]	Time 0.23 (0.24)	Loss 0.17 (0.42)
		cls_loss 0.09 (0.22)	reg_loss 0.07 (0.20)
Epoch: [028][00050/00100]	Time 0.23 (0.24)	Loss 0.05 (0.35)
		cls_loss 0.03 (0.18)	reg_loss 0.02 (0.17)
Epoch: [028][00060/00100]	Time 0.23 (0.24)	Loss 0.14 (0.31)
		cls_loss 0.08 (0.16)	reg_loss 0.06 (0.15)
Epoch: [028][00070/00100]	Time 0.23 (0.24)	Loss 0.13 (0.29)
		cls_loss 0.07 (0.15)	reg_loss 0.06 (0.14)
Epoch: [028][00080/00100]	Time 0.23 (0.24)	Loss 0.03 (0.25)
		cls_loss 0.02 (0.13)	reg_loss 0.01 (0.12)
Epoch: [028][00090/00100]	Time 0.23 (0.24)	Loss 0.14 (0.24)
		cls_loss 0.08 (0.13)	reg_loss 0.06 (0.11)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00100]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.09 (0.09)	reg_loss 0.06 (0.06)
Epoch: [029][00020/00100]	Time 0.23 (0.25)	Loss 0.66 (0.40)
		cls_loss 0.33 (0.21)	reg_loss 0.32 (0.19)
Epoch: [029][00030/00100]	Time 0.23 (0.24)	Loss 0.21 (0.34)
		cls_loss 0.11 (0.18)	reg_loss 0.10 (0.16)
Epoch: [029][00040/00100]	Time 0.23 (0.24)	Loss 0.15 (0.29)
		cls_loss 0.08 (0.15)	reg_loss 0.06 (0.14)
Epoch: [029][00050/00100]	Time 0.23 (0.24)	Loss 0.07 (0.25)
		cls_loss 0.04 (0.13)	reg_loss 0.03 (0.11)
Epoch: [029][00060/00100]	Time 0.23 (0.24)	Loss 0.42 (0.27)
		cls_loss 0.22 (0.15)	reg_loss 0.20 (0.13)
Epoch: [029][00070/00100]	Time 0.23 (0.24)	Loss 0.99 (0.38)
		cls_loss 0.48 (0.19)	reg_loss 0.51 (0.18)
Epoch: [029][00080/00100]	Time 0.23 (0.24)	Loss 0.04 (0.33)
		cls_loss 0.02 (0.17)	reg_loss 0.02 (0.16)
Epoch: [029][00090/00100]	Time 0.23 (0.24)	Loss 0.55 (0.36)
		cls_loss 0.38 (0.19)	reg_loss 0.17 (0.16)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00100]	Time 0.29 (0.29)	Loss 0.29 (0.29)
		cls_loss 0.18 (0.18)	reg_loss 0.11 (0.11)
Epoch: [030][00020/00100]	Time 0.23 (0.26)	Loss 0.31 (0.30)
		cls_loss 0.18 (0.18)	reg_loss 0.13 (0.12)
Epoch: [030][00030/00100]	Time 0.23 (0.25)	Loss 0.07 (0.22)
		cls_loss 0.04 (0.13)	reg_loss 0.03 (0.09)
Epoch: [030][00040/00100]	Time 0.23 (0.25)	Loss 0.40 (0.27)
		cls_loss 0.19 (0.15)	reg_loss 0.21 (0.12)
Epoch: [030][00050/00100]	Time 0.22 (0.24)	Loss 0.05 (0.22)
		cls_loss 0.02 (0.12)	reg_loss 0.03 (0.10)
Epoch: [030][00060/00100]	Time 0.24 (0.24)	Loss 0.58 (0.28)
		cls_loss 0.28 (0.15)	reg_loss 0.30 (0.13)
Epoch: [030][00070/00100]	Time 0.23 (0.24)	Loss 0.17 (0.27)
		cls_loss 0.09 (0.14)	reg_loss 0.08 (0.13)
Epoch: [030][00080/00100]	Time 0.23 (0.24)	Loss 0.20 (0.26)
		cls_loss 0.10 (0.13)	reg_loss 0.10 (0.12)
Epoch: [030][00090/00100]	Time 0.22 (0.24)	Loss 0.03 (0.23)
		cls_loss 0.02 (0.12)	reg_loss 0.01 (0.11)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00100]	Time 0.28 (0.28)	Loss 0.04 (0.04)
		cls_loss 0.02 (0.02)	reg_loss 0.02 (0.02)
Epoch: [031][00020/00100]	Time 0.23 (0.26)	Loss 0.11 (0.08)
		cls_loss 0.06 (0.04)	reg_loss 0.04 (0.03)
Epoch: [031][00030/00100]	Time 0.23 (0.25)	Loss 0.32 (0.16)
		cls_loss 0.21 (0.10)	reg_loss 0.12 (0.06)
Epoch: [031][00040/00100]	Time 0.23 (0.24)	Loss 0.26 (0.18)
		cls_loss 0.14 (0.11)	reg_loss 0.12 (0.08)
Epoch: [031][00050/00100]	Time 0.23 (0.24)	Loss 0.06 (0.16)
		cls_loss 0.04 (0.09)	reg_loss 0.02 (0.07)
Epoch: [031][00060/00100]	Time 0.23 (0.24)	Loss 0.21 (0.17)
		cls_loss 0.13 (0.10)	reg_loss 0.07 (0.07)
Epoch: [031][00070/00100]	Time 0.23 (0.24)	Loss 0.18 (0.17)
		cls_loss 0.11 (0.10)	reg_loss 0.07 (0.07)
Epoch: [031][00080/00100]	Time 0.24 (0.24)	Loss 0.08 (0.16)
		cls_loss 0.06 (0.10)	reg_loss 0.02 (0.06)
Epoch: [031][00090/00100]	Time 0.23 (0.24)	Loss 0.24 (0.17)
		cls_loss 0.13 (0.10)	reg_loss 0.11 (0.07)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00100]	Time 0.28 (0.28)	Loss 0.22 (0.22)
		cls_loss 0.11 (0.11)	reg_loss 0.11 (0.11)
Epoch: [032][00020/00100]	Time 0.23 (0.25)	Loss 0.10 (0.16)
		cls_loss 0.06 (0.08)	reg_loss 0.04 (0.08)
Epoch: [032][00030/00100]	Time 0.23 (0.24)	Loss 0.12 (0.15)
		cls_loss 0.07 (0.08)	reg_loss 0.05 (0.07)
Epoch: [032][00040/00100]	Time 0.23 (0.24)	Loss 0.07 (0.13)
		cls_loss 0.04 (0.07)	reg_loss 0.03 (0.06)
Epoch: [032][00050/00100]	Time 0.24 (0.24)	Loss 0.08 (0.12)
		cls_loss 0.04 (0.06)	reg_loss 0.04 (0.06)
Epoch: [032][00060/00100]	Time 0.24 (0.24)	Loss 0.06 (0.11)
		cls_loss 0.03 (0.06)	reg_loss 0.03 (0.05)
Epoch: [032][00070/00100]	Time 0.23 (0.24)	Loss 0.13 (0.11)
		cls_loss 0.08 (0.06)	reg_loss 0.06 (0.05)
Epoch: [032][00080/00100]	Time 0.23 (0.24)	Loss 0.03 (0.10)
		cls_loss 0.02 (0.05)	reg_loss 0.01 (0.05)
Epoch: [032][00090/00100]	Time 0.23 (0.24)	Loss 0.64 (0.16)
		cls_loss 0.35 (0.09)	reg_loss 0.29 (0.07)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00100]	Time 0.30 (0.30)	Loss 0.06 (0.06)
		cls_loss 0.03 (0.03)	reg_loss 0.03 (0.03)
Epoch: [033][00020/00100]	Time 0.23 (0.26)	Loss 0.50 (0.28)
		cls_loss 0.25 (0.14)	reg_loss 0.25 (0.14)
Epoch: [033][00030/00100]	Time 0.23 (0.25)	Loss 0.21 (0.26)
		cls_loss 0.11 (0.13)	reg_loss 0.11 (0.13)
Epoch: [033][00040/00100]	Time 0.23 (0.25)	Loss 0.27 (0.26)
		cls_loss 0.17 (0.14)	reg_loss 0.11 (0.12)
Epoch: [033][00050/00100]	Time 0.23 (0.24)	Loss 0.05 (0.22)
		cls_loss 0.03 (0.12)	reg_loss 0.03 (0.11)
Epoch: [033][00060/00100]	Time 0.23 (0.24)	Loss 0.89 (0.33)
		cls_loss 0.43 (0.17)	reg_loss 0.46 (0.16)
Epoch: [033][00070/00100]	Time 0.23 (0.24)	Loss 0.38 (0.34)
		cls_loss 0.19 (0.17)	reg_loss 0.19 (0.17)
Epoch: [033][00080/00100]	Time 0.23 (0.24)	Loss 0.05 (0.30)
		cls_loss 0.03 (0.15)	reg_loss 0.02 (0.15)
Epoch: [033][00090/00100]	Time 0.23 (0.24)	Loss 0.16 (0.29)
		cls_loss 0.09 (0.15)	reg_loss 0.07 (0.14)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00100]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.07 (0.07)	reg_loss 0.07 (0.07)
Epoch: [034][00020/00100]	Time 0.23 (0.25)	Loss 0.31 (0.22)
		cls_loss 0.18 (0.12)	reg_loss 0.13 (0.10)
Epoch: [034][00030/00100]	Time 0.23 (0.25)	Loss 0.28 (0.24)
		cls_loss 0.18 (0.14)	reg_loss 0.10 (0.10)
Epoch: [034][00040/00100]	Time 0.23 (0.24)	Loss 0.30 (0.26)
		cls_loss 0.16 (0.15)	reg_loss 0.13 (0.11)
Epoch: [034][00050/00100]	Time 0.24 (0.24)	Loss 0.70 (0.34)
		cls_loss 0.35 (0.19)	reg_loss 0.35 (0.16)
Epoch: [034][00060/00100]	Time 0.24 (0.24)	Loss 0.30 (0.34)
		cls_loss 0.15 (0.18)	reg_loss 0.15 (0.16)
Epoch: [034][00070/00100]	Time 0.24 (0.24)	Loss 0.47 (0.36)
		cls_loss 0.24 (0.19)	reg_loss 0.23 (0.17)
Epoch: [034][00080/00100]	Time 0.24 (0.24)	Loss 0.03 (0.32)
		cls_loss 0.02 (0.17)	reg_loss 0.01 (0.15)
Epoch: [034][00090/00100]	Time 0.24 (0.24)	Loss 0.15 (0.30)
		cls_loss 0.09 (0.16)	reg_loss 0.06 (0.14)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.53 (0.53)
Test: [00020/00212]	Time 0.08 (0.31)
Test: [00030/00212]	Time 0.09 (0.23)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.07 (0.16)
Test: [00070/00212]	Time 0.09 (0.15)
Test: [00080/00212]	Time 0.08 (0.14)
Test: [00090/00212]	Time 0.08 (0.13)
Test: [00100/00212]	Time 0.10 (0.13)
Test: [00110/00212]	Time 0.11 (0.13)
Test: [00120/00212]	Time 0.08 (0.12)
Test: [00130/00212]	Time 0.09 (0.12)
Test: [00140/00212]	Time 0.08 (0.12)
Test: [00150/00212]	Time 0.08 (0.12)
Test: [00160/00212]	Time 0.11 (0.12)
Test: [00170/00212]	Time 0.11 (0.12)
Test: [00180/00212]	Time 0.09 (0.11)
Test: [00190/00212]	Time 0.10 (0.11)
Test: [00200/00212]	Time 0.08 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 82.16 (%) Recall@1x = 84.63 (%) Recall@5x = 96.46 (%) 
|tIoU = 0.40: mAP = 78.28 (%) Recall@1x = 80.82 (%) Recall@5x = 95.09 (%) 
|tIoU = 0.50: mAP = 71.07 (%) Recall@1x = 74.65 (%) Recall@5x = 91.67 (%) 
|tIoU = 0.60: mAP = 58.52 (%) Recall@1x = 64.57 (%) Recall@5x = 83.55 (%) 
|tIoU = 0.70: mAP = 43.77 (%) Recall@1x = 52.65 (%) Recall@5x = 71.37 (%) 
Average mAP: 66.76 (%)
All done! Total time: 279.17 sec
Looking for a split for p=1
Found split for p=1
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00100]	Time 1.41 (1.41)	Loss 6.23 (6.23)
		cls_loss 3.37 (3.37)	reg_loss 2.85 (2.85)
Epoch: [000][00020/00100]	Time 0.24 (0.83)	Loss 1.39 (3.81)
		cls_loss 0.91 (2.14)	reg_loss 0.47 (1.66)
Epoch: [000][00030/00100]	Time 0.23 (0.63)	Loss 0.45 (2.69)
		cls_loss 0.32 (1.53)	reg_loss 0.13 (1.15)
Epoch: [000][00040/00100]	Time 0.23 (0.53)	Loss 1.03 (2.27)
		cls_loss 0.75 (1.34)	reg_loss 0.28 (0.94)
Epoch: [000][00050/00100]	Time 0.23 (0.47)	Loss 1.09 (2.04)
		cls_loss 0.80 (1.23)	reg_loss 0.29 (0.81)
Epoch: [000][00060/00100]	Time 0.23 (0.43)	Loss 0.42 (1.77)
		cls_loss 0.31 (1.08)	reg_loss 0.11 (0.69)
Epoch: [000][00070/00100]	Time 0.32 (0.41)	Loss 4.02 (2.09)
		cls_loss 2.90 (1.34)	reg_loss 1.12 (0.75)
Epoch: [000][00080/00100]	Time 0.22 (0.39)	Loss 1.88 (2.06)
		cls_loss 1.31 (1.33)	reg_loss 0.58 (0.73)
Epoch: [000][00090/00100]	Time 0.23 (0.37)	Loss 0.39 (1.88)
		cls_loss 0.27 (1.21)	reg_loss 0.13 (0.66)
[Train]: Epoch 0 finished with lr=0.00002004


[Train]: Epoch 1 started
Epoch: [001][00010/00100]	Time 0.65 (0.65)	Loss 0.57 (0.57)
		cls_loss 0.41 (0.41)	reg_loss 0.16 (0.16)
Epoch: [001][00020/00100]	Time 0.24 (0.44)	Loss 2.19 (1.38)
		cls_loss 1.64 (1.02)	reg_loss 0.55 (0.35)
Epoch: [001][00030/00100]	Time 0.29 (0.39)	Loss 0.50 (1.09)
		cls_loss 0.33 (0.79)	reg_loss 0.17 (0.29)
Epoch: [001][00040/00100]	Time 0.23 (0.35)	Loss 1.57 (1.21)
		cls_loss 1.19 (0.89)	reg_loss 0.39 (0.32)
Epoch: [001][00050/00100]	Time 0.32 (0.35)	Loss 0.90 (1.15)
		cls_loss 0.69 (0.85)	reg_loss 0.21 (0.29)
Epoch: [001][00060/00100]	Time 0.22 (0.32)	Loss 0.28 (1.00)
		cls_loss 0.18 (0.74)	reg_loss 0.10 (0.26)
Epoch: [001][00070/00100]	Time 0.31 (0.32)	Loss 0.26 (0.90)
		cls_loss 0.19 (0.66)	reg_loss 0.07 (0.23)
Epoch: [001][00080/00100]	Time 0.23 (0.31)	Loss 0.28 (0.82)
		cls_loss 0.19 (0.60)	reg_loss 0.09 (0.22)
Epoch: [001][00090/00100]	Time 0.24 (0.30)	Loss 2.45 (1.00)
		cls_loss 1.37 (0.69)	reg_loss 1.07 (0.31)
[Train]: Epoch 1 finished with lr=0.00004008


[Train]: Epoch 2 started
Epoch: [002][00010/00100]	Time 0.27 (0.27)	Loss 0.48 (0.48)
		cls_loss 0.35 (0.35)	reg_loss 0.13 (0.13)
Epoch: [002][00020/00100]	Time 0.24 (0.26)	Loss 0.96 (0.72)
		cls_loss 0.58 (0.46)	reg_loss 0.38 (0.25)
Epoch: [002][00030/00100]	Time 0.23 (0.25)	Loss 1.24 (0.89)
		cls_loss 0.78 (0.57)	reg_loss 0.46 (0.32)
Epoch: [002][00040/00100]	Time 0.23 (0.24)	Loss 0.39 (0.77)
		cls_loss 0.27 (0.49)	reg_loss 0.13 (0.27)
Epoch: [002][00050/00100]	Time 0.24 (0.24)	Loss 1.86 (0.99)
		cls_loss 1.01 (0.60)	reg_loss 0.85 (0.39)
Epoch: [002][00060/00100]	Time 0.22 (0.24)	Loss 0.67 (0.93)
		cls_loss 0.39 (0.56)	reg_loss 0.28 (0.37)
Epoch: [002][00070/00100]	Time 0.22 (0.24)	Loss 1.01 (0.94)
		cls_loss 0.71 (0.58)	reg_loss 0.30 (0.36)
Epoch: [002][00080/00100]	Time 0.24 (0.24)	Loss 0.89 (0.94)
		cls_loss 0.64 (0.59)	reg_loss 0.24 (0.35)
Epoch: [002][00090/00100]	Time 0.23 (0.24)	Loss 0.71 (0.91)
		cls_loss 0.55 (0.59)	reg_loss 0.16 (0.33)
[Train]: Epoch 2 finished with lr=0.00006012


[Train]: Epoch 3 started
Epoch: [003][00010/00100]	Time 0.28 (0.28)	Loss 0.93 (0.93)
		cls_loss 0.54 (0.54)	reg_loss 0.39 (0.39)
Epoch: [003][00020/00100]	Time 0.23 (0.26)	Loss 0.26 (0.60)
		cls_loss 0.19 (0.36)	reg_loss 0.07 (0.23)
Epoch: [003][00030/00100]	Time 0.23 (0.25)	Loss 1.24 (0.81)
		cls_loss 0.70 (0.48)	reg_loss 0.54 (0.33)
Epoch: [003][00040/00100]	Time 0.23 (0.24)	Loss 0.47 (0.72)
		cls_loss 0.33 (0.44)	reg_loss 0.14 (0.29)
Epoch: [003][00050/00100]	Time 0.23 (0.24)	Loss 0.84 (0.75)
		cls_loss 0.58 (0.47)	reg_loss 0.26 (0.28)
Epoch: [003][00060/00100]	Time 0.24 (0.24)	Loss 2.23 (0.99)
		cls_loss 1.36 (0.62)	reg_loss 0.86 (0.38)
Epoch: [003][00070/00100]	Time 0.23 (0.24)	Loss 0.60 (0.94)
		cls_loss 0.45 (0.59)	reg_loss 0.16 (0.35)
Epoch: [003][00080/00100]	Time 0.24 (0.24)	Loss 0.65 (0.90)
		cls_loss 0.36 (0.56)	reg_loss 0.29 (0.34)
Epoch: [003][00090/00100]	Time 0.23 (0.24)	Loss 0.45 (0.85)
		cls_loss 0.29 (0.53)	reg_loss 0.16 (0.32)
[Train]: Epoch 3 finished with lr=0.00008016


[Train]: Epoch 4 started
Epoch: [004][00010/00100]	Time 0.30 (0.30)	Loss 0.35 (0.35)
		cls_loss 0.23 (0.23)	reg_loss 0.11 (0.11)
Epoch: [004][00020/00100]	Time 0.23 (0.26)	Loss 1.05 (0.70)
		cls_loss 0.57 (0.40)	reg_loss 0.48 (0.29)
Epoch: [004][00030/00100]	Time 0.23 (0.25)	Loss 0.34 (0.58)
		cls_loss 0.23 (0.35)	reg_loss 0.11 (0.23)
Epoch: [004][00040/00100]	Time 0.22 (0.25)	Loss 0.15 (0.47)
		cls_loss 0.10 (0.28)	reg_loss 0.05 (0.19)
Epoch: [004][00050/00100]	Time 0.24 (0.24)	Loss 0.57 (0.49)
		cls_loss 0.42 (0.31)	reg_loss 0.15 (0.18)
Epoch: [004][00060/00100]	Time 0.24 (0.24)	Loss 0.62 (0.51)
		cls_loss 0.37 (0.32)	reg_loss 0.25 (0.19)
Epoch: [004][00070/00100]	Time 0.23 (0.24)	Loss 0.70 (0.54)
		cls_loss 0.37 (0.33)	reg_loss 0.33 (0.21)
Epoch: [004][00080/00100]	Time 0.23 (0.24)	Loss 0.29 (0.51)
		cls_loss 0.20 (0.31)	reg_loss 0.09 (0.20)
Epoch: [004][00090/00100]	Time 0.23 (0.24)	Loss 0.27 (0.48)
		cls_loss 0.18 (0.30)	reg_loss 0.09 (0.18)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00100]	Time 0.28 (0.28)	Loss 0.33 (0.33)
		cls_loss 0.20 (0.20)	reg_loss 0.13 (0.13)
Epoch: [005][00020/00100]	Time 0.23 (0.25)	Loss 0.19 (0.26)
		cls_loss 0.12 (0.16)	reg_loss 0.07 (0.10)
Epoch: [005][00030/00100]	Time 0.23 (0.25)	Loss 1.80 (0.77)
		cls_loss 1.03 (0.45)	reg_loss 0.76 (0.32)
Epoch: [005][00040/00100]	Time 0.23 (0.24)	Loss 0.61 (0.73)
		cls_loss 0.40 (0.44)	reg_loss 0.21 (0.29)
Epoch: [005][00050/00100]	Time 0.23 (0.24)	Loss 0.86 (0.76)
		cls_loss 0.66 (0.48)	reg_loss 0.21 (0.28)
Epoch: [005][00060/00100]	Time 0.23 (0.24)	Loss 0.44 (0.70)
		cls_loss 0.29 (0.45)	reg_loss 0.15 (0.25)
Epoch: [005][00070/00100]	Time 0.23 (0.24)	Loss 0.85 (0.73)
		cls_loss 0.63 (0.48)	reg_loss 0.22 (0.25)
Epoch: [005][00080/00100]	Time 0.23 (0.24)	Loss 0.31 (0.67)
		cls_loss 0.19 (0.44)	reg_loss 0.13 (0.23)
Epoch: [005][00090/00100]	Time 0.23 (0.24)	Loss 0.82 (0.69)
		cls_loss 0.57 (0.45)	reg_loss 0.25 (0.24)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00100]	Time 0.27 (0.27)	Loss 1.32 (1.32)
		cls_loss 0.90 (0.90)	reg_loss 0.41 (0.41)
Epoch: [006][00020/00100]	Time 0.23 (0.25)	Loss 0.59 (0.95)
		cls_loss 0.38 (0.64)	reg_loss 0.21 (0.31)
Epoch: [006][00030/00100]	Time 0.23 (0.24)	Loss 0.32 (0.74)
		cls_loss 0.19 (0.49)	reg_loss 0.13 (0.25)
Epoch: [006][00040/00100]	Time 0.22 (0.24)	Loss 1.07 (0.82)
		cls_loss 0.74 (0.55)	reg_loss 0.34 (0.27)
Epoch: [006][00050/00100]	Time 0.23 (0.24)	Loss 0.31 (0.72)
		cls_loss 0.22 (0.49)	reg_loss 0.09 (0.23)
Epoch: [006][00060/00100]	Time 0.24 (0.24)	Loss 0.60 (0.70)
		cls_loss 0.37 (0.47)	reg_loss 0.23 (0.23)
Epoch: [006][00070/00100]	Time 0.24 (0.24)	Loss 0.48 (0.67)
		cls_loss 0.29 (0.44)	reg_loss 0.19 (0.23)
Epoch: [006][00080/00100]	Time 0.23 (0.24)	Loss 0.17 (0.61)
		cls_loss 0.12 (0.40)	reg_loss 0.05 (0.21)
Epoch: [006][00090/00100]	Time 0.23 (0.24)	Loss 1.32 (0.69)
		cls_loss 0.81 (0.45)	reg_loss 0.51 (0.24)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00100]	Time 0.29 (0.29)	Loss 0.50 (0.50)
		cls_loss 0.34 (0.34)	reg_loss 0.17 (0.17)
Epoch: [007][00020/00100]	Time 0.23 (0.26)	Loss 0.70 (0.60)
		cls_loss 0.46 (0.40)	reg_loss 0.23 (0.20)
Epoch: [007][00030/00100]	Time 0.23 (0.25)	Loss 0.84 (0.68)
		cls_loss 0.48 (0.43)	reg_loss 0.36 (0.25)
Epoch: [007][00040/00100]	Time 0.24 (0.25)	Loss 1.54 (0.90)
		cls_loss 0.99 (0.57)	reg_loss 0.55 (0.33)
Epoch: [007][00050/00100]	Time 0.23 (0.24)	Loss 0.37 (0.79)
		cls_loss 0.23 (0.50)	reg_loss 0.14 (0.29)
Epoch: [007][00060/00100]	Time 0.23 (0.24)	Loss 0.75 (0.78)
		cls_loss 0.49 (0.50)	reg_loss 0.26 (0.29)
Epoch: [007][00070/00100]	Time 0.24 (0.24)	Loss 0.30 (0.72)
		cls_loss 0.22 (0.46)	reg_loss 0.09 (0.26)
Epoch: [007][00080/00100]	Time 0.23 (0.24)	Loss 0.37 (0.67)
		cls_loss 0.23 (0.43)	reg_loss 0.14 (0.24)
Epoch: [007][00090/00100]	Time 0.23 (0.24)	Loss 0.13 (0.61)
		cls_loss 0.08 (0.39)	reg_loss 0.05 (0.22)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00100]	Time 0.27 (0.27)	Loss 0.17 (0.17)
		cls_loss 0.10 (0.10)	reg_loss 0.07 (0.07)
Epoch: [008][00020/00100]	Time 0.23 (0.25)	Loss 0.79 (0.48)
		cls_loss 0.44 (0.27)	reg_loss 0.35 (0.21)
Epoch: [008][00030/00100]	Time 0.24 (0.25)	Loss 1.24 (0.73)
		cls_loss 0.73 (0.42)	reg_loss 0.51 (0.31)
Epoch: [008][00040/00100]	Time 0.23 (0.24)	Loss 0.42 (0.66)
		cls_loss 0.23 (0.38)	reg_loss 0.19 (0.28)
Epoch: [008][00050/00100]	Time 0.23 (0.24)	Loss 0.47 (0.62)
		cls_loss 0.29 (0.36)	reg_loss 0.19 (0.26)
Epoch: [008][00060/00100]	Time 0.24 (0.24)	Loss 0.87 (0.66)
		cls_loss 0.49 (0.38)	reg_loss 0.38 (0.28)
Epoch: [008][00070/00100]	Time 0.24 (0.24)	Loss 0.96 (0.70)
		cls_loss 0.59 (0.41)	reg_loss 0.37 (0.29)
Epoch: [008][00080/00100]	Time 0.23 (0.24)	Loss 0.42 (0.67)
		cls_loss 0.23 (0.39)	reg_loss 0.19 (0.28)
Epoch: [008][00090/00100]	Time 0.23 (0.24)	Loss 0.23 (0.62)
		cls_loss 0.16 (0.36)	reg_loss 0.06 (0.26)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00100]	Time 0.29 (0.29)	Loss 1.51 (1.51)
		cls_loss 0.97 (0.97)	reg_loss 0.54 (0.54)
Epoch: [009][00020/00100]	Time 0.24 (0.26)	Loss 0.33 (0.92)
		cls_loss 0.18 (0.58)	reg_loss 0.15 (0.34)
Epoch: [009][00030/00100]	Time 0.23 (0.25)	Loss 0.88 (0.91)
		cls_loss 0.50 (0.55)	reg_loss 0.38 (0.36)
Epoch: [009][00040/00100]	Time 0.23 (0.25)	Loss 0.36 (0.77)
		cls_loss 0.21 (0.47)	reg_loss 0.14 (0.30)
Epoch: [009][00050/00100]	Time 0.22 (0.24)	Loss 0.21 (0.66)
		cls_loss 0.11 (0.39)	reg_loss 0.10 (0.26)
Epoch: [009][00060/00100]	Time 0.23 (0.24)	Loss 0.28 (0.60)
		cls_loss 0.15 (0.35)	reg_loss 0.14 (0.24)
Epoch: [009][00070/00100]	Time 0.23 (0.24)	Loss 0.30 (0.55)
		cls_loss 0.16 (0.33)	reg_loss 0.15 (0.23)
Epoch: [009][00080/00100]	Time 0.23 (0.24)	Loss 0.27 (0.52)
		cls_loss 0.16 (0.31)	reg_loss 0.11 (0.21)
Epoch: [009][00090/00100]	Time 0.25 (0.24)	Loss 0.32 (0.50)
		cls_loss 0.18 (0.29)	reg_loss 0.13 (0.20)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00100]	Time 0.27 (0.27)	Loss 0.22 (0.22)
		cls_loss 0.14 (0.14)	reg_loss 0.08 (0.08)
Epoch: [010][00020/00100]	Time 0.24 (0.26)	Loss 0.52 (0.37)
		cls_loss 0.29 (0.22)	reg_loss 0.23 (0.15)
Epoch: [010][00030/00100]	Time 0.23 (0.25)	Loss 0.42 (0.39)
		cls_loss 0.23 (0.22)	reg_loss 0.19 (0.16)
Epoch: [010][00040/00100]	Time 0.23 (0.24)	Loss 0.26 (0.35)
		cls_loss 0.14 (0.20)	reg_loss 0.12 (0.15)
Epoch: [010][00050/00100]	Time 0.23 (0.24)	Loss 0.58 (0.40)
		cls_loss 0.31 (0.22)	reg_loss 0.27 (0.18)
Epoch: [010][00060/00100]	Time 0.23 (0.24)	Loss 0.64 (0.44)
		cls_loss 0.37 (0.25)	reg_loss 0.27 (0.19)
Epoch: [010][00070/00100]	Time 0.23 (0.24)	Loss 0.78 (0.49)
		cls_loss 0.43 (0.27)	reg_loss 0.35 (0.21)
Epoch: [010][00080/00100]	Time 0.24 (0.24)	Loss 0.30 (0.46)
		cls_loss 0.18 (0.26)	reg_loss 0.11 (0.20)
Epoch: [010][00090/00100]	Time 0.23 (0.24)	Loss 0.79 (0.50)
		cls_loss 0.38 (0.28)	reg_loss 0.41 (0.22)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00100]	Time 0.29 (0.29)	Loss 2.15 (2.15)
		cls_loss 1.36 (1.36)	reg_loss 0.79 (0.79)
Epoch: [011][00020/00100]	Time 0.23 (0.26)	Loss 1.92 (2.04)
		cls_loss 1.03 (1.19)	reg_loss 0.89 (0.84)
Epoch: [011][00030/00100]	Time 0.23 (0.25)	Loss 0.36 (1.48)
		cls_loss 0.22 (0.87)	reg_loss 0.14 (0.61)
Epoch: [011][00040/00100]	Time 0.24 (0.25)	Loss 0.23 (1.17)
		cls_loss 0.16 (0.69)	reg_loss 0.07 (0.47)
Epoch: [011][00050/00100]	Time 0.24 (0.25)	Loss 0.17 (0.97)
		cls_loss 0.10 (0.57)	reg_loss 0.07 (0.39)
Epoch: [011][00060/00100]	Time 0.23 (0.24)	Loss 0.24 (0.85)
		cls_loss 0.14 (0.50)	reg_loss 0.11 (0.34)
Epoch: [011][00070/00100]	Time 0.23 (0.24)	Loss 0.27 (0.76)
		cls_loss 0.20 (0.46)	reg_loss 0.07 (0.31)
Epoch: [011][00080/00100]	Time 0.23 (0.24)	Loss 0.22 (0.70)
		cls_loss 0.16 (0.42)	reg_loss 0.06 (0.28)
Epoch: [011][00090/00100]	Time 0.23 (0.24)	Loss 0.20 (0.64)
		cls_loss 0.13 (0.39)	reg_loss 0.07 (0.25)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00100]	Time 0.30 (0.30)	Loss 0.33 (0.33)
		cls_loss 0.18 (0.18)	reg_loss 0.15 (0.15)
Epoch: [012][00020/00100]	Time 0.24 (0.27)	Loss 0.86 (0.59)
		cls_loss 0.46 (0.32)	reg_loss 0.39 (0.27)
Epoch: [012][00030/00100]	Time 0.23 (0.26)	Loss 0.55 (0.58)
		cls_loss 0.37 (0.34)	reg_loss 0.18 (0.24)
Epoch: [012][00040/00100]	Time 0.23 (0.25)	Loss 0.22 (0.49)
		cls_loss 0.11 (0.28)	reg_loss 0.10 (0.20)
Epoch: [012][00050/00100]	Time 0.22 (0.24)	Loss 0.14 (0.42)
		cls_loss 0.08 (0.24)	reg_loss 0.06 (0.17)
Epoch: [012][00060/00100]	Time 0.23 (0.24)	Loss 0.77 (0.48)
		cls_loss 0.45 (0.28)	reg_loss 0.32 (0.20)
Epoch: [012][00070/00100]	Time 0.23 (0.24)	Loss 0.25 (0.44)
		cls_loss 0.14 (0.26)	reg_loss 0.10 (0.19)
Epoch: [012][00080/00100]	Time 0.23 (0.24)	Loss 0.40 (0.44)
		cls_loss 0.33 (0.27)	reg_loss 0.08 (0.17)
Epoch: [012][00090/00100]	Time 0.23 (0.24)	Loss 0.59 (0.46)
		cls_loss 0.34 (0.28)	reg_loss 0.25 (0.18)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00100]	Time 0.30 (0.30)	Loss 0.54 (0.54)
		cls_loss 0.32 (0.32)	reg_loss 0.22 (0.22)
Epoch: [013][00020/00100]	Time 0.23 (0.26)	Loss 0.35 (0.45)
		cls_loss 0.19 (0.26)	reg_loss 0.16 (0.19)
Epoch: [013][00030/00100]	Time 0.23 (0.25)	Loss 0.54 (0.48)
		cls_loss 0.41 (0.31)	reg_loss 0.14 (0.17)
Epoch: [013][00040/00100]	Time 0.23 (0.25)	Loss 0.86 (0.57)
		cls_loss 0.51 (0.36)	reg_loss 0.35 (0.22)
Epoch: [013][00050/00100]	Time 0.23 (0.24)	Loss 1.74 (0.81)
		cls_loss 1.10 (0.50)	reg_loss 0.65 (0.30)
Epoch: [013][00060/00100]	Time 0.23 (0.24)	Loss 0.39 (0.74)
		cls_loss 0.23 (0.46)	reg_loss 0.16 (0.28)
Epoch: [013][00070/00100]	Time 0.24 (0.24)	Loss 0.26 (0.67)
		cls_loss 0.15 (0.41)	reg_loss 0.12 (0.26)
Epoch: [013][00080/00100]	Time 0.23 (0.24)	Loss 0.52 (0.65)
		cls_loss 0.37 (0.41)	reg_loss 0.15 (0.24)
Epoch: [013][00090/00100]	Time 0.23 (0.24)	Loss 0.24 (0.61)
		cls_loss 0.14 (0.38)	reg_loss 0.10 (0.23)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00100]	Time 0.29 (0.29)	Loss 0.39 (0.39)
		cls_loss 0.21 (0.21)	reg_loss 0.17 (0.17)
Epoch: [014][00020/00100]	Time 0.23 (0.26)	Loss 0.37 (0.38)
		cls_loss 0.20 (0.21)	reg_loss 0.17 (0.17)
Epoch: [014][00030/00100]	Time 0.23 (0.25)	Loss 0.89 (0.55)
		cls_loss 0.51 (0.31)	reg_loss 0.38 (0.24)
Epoch: [014][00040/00100]	Time 0.23 (0.24)	Loss 0.35 (0.50)
		cls_loss 0.18 (0.28)	reg_loss 0.16 (0.22)
Epoch: [014][00050/00100]	Time 0.23 (0.24)	Loss 1.62 (0.72)
		cls_loss 0.82 (0.39)	reg_loss 0.80 (0.34)
Epoch: [014][00060/00100]	Time 0.23 (0.24)	Loss 0.74 (0.72)
		cls_loss 0.40 (0.39)	reg_loss 0.33 (0.34)
Epoch: [014][00070/00100]	Time 0.23 (0.24)	Loss 0.50 (0.69)
		cls_loss 0.35 (0.38)	reg_loss 0.16 (0.31)
Epoch: [014][00080/00100]	Time 0.23 (0.24)	Loss 0.30 (0.64)
		cls_loss 0.18 (0.36)	reg_loss 0.13 (0.29)
Epoch: [014][00090/00100]	Time 0.22 (0.24)	Loss 0.30 (0.61)
		cls_loss 0.16 (0.33)	reg_loss 0.14 (0.27)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00100]	Time 0.29 (0.29)	Loss 1.89 (1.89)
		cls_loss 1.06 (1.06)	reg_loss 0.83 (0.83)
Epoch: [015][00020/00100]	Time 0.23 (0.26)	Loss 0.58 (1.24)
		cls_loss 0.31 (0.68)	reg_loss 0.28 (0.55)
Epoch: [015][00030/00100]	Time 0.22 (0.25)	Loss 0.39 (0.95)
		cls_loss 0.23 (0.53)	reg_loss 0.16 (0.42)
Epoch: [015][00040/00100]	Time 0.22 (0.24)	Loss 0.29 (0.79)
		cls_loss 0.16 (0.44)	reg_loss 0.14 (0.35)
Epoch: [015][00050/00100]	Time 0.22 (0.24)	Loss 0.29 (0.69)
		cls_loss 0.14 (0.38)	reg_loss 0.15 (0.31)
Epoch: [015][00060/00100]	Time 0.23 (0.24)	Loss 0.37 (0.64)
		cls_loss 0.18 (0.35)	reg_loss 0.19 (0.29)
Epoch: [015][00070/00100]	Time 0.22 (0.23)	Loss 0.25 (0.58)
		cls_loss 0.17 (0.32)	reg_loss 0.08 (0.26)
Epoch: [015][00080/00100]	Time 0.22 (0.23)	Loss 0.38 (0.56)
		cls_loss 0.21 (0.31)	reg_loss 0.17 (0.25)
Epoch: [015][00090/00100]	Time 0.22 (0.23)	Loss 0.13 (0.51)
		cls_loss 0.08 (0.28)	reg_loss 0.05 (0.23)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00100]	Time 0.27 (0.27)	Loss 0.87 (0.87)
		cls_loss 0.60 (0.60)	reg_loss 0.27 (0.27)
Epoch: [016][00020/00100]	Time 0.23 (0.25)	Loss 0.11 (0.49)
		cls_loss 0.07 (0.33)	reg_loss 0.05 (0.16)
Epoch: [016][00030/00100]	Time 0.23 (0.24)	Loss 0.11 (0.36)
		cls_loss 0.06 (0.24)	reg_loss 0.05 (0.12)
Epoch: [016][00040/00100]	Time 0.22 (0.24)	Loss 0.36 (0.36)
		cls_loss 0.23 (0.24)	reg_loss 0.14 (0.13)
Epoch: [016][00050/00100]	Time 0.22 (0.23)	Loss 0.12 (0.32)
		cls_loss 0.07 (0.20)	reg_loss 0.05 (0.11)
Epoch: [016][00060/00100]	Time 0.23 (0.23)	Loss 0.55 (0.35)
		cls_loss 0.31 (0.22)	reg_loss 0.23 (0.13)
Epoch: [016][00070/00100]	Time 0.23 (0.23)	Loss 0.28 (0.34)
		cls_loss 0.17 (0.22)	reg_loss 0.11 (0.13)
Epoch: [016][00080/00100]	Time 0.23 (0.23)	Loss 0.12 (0.32)
		cls_loss 0.07 (0.20)	reg_loss 0.05 (0.12)
Epoch: [016][00090/00100]	Time 0.22 (0.23)	Loss 0.32 (0.32)
		cls_loss 0.18 (0.20)	reg_loss 0.13 (0.12)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00100]	Time 0.28 (0.28)	Loss 0.49 (0.49)
		cls_loss 0.30 (0.30)	reg_loss 0.19 (0.19)
Epoch: [017][00020/00100]	Time 0.23 (0.26)	Loss 0.24 (0.36)
		cls_loss 0.14 (0.22)	reg_loss 0.10 (0.15)
Epoch: [017][00030/00100]	Time 0.23 (0.25)	Loss 0.39 (0.37)
		cls_loss 0.19 (0.21)	reg_loss 0.20 (0.16)
Epoch: [017][00040/00100]	Time 0.23 (0.24)	Loss 0.61 (0.43)
		cls_loss 0.32 (0.24)	reg_loss 0.29 (0.20)
Epoch: [017][00050/00100]	Time 0.23 (0.24)	Loss 0.76 (0.50)
		cls_loss 0.41 (0.27)	reg_loss 0.35 (0.23)
Epoch: [017][00060/00100]	Time 0.22 (0.24)	Loss 1.65 (0.69)
		cls_loss 0.79 (0.36)	reg_loss 0.86 (0.33)
Epoch: [017][00070/00100]	Time 0.22 (0.23)	Loss 0.13 (0.61)
		cls_loss 0.07 (0.32)	reg_loss 0.07 (0.29)
Epoch: [017][00080/00100]	Time 0.22 (0.23)	Loss 0.11 (0.55)
		cls_loss 0.07 (0.29)	reg_loss 0.03 (0.26)
Epoch: [017][00090/00100]	Time 0.23 (0.23)	Loss 0.28 (0.52)
		cls_loss 0.15 (0.27)	reg_loss 0.13 (0.25)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00100]	Time 0.29 (0.29)	Loss 0.58 (0.58)
		cls_loss 0.29 (0.29)	reg_loss 0.29 (0.29)
Epoch: [018][00020/00100]	Time 0.22 (0.26)	Loss 0.03 (0.30)
		cls_loss 0.02 (0.15)	reg_loss 0.01 (0.15)
Epoch: [018][00030/00100]	Time 0.23 (0.25)	Loss 0.19 (0.26)
		cls_loss 0.10 (0.14)	reg_loss 0.08 (0.13)
Epoch: [018][00040/00100]	Time 0.22 (0.24)	Loss 0.11 (0.22)
		cls_loss 0.06 (0.12)	reg_loss 0.04 (0.11)
Epoch: [018][00050/00100]	Time 0.23 (0.24)	Loss 0.57 (0.29)
		cls_loss 0.32 (0.16)	reg_loss 0.26 (0.14)
Epoch: [018][00060/00100]	Time 0.23 (0.24)	Loss 0.07 (0.26)
		cls_loss 0.04 (0.14)	reg_loss 0.04 (0.12)
Epoch: [018][00070/00100]	Time 0.23 (0.23)	Loss 0.26 (0.26)
		cls_loss 0.16 (0.14)	reg_loss 0.10 (0.12)
Epoch: [018][00080/00100]	Time 0.23 (0.23)	Loss 0.22 (0.25)
		cls_loss 0.12 (0.14)	reg_loss 0.09 (0.11)
Epoch: [018][00090/00100]	Time 0.22 (0.23)	Loss 0.13 (0.24)
		cls_loss 0.07 (0.13)	reg_loss 0.05 (0.11)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00100]	Time 0.28 (0.28)	Loss 0.71 (0.71)
		cls_loss 0.37 (0.37)	reg_loss 0.34 (0.34)
Epoch: [019][00020/00100]	Time 0.22 (0.25)	Loss 0.76 (0.73)
		cls_loss 0.46 (0.42)	reg_loss 0.29 (0.32)
Epoch: [019][00030/00100]	Time 0.22 (0.24)	Loss 0.81 (0.76)
		cls_loss 0.44 (0.43)	reg_loss 0.37 (0.34)
Epoch: [019][00040/00100]	Time 0.23 (0.24)	Loss 0.14 (0.61)
		cls_loss 0.08 (0.34)	reg_loss 0.05 (0.26)
Epoch: [019][00050/00100]	Time 0.24 (0.24)	Loss 0.26 (0.54)
		cls_loss 0.14 (0.30)	reg_loss 0.12 (0.24)
Epoch: [019][00060/00100]	Time 0.23 (0.24)	Loss 0.18 (0.48)
		cls_loss 0.11 (0.27)	reg_loss 0.08 (0.21)
Epoch: [019][00070/00100]	Time 0.22 (0.23)	Loss 0.25 (0.44)
		cls_loss 0.13 (0.25)	reg_loss 0.12 (0.20)
Epoch: [019][00080/00100]	Time 0.23 (0.23)	Loss 0.16 (0.41)
		cls_loss 0.09 (0.23)	reg_loss 0.07 (0.18)
Epoch: [019][00090/00100]	Time 0.22 (0.23)	Loss 0.25 (0.39)
		cls_loss 0.13 (0.22)	reg_loss 0.13 (0.17)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00100]	Time 0.28 (0.28)	Loss 0.29 (0.29)
		cls_loss 0.20 (0.20)	reg_loss 0.09 (0.09)
Epoch: [020][00020/00100]	Time 0.23 (0.25)	Loss 0.21 (0.25)
		cls_loss 0.12 (0.16)	reg_loss 0.09 (0.09)
Epoch: [020][00030/00100]	Time 0.23 (0.25)	Loss 0.74 (0.42)
		cls_loss 0.35 (0.22)	reg_loss 0.39 (0.19)
Epoch: [020][00040/00100]	Time 0.23 (0.24)	Loss 0.14 (0.35)
		cls_loss 0.08 (0.19)	reg_loss 0.06 (0.16)
Epoch: [020][00050/00100]	Time 0.23 (0.24)	Loss 0.26 (0.33)
		cls_loss 0.14 (0.18)	reg_loss 0.11 (0.15)
Epoch: [020][00060/00100]	Time 0.23 (0.24)	Loss 0.21 (0.31)
		cls_loss 0.10 (0.17)	reg_loss 0.11 (0.14)
Epoch: [020][00070/00100]	Time 0.23 (0.24)	Loss 0.11 (0.28)
		cls_loss 0.05 (0.15)	reg_loss 0.06 (0.13)
Epoch: [020][00080/00100]	Time 0.23 (0.24)	Loss 1.39 (0.42)
		cls_loss 0.64 (0.21)	reg_loss 0.75 (0.21)
Epoch: [020][00090/00100]	Time 0.23 (0.23)	Loss 1.05 (0.49)
		cls_loss 0.71 (0.27)	reg_loss 0.34 (0.22)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00100]	Time 0.28 (0.28)	Loss 0.16 (0.16)
		cls_loss 0.08 (0.08)	reg_loss 0.08 (0.08)
Epoch: [021][00020/00100]	Time 0.23 (0.25)	Loss 0.18 (0.17)
		cls_loss 0.10 (0.09)	reg_loss 0.08 (0.08)
Epoch: [021][00030/00100]	Time 0.23 (0.25)	Loss 0.17 (0.17)
		cls_loss 0.10 (0.10)	reg_loss 0.07 (0.07)
Epoch: [021][00040/00100]	Time 0.22 (0.24)	Loss 0.14 (0.16)
		cls_loss 0.06 (0.09)	reg_loss 0.09 (0.08)
Epoch: [021][00050/00100]	Time 0.24 (0.24)	Loss 0.22 (0.17)
		cls_loss 0.12 (0.09)	reg_loss 0.10 (0.08)
Epoch: [021][00060/00100]	Time 0.24 (0.24)	Loss 1.17 (0.34)
		cls_loss 0.76 (0.20)	reg_loss 0.41 (0.14)
Epoch: [021][00070/00100]	Time 0.23 (0.24)	Loss 0.15 (0.31)
		cls_loss 0.07 (0.19)	reg_loss 0.08 (0.13)
Epoch: [021][00080/00100]	Time 0.23 (0.24)	Loss 0.14 (0.29)
		cls_loss 0.08 (0.17)	reg_loss 0.05 (0.12)
Epoch: [021][00090/00100]	Time 0.24 (0.24)	Loss 0.34 (0.30)
		cls_loss 0.17 (0.17)	reg_loss 0.17 (0.12)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00100]	Time 0.31 (0.31)	Loss 0.21 (0.21)
		cls_loss 0.08 (0.08)	reg_loss 0.13 (0.13)
Epoch: [022][00020/00100]	Time 0.23 (0.27)	Loss 0.34 (0.27)
		cls_loss 0.20 (0.14)	reg_loss 0.14 (0.13)
Epoch: [022][00030/00100]	Time 0.23 (0.26)	Loss 1.44 (0.66)
		cls_loss 0.75 (0.34)	reg_loss 0.69 (0.32)
Epoch: [022][00040/00100]	Time 0.23 (0.25)	Loss 0.32 (0.58)
		cls_loss 0.17 (0.30)	reg_loss 0.15 (0.28)
Epoch: [022][00050/00100]	Time 0.23 (0.25)	Loss 0.25 (0.51)
		cls_loss 0.13 (0.27)	reg_loss 0.12 (0.25)
Epoch: [022][00060/00100]	Time 0.23 (0.24)	Loss 0.12 (0.45)
		cls_loss 0.06 (0.23)	reg_loss 0.06 (0.21)
Epoch: [022][00070/00100]	Time 0.24 (0.24)	Loss 0.99 (0.52)
		cls_loss 0.44 (0.26)	reg_loss 0.55 (0.26)
Epoch: [022][00080/00100]	Time 0.23 (0.24)	Loss 0.45 (0.51)
		cls_loss 0.26 (0.26)	reg_loss 0.20 (0.25)
Epoch: [022][00090/00100]	Time 0.24 (0.24)	Loss 0.82 (0.55)
		cls_loss 0.44 (0.28)	reg_loss 0.38 (0.27)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00100]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.09 (0.09)	reg_loss 0.05 (0.05)
Epoch: [023][00020/00100]	Time 0.23 (0.26)	Loss 0.35 (0.24)
		cls_loss 0.23 (0.16)	reg_loss 0.12 (0.08)
Epoch: [023][00030/00100]	Time 0.24 (0.25)	Loss 0.14 (0.21)
		cls_loss 0.08 (0.13)	reg_loss 0.07 (0.08)
Epoch: [023][00040/00100]	Time 0.24 (0.25)	Loss 0.12 (0.19)
		cls_loss 0.09 (0.12)	reg_loss 0.03 (0.07)
Epoch: [023][00050/00100]	Time 0.23 (0.24)	Loss 0.14 (0.18)
		cls_loss 0.07 (0.11)	reg_loss 0.08 (0.07)
Epoch: [023][00060/00100]	Time 0.23 (0.24)	Loss 0.15 (0.17)
		cls_loss 0.06 (0.10)	reg_loss 0.08 (0.07)
Epoch: [023][00070/00100]	Time 0.23 (0.24)	Loss 0.65 (0.24)
		cls_loss 0.42 (0.15)	reg_loss 0.24 (0.09)
Epoch: [023][00080/00100]	Time 0.23 (0.24)	Loss 0.97 (0.33)
		cls_loss 0.67 (0.21)	reg_loss 0.30 (0.12)
Epoch: [023][00090/00100]	Time 0.24 (0.24)	Loss 0.19 (0.32)
		cls_loss 0.11 (0.20)	reg_loss 0.08 (0.12)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00100]	Time 0.28 (0.28)	Loss 0.12 (0.12)
		cls_loss 0.06 (0.06)	reg_loss 0.06 (0.06)
Epoch: [024][00020/00100]	Time 0.24 (0.26)	Loss 0.10 (0.11)
		cls_loss 0.06 (0.06)	reg_loss 0.04 (0.05)
Epoch: [024][00030/00100]	Time 0.24 (0.25)	Loss 0.09 (0.10)
		cls_loss 0.06 (0.06)	reg_loss 0.03 (0.04)
Epoch: [024][00040/00100]	Time 0.24 (0.25)	Loss 0.28 (0.15)
		cls_loss 0.15 (0.08)	reg_loss 0.13 (0.06)
Epoch: [024][00050/00100]	Time 0.24 (0.25)	Loss 0.17 (0.15)
		cls_loss 0.08 (0.08)	reg_loss 0.09 (0.07)
Epoch: [024][00060/00100]	Time 0.24 (0.25)	Loss 0.08 (0.14)
		cls_loss 0.06 (0.08)	reg_loss 0.03 (0.06)
Epoch: [024][00070/00100]	Time 0.23 (0.24)	Loss 0.09 (0.13)
		cls_loss 0.06 (0.07)	reg_loss 0.03 (0.06)
Epoch: [024][00080/00100]	Time 0.23 (0.24)	Loss 0.27 (0.15)
		cls_loss 0.15 (0.08)	reg_loss 0.12 (0.07)
Epoch: [024][00090/00100]	Time 0.23 (0.24)	Loss 0.70 (0.21)
		cls_loss 0.37 (0.12)	reg_loss 0.33 (0.09)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00100]	Time 0.28 (0.28)	Loss 0.75 (0.75)
		cls_loss 0.35 (0.35)	reg_loss 0.40 (0.40)
Epoch: [025][00020/00100]	Time 0.23 (0.26)	Loss 0.15 (0.45)
		cls_loss 0.07 (0.21)	reg_loss 0.08 (0.24)
Epoch: [025][00030/00100]	Time 0.23 (0.25)	Loss 0.72 (0.54)
		cls_loss 0.36 (0.26)	reg_loss 0.36 (0.28)
Epoch: [025][00040/00100]	Time 0.24 (0.25)	Loss 0.36 (0.49)
		cls_loss 0.18 (0.24)	reg_loss 0.18 (0.26)
Epoch: [025][00050/00100]	Time 0.24 (0.24)	Loss 0.31 (0.46)
		cls_loss 0.18 (0.23)	reg_loss 0.13 (0.23)
Epoch: [025][00060/00100]	Time 0.24 (0.24)	Loss 0.13 (0.40)
		cls_loss 0.07 (0.20)	reg_loss 0.06 (0.20)
Epoch: [025][00070/00100]	Time 0.24 (0.24)	Loss 0.26 (0.38)
		cls_loss 0.14 (0.19)	reg_loss 0.12 (0.19)
Epoch: [025][00080/00100]	Time 0.23 (0.24)	Loss 0.08 (0.34)
		cls_loss 0.04 (0.17)	reg_loss 0.04 (0.17)
Epoch: [025][00090/00100]	Time 0.23 (0.24)	Loss 0.29 (0.34)
		cls_loss 0.16 (0.17)	reg_loss 0.13 (0.17)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00100]	Time 0.29 (0.29)	Loss 0.26 (0.26)
		cls_loss 0.15 (0.15)	reg_loss 0.11 (0.11)
Epoch: [026][00020/00100]	Time 0.24 (0.27)	Loss 0.05 (0.16)
		cls_loss 0.02 (0.09)	reg_loss 0.03 (0.07)
Epoch: [026][00030/00100]	Time 0.24 (0.26)	Loss 0.12 (0.14)
		cls_loss 0.05 (0.08)	reg_loss 0.06 (0.07)
Epoch: [026][00040/00100]	Time 0.23 (0.25)	Loss 0.16 (0.15)
		cls_loss 0.09 (0.08)	reg_loss 0.07 (0.07)
Epoch: [026][00050/00100]	Time 0.23 (0.25)	Loss 0.38 (0.19)
		cls_loss 0.23 (0.11)	reg_loss 0.15 (0.08)
Epoch: [026][00060/00100]	Time 0.23 (0.24)	Loss 0.81 (0.30)
		cls_loss 0.40 (0.16)	reg_loss 0.42 (0.14)
Epoch: [026][00070/00100]	Time 0.24 (0.24)	Loss 0.24 (0.29)
		cls_loss 0.13 (0.15)	reg_loss 0.11 (0.14)
Epoch: [026][00080/00100]	Time 0.23 (0.24)	Loss 0.36 (0.30)
		cls_loss 0.22 (0.16)	reg_loss 0.13 (0.14)
Epoch: [026][00090/00100]	Time 0.23 (0.24)	Loss 0.08 (0.27)
		cls_loss 0.05 (0.15)	reg_loss 0.04 (0.13)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00100]	Time 0.30 (0.30)	Loss 0.23 (0.23)
		cls_loss 0.18 (0.18)	reg_loss 0.05 (0.05)
Epoch: [027][00020/00100]	Time 0.23 (0.27)	Loss 0.08 (0.16)
		cls_loss 0.05 (0.11)	reg_loss 0.03 (0.04)
Epoch: [027][00030/00100]	Time 0.23 (0.26)	Loss 0.05 (0.12)
		cls_loss 0.03 (0.09)	reg_loss 0.02 (0.04)
Epoch: [027][00040/00100]	Time 0.24 (0.25)	Loss 0.17 (0.13)
		cls_loss 0.08 (0.08)	reg_loss 0.09 (0.05)
Epoch: [027][00050/00100]	Time 0.24 (0.25)	Loss 0.27 (0.16)
		cls_loss 0.16 (0.10)	reg_loss 0.11 (0.06)
Epoch: [027][00060/00100]	Time 0.24 (0.25)	Loss 0.36 (0.19)
		cls_loss 0.19 (0.11)	reg_loss 0.17 (0.08)
Epoch: [027][00070/00100]	Time 0.23 (0.24)	Loss 0.17 (0.19)
		cls_loss 0.11 (0.11)	reg_loss 0.06 (0.08)
Epoch: [027][00080/00100]	Time 0.23 (0.24)	Loss 0.35 (0.21)
		cls_loss 0.21 (0.12)	reg_loss 0.14 (0.09)
Epoch: [027][00090/00100]	Time 0.23 (0.24)	Loss 0.30 (0.22)
		cls_loss 0.14 (0.13)	reg_loss 0.16 (0.09)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00100]	Time 0.29 (0.29)	Loss 0.55 (0.55)
		cls_loss 0.29 (0.29)	reg_loss 0.26 (0.26)
Epoch: [028][00020/00100]	Time 0.24 (0.26)	Loss 0.64 (0.59)
		cls_loss 0.33 (0.31)	reg_loss 0.31 (0.29)
Epoch: [028][00030/00100]	Time 0.24 (0.26)	Loss 0.22 (0.47)
		cls_loss 0.10 (0.24)	reg_loss 0.12 (0.23)
Epoch: [028][00040/00100]	Time 0.24 (0.25)	Loss 0.02 (0.36)
		cls_loss 0.01 (0.18)	reg_loss 0.01 (0.17)
Epoch: [028][00050/00100]	Time 0.24 (0.25)	Loss 0.14 (0.31)
		cls_loss 0.08 (0.16)	reg_loss 0.06 (0.15)
Epoch: [028][00060/00100]	Time 0.23 (0.25)	Loss 0.30 (0.31)
		cls_loss 0.16 (0.16)	reg_loss 0.14 (0.15)
Epoch: [028][00070/00100]	Time 0.23 (0.24)	Loss 0.14 (0.29)
		cls_loss 0.08 (0.15)	reg_loss 0.07 (0.14)
Epoch: [028][00080/00100]	Time 0.23 (0.24)	Loss 0.27 (0.29)
		cls_loss 0.15 (0.15)	reg_loss 0.12 (0.14)
Epoch: [028][00090/00100]	Time 0.24 (0.24)	Loss 0.04 (0.26)
		cls_loss 0.02 (0.14)	reg_loss 0.02 (0.12)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00100]	Time 0.31 (0.31)	Loss 0.69 (0.69)
		cls_loss 0.37 (0.37)	reg_loss 0.32 (0.32)
Epoch: [029][00020/00100]	Time 0.24 (0.27)	Loss 0.12 (0.40)
		cls_loss 0.06 (0.22)	reg_loss 0.06 (0.19)
Epoch: [029][00030/00100]	Time 0.24 (0.26)	Loss 0.20 (0.34)
		cls_loss 0.11 (0.18)	reg_loss 0.10 (0.16)
Epoch: [029][00040/00100]	Time 0.24 (0.25)	Loss 0.17 (0.30)
		cls_loss 0.11 (0.16)	reg_loss 0.07 (0.13)
Epoch: [029][00050/00100]	Time 0.23 (0.25)	Loss 0.22 (0.28)
		cls_loss 0.12 (0.15)	reg_loss 0.11 (0.13)
Epoch: [029][00060/00100]	Time 0.24 (0.25)	Loss 0.05 (0.24)
		cls_loss 0.02 (0.13)	reg_loss 0.03 (0.11)
Epoch: [029][00070/00100]	Time 0.24 (0.25)	Loss 0.65 (0.30)
		cls_loss 0.36 (0.16)	reg_loss 0.29 (0.14)
Epoch: [029][00080/00100]	Time 0.23 (0.24)	Loss 0.22 (0.29)
		cls_loss 0.13 (0.16)	reg_loss 0.09 (0.13)
Epoch: [029][00090/00100]	Time 0.23 (0.24)	Loss 0.14 (0.27)
		cls_loss 0.08 (0.15)	reg_loss 0.06 (0.12)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00100]	Time 0.29 (0.29)	Loss 0.36 (0.36)
		cls_loss 0.20 (0.20)	reg_loss 0.16 (0.16)
Epoch: [030][00020/00100]	Time 0.24 (0.26)	Loss 0.57 (0.47)
		cls_loss 0.28 (0.24)	reg_loss 0.29 (0.22)
Epoch: [030][00030/00100]	Time 0.23 (0.25)	Loss 0.02 (0.32)
		cls_loss 0.01 (0.17)	reg_loss 0.01 (0.15)
Epoch: [030][00040/00100]	Time 0.24 (0.25)	Loss 0.06 (0.25)
		cls_loss 0.04 (0.13)	reg_loss 0.02 (0.12)
Epoch: [030][00050/00100]	Time 0.23 (0.25)	Loss 0.47 (0.30)
		cls_loss 0.24 (0.15)	reg_loss 0.23 (0.14)
Epoch: [030][00060/00100]	Time 0.23 (0.24)	Loss 0.10 (0.26)
		cls_loss 0.06 (0.14)	reg_loss 0.04 (0.12)
Epoch: [030][00070/00100]	Time 0.23 (0.24)	Loss 0.15 (0.25)
		cls_loss 0.07 (0.13)	reg_loss 0.08 (0.12)
Epoch: [030][00080/00100]	Time 0.24 (0.24)	Loss 0.08 (0.23)
		cls_loss 0.04 (0.12)	reg_loss 0.03 (0.11)
Epoch: [030][00090/00100]	Time 0.24 (0.24)	Loss 0.02 (0.20)
		cls_loss 0.01 (0.11)	reg_loss 0.01 (0.10)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00100]	Time 0.29 (0.29)	Loss 0.38 (0.38)
		cls_loss 0.20 (0.20)	reg_loss 0.18 (0.18)
Epoch: [031][00020/00100]	Time 0.24 (0.26)	Loss 0.38 (0.38)
		cls_loss 0.23 (0.22)	reg_loss 0.15 (0.17)
Epoch: [031][00030/00100]	Time 0.24 (0.26)	Loss 0.12 (0.30)
		cls_loss 0.07 (0.17)	reg_loss 0.05 (0.13)
Epoch: [031][00040/00100]	Time 0.24 (0.25)	Loss 0.10 (0.25)
		cls_loss 0.05 (0.14)	reg_loss 0.05 (0.11)
Epoch: [031][00050/00100]	Time 0.23 (0.25)	Loss 0.05 (0.21)
		cls_loss 0.02 (0.12)	reg_loss 0.03 (0.09)
Epoch: [031][00060/00100]	Time 0.24 (0.25)	Loss 0.27 (0.22)
		cls_loss 0.14 (0.12)	reg_loss 0.12 (0.10)
Epoch: [031][00070/00100]	Time 0.23 (0.24)	Loss 0.05 (0.19)
		cls_loss 0.03 (0.11)	reg_loss 0.03 (0.09)
Epoch: [031][00080/00100]	Time 0.23 (0.24)	Loss 1.24 (0.33)
		cls_loss 0.58 (0.17)	reg_loss 0.66 (0.16)
Epoch: [031][00090/00100]	Time 0.24 (0.24)	Loss 0.22 (0.31)
		cls_loss 0.13 (0.16)	reg_loss 0.09 (0.15)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00100]	Time 0.30 (0.30)	Loss 0.18 (0.18)
		cls_loss 0.08 (0.08)	reg_loss 0.10 (0.10)
Epoch: [032][00020/00100]	Time 0.23 (0.26)	Loss 0.17 (0.18)
		cls_loss 0.11 (0.09)	reg_loss 0.07 (0.08)
Epoch: [032][00030/00100]	Time 0.24 (0.26)	Loss 0.13 (0.16)
		cls_loss 0.08 (0.09)	reg_loss 0.05 (0.07)
Epoch: [032][00040/00100]	Time 0.23 (0.25)	Loss 0.34 (0.21)
		cls_loss 0.18 (0.11)	reg_loss 0.16 (0.09)
Epoch: [032][00050/00100]	Time 0.24 (0.25)	Loss 0.86 (0.34)
		cls_loss 0.42 (0.17)	reg_loss 0.44 (0.16)
Epoch: [032][00060/00100]	Time 0.24 (0.25)	Loss 0.08 (0.30)
		cls_loss 0.05 (0.15)	reg_loss 0.04 (0.14)
Epoch: [032][00070/00100]	Time 0.23 (0.24)	Loss 0.06 (0.26)
		cls_loss 0.03 (0.14)	reg_loss 0.03 (0.13)
Epoch: [032][00080/00100]	Time 0.24 (0.24)	Loss 0.14 (0.25)
		cls_loss 0.08 (0.13)	reg_loss 0.06 (0.12)
Epoch: [032][00090/00100]	Time 0.23 (0.24)	Loss 0.11 (0.23)
		cls_loss 0.06 (0.12)	reg_loss 0.05 (0.11)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00100]	Time 0.29 (0.29)	Loss 0.07 (0.07)
		cls_loss 0.04 (0.04)	reg_loss 0.03 (0.03)
Epoch: [033][00020/00100]	Time 0.24 (0.26)	Loss 0.04 (0.05)
		cls_loss 0.02 (0.03)	reg_loss 0.02 (0.02)
Epoch: [033][00030/00100]	Time 0.24 (0.26)	Loss 0.31 (0.14)
		cls_loss 0.17 (0.08)	reg_loss 0.14 (0.06)
Epoch: [033][00040/00100]	Time 0.23 (0.25)	Loss 0.03 (0.11)
		cls_loss 0.02 (0.06)	reg_loss 0.01 (0.05)
Epoch: [033][00050/00100]	Time 0.23 (0.25)	Loss 0.29 (0.15)
		cls_loss 0.16 (0.08)	reg_loss 0.14 (0.07)
Epoch: [033][00060/00100]	Time 0.23 (0.25)	Loss 0.31 (0.18)
		cls_loss 0.20 (0.10)	reg_loss 0.11 (0.07)
Epoch: [033][00070/00100]	Time 0.24 (0.24)	Loss 0.31 (0.20)
		cls_loss 0.17 (0.11)	reg_loss 0.14 (0.08)
Epoch: [033][00080/00100]	Time 0.24 (0.24)	Loss 0.42 (0.22)
		cls_loss 0.22 (0.13)	reg_loss 0.20 (0.10)
Epoch: [033][00090/00100]	Time 0.23 (0.24)	Loss 0.60 (0.27)
		cls_loss 0.33 (0.15)	reg_loss 0.27 (0.12)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00100]	Time 0.29 (0.29)	Loss 0.11 (0.11)
		cls_loss 0.07 (0.07)	reg_loss 0.04 (0.04)
Epoch: [034][00020/00100]	Time 0.24 (0.26)	Loss 0.06 (0.09)
		cls_loss 0.05 (0.06)	reg_loss 0.01 (0.03)
Epoch: [034][00030/00100]	Time 0.24 (0.26)	Loss 0.06 (0.08)
		cls_loss 0.04 (0.05)	reg_loss 0.02 (0.02)
Epoch: [034][00040/00100]	Time 0.24 (0.25)	Loss 0.03 (0.07)
		cls_loss 0.01 (0.04)	reg_loss 0.02 (0.02)
Epoch: [034][00050/00100]	Time 0.24 (0.25)	Loss 0.32 (0.12)
		cls_loss 0.17 (0.07)	reg_loss 0.15 (0.05)
Epoch: [034][00060/00100]	Time 0.24 (0.25)	Loss 0.30 (0.15)
		cls_loss 0.17 (0.09)	reg_loss 0.12 (0.06)
Epoch: [034][00070/00100]	Time 0.24 (0.25)	Loss 0.33 (0.17)
		cls_loss 0.17 (0.10)	reg_loss 0.16 (0.08)
Epoch: [034][00080/00100]	Time 0.23 (0.24)	Loss 0.06 (0.16)
		cls_loss 0.02 (0.09)	reg_loss 0.04 (0.07)
Epoch: [034][00090/00100]	Time 0.24 (0.24)	Loss 0.43 (0.19)
		cls_loss 0.23 (0.10)	reg_loss 0.20 (0.09)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.54 (0.54)
Test: [00020/00212]	Time 0.08 (0.31)
Test: [00030/00212]	Time 0.09 (0.24)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.07 (0.16)
Test: [00070/00212]	Time 0.08 (0.15)
Test: [00080/00212]	Time 0.08 (0.14)
Test: [00090/00212]	Time 0.09 (0.13)
Test: [00100/00212]	Time 0.09 (0.13)
Test: [00110/00212]	Time 0.10 (0.13)
Test: [00120/00212]	Time 0.08 (0.12)
Test: [00130/00212]	Time 0.10 (0.12)
Test: [00140/00212]	Time 0.08 (0.12)
Test: [00150/00212]	Time 0.09 (0.12)
Test: [00160/00212]	Time 0.11 (0.12)
Test: [00170/00212]	Time 0.11 (0.12)
Test: [00180/00212]	Time 0.08 (0.11)
Test: [00190/00212]	Time 0.10 (0.11)
Test: [00200/00212]	Time 0.08 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 81.46 (%) Recall@1x = 83.53 (%) Recall@5x = 96.71 (%) 
|tIoU = 0.40: mAP = 77.04 (%) Recall@1x = 80.02 (%) Recall@5x = 94.87 (%) 
|tIoU = 0.50: mAP = 70.26 (%) Recall@1x = 74.11 (%) Recall@5x = 92.55 (%) 
|tIoU = 0.60: mAP = 57.66 (%) Recall@1x = 64.17 (%) Recall@5x = 83.47 (%) 
|tIoU = 0.70: mAP = 43.32 (%) Recall@1x = 52.49 (%) Recall@5x = 70.39 (%) 
Average mAP: 65.95 (%)
All done! Total time: 65.46 sec
Looking for a split for p=1
Found split for p=1
Moving sampled images to a separate folder
Finished sampling
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
Using model EMA ...

Start training model LocPointTransformer ...

[Train]: Epoch 0 started
Epoch: [000][00010/00100]	Time 0.95 (0.95)	Loss 1.14 (1.14)
		cls_loss 0.66 (0.66)	reg_loss 0.48 (0.48)
Epoch: [000][00020/00100]	Time 0.24 (0.60)	Loss 0.79 (0.96)
		cls_loss 0.47 (0.57)	reg_loss 0.32 (0.40)
Epoch: [000][00030/00100]	Time 0.22 (0.47)	Loss 3.44 (1.79)
		cls_loss 2.46 (1.20)	reg_loss 0.98 (0.59)
Epoch: [000][00040/00100]	Time 0.23 (0.41)	Loss 1.39 (1.69)
		cls_loss 1.05 (1.16)	reg_loss 0.34 (0.53)
Epoch: [000][00050/00100]	Time 0.26 (0.38)	Loss 0.64 (1.48)
		cls_loss 0.47 (1.02)	reg_loss 0.18 (0.46)
Epoch: [000][00060/00100]	Time 0.23 (0.36)	Loss 0.69 (1.35)
		cls_loss 0.53 (0.94)	reg_loss 0.16 (0.41)
Epoch: [000][00070/00100]	Time 0.23 (0.34)	Loss 0.17 (1.18)
		cls_loss 0.12 (0.82)	reg_loss 0.05 (0.36)
Epoch: [000][00080/00100]	Time 0.22 (0.32)	Loss 1.02 (1.16)
		cls_loss 0.64 (0.80)	reg_loss 0.38 (0.36)
Epoch: [000][00090/00100]	Time 0.23 (0.31)	Loss 2.30 (1.29)
		cls_loss 1.43 (0.87)	reg_loss 0.87 (0.42)
[Train]: Epoch 0 finished with lr=0.00002004


[Train]: Epoch 1 started
Epoch: [001][00010/00100]	Time 0.27 (0.27)	Loss 2.49 (2.49)
		cls_loss 1.95 (1.95)	reg_loss 0.54 (0.54)
Epoch: [001][00020/00100]	Time 0.23 (0.25)	Loss 2.43 (2.46)
		cls_loss 1.50 (1.73)	reg_loss 0.93 (0.73)
Epoch: [001][00030/00100]	Time 0.23 (0.24)	Loss 0.64 (1.85)
		cls_loss 0.45 (1.30)	reg_loss 0.19 (0.55)
Epoch: [001][00040/00100]	Time 0.22 (0.24)	Loss 0.39 (1.49)
		cls_loss 0.29 (1.05)	reg_loss 0.10 (0.44)
Epoch: [001][00050/00100]	Time 0.22 (0.23)	Loss 0.54 (1.30)
		cls_loss 0.39 (0.92)	reg_loss 0.15 (0.38)
Epoch: [001][00060/00100]	Time 0.23 (0.23)	Loss 1.27 (1.29)
		cls_loss 0.78 (0.89)	reg_loss 0.48 (0.40)
Epoch: [001][00070/00100]	Time 0.23 (0.23)	Loss 0.64 (1.20)
		cls_loss 0.48 (0.84)	reg_loss 0.16 (0.36)
Epoch: [001][00080/00100]	Time 0.23 (0.23)	Loss 0.66 (1.13)
		cls_loss 0.43 (0.79)	reg_loss 0.23 (0.35)
Epoch: [001][00090/00100]	Time 0.23 (0.23)	Loss 0.32 (1.04)
		cls_loss 0.22 (0.72)	reg_loss 0.10 (0.32)
[Train]: Epoch 1 finished with lr=0.00004008


[Train]: Epoch 2 started
Epoch: [002][00010/00100]	Time 0.28 (0.28)	Loss 2.34 (2.34)
		cls_loss 1.65 (1.65)	reg_loss 0.69 (0.69)
Epoch: [002][00020/00100]	Time 0.23 (0.25)	Loss 0.99 (1.66)
		cls_loss 0.59 (1.12)	reg_loss 0.39 (0.54)
Epoch: [002][00030/00100]	Time 0.23 (0.24)	Loss 1.99 (1.77)
		cls_loss 1.34 (1.19)	reg_loss 0.66 (0.58)
Epoch: [002][00040/00100]	Time 0.23 (0.24)	Loss 1.65 (1.74)
		cls_loss 1.14 (1.18)	reg_loss 0.51 (0.56)
Epoch: [002][00050/00100]	Time 0.23 (0.24)	Loss 0.74 (1.54)
		cls_loss 0.54 (1.05)	reg_loss 0.21 (0.49)
Epoch: [002][00060/00100]	Time 0.24 (0.24)	Loss 0.86 (1.43)
		cls_loss 0.52 (0.96)	reg_loss 0.34 (0.47)
Epoch: [002][00070/00100]	Time 0.23 (0.24)	Loss 0.22 (1.26)
		cls_loss 0.16 (0.85)	reg_loss 0.06 (0.41)
Epoch: [002][00080/00100]	Time 0.23 (0.24)	Loss 1.22 (1.25)
		cls_loss 0.85 (0.85)	reg_loss 0.37 (0.40)
Epoch: [002][00090/00100]	Time 0.23 (0.24)	Loss 0.49 (1.17)
		cls_loss 0.32 (0.79)	reg_loss 0.17 (0.38)
[Train]: Epoch 2 finished with lr=0.00006012


[Train]: Epoch 3 started
Epoch: [003][00010/00100]	Time 0.28 (0.28)	Loss 0.99 (0.99)
		cls_loss 0.72 (0.72)	reg_loss 0.27 (0.27)
Epoch: [003][00020/00100]	Time 0.23 (0.26)	Loss 0.77 (0.88)
		cls_loss 0.51 (0.61)	reg_loss 0.26 (0.26)
Epoch: [003][00030/00100]	Time 0.23 (0.25)	Loss 0.91 (0.89)
		cls_loss 0.55 (0.59)	reg_loss 0.37 (0.30)
Epoch: [003][00040/00100]	Time 0.22 (0.24)	Loss 0.42 (0.77)
		cls_loss 0.27 (0.51)	reg_loss 0.15 (0.26)
Epoch: [003][00050/00100]	Time 0.23 (0.24)	Loss 0.19 (0.66)
		cls_loss 0.14 (0.44)	reg_loss 0.05 (0.22)
Epoch: [003][00060/00100]	Time 0.23 (0.24)	Loss 0.37 (0.61)
		cls_loss 0.23 (0.40)	reg_loss 0.13 (0.20)
Epoch: [003][00070/00100]	Time 0.24 (0.24)	Loss 1.50 (0.73)
		cls_loss 1.02 (0.49)	reg_loss 0.49 (0.25)
Epoch: [003][00080/00100]	Time 0.23 (0.24)	Loss 0.28 (0.68)
		cls_loss 0.19 (0.45)	reg_loss 0.09 (0.23)
Epoch: [003][00090/00100]	Time 0.23 (0.24)	Loss 1.49 (0.77)
		cls_loss 0.76 (0.49)	reg_loss 0.74 (0.28)
[Train]: Epoch 3 finished with lr=0.00008016


[Train]: Epoch 4 started
Epoch: [004][00010/00100]	Time 0.30 (0.30)	Loss 0.62 (0.62)
		cls_loss 0.37 (0.37)	reg_loss 0.26 (0.26)
Epoch: [004][00020/00100]	Time 0.24 (0.27)	Loss 0.55 (0.59)
		cls_loss 0.32 (0.35)	reg_loss 0.23 (0.24)
Epoch: [004][00030/00100]	Time 0.23 (0.25)	Loss 0.08 (0.42)
		cls_loss 0.05 (0.25)	reg_loss 0.03 (0.17)
Epoch: [004][00040/00100]	Time 0.23 (0.25)	Loss 0.84 (0.52)
		cls_loss 0.60 (0.34)	reg_loss 0.24 (0.19)
Epoch: [004][00050/00100]	Time 0.22 (0.24)	Loss 1.37 (0.69)
		cls_loss 0.88 (0.45)	reg_loss 0.49 (0.25)
Epoch: [004][00060/00100]	Time 0.23 (0.24)	Loss 0.55 (0.67)
		cls_loss 0.38 (0.43)	reg_loss 0.17 (0.23)
Epoch: [004][00070/00100]	Time 0.23 (0.24)	Loss 0.65 (0.67)
		cls_loss 0.38 (0.43)	reg_loss 0.26 (0.24)
Epoch: [004][00080/00100]	Time 0.23 (0.24)	Loss 1.18 (0.73)
		cls_loss 0.73 (0.47)	reg_loss 0.45 (0.27)
Epoch: [004][00090/00100]	Time 0.23 (0.24)	Loss 0.97 (0.76)
		cls_loss 0.65 (0.49)	reg_loss 0.32 (0.27)
[Train]: Epoch 4 finished with lr=0.00010000


[Train]: Epoch 5 started
Epoch: [005][00010/00100]	Time 0.29 (0.29)	Loss 0.95 (0.95)
		cls_loss 0.68 (0.68)	reg_loss 0.27 (0.27)
Epoch: [005][00020/00100]	Time 0.24 (0.26)	Loss 0.39 (0.67)
		cls_loss 0.24 (0.46)	reg_loss 0.15 (0.21)
Epoch: [005][00030/00100]	Time 0.22 (0.25)	Loss 1.33 (0.89)
		cls_loss 0.88 (0.60)	reg_loss 0.44 (0.29)
Epoch: [005][00040/00100]	Time 0.30 (0.26)	Loss 0.29 (0.74)
		cls_loss 0.19 (0.50)	reg_loss 0.10 (0.24)
Epoch: [005][00050/00100]	Time 0.23 (0.26)	Loss 1.51 (0.90)
		cls_loss 0.94 (0.59)	reg_loss 0.57 (0.31)
Epoch: [005][00060/00100]	Time 0.23 (0.25)	Loss 0.76 (0.87)
		cls_loss 0.49 (0.57)	reg_loss 0.27 (0.30)
Epoch: [005][00070/00100]	Time 0.23 (0.25)	Loss 1.27 (0.93)
		cls_loss 0.87 (0.61)	reg_loss 0.40 (0.32)
Epoch: [005][00080/00100]	Time 0.23 (0.25)	Loss 1.33 (0.98)
		cls_loss 0.66 (0.62)	reg_loss 0.67 (0.36)
Epoch: [005][00090/00100]	Time 0.23 (0.24)	Loss 0.20 (0.89)
		cls_loss 0.11 (0.56)	reg_loss 0.08 (0.33)
[Train]: Epoch 5 finished with lr=0.00009973


[Train]: Epoch 6 started
Epoch: [006][00010/00100]	Time 0.28 (0.28)	Loss 0.54 (0.54)
		cls_loss 0.33 (0.33)	reg_loss 0.21 (0.21)
Epoch: [006][00020/00100]	Time 0.23 (0.26)	Loss 0.23 (0.38)
		cls_loss 0.15 (0.24)	reg_loss 0.08 (0.15)
Epoch: [006][00030/00100]	Time 0.23 (0.25)	Loss 0.42 (0.40)
		cls_loss 0.25 (0.24)	reg_loss 0.17 (0.15)
Epoch: [006][00040/00100]	Time 0.23 (0.24)	Loss 0.56 (0.44)
		cls_loss 0.41 (0.28)	reg_loss 0.15 (0.15)
Epoch: [006][00050/00100]	Time 0.23 (0.24)	Loss 0.65 (0.48)
		cls_loss 0.47 (0.32)	reg_loss 0.18 (0.16)
Epoch: [006][00060/00100]	Time 0.23 (0.24)	Loss 0.46 (0.48)
		cls_loss 0.27 (0.31)	reg_loss 0.19 (0.17)
Epoch: [006][00070/00100]	Time 0.23 (0.24)	Loss 0.49 (0.48)
		cls_loss 0.36 (0.32)	reg_loss 0.14 (0.16)
Epoch: [006][00080/00100]	Time 0.23 (0.24)	Loss 0.45 (0.48)
		cls_loss 0.30 (0.32)	reg_loss 0.15 (0.16)
Epoch: [006][00090/00100]	Time 0.23 (0.24)	Loss 0.53 (0.48)
		cls_loss 0.31 (0.32)	reg_loss 0.22 (0.17)
[Train]: Epoch 6 finished with lr=0.00009891


[Train]: Epoch 7 started
Epoch: [007][00010/00100]	Time 0.30 (0.30)	Loss 0.96 (0.96)
		cls_loss 0.57 (0.57)	reg_loss 0.39 (0.39)
Epoch: [007][00020/00100]	Time 0.23 (0.26)	Loss 0.30 (0.63)
		cls_loss 0.18 (0.37)	reg_loss 0.12 (0.26)
Epoch: [007][00030/00100]	Time 0.23 (0.25)	Loss 1.13 (0.80)
		cls_loss 0.82 (0.52)	reg_loss 0.31 (0.27)
Epoch: [007][00040/00100]	Time 0.23 (0.25)	Loss 0.27 (0.67)
		cls_loss 0.16 (0.43)	reg_loss 0.11 (0.23)
Epoch: [007][00050/00100]	Time 0.23 (0.24)	Loss 0.51 (0.63)
		cls_loss 0.41 (0.43)	reg_loss 0.10 (0.21)
Epoch: [007][00060/00100]	Time 0.23 (0.24)	Loss 0.17 (0.56)
		cls_loss 0.10 (0.37)	reg_loss 0.08 (0.18)
Epoch: [007][00070/00100]	Time 0.23 (0.24)	Loss 0.65 (0.57)
		cls_loss 0.39 (0.38)	reg_loss 0.26 (0.20)
Epoch: [007][00080/00100]	Time 0.23 (0.24)	Loss 0.65 (0.58)
		cls_loss 0.36 (0.37)	reg_loss 0.29 (0.21)
Epoch: [007][00090/00100]	Time 0.23 (0.24)	Loss 0.13 (0.53)
		cls_loss 0.07 (0.34)	reg_loss 0.06 (0.19)
[Train]: Epoch 7 finished with lr=0.00009755


[Train]: Epoch 8 started
Epoch: [008][00010/00100]	Time 0.29 (0.29)	Loss 0.74 (0.74)
		cls_loss 0.35 (0.35)	reg_loss 0.39 (0.39)
Epoch: [008][00020/00100]	Time 0.23 (0.26)	Loss 0.26 (0.50)
		cls_loss 0.18 (0.27)	reg_loss 0.08 (0.24)
Epoch: [008][00030/00100]	Time 0.23 (0.25)	Loss 0.52 (0.51)
		cls_loss 0.30 (0.28)	reg_loss 0.22 (0.23)
Epoch: [008][00040/00100]	Time 0.23 (0.24)	Loss 0.75 (0.57)
		cls_loss 0.37 (0.30)	reg_loss 0.38 (0.27)
Epoch: [008][00050/00100]	Time 0.23 (0.24)	Loss 0.53 (0.56)
		cls_loss 0.30 (0.30)	reg_loss 0.23 (0.26)
Epoch: [008][00060/00100]	Time 0.23 (0.24)	Loss 0.25 (0.51)
		cls_loss 0.13 (0.27)	reg_loss 0.12 (0.24)
Epoch: [008][00070/00100]	Time 0.23 (0.24)	Loss 0.44 (0.50)
		cls_loss 0.37 (0.29)	reg_loss 0.08 (0.21)
Epoch: [008][00080/00100]	Time 0.23 (0.24)	Loss 1.05 (0.57)
		cls_loss 0.73 (0.34)	reg_loss 0.32 (0.23)
Epoch: [008][00090/00100]	Time 0.24 (0.24)	Loss 1.09 (0.63)
		cls_loss 0.73 (0.38)	reg_loss 0.37 (0.24)
[Train]: Epoch 8 finished with lr=0.00009568


[Train]: Epoch 9 started
Epoch: [009][00010/00100]	Time 0.29 (0.29)	Loss 0.40 (0.40)
		cls_loss 0.21 (0.21)	reg_loss 0.20 (0.20)
Epoch: [009][00020/00100]	Time 0.23 (0.26)	Loss 0.46 (0.43)
		cls_loss 0.30 (0.25)	reg_loss 0.16 (0.18)
Epoch: [009][00030/00100]	Time 0.23 (0.25)	Loss 0.52 (0.46)
		cls_loss 0.30 (0.27)	reg_loss 0.22 (0.19)
Epoch: [009][00040/00100]	Time 0.23 (0.25)	Loss 0.52 (0.48)
		cls_loss 0.35 (0.29)	reg_loss 0.18 (0.19)
Epoch: [009][00050/00100]	Time 0.23 (0.24)	Loss 1.52 (0.69)
		cls_loss 0.91 (0.41)	reg_loss 0.61 (0.27)
Epoch: [009][00060/00100]	Time 0.22 (0.24)	Loss 0.23 (0.61)
		cls_loss 0.14 (0.37)	reg_loss 0.09 (0.24)
Epoch: [009][00070/00100]	Time 0.23 (0.24)	Loss 1.01 (0.67)
		cls_loss 0.66 (0.41)	reg_loss 0.36 (0.26)
Epoch: [009][00080/00100]	Time 0.23 (0.24)	Loss 0.38 (0.63)
		cls_loss 0.28 (0.39)	reg_loss 0.10 (0.24)
Epoch: [009][00090/00100]	Time 0.23 (0.24)	Loss 0.71 (0.64)
		cls_loss 0.45 (0.40)	reg_loss 0.26 (0.24)
[Train]: Epoch 9 finished with lr=0.00009330


[Train]: Epoch 10 started
Epoch: [010][00010/00100]	Time 0.30 (0.30)	Loss 0.20 (0.20)
		cls_loss 0.11 (0.11)	reg_loss 0.08 (0.08)
Epoch: [010][00020/00100]	Time 0.23 (0.27)	Loss 0.27 (0.23)
		cls_loss 0.15 (0.13)	reg_loss 0.12 (0.10)
Epoch: [010][00030/00100]	Time 0.24 (0.26)	Loss 1.17 (0.55)
		cls_loss 0.85 (0.37)	reg_loss 0.32 (0.17)
Epoch: [010][00040/00100]	Time 0.23 (0.25)	Loss 0.44 (0.52)
		cls_loss 0.27 (0.35)	reg_loss 0.17 (0.17)
Epoch: [010][00050/00100]	Time 0.23 (0.25)	Loss 0.38 (0.49)
		cls_loss 0.26 (0.33)	reg_loss 0.12 (0.16)
Epoch: [010][00060/00100]	Time 0.23 (0.24)	Loss 2.57 (0.84)
		cls_loss 1.55 (0.53)	reg_loss 1.02 (0.30)
Epoch: [010][00070/00100]	Time 0.25 (0.24)	Loss 0.08 (0.73)
		cls_loss 0.05 (0.46)	reg_loss 0.03 (0.27)
Epoch: [010][00080/00100]	Time 0.23 (0.24)	Loss 0.29 (0.67)
		cls_loss 0.20 (0.43)	reg_loss 0.08 (0.24)
Epoch: [010][00090/00100]	Time 0.24 (0.24)	Loss 0.36 (0.64)
		cls_loss 0.21 (0.41)	reg_loss 0.15 (0.23)
[Train]: Epoch 10 finished with lr=0.00009045


[Train]: Epoch 11 started
Epoch: [011][00010/00100]	Time 0.28 (0.28)	Loss 0.53 (0.53)
		cls_loss 0.32 (0.32)	reg_loss 0.21 (0.21)
Epoch: [011][00020/00100]	Time 0.23 (0.26)	Loss 0.43 (0.48)
		cls_loss 0.28 (0.30)	reg_loss 0.14 (0.18)
Epoch: [011][00030/00100]	Time 0.23 (0.25)	Loss 1.08 (0.68)
		cls_loss 0.53 (0.38)	reg_loss 0.55 (0.30)
Epoch: [011][00040/00100]	Time 0.23 (0.24)	Loss 0.39 (0.61)
		cls_loss 0.24 (0.34)	reg_loss 0.15 (0.26)
Epoch: [011][00050/00100]	Time 0.23 (0.24)	Loss 0.97 (0.68)
		cls_loss 0.54 (0.38)	reg_loss 0.44 (0.30)
Epoch: [011][00060/00100]	Time 0.23 (0.24)	Loss 0.46 (0.64)
		cls_loss 0.31 (0.37)	reg_loss 0.16 (0.27)
Epoch: [011][00070/00100]	Time 0.23 (0.24)	Loss 0.23 (0.59)
		cls_loss 0.14 (0.34)	reg_loss 0.09 (0.25)
Epoch: [011][00080/00100]	Time 0.23 (0.24)	Loss 1.06 (0.64)
		cls_loss 0.55 (0.36)	reg_loss 0.51 (0.28)
Epoch: [011][00090/00100]	Time 0.23 (0.24)	Loss 0.52 (0.63)
		cls_loss 0.30 (0.36)	reg_loss 0.23 (0.28)
[Train]: Epoch 11 finished with lr=0.00008716


[Train]: Epoch 12 started
Epoch: [012][00010/00100]	Time 0.29 (0.29)	Loss 0.25 (0.25)
		cls_loss 0.14 (0.14)	reg_loss 0.11 (0.11)
Epoch: [012][00020/00100]	Time 0.23 (0.26)	Loss 0.73 (0.49)
		cls_loss 0.38 (0.26)	reg_loss 0.35 (0.23)
Epoch: [012][00030/00100]	Time 0.23 (0.25)	Loss 0.81 (0.59)
		cls_loss 0.44 (0.32)	reg_loss 0.37 (0.27)
Epoch: [012][00040/00100]	Time 0.22 (0.24)	Loss 0.10 (0.47)
		cls_loss 0.06 (0.26)	reg_loss 0.04 (0.21)
Epoch: [012][00050/00100]	Time 0.23 (0.24)	Loss 0.21 (0.42)
		cls_loss 0.11 (0.23)	reg_loss 0.11 (0.19)
Epoch: [012][00060/00100]	Time 0.24 (0.24)	Loss 0.75 (0.47)
		cls_loss 0.51 (0.27)	reg_loss 0.24 (0.20)
Epoch: [012][00070/00100]	Time 0.23 (0.24)	Loss 0.12 (0.42)
		cls_loss 0.08 (0.24)	reg_loss 0.05 (0.18)
Epoch: [012][00080/00100]	Time 0.23 (0.24)	Loss 0.72 (0.46)
		cls_loss 0.48 (0.27)	reg_loss 0.25 (0.19)
Epoch: [012][00090/00100]	Time 0.23 (0.24)	Loss 0.11 (0.42)
		cls_loss 0.06 (0.25)	reg_loss 0.05 (0.17)
[Train]: Epoch 12 finished with lr=0.00008346


[Train]: Epoch 13 started
Epoch: [013][00010/00100]	Time 0.29 (0.29)	Loss 0.45 (0.45)
		cls_loss 0.24 (0.24)	reg_loss 0.21 (0.21)
Epoch: [013][00020/00100]	Time 0.23 (0.26)	Loss 0.59 (0.52)
		cls_loss 0.39 (0.31)	reg_loss 0.20 (0.21)
Epoch: [013][00030/00100]	Time 0.24 (0.25)	Loss 1.56 (0.87)
		cls_loss 0.82 (0.48)	reg_loss 0.74 (0.38)
Epoch: [013][00040/00100]	Time 0.24 (0.25)	Loss 0.55 (0.79)
		cls_loss 0.28 (0.43)	reg_loss 0.27 (0.36)
Epoch: [013][00050/00100]	Time 0.23 (0.24)	Loss 0.17 (0.66)
		cls_loss 0.09 (0.36)	reg_loss 0.08 (0.30)
Epoch: [013][00060/00100]	Time 0.23 (0.24)	Loss 0.20 (0.59)
		cls_loss 0.15 (0.33)	reg_loss 0.05 (0.26)
Epoch: [013][00070/00100]	Time 0.23 (0.24)	Loss 0.16 (0.53)
		cls_loss 0.10 (0.29)	reg_loss 0.06 (0.23)
Epoch: [013][00080/00100]	Time 0.23 (0.24)	Loss 0.06 (0.47)
		cls_loss 0.03 (0.26)	reg_loss 0.03 (0.21)
Epoch: [013][00090/00100]	Time 0.24 (0.24)	Loss 0.36 (0.46)
		cls_loss 0.24 (0.26)	reg_loss 0.12 (0.20)
[Train]: Epoch 13 finished with lr=0.00007939


[Train]: Epoch 14 started
Epoch: [014][00010/00100]	Time 0.28 (0.28)	Loss 0.67 (0.67)
		cls_loss 0.40 (0.40)	reg_loss 0.27 (0.27)
Epoch: [014][00020/00100]	Time 0.23 (0.26)	Loss 0.35 (0.51)
		cls_loss 0.20 (0.30)	reg_loss 0.15 (0.21)
Epoch: [014][00030/00100]	Time 0.23 (0.25)	Loss 0.21 (0.41)
		cls_loss 0.13 (0.25)	reg_loss 0.08 (0.17)
Epoch: [014][00040/00100]	Time 0.23 (0.25)	Loss 0.84 (0.52)
		cls_loss 0.55 (0.32)	reg_loss 0.29 (0.20)
Epoch: [014][00050/00100]	Time 0.23 (0.24)	Loss 0.62 (0.54)
		cls_loss 0.33 (0.32)	reg_loss 0.29 (0.22)
Epoch: [014][00060/00100]	Time 0.22 (0.24)	Loss 0.66 (0.56)
		cls_loss 0.33 (0.32)	reg_loss 0.33 (0.24)
Epoch: [014][00070/00100]	Time 0.23 (0.24)	Loss 0.10 (0.49)
		cls_loss 0.05 (0.29)	reg_loss 0.05 (0.21)
Epoch: [014][00080/00100]	Time 0.23 (0.24)	Loss 0.26 (0.46)
		cls_loss 0.11 (0.26)	reg_loss 0.15 (0.20)
Epoch: [014][00090/00100]	Time 0.23 (0.24)	Loss 0.50 (0.47)
		cls_loss 0.25 (0.26)	reg_loss 0.25 (0.21)
[Train]: Epoch 14 finished with lr=0.00007500


[Train]: Epoch 15 started
Epoch: [015][00010/00100]	Time 0.28 (0.28)	Loss 0.14 (0.14)
		cls_loss 0.07 (0.07)	reg_loss 0.07 (0.07)
Epoch: [015][00020/00100]	Time 0.23 (0.25)	Loss 0.64 (0.39)
		cls_loss 0.33 (0.20)	reg_loss 0.31 (0.19)
Epoch: [015][00030/00100]	Time 0.23 (0.24)	Loss 0.91 (0.56)
		cls_loss 0.56 (0.32)	reg_loss 0.36 (0.25)
Epoch: [015][00040/00100]	Time 0.22 (0.24)	Loss 0.46 (0.54)
		cls_loss 0.26 (0.30)	reg_loss 0.20 (0.23)
Epoch: [015][00050/00100]	Time 0.22 (0.24)	Loss 0.85 (0.60)
		cls_loss 0.45 (0.33)	reg_loss 0.39 (0.27)
Epoch: [015][00060/00100]	Time 0.23 (0.24)	Loss 0.22 (0.54)
		cls_loss 0.13 (0.30)	reg_loss 0.09 (0.24)
Epoch: [015][00070/00100]	Time 0.24 (0.24)	Loss 0.41 (0.52)
		cls_loss 0.25 (0.29)	reg_loss 0.16 (0.23)
Epoch: [015][00080/00100]	Time 0.23 (0.24)	Loss 0.12 (0.47)
		cls_loss 0.08 (0.27)	reg_loss 0.03 (0.20)
Epoch: [015][00090/00100]	Time 0.23 (0.23)	Loss 0.74 (0.50)
		cls_loss 0.38 (0.28)	reg_loss 0.35 (0.22)
[Train]: Epoch 15 finished with lr=0.00007034


[Train]: Epoch 16 started
Epoch: [016][00010/00100]	Time 0.37 (0.37)	Loss 0.26 (0.26)
		cls_loss 0.15 (0.15)	reg_loss 0.10 (0.10)
Epoch: [016][00020/00100]	Time 0.23 (0.30)	Loss 0.25 (0.25)
		cls_loss 0.14 (0.15)	reg_loss 0.12 (0.11)
Epoch: [016][00030/00100]	Time 0.23 (0.27)	Loss 0.27 (0.26)
		cls_loss 0.13 (0.14)	reg_loss 0.13 (0.12)
Epoch: [016][00040/00100]	Time 0.23 (0.26)	Loss 0.09 (0.22)
		cls_loss 0.04 (0.12)	reg_loss 0.04 (0.10)
Epoch: [016][00050/00100]	Time 0.23 (0.26)	Loss 0.28 (0.23)
		cls_loss 0.16 (0.12)	reg_loss 0.12 (0.10)
Epoch: [016][00060/00100]	Time 0.23 (0.25)	Loss 0.60 (0.29)
		cls_loss 0.31 (0.16)	reg_loss 0.28 (0.13)
Epoch: [016][00070/00100]	Time 0.23 (0.25)	Loss 0.55 (0.33)
		cls_loss 0.37 (0.19)	reg_loss 0.18 (0.14)
Epoch: [016][00080/00100]	Time 0.23 (0.25)	Loss 0.17 (0.31)
		cls_loss 0.08 (0.17)	reg_loss 0.09 (0.13)
Epoch: [016][00090/00100]	Time 0.23 (0.24)	Loss 0.61 (0.34)
		cls_loss 0.41 (0.20)	reg_loss 0.20 (0.14)
[Train]: Epoch 16 finished with lr=0.00006545


[Train]: Epoch 17 started
Epoch: [017][00010/00100]	Time 0.30 (0.30)	Loss 0.38 (0.38)
		cls_loss 0.23 (0.23)	reg_loss 0.15 (0.15)
Epoch: [017][00020/00100]	Time 0.23 (0.26)	Loss 0.21 (0.29)
		cls_loss 0.11 (0.17)	reg_loss 0.10 (0.12)
Epoch: [017][00030/00100]	Time 0.23 (0.25)	Loss 0.17 (0.25)
		cls_loss 0.09 (0.14)	reg_loss 0.08 (0.11)
Epoch: [017][00040/00100]	Time 0.23 (0.25)	Loss 0.17 (0.23)
		cls_loss 0.09 (0.13)	reg_loss 0.08 (0.10)
Epoch: [017][00050/00100]	Time 0.23 (0.24)	Loss 1.28 (0.44)
		cls_loss 0.63 (0.23)	reg_loss 0.65 (0.21)
Epoch: [017][00060/00100]	Time 0.23 (0.24)	Loss 0.26 (0.41)
		cls_loss 0.13 (0.21)	reg_loss 0.12 (0.19)
Epoch: [017][00070/00100]	Time 0.23 (0.24)	Loss 0.44 (0.41)
		cls_loss 0.25 (0.22)	reg_loss 0.19 (0.19)
Epoch: [017][00080/00100]	Time 0.23 (0.24)	Loss 0.21 (0.39)
		cls_loss 0.12 (0.21)	reg_loss 0.08 (0.18)
Epoch: [017][00090/00100]	Time 0.23 (0.24)	Loss 0.41 (0.39)
		cls_loss 0.24 (0.21)	reg_loss 0.17 (0.18)
[Train]: Epoch 17 finished with lr=0.00006040


[Train]: Epoch 18 started
Epoch: [018][00010/00100]	Time 0.27 (0.27)	Loss 0.17 (0.17)
		cls_loss 0.09 (0.09)	reg_loss 0.08 (0.08)
Epoch: [018][00020/00100]	Time 0.23 (0.25)	Loss 0.93 (0.55)
		cls_loss 0.56 (0.33)	reg_loss 0.37 (0.22)
Epoch: [018][00030/00100]	Time 0.23 (0.24)	Loss 0.31 (0.47)
		cls_loss 0.17 (0.27)	reg_loss 0.14 (0.20)
Epoch: [018][00040/00100]	Time 0.23 (0.24)	Loss 0.07 (0.37)
		cls_loss 0.04 (0.22)	reg_loss 0.03 (0.15)
Epoch: [018][00050/00100]	Time 0.23 (0.24)	Loss 0.11 (0.32)
		cls_loss 0.05 (0.18)	reg_loss 0.06 (0.13)
Epoch: [018][00060/00100]	Time 0.23 (0.24)	Loss 0.14 (0.29)
		cls_loss 0.07 (0.16)	reg_loss 0.07 (0.12)
Epoch: [018][00070/00100]	Time 0.23 (0.23)	Loss 0.03 (0.25)
		cls_loss 0.01 (0.14)	reg_loss 0.01 (0.11)
Epoch: [018][00080/00100]	Time 0.23 (0.23)	Loss 0.31 (0.26)
		cls_loss 0.18 (0.15)	reg_loss 0.13 (0.11)
Epoch: [018][00090/00100]	Time 0.23 (0.23)	Loss 0.08 (0.24)
		cls_loss 0.05 (0.14)	reg_loss 0.03 (0.10)
[Train]: Epoch 18 finished with lr=0.00005523


[Train]: Epoch 19 started
Epoch: [019][00010/00100]	Time 0.28 (0.28)	Loss 0.32 (0.32)
		cls_loss 0.17 (0.17)	reg_loss 0.16 (0.16)
Epoch: [019][00020/00100]	Time 0.23 (0.26)	Loss 0.66 (0.49)
		cls_loss 0.32 (0.24)	reg_loss 0.34 (0.25)
Epoch: [019][00030/00100]	Time 0.23 (0.25)	Loss 1.01 (0.66)
		cls_loss 0.53 (0.34)	reg_loss 0.48 (0.32)
Epoch: [019][00040/00100]	Time 0.23 (0.24)	Loss 1.75 (0.93)
		cls_loss 0.82 (0.46)	reg_loss 0.93 (0.47)
Epoch: [019][00050/00100]	Time 0.23 (0.24)	Loss 0.32 (0.81)
		cls_loss 0.18 (0.40)	reg_loss 0.14 (0.41)
Epoch: [019][00060/00100]	Time 0.22 (0.24)	Loss 0.11 (0.69)
		cls_loss 0.07 (0.35)	reg_loss 0.04 (0.35)
Epoch: [019][00070/00100]	Time 0.22 (0.23)	Loss 0.42 (0.66)
		cls_loss 0.27 (0.34)	reg_loss 0.15 (0.32)
Epoch: [019][00080/00100]	Time 0.23 (0.23)	Loss 0.62 (0.65)
		cls_loss 0.34 (0.34)	reg_loss 0.28 (0.31)
Epoch: [019][00090/00100]	Time 0.23 (0.23)	Loss 0.11 (0.59)
		cls_loss 0.05 (0.31)	reg_loss 0.05 (0.28)
[Train]: Epoch 19 finished with lr=0.00005000


[Train]: Epoch 20 started
Epoch: [020][00010/00100]	Time 0.29 (0.29)	Loss 0.73 (0.73)
		cls_loss 0.47 (0.47)	reg_loss 0.26 (0.26)
Epoch: [020][00020/00100]	Time 0.23 (0.26)	Loss 0.06 (0.39)
		cls_loss 0.03 (0.25)	reg_loss 0.02 (0.14)
Epoch: [020][00030/00100]	Time 0.23 (0.25)	Loss 0.33 (0.37)
		cls_loss 0.19 (0.23)	reg_loss 0.14 (0.14)
Epoch: [020][00040/00100]	Time 0.22 (0.24)	Loss 0.08 (0.30)
		cls_loss 0.05 (0.19)	reg_loss 0.03 (0.11)
Epoch: [020][00050/00100]	Time 0.22 (0.24)	Loss 0.12 (0.26)
		cls_loss 0.08 (0.16)	reg_loss 0.04 (0.10)
Epoch: [020][00060/00100]	Time 0.23 (0.24)	Loss 0.25 (0.26)
		cls_loss 0.15 (0.16)	reg_loss 0.10 (0.10)
Epoch: [020][00070/00100]	Time 0.22 (0.23)	Loss 0.28 (0.26)
		cls_loss 0.15 (0.16)	reg_loss 0.13 (0.10)
Epoch: [020][00080/00100]	Time 0.22 (0.23)	Loss 0.22 (0.26)
		cls_loss 0.13 (0.16)	reg_loss 0.09 (0.10)
Epoch: [020][00090/00100]	Time 0.23 (0.23)	Loss 0.17 (0.25)
		cls_loss 0.11 (0.15)	reg_loss 0.07 (0.10)
[Train]: Epoch 20 finished with lr=0.00004478


[Train]: Epoch 21 started
Epoch: [021][00010/00100]	Time 0.40 (0.40)	Loss 0.53 (0.53)
		cls_loss 0.28 (0.28)	reg_loss 0.24 (0.24)
Epoch: [021][00020/00100]	Time 0.23 (0.32)	Loss 0.12 (0.32)
		cls_loss 0.06 (0.17)	reg_loss 0.06 (0.15)
Epoch: [021][00030/00100]	Time 0.23 (0.29)	Loss 0.06 (0.24)
		cls_loss 0.04 (0.13)	reg_loss 0.02 (0.11)
Epoch: [021][00040/00100]	Time 0.22 (0.27)	Loss 0.41 (0.28)
		cls_loss 0.21 (0.15)	reg_loss 0.20 (0.13)
Epoch: [021][00050/00100]	Time 0.23 (0.26)	Loss 0.96 (0.41)
		cls_loss 0.53 (0.22)	reg_loss 0.43 (0.19)
Epoch: [021][00060/00100]	Time 0.24 (0.26)	Loss 0.40 (0.41)
		cls_loss 0.21 (0.22)	reg_loss 0.18 (0.19)
Epoch: [021][00070/00100]	Time 0.23 (0.25)	Loss 0.23 (0.39)
		cls_loss 0.12 (0.21)	reg_loss 0.11 (0.18)
Epoch: [021][00080/00100]	Time 0.23 (0.25)	Loss 0.19 (0.36)
		cls_loss 0.09 (0.19)	reg_loss 0.09 (0.17)
Epoch: [021][00090/00100]	Time 0.23 (0.25)	Loss 0.16 (0.34)
		cls_loss 0.09 (0.18)	reg_loss 0.08 (0.16)
[Train]: Epoch 21 finished with lr=0.00003961


[Train]: Epoch 22 started
Epoch: [022][00010/00100]	Time 0.28 (0.28)	Loss 0.63 (0.63)
		cls_loss 0.38 (0.38)	reg_loss 0.25 (0.25)
Epoch: [022][00020/00100]	Time 0.22 (0.25)	Loss 0.09 (0.36)
		cls_loss 0.04 (0.21)	reg_loss 0.04 (0.15)
Epoch: [022][00030/00100]	Time 0.23 (0.24)	Loss 0.15 (0.29)
		cls_loss 0.08 (0.17)	reg_loss 0.07 (0.12)
Epoch: [022][00040/00100]	Time 0.23 (0.24)	Loss 0.06 (0.23)
		cls_loss 0.03 (0.14)	reg_loss 0.02 (0.10)
Epoch: [022][00050/00100]	Time 0.23 (0.24)	Loss 0.57 (0.30)
		cls_loss 0.32 (0.17)	reg_loss 0.25 (0.13)
Epoch: [022][00060/00100]	Time 0.23 (0.24)	Loss 0.49 (0.33)
		cls_loss 0.27 (0.19)	reg_loss 0.22 (0.14)
Epoch: [022][00070/00100]	Time 0.24 (0.24)	Loss 0.10 (0.30)
		cls_loss 0.06 (0.17)	reg_loss 0.04 (0.13)
Epoch: [022][00080/00100]	Time 0.23 (0.24)	Loss 0.25 (0.29)
		cls_loss 0.13 (0.17)	reg_loss 0.12 (0.13)
Epoch: [022][00090/00100]	Time 0.23 (0.24)	Loss 0.18 (0.28)
		cls_loss 0.09 (0.16)	reg_loss 0.09 (0.12)
[Train]: Epoch 22 finished with lr=0.00003456


[Train]: Epoch 23 started
Epoch: [023][00010/00100]	Time 0.28 (0.28)	Loss 0.08 (0.08)
		cls_loss 0.04 (0.04)	reg_loss 0.04 (0.04)
Epoch: [023][00020/00100]	Time 0.23 (0.26)	Loss 0.51 (0.29)
		cls_loss 0.23 (0.13)	reg_loss 0.27 (0.16)
Epoch: [023][00030/00100]	Time 0.24 (0.25)	Loss 0.44 (0.34)
		cls_loss 0.23 (0.17)	reg_loss 0.21 (0.17)
Epoch: [023][00040/00100]	Time 0.23 (0.25)	Loss 0.19 (0.30)
		cls_loss 0.10 (0.15)	reg_loss 0.09 (0.15)
Epoch: [023][00050/00100]	Time 0.23 (0.24)	Loss 0.17 (0.28)
		cls_loss 0.09 (0.14)	reg_loss 0.08 (0.14)
Epoch: [023][00060/00100]	Time 0.23 (0.24)	Loss 0.52 (0.32)
		cls_loss 0.25 (0.16)	reg_loss 0.27 (0.16)
Epoch: [023][00070/00100]	Time 0.23 (0.24)	Loss 0.22 (0.30)
		cls_loss 0.12 (0.15)	reg_loss 0.10 (0.15)
Epoch: [023][00080/00100]	Time 0.23 (0.24)	Loss 0.05 (0.27)
		cls_loss 0.03 (0.14)	reg_loss 0.02 (0.14)
Epoch: [023][00090/00100]	Time 0.23 (0.24)	Loss 0.66 (0.31)
		cls_loss 0.42 (0.17)	reg_loss 0.24 (0.15)
[Train]: Epoch 23 finished with lr=0.00002967


[Train]: Epoch 24 started
Epoch: [024][00010/00100]	Time 0.27 (0.27)	Loss 0.45 (0.45)
		cls_loss 0.24 (0.24)	reg_loss 0.20 (0.20)
Epoch: [024][00020/00100]	Time 0.23 (0.25)	Loss 0.10 (0.28)
		cls_loss 0.06 (0.15)	reg_loss 0.04 (0.12)
Epoch: [024][00030/00100]	Time 0.23 (0.24)	Loss 0.23 (0.26)
		cls_loss 0.11 (0.14)	reg_loss 0.12 (0.12)
Epoch: [024][00040/00100]	Time 0.23 (0.24)	Loss 0.09 (0.22)
		cls_loss 0.05 (0.11)	reg_loss 0.05 (0.10)
Epoch: [024][00050/00100]	Time 0.24 (0.24)	Loss 0.37 (0.25)
		cls_loss 0.22 (0.14)	reg_loss 0.15 (0.11)
Epoch: [024][00060/00100]	Time 0.23 (0.24)	Loss 0.23 (0.25)
		cls_loss 0.13 (0.14)	reg_loss 0.10 (0.11)
Epoch: [024][00070/00100]	Time 0.23 (0.24)	Loss 0.22 (0.24)
		cls_loss 0.11 (0.13)	reg_loss 0.11 (0.11)
Epoch: [024][00080/00100]	Time 0.23 (0.24)	Loss 0.91 (0.32)
		cls_loss 0.43 (0.17)	reg_loss 0.48 (0.16)
Epoch: [024][00090/00100]	Time 0.24 (0.24)	Loss 0.39 (0.33)
		cls_loss 0.21 (0.17)	reg_loss 0.18 (0.16)
[Train]: Epoch 24 finished with lr=0.00002501


[Train]: Epoch 25 started
Epoch: [025][00010/00100]	Time 0.29 (0.29)	Loss 0.03 (0.03)
		cls_loss 0.02 (0.02)	reg_loss 0.01 (0.01)
Epoch: [025][00020/00100]	Time 0.24 (0.26)	Loss 0.25 (0.14)
		cls_loss 0.13 (0.07)	reg_loss 0.12 (0.06)
Epoch: [025][00030/00100]	Time 0.23 (0.25)	Loss 0.58 (0.29)
		cls_loss 0.30 (0.15)	reg_loss 0.27 (0.13)
Epoch: [025][00040/00100]	Time 0.23 (0.25)	Loss 0.05 (0.23)
		cls_loss 0.02 (0.12)	reg_loss 0.03 (0.11)
Epoch: [025][00050/00100]	Time 0.24 (0.25)	Loss 0.62 (0.31)
		cls_loss 0.32 (0.16)	reg_loss 0.30 (0.15)
Epoch: [025][00060/00100]	Time 0.23 (0.24)	Loss 0.60 (0.36)
		cls_loss 0.31 (0.18)	reg_loss 0.30 (0.17)
Epoch: [025][00070/00100]	Time 0.23 (0.24)	Loss 0.08 (0.32)
		cls_loss 0.04 (0.16)	reg_loss 0.03 (0.15)
Epoch: [025][00080/00100]	Time 0.29 (0.25)	Loss 0.08 (0.29)
		cls_loss 0.05 (0.15)	reg_loss 0.03 (0.14)
Epoch: [025][00090/00100]	Time 0.23 (0.25)	Loss 0.06 (0.26)
		cls_loss 0.02 (0.13)	reg_loss 0.05 (0.13)
[Train]: Epoch 25 finished with lr=0.00002062


[Train]: Epoch 26 started
Epoch: [026][00010/00100]	Time 0.29 (0.29)	Loss 0.19 (0.19)
		cls_loss 0.11 (0.11)	reg_loss 0.08 (0.08)
Epoch: [026][00020/00100]	Time 0.24 (0.26)	Loss 0.07 (0.13)
		cls_loss 0.04 (0.07)	reg_loss 0.03 (0.06)
Epoch: [026][00030/00100]	Time 0.24 (0.26)	Loss 0.42 (0.23)
		cls_loss 0.21 (0.12)	reg_loss 0.21 (0.11)
Epoch: [026][00040/00100]	Time 0.24 (0.25)	Loss 0.38 (0.27)
		cls_loss 0.20 (0.14)	reg_loss 0.18 (0.13)
Epoch: [026][00050/00100]	Time 0.24 (0.25)	Loss 0.14 (0.24)
		cls_loss 0.06 (0.12)	reg_loss 0.08 (0.12)
Epoch: [026][00060/00100]	Time 0.24 (0.25)	Loss 0.24 (0.24)
		cls_loss 0.13 (0.13)	reg_loss 0.11 (0.11)
Epoch: [026][00070/00100]	Time 0.23 (0.24)	Loss 0.72 (0.31)
		cls_loss 0.39 (0.16)	reg_loss 0.33 (0.15)
Epoch: [026][00080/00100]	Time 0.23 (0.24)	Loss 0.03 (0.27)
		cls_loss 0.01 (0.14)	reg_loss 0.02 (0.13)
Epoch: [026][00090/00100]	Time 0.23 (0.24)	Loss 0.11 (0.26)
		cls_loss 0.06 (0.13)	reg_loss 0.06 (0.12)
[Train]: Epoch 26 finished with lr=0.00001655


[Train]: Epoch 27 started
Epoch: [027][00010/00100]	Time 0.28 (0.28)	Loss 0.33 (0.33)
		cls_loss 0.18 (0.18)	reg_loss 0.15 (0.15)
Epoch: [027][00020/00100]	Time 0.23 (0.25)	Loss 0.16 (0.24)
		cls_loss 0.08 (0.13)	reg_loss 0.08 (0.11)
Epoch: [027][00030/00100]	Time 0.24 (0.25)	Loss 0.56 (0.35)
		cls_loss 0.31 (0.19)	reg_loss 0.25 (0.16)
Epoch: [027][00040/00100]	Time 0.24 (0.25)	Loss 0.17 (0.31)
		cls_loss 0.09 (0.17)	reg_loss 0.08 (0.14)
Epoch: [027][00050/00100]	Time 0.23 (0.24)	Loss 0.03 (0.25)
		cls_loss 0.02 (0.14)	reg_loss 0.01 (0.11)
Epoch: [027][00060/00100]	Time 0.24 (0.24)	Loss 0.12 (0.23)
		cls_loss 0.06 (0.12)	reg_loss 0.06 (0.10)
Epoch: [027][00070/00100]	Time 0.23 (0.24)	Loss 0.21 (0.23)
		cls_loss 0.12 (0.12)	reg_loss 0.09 (0.10)
Epoch: [027][00080/00100]	Time 0.23 (0.24)	Loss 0.11 (0.21)
		cls_loss 0.07 (0.12)	reg_loss 0.05 (0.10)
Epoch: [027][00090/00100]	Time 0.24 (0.24)	Loss 0.85 (0.28)
		cls_loss 0.45 (0.15)	reg_loss 0.40 (0.13)
[Train]: Epoch 27 finished with lr=0.00001285


[Train]: Epoch 28 started
Epoch: [028][00010/00100]	Time 0.28 (0.28)	Loss 0.06 (0.06)
		cls_loss 0.03 (0.03)	reg_loss 0.03 (0.03)
Epoch: [028][00020/00100]	Time 0.24 (0.26)	Loss 0.33 (0.19)
		cls_loss 0.17 (0.10)	reg_loss 0.16 (0.09)
Epoch: [028][00030/00100]	Time 0.23 (0.25)	Loss 0.17 (0.18)
		cls_loss 0.10 (0.10)	reg_loss 0.07 (0.08)
Epoch: [028][00040/00100]	Time 0.23 (0.25)	Loss 0.34 (0.22)
		cls_loss 0.19 (0.12)	reg_loss 0.15 (0.10)
Epoch: [028][00050/00100]	Time 0.24 (0.24)	Loss 0.20 (0.22)
		cls_loss 0.14 (0.13)	reg_loss 0.05 (0.09)
Epoch: [028][00060/00100]	Time 0.23 (0.24)	Loss 0.02 (0.18)
		cls_loss 0.01 (0.11)	reg_loss 0.02 (0.08)
Epoch: [028][00070/00100]	Time 0.24 (0.24)	Loss 0.23 (0.19)
		cls_loss 0.13 (0.11)	reg_loss 0.10 (0.08)
Epoch: [028][00080/00100]	Time 0.23 (0.24)	Loss 0.05 (0.17)
		cls_loss 0.04 (0.10)	reg_loss 0.01 (0.07)
Epoch: [028][00090/00100]	Time 0.24 (0.24)	Loss 0.16 (0.17)
		cls_loss 0.09 (0.10)	reg_loss 0.06 (0.07)
[Train]: Epoch 28 finished with lr=0.00000956


[Train]: Epoch 29 started
Epoch: [029][00010/00100]	Time 0.30 (0.30)	Loss 0.36 (0.36)
		cls_loss 0.18 (0.18)	reg_loss 0.18 (0.18)
Epoch: [029][00020/00100]	Time 0.24 (0.27)	Loss 0.22 (0.29)
		cls_loss 0.10 (0.14)	reg_loss 0.11 (0.15)
Epoch: [029][00030/00100]	Time 0.23 (0.26)	Loss 0.13 (0.24)
		cls_loss 0.06 (0.11)	reg_loss 0.07 (0.12)
Epoch: [029][00040/00100]	Time 0.23 (0.25)	Loss 0.08 (0.20)
		cls_loss 0.05 (0.10)	reg_loss 0.03 (0.10)
Epoch: [029][00050/00100]	Time 0.24 (0.25)	Loss 0.64 (0.28)
		cls_loss 0.37 (0.15)	reg_loss 0.27 (0.13)
Epoch: [029][00060/00100]	Time 0.23 (0.25)	Loss 0.09 (0.25)
		cls_loss 0.05 (0.13)	reg_loss 0.04 (0.12)
Epoch: [029][00070/00100]	Time 0.23 (0.24)	Loss 0.61 (0.30)
		cls_loss 0.33 (0.16)	reg_loss 0.28 (0.14)
Epoch: [029][00080/00100]	Time 0.23 (0.24)	Loss 0.22 (0.29)
		cls_loss 0.12 (0.16)	reg_loss 0.10 (0.14)
Epoch: [029][00090/00100]	Time 0.24 (0.24)	Loss 0.60 (0.33)
		cls_loss 0.31 (0.17)	reg_loss 0.29 (0.15)
[Train]: Epoch 29 finished with lr=0.00000671


[Train]: Epoch 30 started
Epoch: [030][00010/00100]	Time 0.30 (0.30)	Loss 0.31 (0.31)
		cls_loss 0.16 (0.16)	reg_loss 0.15 (0.15)
Epoch: [030][00020/00100]	Time 0.23 (0.27)	Loss 0.12 (0.22)
		cls_loss 0.07 (0.12)	reg_loss 0.05 (0.10)
Epoch: [030][00030/00100]	Time 0.23 (0.26)	Loss 0.39 (0.27)
		cls_loss 0.19 (0.14)	reg_loss 0.20 (0.13)
Epoch: [030][00040/00100]	Time 0.23 (0.25)	Loss 0.14 (0.24)
		cls_loss 0.10 (0.13)	reg_loss 0.04 (0.11)
Epoch: [030][00050/00100]	Time 0.24 (0.25)	Loss 0.15 (0.22)
		cls_loss 0.09 (0.12)	reg_loss 0.06 (0.10)
Epoch: [030][00060/00100]	Time 0.24 (0.25)	Loss 0.05 (0.19)
		cls_loss 0.02 (0.11)	reg_loss 0.03 (0.09)
Epoch: [030][00070/00100]	Time 0.24 (0.24)	Loss 0.34 (0.22)
		cls_loss 0.18 (0.12)	reg_loss 0.16 (0.10)
Epoch: [030][00080/00100]	Time 0.23 (0.24)	Loss 0.43 (0.24)
		cls_loss 0.22 (0.13)	reg_loss 0.21 (0.11)
Epoch: [030][00090/00100]	Time 0.23 (0.24)	Loss 0.16 (0.23)
		cls_loss 0.10 (0.13)	reg_loss 0.06 (0.11)
[Train]: Epoch 30 finished with lr=0.00000433


[Train]: Epoch 31 started
Epoch: [031][00010/00100]	Time 0.36 (0.36)	Loss 0.22 (0.22)
		cls_loss 0.10 (0.10)	reg_loss 0.12 (0.12)
Epoch: [031][00020/00100]	Time 0.24 (0.30)	Loss 0.31 (0.26)
		cls_loss 0.17 (0.14)	reg_loss 0.13 (0.13)
Epoch: [031][00030/00100]	Time 0.23 (0.28)	Loss 0.02 (0.18)
		cls_loss 0.01 (0.09)	reg_loss 0.01 (0.09)
Epoch: [031][00040/00100]	Time 0.23 (0.26)	Loss 0.12 (0.16)
		cls_loss 0.07 (0.09)	reg_loss 0.05 (0.08)
Epoch: [031][00050/00100]	Time 0.24 (0.26)	Loss 0.11 (0.15)
		cls_loss 0.06 (0.08)	reg_loss 0.05 (0.07)
Epoch: [031][00060/00100]	Time 0.24 (0.26)	Loss 0.35 (0.19)
		cls_loss 0.16 (0.10)	reg_loss 0.19 (0.09)
Epoch: [031][00070/00100]	Time 0.24 (0.25)	Loss 0.08 (0.17)
		cls_loss 0.05 (0.09)	reg_loss 0.03 (0.08)
Epoch: [031][00080/00100]	Time 0.24 (0.25)	Loss 0.02 (0.15)
		cls_loss 0.01 (0.08)	reg_loss 0.01 (0.07)
Epoch: [031][00090/00100]	Time 0.23 (0.25)	Loss 0.08 (0.14)
		cls_loss 0.04 (0.08)	reg_loss 0.03 (0.07)
[Train]: Epoch 31 finished with lr=0.00000246


[Train]: Epoch 32 started
Epoch: [032][00010/00100]	Time 0.28 (0.28)	Loss 0.13 (0.13)
		cls_loss 0.08 (0.08)	reg_loss 0.05 (0.05)
Epoch: [032][00020/00100]	Time 0.24 (0.26)	Loss 0.50 (0.32)
		cls_loss 0.31 (0.20)	reg_loss 0.20 (0.12)
Epoch: [032][00030/00100]	Time 0.23 (0.25)	Loss 0.44 (0.36)
		cls_loss 0.23 (0.21)	reg_loss 0.21 (0.15)
Epoch: [032][00040/00100]	Time 0.24 (0.25)	Loss 0.54 (0.40)
		cls_loss 0.28 (0.23)	reg_loss 0.25 (0.18)
Epoch: [032][00050/00100]	Time 0.24 (0.25)	Loss 0.07 (0.34)
		cls_loss 0.03 (0.19)	reg_loss 0.04 (0.15)
Epoch: [032][00060/00100]	Time 0.23 (0.24)	Loss 0.18 (0.31)
		cls_loss 0.11 (0.17)	reg_loss 0.07 (0.14)
Epoch: [032][00070/00100]	Time 0.23 (0.24)	Loss 0.23 (0.30)
		cls_loss 0.10 (0.16)	reg_loss 0.12 (0.13)
Epoch: [032][00080/00100]	Time 0.24 (0.24)	Loss 0.14 (0.28)
		cls_loss 0.07 (0.15)	reg_loss 0.07 (0.13)
Epoch: [032][00090/00100]	Time 0.24 (0.24)	Loss 0.23 (0.27)
		cls_loss 0.18 (0.15)	reg_loss 0.06 (0.12)
[Train]: Epoch 32 finished with lr=0.00000110


[Train]: Epoch 33 started
Epoch: [033][00010/00100]	Time 0.29 (0.29)	Loss 0.29 (0.29)
		cls_loss 0.18 (0.18)	reg_loss 0.11 (0.11)
Epoch: [033][00020/00100]	Time 0.24 (0.27)	Loss 0.54 (0.42)
		cls_loss 0.30 (0.24)	reg_loss 0.24 (0.18)
Epoch: [033][00030/00100]	Time 0.23 (0.26)	Loss 0.16 (0.33)
		cls_loss 0.08 (0.19)	reg_loss 0.07 (0.14)
Epoch: [033][00040/00100]	Time 0.23 (0.25)	Loss 0.24 (0.31)
		cls_loss 0.12 (0.17)	reg_loss 0.12 (0.14)
Epoch: [033][00050/00100]	Time 0.23 (0.25)	Loss 0.09 (0.26)
		cls_loss 0.04 (0.15)	reg_loss 0.04 (0.12)
Epoch: [033][00060/00100]	Time 0.24 (0.25)	Loss 0.16 (0.25)
		cls_loss 0.08 (0.13)	reg_loss 0.08 (0.11)
Epoch: [033][00070/00100]	Time 0.29 (0.25)	Loss 0.06 (0.22)
		cls_loss 0.04 (0.12)	reg_loss 0.02 (0.10)
Epoch: [033][00080/00100]	Time 0.53 (0.29)	Loss 0.22 (0.22)
		cls_loss 0.11 (0.12)	reg_loss 0.11 (0.10)
Epoch: [033][00090/00100]	Time 0.23 (0.28)	Loss 0.43 (0.24)
		cls_loss 0.22 (0.13)	reg_loss 0.22 (0.11)
[Train]: Epoch 33 finished with lr=0.00000028


[Train]: Epoch 34 started
Epoch: [034][00010/00100]	Time 0.30 (0.30)	Loss 0.96 (0.96)
		cls_loss 0.42 (0.42)	reg_loss 0.54 (0.54)
Epoch: [034][00020/00100]	Time 0.24 (0.27)	Loss 0.06 (0.51)
		cls_loss 0.03 (0.23)	reg_loss 0.03 (0.29)
Epoch: [034][00030/00100]	Time 0.24 (0.26)	Loss 0.04 (0.35)
		cls_loss 0.02 (0.16)	reg_loss 0.02 (0.20)
Epoch: [034][00040/00100]	Time 0.23 (0.25)	Loss 0.13 (0.30)
		cls_loss 0.07 (0.14)	reg_loss 0.06 (0.16)
Epoch: [034][00050/00100]	Time 0.43 (0.29)	Loss 0.20 (0.28)
		cls_loss 0.12 (0.13)	reg_loss 0.08 (0.15)
Epoch: [034][00060/00100]	Time 0.32 (0.29)	Loss 0.49 (0.31)
		cls_loss 0.25 (0.15)	reg_loss 0.24 (0.16)
Epoch: [034][00070/00100]	Time 0.23 (0.28)	Loss 0.08 (0.28)
		cls_loss 0.04 (0.14)	reg_loss 0.04 (0.14)
Epoch: [034][00080/00100]	Time 0.23 (0.28)	Loss 0.62 (0.32)
		cls_loss 0.36 (0.16)	reg_loss 0.27 (0.16)
Epoch: [034][00090/00100]	Time 0.23 (0.27)	Loss 0.05 (0.29)
		cls_loss 0.01 (0.15)	reg_loss 0.03 (0.14)
[Train]: Epoch 34 finished with lr=0.00000001

All done!
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/jwarchocki/.conda/envs/action-former/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
{'dataset': {'crop_ratio': [0.9, 1.0],
             'default_fps': None,
             'downsample_rate': 1,
             'feat_folder': './data/thumos/i3d_features',
             'feat_stride': 4,
             'file_ext': '.npy',
             'file_prefix': None,
             'force_upsampling': False,
             'input_dim': 2048,
             'json_file': './data/thumos/annotations/thumos14.json',
             'max_seq_len': 2304,
             'num_classes': 20,
             'num_frames': 16,
             'trunc_thresh': 0.5},
 'dataset_name': 'thumos',
 'devices': ['cuda:0'],
 'init_rand_seed': 1234567891,
 'loader': {'batch_size': 2, 'num_workers': 4},
 'model': {'backbone_arch': (2, 2, 5),
           'backbone_type': 'convTransformer',
           'embd_dim': 512,
           'embd_kernel_size': 3,
           'embd_with_ln': True,
           'fpn_dim': 512,
           'fpn_start_level': 0,
           'fpn_type': 'identity',
           'fpn_with_ln': True,
           'head_dim': 512,
           'head_kernel_size': 3,
           'head_num_layers': 3,
           'head_with_ln': True,
           'input_dim': 2048,
           'max_buffer_len_factor': 6.0,
           'max_seq_len': 2304,
           'n_head': 4,
           'n_mha_win_size': 19,
           'num_classes': 20,
           'regression_range': [(0, 4),
                                (4, 8),
                                (8, 16),
                                (16, 32),
                                (32, 64),
                                (64, 10000)],
           'scale_factor': 2,
           'test_cfg': {'duration_thresh': 0.05,
                        'ext_score_file': None,
                        'iou_threshold': 0.1,
                        'max_seg_num': 200,
                        'min_score': 0.001,
                        'multiclass_nms': True,
                        'nms_method': 'soft',
                        'nms_sigma': 0.5,
                        'pre_nms_thresh': 0.001,
                        'pre_nms_topk': 2000,
                        'voting_thresh': 0.7},
           'train_cfg': {'center_sample': 'radius',
                         'center_sample_radius': 1.5,
                         'clip_grad_l2norm': 1.0,
                         'cls_prior_prob': 0.01,
                         'dropout': 0.0,
                         'droppath': 0.1,
                         'head_empty_cls': [],
                         'init_loss_norm': 100,
                         'label_smoothing': 0.0,
                         'loss_weight': 1.0},
           'use_abs_pe': False,
           'use_rel_pe': False},
 'model_name': 'LocPointTransformer',
 'opt': {'epochs': 30,
         'learning_rate': 0.0001,
         'momentum': 0.9,
         'schedule_gamma': 0.1,
         'schedule_steps': [],
         'schedule_type': 'cosine',
         'type': 'AdamW',
         'warmup': True,
         'warmup_epochs': 5,
         'weight_decay': 0.05},
 'output_folder': './ckpt/',
 'test_cfg': {'duration_thresh': 0.05,
              'ext_score_file': None,
              'iou_threshold': 0.1,
              'max_seg_num': 200,
              'min_score': 0.001,
              'multiclass_nms': True,
              'nms_method': 'soft',
              'nms_sigma': 0.5,
              'pre_nms_thresh': 0.001,
              'pre_nms_topk': 2000,
              'voting_thresh': 0.7},
 'train_cfg': {'center_sample': 'radius',
               'center_sample_radius': 1.5,
               'clip_grad_l2norm': 1.0,
               'cls_prior_prob': 0.01,
               'dropout': 0.0,
               'droppath': 0.1,
               'head_empty_cls': [],
               'init_loss_norm': 100,
               'label_smoothing': 0.0,
               'loss_weight': 1.0},
 'train_split': ['validation'],
 'val_split': ['test']}
=> loading checkpoint './ckpt/thumos_i3d_reproduce/epoch_035.pth.tar'
Loading from EMA model ...

Start testing model LocPointTransformer ...
Test: [00010/00212]	Time 0.53 (0.53)
Test: [00020/00212]	Time 0.08 (0.31)
Test: [00030/00212]	Time 0.08 (0.23)
Test: [00040/00212]	Time 0.09 (0.20)
Test: [00050/00212]	Time 0.09 (0.18)
Test: [00060/00212]	Time 0.08 (0.16)
Test: [00070/00212]	Time 0.08 (0.15)
Test: [00080/00212]	Time 0.09 (0.14)
Test: [00090/00212]	Time 0.08 (0.13)
Test: [00100/00212]	Time 0.10 (0.13)
Test: [00110/00212]	Time 0.10 (0.13)
Test: [00120/00212]	Time 0.08 (0.12)
Test: [00130/00212]	Time 0.09 (0.12)
Test: [00140/00212]	Time 0.08 (0.12)
Test: [00150/00212]	Time 0.08 (0.11)
Test: [00160/00212]	Time 0.11 (0.11)
Test: [00170/00212]	Time 0.11 (0.11)
Test: [00180/00212]	Time 0.09 (0.11)
Test: [00190/00212]	Time 0.09 (0.11)
Test: [00200/00212]	Time 0.08 (0.11)
Test: [00210/00212]	Time 0.07 (0.11)
[RESULTS] Action detection results on thumos14.

|tIoU = 0.30: mAP = 81.47 (%) Recall@1x = 84.26 (%) Recall@5x = 96.74 (%) 
|tIoU = 0.40: mAP = 77.14 (%) Recall@1x = 80.22 (%) Recall@5x = 94.85 (%) 
|tIoU = 0.50: mAP = 70.21 (%) Recall@1x = 74.64 (%) Recall@5x = 91.97 (%) 
|tIoU = 0.60: mAP = 58.66 (%) Recall@1x = 64.79 (%) Recall@5x = 84.41 (%) 
|tIoU = 0.70: mAP = 43.15 (%) Recall@1x = 52.80 (%) Recall@5x = 71.07 (%) 
Average mAP: 66.13 (%)
All done! Total time: 75.01 sec
